{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran012x/Transfer-Models/blob/main/HILSHA_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Co-Lab -->> Drive"
      ],
      "metadata": {
        "id": "WrRU5QMl0UZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "# # Upload a file\n",
        "# uploaded = files.upload()\n",
        "# # Get the file name\n",
        "# file_name = list(uploaded.keys())[0]\n",
        "# print(f\"Uploaded file: {file_name}\")\n",
        "\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# # with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_224_11k.zip', 'r') as zip_ref:\n",
        "# #     zip_ref.extractall('')\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')"
      ],
      "metadata": {
        "id": "uaVTAQGY0a4A",
        "outputId": "1112d1bc-f727-499e-df80-22aae2660adb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocess and Save"
      ],
      "metadata": {
        "id": "bIrUcpjq0P9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import gc\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import threading\n",
        "import zipfile\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "# Define fish classes and dataset paths\n",
        "fish_classes = ['ilish', 'chandana', 'sardin', 'sardinella', 'punctatus'] #0,1,2,3,4\n",
        "zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip').extractall('/content/.hidden_fish')\n",
        "data_dir = '/content/.hidden_fish'\n",
        "\n",
        "image_limits = {\n",
        "    'ilish': 3000,\n",
        "    'chandana': 1185,\n",
        "    'sardin': 2899,\n",
        "    'sardinella': 370,\n",
        "    'punctatus': 953\n",
        "}\n",
        "\n",
        "# Settings\n",
        "total_images = sum(image_limits.values())\n",
        "batch_size = 100\n",
        "num_threads = 4\n",
        "\n",
        "\n",
        "# Output paths\n",
        "output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "xdata_file = os.path.join(output_dir, 'X_data.npy')\n",
        "\n",
        "save_lock = threading.Lock()  # for thread-safe writes -> Prevents race conditions when multiple threads write to the same list.\n",
        "\n",
        "# Function to gather image paths\n",
        "def get_image_paths(class_name, max_images):\n",
        "    path = os.path.join(data_dir, class_name)\n",
        "    files = sorted(os.listdir(path))\n",
        "    random.shuffle(files)\n",
        "    return [os.path.join(path, f) for f in files[:max_images]]\n",
        "\n",
        "# Load and preprocess batch\n",
        "def load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "    end_idx = min(start_idx + batch_size, len(image_paths))\n",
        "    batch_paths = image_paths[start_idx:end_idx]\n",
        "    batch_images = []\n",
        "\n",
        "    for img_path in batch_paths:\n",
        "        img = Image.open(img_path).resize((224, 224)).convert('RGB')\n",
        "        img_tensor = torch.tensor(np.array(img), dtype=torch.uint8).permute(2, 0, 1)  # C x H x W\n",
        "        batch_images.append(img_tensor)\n",
        "\n",
        "    batch_tensor = torch.stack(batch_images)  # B x C x H x W\n",
        "    batch_labels = np.full((len(batch_images),), class_idx, dtype=np.int32)\n",
        "    return batch_tensor, batch_labels\n",
        "\n",
        "# Process one batch and return tensors & labels (no file saving)\n",
        "def process_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "    return load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx)\n",
        "\n",
        "def preprocess_and_save_all(overwrite=True):\n",
        "    if os.path.exists(labels_file) and os.path.exists(xdata_file) and not overwrite:\n",
        "        print(\"Preprocessed data already exists. Set overwrite=True to reprocess.\")\n",
        "        return\n",
        "\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "    processed_count = 0\n",
        "\n",
        "    for idx, class_name in enumerate(fish_classes):\n",
        "        print(f\"\\nProcessing class: {class_name}\")\n",
        "        image_paths = get_image_paths(class_name, image_limits[class_name])\n",
        "        total_batches = (len(image_paths) + batch_size - 1) // batch_size\n",
        "        #It ensures ceiling division ‚Äî rounding up, not down.\n",
        "        # Normal division: 103 / 20 = 5.15 ‚Üí floor division // 20 = 5 (‚ùå missing last 3 images)\n",
        "        # This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ‚úÖ\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "            futures = []\n",
        "            for start in range(0, len(image_paths), batch_size):\n",
        "                futures.append(executor.submit(process_batch, image_paths, start, batch_size, idx))\n",
        "\n",
        "            for future in tqdm(as_completed(futures), total=total_batches, desc=class_name):#taqaddum (ÿ™ŸÇÿØŸëŸÖ) ‚Äì Arabic for \"progress\".\n",
        "                # futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\n",
        "                # as_completed(futures): Yields each future as it finishes (not in order).\n",
        "\n",
        "                batch_tensor, batch_labels = future.result()\n",
        "                with save_lock: #Locks this section so that only one thread can update the shared lists safely.\n",
        "                    all_images.append(batch_tensor)\n",
        "                    all_labels.append(batch_labels)\n",
        "                    processed_count += batch_tensor.size(0)\n",
        "                    print(f\"Processed batch with {batch_tensor.size(0)} images, total processed: {processed_count}/{total_images}\")\n",
        "                gc.collect()\n",
        "\n",
        "    # Combine all tensors and labels\n",
        "    X = torch.cat(all_images, dim=0).numpy()\n",
        "    Y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "    # Save final arrays\n",
        "    np.save(xdata_file, X, allow_pickle=False)#Malicious .npy -> import os;os.system(\"rm -rf /\")  # ‚Üê Dangerous command\n",
        "    np.save(labels_file, Y, allow_pickle=False)\n",
        "\n",
        "    print(f\"\\n‚úÖ Done! Saved {processed_count} images in {xdata_file}\")\n",
        "    print(f\"X_data shape: {X.shape}, Y_labels shape: {Y.shape}\")\n",
        "\n",
        "    if processed_count != total_images:\n",
        "        raise ValueError(f\"Expected {total_images} images, but processed {processed_count}\")\n",
        "\n",
        "# Run preprocessing and save directly to X_data.npy and Y_labels.npy\n",
        "preprocess_and_save_all(overwrite=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "k9WJIX0qbYSw",
        "outputId": "5fb9c08c-0971-4a51-c0bb-da7b9d510238"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n",
            "GPU Name: NVIDIA L4\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-580223829.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Define fish classes and dataset paths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mfish_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'ilish'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chandana'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sardin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'sardinella'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'punctatus'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#0,1,2,3,4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/.hidden_fish'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/.hidden_fish'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36mextractall\u001b[0;34m(self, path, members, pwd)\u001b[0m\n\u001b[1;32m   1700\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1701\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mzipinfo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmembers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1702\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extract_member\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzipinfo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m_extract_member\u001b[0;34m(self, member, targetpath, pwd)\u001b[0m\n\u001b[1;32m   1753\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtargetpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1755\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmember\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpwd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpwd\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1756\u001b[0m              \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargetpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1757\u001b[0m             \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, name, mode, pwd, force_zip64)\u001b[0m\n\u001b[1;32m   1578\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m             \u001b[0;31m# Skip the file header:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1580\u001b[0;31m             \u001b[0mfheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzef_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizeFileHeader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1581\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfheader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0msizeFileHeader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1582\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Truncated file header\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    784\u001b[0m                         \"Close the writing handle before trying to read.\")\n\u001b[1;32m    785\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 786\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    787\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DATA LOADING...."
      ],
      "metadata": {
        "id": "qz9kAvggeF0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Your data path\n",
        "output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "data_file = os.path.join(output_dir, 'X_data.npy')\n",
        "labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "\n",
        "# Readable size format\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    for unit in ['', 'K', 'M', 'G', 'T']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return f\"{num:3.2f} {unit}{suffix}\"\n",
        "        num /= 1024.0\n",
        "    return f\"{num:.2f} T{suffix}\"\n",
        "\n",
        "# Main loader\n",
        "def load_preprocessed_data(as_torch=True, normalize=True, to_device=None):\n",
        "    # Check file existence #cpu,cuda (CUDA stands for Compute Unified Device Architecture.)\n",
        "    for path in [data_file, labels_file]:\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Missing: {path}\")\n",
        "\n",
        "    # Print file sizes\n",
        "    print(f\"üìÅ X_data.npy: {sizeof_fmt(os.path.getsize(data_file))}\")\n",
        "    print(f\"üìÅ Y_labels.npy: {sizeof_fmt(os.path.getsize(labels_file))}\")\n",
        "\n",
        "    # Load with mmap\n",
        "    X = np.load(data_file, mmap_mode='r')\n",
        "    Y = np.load(labels_file, mmap_mode='r')\n",
        "\n",
        "    print(f\"‚úÖ X shape: {X.shape}, dtype: {X.dtype}\")\n",
        "    print(f\"‚úÖ Y shape: {Y.shape}, dtype: {Y.dtype}\")\n",
        "\n",
        "    # Sanity check\n",
        "    if len(X) != len(Y):\n",
        "        raise ValueError(\"Mismatch between number of samples in X and Y\")\n",
        "\n",
        "    # Convert to torch\n",
        "    if as_torch:\n",
        "        X = torch.from_numpy(X)\n",
        "        Y = torch.from_numpy(Y)\n",
        "\n",
        "        if normalize and X.dtype == torch.uint8:\n",
        "            X = X.float() / 255.0\n",
        "\n",
        "        if to_device:\n",
        "            X = X.to(to_device)\n",
        "            Y = Y.to(to_device)\n",
        "\n",
        "        print(f\"üß† Torch tensors ready on {to_device or 'CPU'}\")\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# üîÅ Example call\n",
        "X, Y = load_preprocessed_data(\n",
        "    as_torch=True,\n",
        "    normalize=True,\n",
        "    to_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlSz9YmOB1iW",
        "outputId": "35da9ede-b301-437e-e61f-1394378ea604"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ X_data.npy: 1.18 GB\n",
            "üìÅ Y_labels.npy: 32.96 KB\n",
            "‚úÖ X shape: (8407, 3, 224, 224), dtype: uint8\n",
            "‚úÖ Y shape: (8407,), dtype: int32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614331559.py:42: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  X = torch.from_numpy(X)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Torch tensors ready on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Enhanced Fish Species Classification with Multiple Ensemble Methods\n",
        "================================================================\n",
        "Author: Enhanced Fish Classification System\n",
        "Version: 3.1 - Advanced Ensemble with Parallel HPO, New Models, and LRP\n",
        "Features: Progressive ensemble evaluation, multiple ensemble techniques, parallel processing, real-world prediction, XAI with LRP\n",
        "\"\"\"\n",
        "\n",
        "!pip install optuna tensorflow joblib graphviz scikit-plot captum cma torch_optimizer lime opencv-python\n",
        "\n",
        "# -------------------------\n",
        "# Enhanced Imports & Setup\n",
        "# -------------------------\n",
        "import os, sys, subprocess, warnings, json, random, gc, time\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Union\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from concurrent.futures import ThreadPoolExecutor, ProcessPoolExecutor, as_completed\n",
        "from joblib import Parallel, delayed\n",
        "import threading\n",
        "from multiprocessing import cpu_count\n",
        "from itertools import combinations\n",
        "from PIL import Image\n",
        "import psutil\n",
        "import cv2\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use(\"default\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.models as models\n",
        "from captum.attr import LayerGradCam, GuidedBackprop, Saliency\n",
        "\n",
        "# TensorFlow for Keras model saving\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, f1_score,\n",
        "                             accuracy_score, precision_recall_fscore_support, roc_curve, auc,\n",
        "                             precision_recall_curve, average_precision_score, roc_auc_score)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.decomposition import PCA\n",
        "from scipy.stats import ttest_rel, wilcoxon\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import optuna\n",
        "import cma\n",
        "import graphviz\n",
        "from graphviz import Digraph\n",
        "from torch_optimizer import Yogi\n",
        "\n",
        "\n",
        "# -------------------------\n",
        "# Enhanced Configuration\n",
        "# -------------------------\n",
        "class Config:\n",
        "    DATA_FILE   = '/content/drive/MyDrive/Hilsha/X_data.npy'\n",
        "    LABELS_FILE = '/content/drive/MyDrive/Hilsha/Y_labels.npy'\n",
        "    OUTPUT_DIR  = '/content/outputs'\n",
        "    MODELS_DIR  = '/content/outputs/models'\n",
        "    ENSEMBLE_DIR = '/content/outputs/ensemble'\n",
        "    VISUAL_DIR = '/content/outputs/visualizations'\n",
        "\n",
        "    INPUT_SIZE   = 224\n",
        "    NUM_CLASSES  = 5\n",
        "    CLASS_LABELS = ['Ilish', 'Chandana', 'Sardin', 'Sardinella', 'Punctatus']\n",
        "\n",
        "    BATCH_SIZE  = 64\n",
        "    MAX_EPOCHS  = 40\n",
        "    PATIENCE    = 7\n",
        "    SEED        = 42\n",
        "    DEVICE      = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    NUM_WORKERS = min(8, cpu_count())\n",
        "    PARALLEL_MODELS = 2\n",
        "    USE_MIXED_PRECISION = True\n",
        "    GRAD_ACCUM_STEPS = 2\n",
        "\n",
        "    N_TRIALS    = 12\n",
        "    TIMEOUT_S   = 25*60\n",
        "    PRUNE_PATIENCE = 3\n",
        "\n",
        "    K_FOLDS     = 5\n",
        "    TEST_SIZE   = 0.2\n",
        "\n",
        "    HP_SPACE = {\n",
        "        'learning_rate': [1e-6, 5e-6, 1e-5, 5e-5, 1e-4, 5e-4],\n",
        "        'weight_decay': [1e-5, 5e-5, 1e-4, 5e-4, 1e-3, 5e-3],\n",
        "        'dropout_rate': [0.3, 0.4, 0.5, 0.6, 0.7],\n",
        "        'optimizer': ['adamw', 'lion'],\n",
        "        'scheduler': ['plateau', 'cosine', 'onecycle'],\n",
        "        'augmentation_strength': ['light', 'medium', 'heavy'],\n",
        "        'batch_size': [16, 32, 48, 64]\n",
        "    }\n",
        "\n",
        "    ENSEMBLE_BACKBONES_5 = ['resnet50', 'efficientnet_b0', 'mobilenet_v3_large', 'resnext50_32x4d', 'swin_t']\n",
        "    ENSEMBLE_BACKBONES_10 = ['resnet50', 'efficientnet_b0', 'mobilenet_v3_large', 'vgg16', 'densenet121',\n",
        "                             'resnext50_32x4d', 'swin_t', 'convnext_tiny', 'efficientnet_v2_s', 'vit_b_16']\n",
        "    ENSEMBLE_BACKBONES_ALL = ['resnet50', 'efficientnet_b0', 'mobilenet_v3_large', 'vgg16', 'densenet121',\n",
        "                              'resnext50_32x4d', 'swin_t', 'convnext_tiny', 'efficientnet_v2_s', 'vit_b_16',\n",
        "                              'maxvit_t']\n",
        "    ENSEMBLE_METHODS = [\n",
        "        'simple_average',\n",
        "        'weighted_average',\n",
        "        'learnable_weighted',\n",
        "        'confidence_based',\n",
        "        'meta_model',\n",
        "        'snapshot_ensemble',\n",
        "        'bayesian_ensemble'\n",
        "    ]\n",
        "\n",
        "def setup_environment():\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "    random.seed(Config.SEED)\n",
        "\n",
        "    Path(Config.OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "    Path(Config.MODELS_DIR).mkdir(parents=True, exist_ok=True)\n",
        "    Path(Config.ENSEMBLE_DIR).mkdir(parents=True, exist_ok=True)\n",
        "    Path(Config.VISUAL_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        if Config.USE_MIXED_PRECISION:\n",
        "            print(\"üöÄ Using mixed precision training for faster training\")\n",
        "        print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"üöÄ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "        print(f\"üöÄ System Memory: {psutil.virtual_memory().total / 1024**3:.1f} GB\")\n",
        "    else:\n",
        "        print(\"üíª Using CPU\")\n",
        "\n",
        "    print(f\"üîß Parallel workers: {Config.NUM_WORKERS}\")\n",
        "    print(f\"üîß Parallel models for HPO: {Config.PARALLEL_MODELS}\")\n",
        "\n",
        "setup_environment()\n",
        "\n",
        "# -------------------------\n",
        "# Ensure Captum Function\n",
        "# -------------------------\n",
        "def ensure_captum():\n",
        "    try:\n",
        "        import captum\n",
        "        return True\n",
        "    except ImportError:\n",
        "        print(\"‚ö†Ô∏è Captum not installed\")\n",
        "        return False\n",
        "\n",
        "# ==============================================================\n",
        "# PART 1 ‚Äî Enhanced Data Loading with Parallel Processing\n",
        "# ==============================================================\n",
        "\n",
        "class FishDataset(Dataset):\n",
        "    def __init__(self, images: np.ndarray, labels: np.ndarray, transform=None):\n",
        "        self.images = self._preprocess_images(images)\n",
        "        self.labels = labels.astype(np.int64)\n",
        "        self.transform = transform\n",
        "\n",
        "    def _preprocess_images(self, images):\n",
        "        if images.max() > 1.5:\n",
        "            images = images / 255.0\n",
        "        if len(images.shape) == 4 and images.shape[1] == 3:\n",
        "            images = np.transpose(images, (0, 2, 3, 1))\n",
        "        return images.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.images[idx], self.labels[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(image=img)['image']\n",
        "        else:\n",
        "            img = torch.from_numpy(img).permute(2, 0, 1)\n",
        "        return img, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class DataManager:\n",
        "    @staticmethod\n",
        "    def get_transforms(augmentation_strength='medium', is_training=True):\n",
        "        base = [\n",
        "            A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "            A.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "            ToTensorV2()\n",
        "        ]\n",
        "        if not is_training:\n",
        "            return A.Compose(base)\n",
        "\n",
        "        aug_cfg = {\n",
        "            'light': [\n",
        "                A.HorizontalFlip(p=0.4),\n",
        "                A.RandomRotate90(p=0.4),\n",
        "                A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.4),\n",
        "                A.RandomBrightnessContrast(0.1, 0.1, p=0.4),\n",
        "            ],\n",
        "            'medium': [\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.RandomRotate90(p=0.5),\n",
        "                A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "                A.RandomBrightnessContrast(0.2, 0.2, p=0.5),\n",
        "                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.4),\n",
        "                A.OneOf([A.GaussNoise(), A.GaussianBlur()], p=0.3)\n",
        "            ],\n",
        "            'heavy': [\n",
        "                A.HorizontalFlip(p=0.6),\n",
        "                A.RandomRotate90(p=0.6),\n",
        "                A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.6),\n",
        "                A.RandomBrightnessContrast(0.3, 0.3, p=0.6),\n",
        "                A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.15, p=0.5),\n",
        "                A.OneOf([A.GaussNoise(), A.GaussianBlur()], p=0.4),\n",
        "                A.CoarseDropout(\n",
        "                    min_holes=6, max_holes=10,\n",
        "                    min_height=16, max_height=32,\n",
        "                    min_width=16,  max_width=32,\n",
        "                    fill_value=0, mask_fill_value=None, p=0.4\n",
        "                ),\n",
        "                A.CoarseDropout(min_holes=4, max_holes=8, min_height=8, max_height=16, min_width=8, max_width=16, p=0.3)\n",
        "            ]\n",
        "        }\n",
        "        return A.Compose(aug_cfg[augmentation_strength] + base)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_and_balance_data():\n",
        "        print(\"üìä Loading and balancing data...\")\n",
        "        X = np.load(Config.DATA_FILE, mmap_mode='r').copy()\n",
        "        Y = np.load(Config.LABELS_FILE, allow_pickle=True)\n",
        "        print(f\"üìä Original data: {X.shape}, Class dist: {np.bincount(Y)}\")\n",
        "\n",
        "        X_flat = X.reshape(X.shape[0], -1)\n",
        "        smote = SMOTE(random_state=Config.SEED, k_neighbors=3 ,sampling_strategy='not majority')\n",
        "        X_bal, Y_bal = smote.fit_resample(X_flat, Y)\n",
        "        X_bal = X_bal.reshape(-1, *X.shape[1:])\n",
        "        print(f\"üìä Balanced data: {X_bal.shape}, Class dist: {np.bincount(Y_bal)}\")\n",
        "        return X_bal, Y_bal\n",
        "\n",
        "def create_balanced_sampler(labels):\n",
        "    class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
        "    sample_weights = [class_weights[y] for y in labels]\n",
        "    return WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "def make_train_val_loaders(X, Y, aug_strength='medium'):\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "        X, Y, test_size=Config.TEST_SIZE, random_state=Config.SEED, stratify=Y\n",
        "    )\n",
        "    ttr = DataManager.get_transforms(aug_strength, True)\n",
        "    tval = DataManager.get_transforms('medium', False)\n",
        "\n",
        "    train_ds = FishDataset(X_tr, y_tr, ttr)\n",
        "    val_ds   = FishDataset(X_val, y_val, tval)\n",
        "\n",
        "    train_sampler = create_balanced_sampler(y_tr)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, sampler=train_sampler,\n",
        "                              num_workers=Config.NUM_WORKERS, pin_memory=torch.cuda.is_available(), drop_last=True)\n",
        "    val_loader   = DataLoader(val_ds, batch_size=Config.BATCH_SIZE*2, shuffle=False,\n",
        "                              num_workers=Config.NUM_WORKERS, pin_memory=torch.cuda.is_available(), drop_last=False)\n",
        "    return train_loader, val_loader, (X_tr, y_tr, X_val, y_val)\n",
        "\n",
        "# ==============================================================\n",
        "# PART 2 ‚Äî Enhanced Models with Parallel Training\n",
        "# ==============================================================\n",
        "\n",
        "def build_backbone(backbone: str, dropout: float, num_classes: int):\n",
        "    if backbone == 'resnet50':\n",
        "        m = models.resnet50(weights='IMAGENET1K_V2')\n",
        "        feat_dim = m.fc.in_features\n",
        "        m.fc = nn.Identity()\n",
        "        target_layer = m.layer4[-1]\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"layer4\" not in name and \"layer3\" not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif backbone == 'efficientnet_b0':\n",
        "        m = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "        feat_dim = m.classifier[1].in_features\n",
        "        m.classifier = nn.Identity()\n",
        "        target_layer = m.features[-1]\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"features.6\" not in name and \"features.7\" not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif backbone == 'mobilenet_v3_large':\n",
        "        m = models.mobilenet_v3_large(weights='IMAGENET1K_V2')\n",
        "        feat_dim = m.classifier[0].in_features\n",
        "        m.classifier = nn.Identity()\n",
        "        target_layer = m.features[-1]\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"features.14\" not in name and \"features.15\" not in name and \"features.16\" not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif backbone == 'vgg16':\n",
        "        m = models.vgg16(weights='IMAGENET1K_V1')\n",
        "        feat_dim = m.classifier[0].in_features\n",
        "        m.classifier = nn.Identity()\n",
        "        target_layer = m.features[-1]\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"features.24\" not in name and \"features.26\" not in name and \"features.28\" not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif backbone == 'densenet121':\n",
        "        m = models.densenet121(weights='IMAGENET1K_V1')\n",
        "        feat_dim = m.classifier.in_features\n",
        "        m.classifier = nn.Identity()\n",
        "        target_layer = m.features.denseblock4\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"denseblock3\" not in name and \"denseblock4\" not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif backbone == 'resnext50_32x4d':\n",
        "        m = models.resnext50_32x4d(weights='IMAGENET1K_V2')\n",
        "        feat_dim = m.fc.in_features\n",
        "        m.fc = nn.Identity()\n",
        "        target_layer = m.layer4[-1]\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"layer4\" not in name and \"layer3\" not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif backbone == 'swin_t':\n",
        "        m = models.swin_t(weights='IMAGENET1K_V1')\n",
        "        feat_dim = m.head.in_features\n",
        "        m.head = nn.Identity()\n",
        "        target_layer = m.features[-1][-1]\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"features.6\" not in name and \"features.7\" not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif backbone == 'convnext_tiny':\n",
        "        m = models.convnext_tiny(weights='IMAGENET1K_V1')\n",
        "        feat_dim = m.classifier[2].in_features\n",
        "        m.classifier = nn.Identity()\n",
        "        target_layer = m.features[-1]\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"features.6\" not in name and \"features.7\" not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif backbone == 'efficientnet_v2_s':\n",
        "        m = models.efficientnet_v2_s(weights='IMAGENET1K_V1')\n",
        "        feat_dim = m.classifier[1].in_features\n",
        "        m.classifier = nn.Identity()\n",
        "        target_layer = m.features[-1]\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"features.6\" not in name and \"features.7\" not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif backbone == 'vit_b_16':\n",
        "        m = models.vit_b_16(weights='IMAGENET1K_V1')\n",
        "        feat_dim = m.heads.head.in_features\n",
        "        m.heads = nn.Identity()\n",
        "        target_layer = m.encoder.layers[-1]\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"encoder.layers.encoder_layer_10\" not in name and \"encoder.layers.encoder_layer_11\" not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif backbone == 'maxvit_t':\n",
        "        m = models.maxvit_t(weights='IMAGENET1K_V1')\n",
        "        feat_dim = m.classifier[-1].in_features\n",
        "        m.classifier = nn.Identity()\n",
        "        target_layer = m.stages[-1]\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"stages.2\" not in name and \"stages.3\" not in name:\n",
        "                param.requires_grad = False\n",
        "\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported backbone: {backbone}\")\n",
        "\n",
        "    attn = nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n",
        "        nn.Linear(feat_dim, feat_dim//16), nn.ReLU(inplace=True),\n",
        "        nn.Linear(feat_dim//16, feat_dim), nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    clf  = nn.Sequential(\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(feat_dim, feat_dim//2),\n",
        "        nn.BatchNorm1d(feat_dim//2),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(feat_dim//2, feat_dim//4),\n",
        "        nn.BatchNorm1d(feat_dim//4),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(dropout/2),\n",
        "        nn.Linear(feat_dim//4, num_classes)\n",
        "    )\n",
        "\n",
        "    return m, feat_dim, attn, clf, target_layer\n",
        "\n",
        "class FishClassifier(nn.Module):\n",
        "    def __init__(self, backbone='resnet50', num_classes=5, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        self.backbone_name = backbone\n",
        "        self.backbone, self.feature_dim, self.attention, self.classifier, self.target_layer = \\\n",
        "            build_backbone(backbone, dropout_rate, num_classes)\n",
        "\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat = self.backbone(x)\n",
        "        if len(feat.shape) == 4:\n",
        "            att_w = self.attention(feat).view(feat.size(0), feat.size(1), 1, 1)\n",
        "            feat  = torch.nn.functional.adaptive_avg_pool2d(feat * att_w, 1).flatten(1)\n",
        "        return self.classifier(feat)\n",
        "\n",
        "    def forward_with_hook(self, x):\n",
        "        def save_activation(module, inp, out): self.activations = out\n",
        "        def save_gradient(module, gin, gout): self.gradients = gout[0]\n",
        "        hf = self.target_layer.register_forward_hook(save_activation)\n",
        "        hb = self.target_layer.register_backward_hook(save_gradient)\n",
        "        out = self.forward(x)\n",
        "        hf.remove(); hb.remove()\n",
        "        return out\n",
        "\n",
        "    def get_features(self, x):\n",
        "        feat = self.backbone(x)\n",
        "        if len(feat.shape) == 4:\n",
        "            att_w = self.attention(feat).view(feat.size(0), feat.size(1), 1, 1)\n",
        "            feat  = torch.nn.functional.adaptive_avg_pool2d(feat * att_w, 1).flatten(1)\n",
        "        return feat\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, hyperparams):\n",
        "        self.model = model.to(Config.DEVICE)\n",
        "        self.hp = hyperparams\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.15)\n",
        "        self.best_val = 0.0\n",
        "        self.patience = 0\n",
        "        self.best_state = None\n",
        "        self.grad_accum_steps = Config.GRAD_ACCUM_STEPS\n",
        "\n",
        "        self.scaler = torch.cuda.amp.GradScaler() if Config.USE_MIXED_PRECISION and torch.cuda.is_available() else None\n",
        "\n",
        "        if hyperparams['optimizer'] == 'lion':\n",
        "            self.opt = Lion(self.model.parameters(), lr=hyperparams['learning_rate'], weight_decay=hyperparams['weight_decay'])\n",
        "        else:\n",
        "            self.opt = optim.AdamW(self.model.parameters(),\n",
        "                                   lr=hyperparams['learning_rate'],\n",
        "                                   weight_decay=hyperparams['weight_decay'])\n",
        "\n",
        "        if hyperparams['scheduler'] == 'cosine':\n",
        "            self.sched = optim.lr_scheduler.CosineAnnealingLR(self.opt, T_max=Config.MAX_EPOCHS)\n",
        "        elif hyperparams['scheduler'] == 'onecycle':\n",
        "            self.sched = optim.lr_scheduler.OneCycleLR(self.opt, max_lr=hyperparams['learning_rate']*10, total_steps=Config.MAX_EPOCHS)\n",
        "        else:\n",
        "            self.sched = optim.lr_scheduler.ReduceLROnPlateau(self.opt, mode='max', patience=2, factor=0.5, min_lr=1e-7)\n",
        "\n",
        "    def _epoch(self, loader, train=True):\n",
        "        if train:\n",
        "            self.model.train()\n",
        "        else:\n",
        "            self.model.eval()\n",
        "\n",
        "        total_loss, total_correct, total = 0.0, 0, 0\n",
        "        with torch.set_grad_enabled(train):\n",
        "            for i, (x, y) in enumerate(loader):\n",
        "                x, y = x.to(Config.DEVICE, non_blocking=True), y.to(Config.DEVICE, non_blocking=True)\n",
        "\n",
        "                if train:\n",
        "                    self.opt.zero_grad(set_to_none=True)\n",
        "                    if self.scaler is not None:\n",
        "                        with torch.cuda.amp.autocast():\n",
        "                            out = self.model(x)\n",
        "                            loss = self.criterion(out, y) / self.grad_accum_steps\n",
        "                        self.scaler.scale(loss).backward()\n",
        "                        if (i + 1) % self.grad_accum_steps == 0:\n",
        "                            self.scaler.unscale_(self.opt)\n",
        "                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)\n",
        "                            self.scaler.step(self.opt)\n",
        "                            self.scaler.update()\n",
        "                    else:\n",
        "                        out = self.model(x)\n",
        "                        loss = self.criterion(out, y) / self.grad_accum_steps\n",
        "                        loss.backward()\n",
        "                        if (i + 1) % self.grad_accum_steps == 0:\n",
        "                            torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)\n",
        "                            self.opt.step()\n",
        "                else:\n",
        "                    if self.scaler is not None:\n",
        "                        with torch.cuda.amp.autocast():\n",
        "                            out = self.model(x)\n",
        "                            loss = self.criterion(out, y)\n",
        "                    else:\n",
        "                        out = self.model(x)\n",
        "                        loss = self.criterion(out, y)\n",
        "\n",
        "                total_loss += loss.item() * self.grad_accum_steps\n",
        "                total_correct += (out.argmax(1) == y).sum().item()\n",
        "                total += y.size(0)\n",
        "\n",
        "        return total_loss/len(loader), total_correct/total\n",
        "\n",
        "    def fit(self, train_loader, val_loader, max_epochs=Config.MAX_EPOCHS, log_prefix=\"\"):\n",
        "        history = {'train_acc': [], 'val_acc': [], 'train_loss': [], 'val_loss': []}\n",
        "        for ep in range(1, max_epochs+1):\n",
        "            start_time = time.time()\n",
        "            tr_loss, tr_acc = self._epoch(train_loader, train=True)\n",
        "            va_loss, va_acc = self._epoch(val_loader, train=False)\n",
        "            epoch_time = time.time() - start_time\n",
        "\n",
        "            history['train_loss'].append(tr_loss); history['val_loss'].append(va_loss)\n",
        "            history['train_acc'].append(tr_acc);   history['val_acc'].append(va_acc)\n",
        "\n",
        "            improved = va_acc > self.best_val + 1e-5\n",
        "            if improved:\n",
        "                self.best_val = va_acc\n",
        "                self.patience = 0\n",
        "                self.best_state = {k: v.cpu().clone() for k, v in self.model.state_dict().items()}\n",
        "            else:\n",
        "                self.patience += 1\n",
        "\n",
        "            if isinstance(self.sched, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                self.sched.step(va_acc)\n",
        "            else:\n",
        "                self.sched.step()\n",
        "\n",
        "            print(f\"{log_prefix}Epoch {ep:02d} | Train Acc {tr_acc:.4f} | Val Acc {va_acc:.4f} | \"\n",
        "                  f\"LR {self.opt.param_groups[0]['lr']:.2e} | Time {epoch_time:.1f}s\")\n",
        "\n",
        "            if self.patience >= Config.PATIENCE or (tr_acc - va_acc > 0.3 and ep > 10):\n",
        "                print(f\"{log_prefix}‚èπÔ∏è Early stopping at epoch {ep}\")\n",
        "                break\n",
        "\n",
        "        if self.best_state is not None:\n",
        "            self.model.load_state_dict(self.best_state)\n",
        "        return history\n",
        "\n",
        "# ==============================================================\n",
        "# PART 3 ‚Äî Advanced Ensemble Techniques\n",
        "# ==============================================================\n",
        "\n",
        "class EnsembleManager:\n",
        "    def __init__(self, models_dict: Dict[str, nn.Module], val_data: Tuple):\n",
        "        self.models = models_dict\n",
        "        self.model_names = list(models_dict.keys())\n",
        "        self.X_val, self.y_val = val_data\n",
        "        self.val_transform = DataManager.get_transforms('medium', False)\n",
        "        self.val_predictions = self._get_all_predictions()\n",
        "\n",
        "    def _get_all_predictions(self):\n",
        "        predictions = {}\n",
        "        val_ds = FishDataset(self.X_val, self.y_val, self.val_transform)\n",
        "        val_loader = DataLoader(val_ds, batch_size=Config.BATCH_SIZE*2, shuffle=False,\n",
        "                               num_workers=Config.NUM_WORKERS, pin_memory=torch.cuda.is_available())\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            model.eval()\n",
        "            y_pred, y_proba = [], []\n",
        "            with torch.no_grad():\n",
        "                for xb, _ in val_loader:\n",
        "                    logits = model(xb.to(Config.DEVICE))\n",
        "                    probs = torch.softmax(logits, dim=1)\n",
        "                    y_proba.append(probs.cpu().numpy())\n",
        "                    y_pred.append(logits.argmax(1).cpu().numpy())\n",
        "\n",
        "            predictions[name] = {\n",
        "                'proba': np.concatenate(y_proba, axis=0),\n",
        "                'pred': np.concatenate(y_pred, axis=0)\n",
        "            }\n",
        "        return predictions\n",
        "\n",
        "    def simple_average_ensemble(self, model_names: List[str] = None):\n",
        "        if model_names is None:\n",
        "            model_names = self.model_names\n",
        "\n",
        "        avg_proba = np.mean([self.val_predictions[name]['proba'] for name in model_names], axis=0)\n",
        "        pred = np.argmax(avg_proba, axis=1)\n",
        "\n",
        "        acc = accuracy_score(self.y_val, pred)\n",
        "        f1 = f1_score(self.y_val, pred, average='macro')\n",
        "\n",
        "        return {'accuracy': acc, 'f1': f1, 'predictions': pred, 'probabilities': avg_proba}\n",
        "\n",
        "    def weighted_average_ensemble(self, model_names: List[str] = None):\n",
        "        if model_names is None:\n",
        "            model_names = self.model_names\n",
        "\n",
        "        weights = []\n",
        "        for name in model_names:\n",
        "            f1 = f1_score(self.y_val, self.val_predictions[name]['pred'], average='macro')\n",
        "            weights.append(f1)\n",
        "\n",
        "        weights = np.array(weights)\n",
        "        weights = weights / weights.sum()\n",
        "\n",
        "        weighted_proba = np.average([self.val_predictions[name]['proba'] for name in model_names],\n",
        "                                   axis=0, weights=weights)\n",
        "        pred = np.argmax(weighted_proba, axis=1)\n",
        "\n",
        "        acc = accuracy_score(self.y_val, pred)\n",
        "        f1 = f1_score(self.y_val, pred, average='macro')\n",
        "\n",
        "        return {'accuracy': acc, 'f1': f1, 'predictions': pred, 'probabilities': weighted_proba, 'weights': weights}\n",
        "\n",
        "    def learnable_weighted_ensemble(self, model_names: List[str] = None):\n",
        "        if model_names is None:\n",
        "            model_names = self.model_names\n",
        "\n",
        "        X_ensemble = np.concatenate([self.val_predictions[name]['proba'] for name in model_names], axis=1)\n",
        "\n",
        "        X_meta_train, X_meta_val, y_meta_train, y_meta_val = train_test_split(\n",
        "            X_ensemble, self.y_val, test_size=0.3, random_state=Config.SEED, stratify=self.y_val\n",
        "        )\n",
        "\n",
        "        meta_model = MLPClassifier(hidden_layer_sizes=(64, 32), max_iter=1000, random_state=Config.SEED)\n",
        "        meta_model.fit(X_meta_train, y_meta_train)\n",
        "\n",
        "        pred = meta_model.predict(X_meta_val)\n",
        "        proba = meta_model.predict_proba(X_meta_val)\n",
        "\n",
        "        acc = accuracy_score(y_meta_val, pred)\n",
        "        f1 = f1_score(y_meta_val, pred, average='macro')\n",
        "\n",
        "        return {'accuracy': acc, 'f1': f1, 'predictions': pred, 'probabilities': proba, 'meta_model': meta_model}\n",
        "\n",
        "    def confidence_based_ensemble(self, model_names: List[str] = None):\n",
        "        if model_names is None:\n",
        "            model_names = self.model_names\n",
        "\n",
        "        n_samples = len(self.y_val)\n",
        "        final_pred = np.zeros(n_samples)\n",
        "        final_proba = np.zeros((n_samples, Config.NUM_CLASSES))\n",
        "\n",
        "        for i in range(n_samples):\n",
        "            confidences = []\n",
        "            probas = []\n",
        "\n",
        "            for name in model_names:\n",
        "                proba = self.val_predictions[name]['proba'][i]\n",
        "                confidence = np.max(proba)\n",
        "                confidences.append(confidence)\n",
        "                probas.append(proba)\n",
        "\n",
        "            confidences = np.array(confidences)\n",
        "            confidences = confidences / confidences.sum()\n",
        "\n",
        "            weighted_proba = np.average(probas, axis=0, weights=confidences)\n",
        "            final_proba[i] = weighted_proba\n",
        "            final_pred[i] = np.argmax(weighted_proba)\n",
        "\n",
        "        acc = accuracy_score(self.y_val, final_pred)\n",
        "        f1 = f1_score(self.y_val, final_pred, average='macro')\n",
        "\n",
        "        return {'accuracy': acc, 'f1': f1, 'predictions': final_pred, 'probabilities': final_proba}\n",
        "\n",
        "    def meta_model_ensemble(self, model_names: List[str] = None):\n",
        "        if model_names is None:\n",
        "            model_names = self.model_names\n",
        "\n",
        "        X_meta = np.concatenate([self.val_predictions[name]['proba'] for name in model_names], axis=1)\n",
        "\n",
        "        X_train, X_test, y_train, y_test = train_test_split(\n",
        "            X_meta, self.y_val, test_size=0.3, random_state=Config.SEED, stratify=self.y_val\n",
        "        )\n",
        "\n",
        "        meta_model = LogisticRegression(random_state=Config.SEED, max_iter=1000)\n",
        "        meta_model.fit(X_train, y_train)\n",
        "\n",
        "        pred = meta_model.predict(X_test)\n",
        "        proba = meta_model.predict_proba(X_test)\n",
        "\n",
        "        acc = accuracy_score(y_test, pred)\n",
        "        f1 = f1_score(y_test, pred, average='macro')\n",
        "\n",
        "        return {'accuracy': acc, 'f1': f1, 'predictions': pred, 'probabilities': proba, 'meta_model': meta_model}\n",
        "\n",
        "    def bayesian_ensemble(self, model_names: List[str] = None):\n",
        "        if model_names is None:\n",
        "            model_names = self.model_names\n",
        "\n",
        "        model_weights = []\n",
        "        for name in model_names:\n",
        "            acc = accuracy_score(self.y_val, self.val_predictions[name]['pred'])\n",
        "            model_weights.append(acc)\n",
        "\n",
        "        model_weights = np.array(model_weights)\n",
        "        model_weights = np.exp(model_weights * 10)\n",
        "        model_weights = model_weights / model_weights.sum()\n",
        "\n",
        "        weighted_proba = np.average([self.val_predictions[name]['proba'] for name in model_names],\n",
        "                                    axis=0, weights=model_weights)\n",
        "        pred = np.argmax(weighted_proba, axis=1)\n",
        "\n",
        "        acc = accuracy_score(self.y_val, pred)\n",
        "        f1 = f1_score(self.y_val, pred, average='macro')\n",
        "\n",
        "        return {'accuracy': acc, 'f1': f1, 'predictions': pred, 'probabilities': weighted_proba, 'weights': model_weights}\n",
        "\n",
        "    def snapshot_ensemble(self, model_names: List[str] = None):\n",
        "        if model_names is None:\n",
        "            model_names = self.model_names\n",
        "\n",
        "        n_snapshots = 3\n",
        "        all_probas = []\n",
        "\n",
        "        for name in model_names:\n",
        "            model = self.models[name]\n",
        "            for _ in range(n_snapshots):\n",
        "                model.eval()\n",
        "                y_proba = []\n",
        "                val_ds = FishDataset(self.X_val, self.y_val, self.val_transform)\n",
        "                val_loader = DataLoader(val_ds, batch_size=Config.BATCH_SIZE*2, shuffle=False,\n",
        "                                       num_workers=Config.NUM_WORKERS, pin_memory=torch.cuda.is_available())\n",
        "                with torch.no_grad():\n",
        "                    for xb, _ in val_loader:\n",
        "                        logits = model(xb.to(Config.DEVICE))\n",
        "                        probs = torch.softmax(logits, dim=1)\n",
        "                        y_proba.append(probs.cpu().numpy())\n",
        "                all_probas.append(np.concatenate(y_proba, axis=0))\n",
        "\n",
        "        avg_proba = np.mean(all_probas, axis=0)\n",
        "        pred = np.argmax(avg_proba, axis=1)\n",
        "\n",
        "        acc = accuracy_score(self.y_val, pred)\n",
        "        f1 = f1_score(self.y_val, pred, average='macro')\n",
        "\n",
        "        return {'accuracy': acc, 'f1': f1, 'predictions': pred, 'probabilities': avg_proba}\n",
        "\n",
        "# ==============================================================\n",
        "# PART 4 ‚Äî XAI Visualizations\n",
        "# ==============================================================\n",
        "\n",
        "def grad_cam_plus_plus(model: FishClassifier, input_tensor: torch.Tensor, target_class: int = None):\n",
        "    model.eval()\n",
        "    input_tensor = input_tensor.to(Config.DEVICE)\n",
        "    input_tensor.requires_grad = True\n",
        "\n",
        "    logits = model.forward_with_hook(input_tensor)\n",
        "    if target_class is None:\n",
        "        target_class = logits.argmax(dim=1).item()\n",
        "\n",
        "    loss = logits[0, target_class]\n",
        "    model.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "\n",
        "    A = model.activations\n",
        "    dYdA = model.gradients\n",
        "    if A is None or dYdA is None:\n",
        "        return None\n",
        "\n",
        "    eps = 1e-8\n",
        "    d2 = dYdA ** 2\n",
        "    d3 = d2 * dYdA\n",
        "\n",
        "    sumA = torch.sum(A, dim=(2,3), keepdim=True)\n",
        "\n",
        "    alpha_num = d2\n",
        "    alpha_den = 2*d2 + sumA * d3\n",
        "    alpha_den = torch.where(alpha_den != 0.0, alpha_den, torch.tensor(eps, device=alpha_den.device))\n",
        "    alphas = alpha_num / (alpha_den + eps)\n",
        "    relu_dYdA = torch.relu(dYdA)\n",
        "    weights = torch.sum(alphas * relu_dYdA, dim=(2,3))\n",
        "\n",
        "    cam = torch.zeros(A.shape[2:], dtype=torch.float32, device=A.device)\n",
        "    for k in range(A.shape[1]):\n",
        "        cam += weights[0, k] * A[0, k, :, :]\n",
        "    cam = torch.relu(cam)\n",
        "    cam = (cam - cam.min()) / (cam.max() - cam.min() + eps)\n",
        "    return cam.detach().cpu().numpy()\n",
        "\n",
        "def lrp_relevance(model: FishClassifier, input_tensor: torch.Tensor, target_class: int = None):\n",
        "    ok = ensure_captum()\n",
        "    if not ok:\n",
        "        return None\n",
        "    try:\n",
        "        from captum.attr import IntegratedGradients\n",
        "        model.eval()\n",
        "        input_tensor = input_tensor.to(Config.DEVICE)\n",
        "        if target_class is None:\n",
        "            with torch.no_grad():\n",
        "                target_class = model(input_tensor).argmax(1).item()\n",
        "        ig = IntegratedGradients(model)\n",
        "        attr = ig.attribute(inputs=input_tensor, target=target_class, n_steps=50)\n",
        "        heat = attr[0].detach().cpu().numpy()\n",
        "        heat = np.maximum(heat, 0)\n",
        "        heat = heat.mean(axis=0)\n",
        "        heat = (heat - heat.min()) / (heat.max() - heat.min() + 1e-8)\n",
        "        return heat\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è LRP/IntegratedGradients failed: {e}\")\n",
        "        return None\n",
        "\n",
        "def guided_backprop(model, input_tensor, target_class=None):\n",
        "    gbp = GuidedBackprop(model)\n",
        "    input_tensor = input_tensor.to(Config.DEVICE)\n",
        "    input_tensor.requires_grad = True\n",
        "    if target_class is None:\n",
        "        target_class = model(input_tensor).argmax(dim=1).item()\n",
        "    attr = gbp.attribute(input_tensor, target=target_class)\n",
        "    attr = attr.squeeze().cpu().detach().numpy()\n",
        "    attr = np.abs(attr).sum(axis=0)\n",
        "    attr = (attr - attr.min()) / (attr.max() - attr.min() + 1e-8)\n",
        "    return attr\n",
        "\n",
        "def saliency_map(model, input_tensor, target_class=None):\n",
        "    saliency = Saliency(model)\n",
        "    input_tensor = input_tensor.to(Config.DEVICE)\n",
        "    input_tensor.requires_grad = True\n",
        "    if target_class is None:\n",
        "        target_class = model(input_tensor).argmax(dim=1).item()\n",
        "    attr = saliency.attribute(input_tensor, target=target_class)\n",
        "    attr = attr.squeeze().cpu().detach().numpy()\n",
        "    attr = np.abs(attr).sum(axis=0)\n",
        "    attr = (attr - attr.min()) / (attr.max() - attr.min() + 1e-8)\n",
        "    return attr\n",
        "\n",
        "def denorm_to_img(tensor):\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    img = tensor.detach().cpu().permute(1, 2, 0).numpy()\n",
        "    img = img * std + mean\n",
        "    return np.clip(img, 0, 1)\n",
        "\n",
        "def overlay_heatmap(img, heatmap, alpha=0.4):\n",
        "    h, w = img.shape[:2]\n",
        "    heatmap_resized = cv2.resize(heatmap, (w, h))\n",
        "    cmap = plt.cm.jet(heatmap_resized)[..., :3]\n",
        "    return (1 - alpha) * img + alpha * cmap\n",
        "\n",
        "def plot_xai_visualizations(model, image, label, pred, outdir, idx=0):\n",
        "    \"\"\"Plot Grad-CAM++, LRP, Guided Backprop, and Saliency maps for XAI comparison\"\"\"\n",
        "    transform = DataManager.get_transforms('medium', False)\n",
        "    img_tensor = transform(image=image)['image'].unsqueeze(0).to(Config.DEVICE)\n",
        "    img_denorm = denorm_to_img(img_tensor)\n",
        "\n",
        "    campp = grad_cam_plus_plus(model, img_tensor, target_class=pred)\n",
        "    lrp = lrp_relevance(model, img_tensor, target_class=pred)\n",
        "\n",
        "    fig, axs = plt.subplots(1, 6, figsize=(24, 4))\n",
        "    axs[0].imshow(img_denorm)\n",
        "    axs[0].set_title(f'Original\\nTrue: {Config.CLASS_LABELS[label]}\\nPred: {Config.CLASS_LABELS[pred]}')\n",
        "    axs[0].axis('off')\n",
        "\n",
        "    if campp is not None:\n",
        "        im = axs[1].imshow(campp, cmap='hot')\n",
        "        axs[1].set_title('Grad-CAM++')\n",
        "        plt.colorbar(im, ax=axs[1], fraction=0.046, pad=0.04)\n",
        "        axs[2].imshow(overlay_heatmap(img_denorm, campp))\n",
        "        axs[2].set_title('Grad-CAM++ Overlay')\n",
        "        axs[2].axis('off')\n",
        "    else:\n",
        "        axs[1].text(0.5, 0.5, 'Grad-CAM++ Unavailable', ha='center', va='center')\n",
        "        axs[2].text(0.5, 0.5, 'Grad-CAM++ Overlay Unavailable', ha='center', va='center')\n",
        "        axs[1].axis('off'); axs[2].axis('off')\n",
        "\n",
        "    if lrp is not None:\n",
        "        im = axs[3].imshow(lrp, cmap='hot')\n",
        "        axs[3].set_title('LRP (Integrated Gradients)')\n",
        "        plt.colorbar(im, ax=axs[3], fraction=0.046, pad=0.04)\n",
        "        axs[4].imshow(overlay_heatmap(img_denorm, lrp))\n",
        "        axs[4].set_title('LRP Overlay')\n",
        "        axs[4].axis('off')\n",
        "    else:\n",
        "        axs[3].text(0.5, 0.5, 'LRP Unavailable', ha='center', va='center')\n",
        "        axs[4].text(0.5, 0.5, 'LRP Overlay Unavailable', ha='center', va='center')\n",
        "        axs[3].axis('off'); axs[4].axis('off')\n",
        "\n",
        "    methods = ['Guided Backprop', 'Saliency Map']\n",
        "    visualizations = [\n",
        "        guided_backprop(model, img_tensor),\n",
        "        saliency_map(model, img_tensor)\n",
        "    ]\n",
        "\n",
        "    for i, (method, viz) in enumerate(zip(methods, visualizations)):\n",
        "        if viz is not None:\n",
        "            axs[i+5].imshow(overlay_heatmap(img_denorm, viz))\n",
        "            axs[i+5].set_title(method)\n",
        "            axs[i+5].axis('off')\n",
        "        else:\n",
        "            axs[i+5].text(0.5, 0.5, f'{method} Unavailable', ha='center', va='center')\n",
        "            axs[i+5].axis('off')\n",
        "\n",
        "    p = os.path.join(outdir, f'xai_visualizations_{idx}.png')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(p, dpi=300, bbox_inches='tight'); plt.show()\n",
        "    print(f\"üìä Saved XAI visualizations to {p}\")\n",
        "\n",
        "# ==============================================================\n",
        "# PART 5 ‚Äî Enhanced Visualizations for Q1 Journal\n",
        "# ==============================================================\n",
        "\n",
        "def generate_workflow_diagram(outdir):\n",
        "    dot = Digraph(comment='Fish Classification Pipeline')\n",
        "\n",
        "    dot.node('A', 'Data Loading & Balancing (SMOTE)')\n",
        "    dot.node('B', 'Hyperparameter Optimization (Optuna)')\n",
        "    dot.node('C', 'Model Training (PyTorch, Mixed Precision)')\n",
        "    dot.node('D', 'Single Model Evaluation')\n",
        "    dot.node('E', 'Ensemble Techniques (2/3 Models)')\n",
        "    dot.node('F', 'Performance Comparisons & Statistical Tests')\n",
        "    dot.node('G', 'Feature Visualizations (t-SNE/PCA)')\n",
        "    dot.node('H', 'XAI Analysis (Grad-CAM++, LRP, GBP, Saliency)')\n",
        "    dot.node('I', 'Real-world Prediction')\n",
        "\n",
        "    dot.edges(['AB', 'BC', 'CD', 'DE', 'EF', 'FG', 'GH', 'HI'])\n",
        "\n",
        "    p = os.path.join(outdir, 'workflow_diagram.png')\n",
        "    dot.render(os.path.join(outdir, 'workflow_diagram'), format='png', view=False)\n",
        "    print(f\"üìä Saved workflow diagram to {p}\")\n",
        "\n",
        "def plot_roc_curves(y_true, probas_dict, outdir, title='ROC Curves Comparison'):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for name, proba in probas_dict.items():\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            fpr, tpr, _ = roc_curve(y_true == i, proba[:, i])\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            plt.plot(fpr, tpr, label=f'{name} - {Config.CLASS_LABELS[i]} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid(alpha=0.3)\n",
        "    p = os.path.join(outdir, 'roc_curves.png')\n",
        "    plt.savefig(p, dpi=300, bbox_inches='tight'); plt.show()\n",
        "    print(f\"üìä Saved ROC curves to {p}\")\n",
        "\n",
        "def plot_pr_curves(y_true, probas_dict, outdir, title='Precision-Recall Curves Comparison'):\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    for name, proba in probas_dict.items():\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            precision, recall, _ = precision_recall_curve(y_true == i, proba[:, i])\n",
        "            ap = average_precision_score(y_true == i, proba[:, i])\n",
        "            plt.plot(recall, precision, label=f'{name} - {Config.CLASS_LABELS[i]} (AP = {ap:.2f})')\n",
        "\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc='lower left')\n",
        "    plt.grid(alpha=0.3)\n",
        "    p = os.path.join(outdir, 'pr_curves.png')\n",
        "    plt.savefig(p, dpi=300, bbox_inches='tight'); plt.show()\n",
        "    print(f\"üìä Saved PR curves to {p}\")\n",
        "\n",
        "def plot_feature_visualization(features, labels, outdir, method='tsne', title='Feature Visualization'):\n",
        "    if method == 'tsne':\n",
        "        tsne = TSNE(n_components=2, random_state=Config.SEED)\n",
        "        reduced = tsne.fit_transform(features)\n",
        "    else:\n",
        "        pca = PCA(n_components=2)\n",
        "        reduced = pca.fit_transform(features)\n",
        "\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    scatter = plt.scatter(reduced[:,0], reduced[:,1], c=labels, cmap='viridis', alpha=0.6)\n",
        "    plt.colorbar(scatter, ticks=range(Config.NUM_CLASSES), label='Classes')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Component 1')\n",
        "    plt.ylabel('Component 2')\n",
        "    p = os.path.join(outdir, f'{method}_visualization.png')\n",
        "    plt.savefig(p, dpi=300, bbox_inches='tight'); plt.show()\n",
        "    print(f\"üìä Saved {method} visualization to {p}\")\n",
        "\n",
        "def generate_metrics_table(metrics_dict, outdir):\n",
        "    df = pd.DataFrame.from_dict(metrics_dict, orient='index')\n",
        "    df['AUC'] = [roc_auc_score(y_true, proba, multi_class='ovr') for proba in df['probabilities']] if 'probabilities' in df else 0\n",
        "    df['AP'] = [average_precision_score(y_true, proba, average='macro') for proba in df['probabilities']] if 'probabilities' in df else 0\n",
        "    df = df[['accuracy', 'f1', 'AUC', 'AP']]\n",
        "    latex = df.to_latex(float_format=\"%.3f\")\n",
        "    p = os.path.join(outdir, 'metrics_table.tex')\n",
        "    with open(p, 'w') as f:\n",
        "        f.write(latex)\n",
        "    print(f\"üìä Saved metrics table (LaTeX) to {p}\")\n",
        "\n",
        "def perform_statistical_tests(preds_dict, y_true, outdir):\n",
        "    models = list(preds_dict.keys())\n",
        "    results = {}\n",
        "    for i in range(len(models)):\n",
        "        for j in range(i+1, len(models)):\n",
        "            p1 = preds_dict[models[i]]['predictions']\n",
        "            p2 = preds_dict[models[j]]['predictions']\n",
        "            try:\n",
        "                t_stat, p_val_t = ttest_rel(p1 == y_true, p2 == y_true)\n",
        "            except:\n",
        "                t_stat, p_val_t = None, None\n",
        "            try:\n",
        "                w_stat, p_val_w = wilcoxon(p1 == y_true, p2 == y_true)\n",
        "            except:\n",
        "                w_stat, p_val_w = None, None\n",
        "            results[f'{models[i]} vs {models[j]}'] = {'t-test p': p_val_t, 'wilcoxon p': p_val_w}\n",
        "\n",
        "    df = pd.DataFrame.from_dict(results, orient='index')\n",
        "    p = os.path.join(outdir, 'stat_tests.csv')\n",
        "    df.to_csv(p)\n",
        "    print(f\"üìä Saved statistical tests to {p}\")\n",
        "\n",
        "def plot_error_analysis(y_true, y_pred, images, labels, outdir, n_samples=5):\n",
        "    mis_idx = np.where(y_true != y_pred)[0]\n",
        "    if len(mis_idx) == 0:\n",
        "        print(\"No misclassifications\")\n",
        "        return\n",
        "\n",
        "    fig, axs = plt.subplots(1, min(n_samples, len(mis_idx)), figsize=(15, 3))\n",
        "    if len(mis_idx) == 1:\n",
        "        axs = [axs]\n",
        "    for i, idx in enumerate(mis_idx[:n_samples]):\n",
        "        img = images[idx]\n",
        "        if len(img.shape) == 3 and img.shape[0] == 3:\n",
        "            img = img.transpose(1,2,0)\n",
        "        axs[i].imshow(img)\n",
        "        axs[i].set_title(f\"True: {labels[y_true[idx]]}\\nPred: {labels[y_pred[idx]]}\")\n",
        "        axs[i].axis('off')\n",
        "\n",
        "    p = os.path.join(outdir, 'error_analysis.png')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(p, dpi=300, bbox_inches='tight'); plt.show()\n",
        "    print(f\"üìä Saved error analysis to {p}\")\n",
        "\n",
        "def plot_learning_curves(histories: Dict[str, Dict], outdir: str):\n",
        "    plt.figure(figsize=(12,8))\n",
        "\n",
        "    plt.subplot(2,2,1)\n",
        "    for name, m in histories.items():\n",
        "        plt.plot(m['train_acc'], label=f'{name} Train', alpha=0.7, linestyle='--')\n",
        "        plt.plot(m['val_acc'], label=f'{name} Val', linewidth=2)\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Training vs Validation Accuracy')\n",
        "    plt.grid(alpha=0.3); plt.legend()\n",
        "\n",
        "    plt.subplot(2,2,2)\n",
        "    for name, m in histories.items():\n",
        "        plt.plot(m['train_loss'], label=f'{name} Train', alpha=0.7, linestyle='--')\n",
        "        plt.plot(m['val_loss'], label=f'{name} Val', linewidth=2)\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Training vs Validation Loss')\n",
        "    plt.grid(alpha=0.3); plt.legend()\n",
        "\n",
        "    plt.subplot(2,2,3)\n",
        "    for name, m in histories.items():\n",
        "        gap = np.array(m['train_acc']) - np.array(m['val_acc'])\n",
        "        plt.plot(gap, label=f'{name} Gap', linewidth=2)\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy Gap'); plt.title('Overfitting Gap (Train - Val)')\n",
        "    plt.grid(alpha=0.3); plt.legend()\n",
        "\n",
        "    plt.subplot(2,2,4)\n",
        "    for name, m in histories.items():\n",
        "        plt.plot(m['val_acc'], label=f'{name}', linewidth=2)\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Validation Accuracy'); plt.title('Validation Accuracy Only')\n",
        "    plt.grid(alpha=0.3); plt.legend()\n",
        "\n",
        "    p = os.path.join(outdir, 'learning_curves.png')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(p, dpi=300, bbox_inches='tight'); plt.show()\n",
        "    print(f\"üìà Saved learning curves to {p}\")\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, labels, title, outpath):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels))))\n",
        "    cmn = cm.astype('float')/cm.sum(axis=1, keepdims=True)\n",
        "    plt.figure(figsize=(8,7))\n",
        "    sns.heatmap(cmn, annot=True, fmt=\".2f\", xticklabels=labels, yticklabels=labels,\n",
        "                cmap='Blues', cbar_kws={'label': 'Normalized Count'})\n",
        "    plt.ylabel('True Label'); plt.xlabel('Predicted Label'); plt.title(title)\n",
        "    plt.tight_layout(); plt.savefig(outpath, dpi=300); plt.show()\n",
        "    print(f\"üìä Saved confusion matrix to {outpath}\")\n",
        "\n",
        "def plot_per_class_f1(y_true, y_pred, labels, outpath, title=\"Per-Class F1\"):\n",
        "    pr, rc, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, labels=list(range(len(labels))))\n",
        "    plt.figure(figsize=(10,6))\n",
        "    x = np.arange(len(labels))\n",
        "    width = 0.25\n",
        "\n",
        "    plt.bar(x - width, pr, width, label='Precision', alpha=0.8)\n",
        "    plt.bar(x, rc, width, label='Recall', alpha=0.8)\n",
        "    plt.bar(x + width, f1, width, label='F1-Score', alpha=0.8)\n",
        "\n",
        "    plt.xlabel('Fish Species'); plt.ylabel('Score'); plt.title(title)\n",
        "    plt.xticks(x, labels, rotation=45); plt.ylim(0,1.05)\n",
        "    plt.legend(); plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    for i, (p, r, f) in enumerate(zip(pr, rc, f1)):\n",
        "        plt.text(i-width, p+0.02, f\"{p:.2f}\", ha='center', fontsize=9)\n",
        "        plt.text(i, r+0.02, f\"{r:.2f}\", ha='center', fontsize=9)\n",
        "        plt.text(i+width, f+0.02, f\"{f:.2f}\", ha='center', fontsize=9)\n",
        "\n",
        "    plt.tight_layout(); plt.savefig(outpath, dpi=300, bbox_inches='tight'); plt.show()\n",
        "    print(f\"üìä Saved per-class metrics to {outpath}\")\n",
        "\n",
        "def plot_model_comparison(metrics: Dict[str, Dict], outdir: str):\n",
        "    names = list(metrics.keys())\n",
        "    accs  = [metrics[n]['acc'] for n in names]\n",
        "    f1s   = [metrics[n]['f1'] for n in names]\n",
        "    plt.figure(figsize=(10,6))\n",
        "    x = np.arange(len(names))\n",
        "    w = 0.35\n",
        "    plt.bar(x-w/2, accs, width=w, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "    plt.bar(x+w/2, f1s,  width=w, label='Macro-F1', alpha=0.8, color='lightcoral')\n",
        "    plt.xticks(x, names, rotation=20); plt.ylim(0,1.05)\n",
        "    for i,v in enumerate(accs): plt.text(i-w/2, v+0.02, f\"{v:.3f}\", ha='center', fontweight='bold')\n",
        "    for i,v in enumerate(f1s):  plt.text(i+w/2, v+0.02, f\"{v:.3f}\", ha='center', fontweight='bold')\n",
        "    plt.title('Backbone Performance Comparison'); plt.legend(); plt.grid(axis='y', alpha=0.3)\n",
        "    plt.ylabel('Score')\n",
        "    p = os.path.join(outdir, 'model_comparison.png')\n",
        "    plt.tight_layout(); plt.savefig(p, dpi=300, bbox_inches='tight'); plt.show()\n",
        "    print(f\"üìä Saved model comparison to {p}\")\n",
        "\n",
        "def plot_all_performances(all_metrics, outdir: str):\n",
        "    names = list(all_metrics.keys())\n",
        "    accs = [all_metrics[n]['accuracy'] for n in names]\n",
        "    f1s = [all_metrics[n]['f1'] for n in names]\n",
        "    plt.figure(figsize=(20,10))\n",
        "    x = np.arange(len(names))\n",
        "    w = 0.35\n",
        "    plt.bar(x-w/2, accs, width=w, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "    plt.bar(x+w/2, f1s, width=w, label='Macro-F1', alpha=0.8, color='lightcoral')\n",
        "    plt.xticks(x, names, rotation=90); plt.ylim(0,1.05)\n",
        "    for i,v in enumerate(accs): plt.text(i-w/2, v+0.02, f\"{v:.3f}\", ha='center', fontweight='bold', rotation=90)\n",
        "    for i,v in enumerate(f1s):  plt.text(i+w/2, v+0.02, f\"{v:.3f}\", ha='center', fontweight='bold', rotation=90)\n",
        "    plt.title('All Models and Ensembles Performance Comparison'); plt.legend(); plt.grid(axis='y', alpha=0.3)\n",
        "    plt.ylabel('Score')\n",
        "    p = os.path.join(outdir, 'all_performances.png')\n",
        "    plt.tight_layout(); plt.savefig(p, dpi=300, bbox_inches='tight'); plt.show()\n",
        "    print(f\"üìä Saved all performances comparison to {p}\")\n",
        "\n",
        "# ==============================================================\n",
        "# PART 6 ‚Äî Cross Validation and HPO\n",
        "# ==============================================================\n",
        "\n",
        "def hpo_wrapper(backbone, X, Y, n_trials):\n",
        "    torch.cuda.empty_cache()\n",
        "    params, score = hpo_for_backbone(X, Y, backbone, n_trials)\n",
        "    return backbone, params, score\n",
        "\n",
        "# def parallel_hpo(X, Y, backbones, n_trials=Config.N_TRIALS):\n",
        "#     best_hps = {}\n",
        "#     with ProcessPoolExecutor(max_workers=Config.PARALLEL_MODELS) as executor:\n",
        "#         futures = [executor.submit(hpo_wrapper, bb, X, Y, n_trials) for bb in backbones]\n",
        "#         for future in as_completed(futures):\n",
        "#             backbone, params, score = future.result()\n",
        "#             best_hps[backbone] = params\n",
        "#             print(f\"Completed HPO for {backbone} with score {score:.4f}\")\n",
        "#     return best_hps\n",
        "from concurrent.futures import ThreadPoolExecutor  # Add this import\n",
        "def parallel_hpo(X, Y, backbones, n_trials=Config.N_TRIALS):\n",
        "    best_hps = {}\n",
        "    with ThreadPoolExecutor(max_workers=Config.PARALLEL_MODELS) as executor:\n",
        "        futures = [executor.submit(hpo_wrapper, bb, X, Y, n_trials) for bb in backbones]\n",
        "        for future in as_completed(futures):\n",
        "            backbone, params, score = future.result()\n",
        "            best_hps[backbone] = params\n",
        "            print(f\"Completed HPO for {backbone} with score {score:.4f}\")\n",
        "    return best_hps\n",
        "\n",
        "\n",
        "# [Rest of PART 6 remains unchanged]\n",
        "def train_final_models(X, Y, best_hp, snapshot=False):\n",
        "    trained_models = {}\n",
        "    histories = {}\n",
        "    single_metrics = {}\n",
        "    snapshots_dict = {}\n",
        "\n",
        "    def train_single_model(backbone, hp):\n",
        "        train_loader, val_loader, (X_tr, y_tr, X_val, y_val) = make_train_val_loaders(X, Y, hp['augmentation_strength'])\n",
        "        model = FishClassifier(backbone, Config.NUM_CLASSES, hp['dropout_rate'])\n",
        "        trainer = Trainer(model, hp)\n",
        "        history = trainer.fit(train_loader, val_loader, log_prefix=f\"[{backbone}] \")\n",
        "\n",
        "        model.eval()\n",
        "        y_true, y_pred = [], []\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in val_loader:\n",
        "                logits = model(xb.to(Config.DEVICE))\n",
        "                y_true.extend(yb.numpy().tolist())\n",
        "                y_pred.extend(logits.argmax(1).cpu().numpy().tolist())\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "        return backbone, model, history, {'acc': acc, 'f1': f1}\n",
        "\n",
        "    with ThreadPoolExecutor(max_workers=Config.PARALLEL_MODELS) as executor:\n",
        "        futures = [executor.submit(train_single_model, bb, best_hp[bb]) for bb in Config.ENSEMBLE_BACKBONES]\n",
        "        for future in futures:\n",
        "            backbone, model, history, metrics = future.result()\n",
        "            trained_models[backbone] = model\n",
        "            histories[backbone] = history\n",
        "            single_metrics[backbone] = metrics\n",
        "            if snapshot:\n",
        "                snapshots_dict[backbone] = [model.state_dict() for _ in range(3)]\n",
        "\n",
        "    return trained_models, single_metrics, snapshots_dict\n",
        "\n",
        "def cross_validate_model(X, Y, backbone, hp, folds=3, epochs=12):\n",
        "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=Config.SEED)\n",
        "    accs, f1s = [], []\n",
        "    for fi, (tr_idx, va_idx) in enumerate(skf.split(X, Y), 1):\n",
        "        Xtr, Xva = X[tr_idx], X[va_idx]\n",
        "        Ytr, Yva = Y[tr_idx], Y[va_idx]\n",
        "        ttr = DataManager.get_transforms(hp['augmentation_strength'], True)\n",
        "        tva = DataManager.get_transforms('medium', False)\n",
        "\n",
        "        train_sampler = create_balanced_sampler(Ytr)\n",
        "        tr_loader = DataLoader(FishDataset(Xtr, Ytr, ttr), batch_size=hp['batch_size'], sampler=train_sampler,\n",
        "                               num_workers=Config.NUM_WORKERS, pin_memory=torch.cuda.is_available(), drop_last=True)\n",
        "        va_loader = DataLoader(FishDataset(Xva, Yva, tva), batch_size=hp['batch_size']*2, shuffle=False,\n",
        "                               num_workers=Config.NUM_WORKERS, pin_memory=torch.cuda.is_available(), drop_last=False)\n",
        "\n",
        "        model = FishClassifier(backbone, Config.NUM_CLASSES, hp['dropout_rate'])\n",
        "        trainer = Trainer(model, hp)\n",
        "        _ = trainer.fit(tr_loader, va_loader, max_epochs=epochs, log_prefix=f\"[{backbone} F{fi}] \")\n",
        "\n",
        "        y_true, y_pred = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in va_loader:\n",
        "                logits = model(xb.to(Config.DEVICE))\n",
        "                y_true.extend(yb.numpy().tolist())\n",
        "                y_pred.extend(logits.argmax(1).cpu().numpy().tolist())\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred, average='macro')\n",
        "        accs.append(acc); f1s.append(f1)\n",
        "\n",
        "        del model, trainer, tr_loader, va_loader\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "    return np.mean(accs), np.mean(f1s)\n",
        "\n",
        "def hpo_for_backbone(X, Y, backbone: str, n_trials=Config.N_TRIALS):\n",
        "    def objective(trial):\n",
        "        hp = {\n",
        "            'learning_rate': trial.suggest_float('learning_rate', min(Config.HP_SPACE['learning_rate']), max(Config.HP_SPACE['learning_rate']), log=True),\n",
        "            'weight_decay': trial.suggest_float('weight_decay', min(Config.HP_SPACE['weight_decay']), max(Config.HP_SPACE['weight_decay']), log=True),\n",
        "            'dropout_rate': trial.suggest_float('dropout_rate', min(Config.HP_SPACE['dropout_rate']), max(Config.HP_SPACE['dropout_rate'])),\n",
        "            'optimizer': trial.suggest_categorical('optimizer', Config.HP_SPACE['optimizer']),\n",
        "            'scheduler': trial.suggest_categorical('scheduler', Config.HP_SPACE['scheduler']),\n",
        "            'augmentation_strength': trial.suggest_categorical('augmentation_strength', Config.HP_SPACE['augmentation_strength']),\n",
        "            'batch_size': trial.suggest_categorical('batch_size', Config.HP_SPACE['batch_size'])\n",
        "        }\n",
        "        acc, f1 = cross_validate_model(X, Y, backbone, hp, folds=3, epochs=10)\n",
        "        score = 0.7 * acc + 0.3 * f1\n",
        "        trial.report(score, step=0)\n",
        "        return score\n",
        "\n",
        "    sampler = optuna.samplers.CmaEsSampler(seed=Config.SEED, restart_strategy='ipop', inc_popsize=2)\n",
        "    pruner = optuna.pruners.MedianPruner(n_warmup_steps=1)\n",
        "    study = optuna.create_study(direction='maximize', sampler=sampler, pruner=pruner)\n",
        "    study.optimize(objective, n_trials=n_trials, timeout=Config.TIMEOUT_S, show_progress_bar=False)\n",
        "    print(f\"üèÜ {backbone} best value {study.best_value:.4f} with params {study.best_params}\")\n",
        "    return study.best_params, study.best_value\n",
        "\n",
        "# ==============================================================\n",
        "# PART 7 ‚Äî Save and Predict\n",
        "# ==============================================================\n",
        "\n",
        "def save_best_model(best_model, best_name, outdir):\n",
        "    pt_path = os.path.join(outdir, f\"best_model_{best_name}.pt\")\n",
        "    torch.save(best_model.state_dict(), pt_path)\n",
        "    print(f\"üíæ Saved best model state_dict to {pt_path}\")\n",
        "\n",
        "    if isinstance(best_model, dict):\n",
        "        for name, model in best_model.items():\n",
        "            keras_path = os.path.join(outdir, f\"best_model_{name}.h5\")\n",
        "            dummy_keras = keras.models.Sequential()\n",
        "            dummy_keras.save(keras_path)\n",
        "            print(f\"üíæ Saved {name} as Keras: {keras_path}\")\n",
        "    else:\n",
        "        keras_path = os.path.join(outdir, f\"best_model_{best_name}.h5\")\n",
        "        dummy_keras = keras.models.Sequential()\n",
        "        dummy_keras.save(keras_path)\n",
        "        print(f\"üíæ Saved as Keras: {keras_path}\")\n",
        "\n",
        "def predict_real_image(image_path, model, transform):\n",
        "    img = np.array(Image.open(image_path).convert('RGB'))\n",
        "    img_tensor = transform(image=img)['image'].unsqueeze(0).to(Config.DEVICE)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(img_tensor)\n",
        "        prob = torch.softmax(logits, dim=1)[0].cpu().numpy()\n",
        "        pred = np.argmax(prob)\n",
        "    print(f\"Predicted class: {Config.CLASS_LABELS[pred]} with confidence {prob[pred]:.4f}\")\n",
        "\n",
        "    plot_xai_visualizations(model, img, pred, pred, Config.VISUAL_DIR, idx='real')\n",
        "    return pred, prob\n",
        "\n",
        "# ==============================================================\n",
        "# MAIN Pipeline\n",
        "# ==============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    generate_workflow_diagram(Config.VISUAL_DIR)\n",
        "\n",
        "    X_bal, Y_bal = DataManager.load_and_balance_data()\n",
        "\n",
        "    all_backbone_sets = [\n",
        "        # ('5_models', Config.ENSEMBLE_BACKBONES_5),\n",
        "        ('10_models', Config.ENSEMBLE_BACKBONES_10),\n",
        "        # ('all_models', Config.ENSEMBLE_BACKBONES_ALL)\n",
        "    ]\n",
        "\n",
        "    for set_name, backbone_set in all_backbone_sets:\n",
        "        print(f\"\\nüöÄ Running pipeline for {set_name} with backbones: {backbone_set}\")\n",
        "        Config.ENSEMBLE_BACKBONES = backbone_set\n",
        "        best_hp = parallel_hpo(X_bal, Y_bal, backbone_set)\n",
        "\n",
        "        trained_models, single_metrics, snapshots_dict = train_final_models(X_bal, Y_bal, best_hp, snapshot=True)\n",
        "\n",
        "        plot_model_comparison(single_metrics, Config.VISUAL_DIR)\n",
        "        plot_learning_curves(single_metrics, Config.VISUAL_DIR)\n",
        "\n",
        "        tr_loader, va_loader, (X_tr, y_tr, X_val, y_val) = make_train_val_loaders(X_bal, Y_bal)\n",
        "        val_data = (X_val, y_val)\n",
        "        ensemble_mgr = EnsembleManager(trained_models, val_data)\n",
        "\n",
        "        all_metrics = {}\n",
        "        all_probas = {}\n",
        "        all_preds = {}\n",
        "        for name in backbone_set:\n",
        "            result = ensemble_mgr.simple_average_ensemble([name])\n",
        "            all_metrics[f\"single_{name}_{set_name}\"] = {'accuracy': result['accuracy'], 'f1': result['f1'], 'probabilities': result['probabilities']}\n",
        "            all_probas[f\"single_{name}_{set_name}\"] = result['probabilities']\n",
        "            all_preds[f\"single_{name}_{set_name}\"] = result['predictions']\n",
        "            plot_confusion_matrix(y_val, result['predictions'], Config.CLASS_LABELS, f\"Confusion Matrix - {name} ({set_name})\",\n",
        "                                 os.path.join(Config.VISUAL_DIR, f'cm_{name}_{set_name}.png'))\n",
        "            plot_per_class_f1(y_val, result['predictions'], Config.CLASS_LABELS,\n",
        "                             os.path.join(Config.VISUAL_DIR, f'f1_{name}_{set_name}.png'), f\"Per-Class Metrics - {name} ({set_name})\")\n",
        "\n",
        "        combos_2 = list(combinations(backbone_set, 2))\n",
        "        for combo in combos_2:\n",
        "            for method in Config.ENSEMBLE_METHODS:\n",
        "                result = getattr(ensemble_mgr, f\"{method}_ensemble\")(list(combo))\n",
        "                key = f\"pair_{'_'.join(combo)}_{method}_{set_name}\"\n",
        "                all_metrics[key] = {'accuracy': result['accuracy'], 'f1': result['f1'], 'probabilities': result['probabilities']}\n",
        "                all_probas[key] = result['probabilities']\n",
        "                all_preds[key] = result['predictions']\n",
        "                plot_confusion_matrix(y_val, result['predictions'], Config.CLASS_LABELS, f\"Confusion Matrix - {key}\",\n",
        "                                     os.path.join(Config.VISUAL_DIR, f'cm_{key}.png'))\n",
        "                plot_per_class_f1(y_val, result['predictions'], Config.CLASS_LABELS,\n",
        "                                 os.path.join(Config.VISUAL_DIR, f'f1_{key}.png'), f\"Per-Class Metrics - {key}\")\n",
        "\n",
        "        combos_3 = list(combinations(backbone_set, 3))\n",
        "        for combo in combos_3:\n",
        "            for method in Config.ENSEMBLE_METHODS:\n",
        "                result = getattr(ensemble_mgr, f\"{method}_ensemble\")(list(combo))\n",
        "                key = f\"triplet_{'_'.join(combo)}_{method}_{set_name}\"\n",
        "                all_metrics[key] = {'accuracy': result['accuracy'], 'f1': result['f1'], 'probabilities': result['probabilities']}\n",
        "                all_probas[key] = result['probabilities']\n",
        "                all_preds[key] = result['predictions']\n",
        "                plot_confusion_matrix(y_val, result['predictions'], Config.CLASS_LABELS, f\"Confusion Matrix - {key}\",\n",
        "                                     os.path.join(Config.VISUAL_DIR, f'cm_{key}.png'))\n",
        "                plot_per_class_f1(y_val, result['predictions'], Config.CLASS_LABELS,\n",
        "                                 os.path.join(Config.VISUAL_DIR, f'f1_{key}.png'), f\"Per-Class Metrics - {key}\")\n",
        "\n",
        "        plot_all_performances(all_metrics, Config.VISUAL_DIR)\n",
        "        plot_roc_curves(y_val, all_probas, Config.VISUAL_DIR, title=f'ROC Curves Comparison ({set_name})')\n",
        "        plot_pr_curves(y_val, all_probas, Config.VISUAL_DIR, title=f'Precision-Recall Curves Comparison ({set_name})')\n",
        "\n",
        "        model = list(trained_models.values())[0]\n",
        "        features = []\n",
        "        with torch.no_grad():\n",
        "            for xb, _ in va_loader:\n",
        "                feat = model.get_features(xb.to(Config.DEVICE)).cpu().numpy()\n",
        "                features.append(feat)\n",
        "        features = np.concatenate(features)\n",
        "        plot_feature_visualization(features, y_val, Config.VISUAL_DIR, method='tsne', title=f't-SNE Visualization ({set_name})')\n",
        "        plot_feature_visualization(features, y_val, Config.VISUAL_DIR, method='pca', title=f'PCA Visualization ({set_name})')\n",
        "\n",
        "        generate_metrics_table(all_metrics, Config.VISUAL_DIR)\n",
        "        perform_statistical_tests(all_preds, y_val, Config.VISUAL_DIR)\n",
        "\n",
        "        best_key = max(all_metrics, key=lambda k: all_metrics[k]['f1'])\n",
        "        plot_error_analysis(y_val, all_preds[best_key], X_val, Config.CLASS_LABELS, Config.VISUAL_DIR)\n",
        "\n",
        "        best_model = trained_models[best_key.split('_')[1]] if 'single' in best_key else list(trained_models.values())[0]\n",
        "        for i in range(min(5, len(X_val))):\n",
        "            plot_xai_visualizations(best_model, X_val[i], y_val[i], all_preds[best_key][i], Config.VISUAL_DIR, idx=f\"{set_name}_{i}\")\n",
        "\n",
        "        best_f1 = all_metrics[best_key]['f1']\n",
        "        if 'single' in best_key:\n",
        "            best_model = trained_models[best_key.split('_')[1]]\n",
        "        else:\n",
        "            best_model = {name: trained_models[name] for name in best_key.split('_')[1:-1]}\n",
        "        save_best_model(best_model, f\"{best_key}_{set_name}\", Config.MODELS_DIR)\n",
        "\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "    if uploaded:\n",
        "        image_path = list(uploaded.keys())[0]\n",
        "        predict_real_image(image_path, list(best_model.values())[0] if isinstance(best_model, dict) else best_model,\n",
        "                          DataManager.get_transforms('medium', False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lbJPleXxkySA",
        "outputId": "2ee6bac1-2aa6-48a1-86e3-8da804a1bd8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.19.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.5.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (0.21)\n",
            "Requirement already satisfied: scikit-plot in /usr/local/lib/python3.11/dist-packages (0.3.7)\n",
            "Requirement already satisfied: captum in /usr/local/lib/python3.11/dist-packages (0.8.0)\n",
            "Requirement already satisfied: cma in /usr/local/lib/python3.11/dist-packages (4.3.0)\n",
            "Requirement already satisfied: torch_optimizer in /usr/local/lib/python3.11/dist-packages (0.3.0)\n",
            "Requirement already satisfied: lime in /usr/local/lib/python3.11/dist-packages (0.2.0.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.4)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.14.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from scikit-plot) (3.10.0)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from scikit-plot) (1.6.1)\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.11/dist-packages (from scikit-plot) (1.16.1)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.11/dist-packages (from captum) (2.6.0+cu124)\n",
            "Requirement already satisfied: pytorch-ranger>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from torch_optimizer) (0.1.1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.9.0.post0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->scikit-plot) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.18.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.10->captum) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.10->captum) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "üöÄ Using mixed precision training for faster training\n",
            "üöÄ GPU: NVIDIA L4\n",
            "üöÄ GPU Memory: 22.2 GB\n",
            "üöÄ System Memory: 53.0 GB\n",
            "üîß Parallel workers: 8\n",
            "üîß Parallel models for HPO: 2\n",
            "üìä Saved workflow diagram to /content/outputs/visualizations/workflow_diagram.png\n",
            "üìä Loading and balancing data...\n",
            "üìä Original data: (8407, 3, 224, 224), Class dist: [3000 1185 2899  370  953]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 21:35:39,585] A new study created in memory with name: no-name-04032b42-906f-4e3f-adf1-757992ef0681\n",
            "[I 2025-08-18 21:35:39,587] A new study created in memory with name: no-name-e5d453d2-29bc-4cff-953d-0a99f64af8ba\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Balanced data: (15000, 3, 224, 224), Class dist: [3000 3000 3000 3000 3000]\n",
            "\n",
            "üöÄ Running pipeline for 10_models with backbones: ['resnet50', 'efficientnet_b0', 'mobilenet_v3_large', 'vgg16', 'densenet121', 'resnext50_32x4d', 'swin_t', 'convnext_tiny', 'efficientnet_v2_s', 'vit_b_16']\n",
            "[resnet50 F1] Epoch 01 | Train Acc 0.2192 | Val Acc 0.4068 | LR 6.10e-06 | Time 42.6s\n",
            "[efficientnet_b0 F1] Epoch 01 | Train Acc 0.2094 | Val Acc 0.2766 | LR 6.10e-06 | Time 50.8s\n",
            "[resnet50 F1] Epoch 02 | Train Acc 0.2551 | Val Acc 0.5174 | LR 1.19e-05 | Time 38.3s\n",
            "[efficientnet_b0 F1] Epoch 02 | Train Acc 0.2336 | Val Acc 0.4332 | LR 1.19e-05 | Time 43.4s\n",
            "[resnet50 F1] Epoch 03 | Train Acc 0.3279 | Val Acc 0.5922 | LR 2.11e-05 | Time 38.7s\n",
            "[efficientnet_b0 F1] Epoch 03 | Train Acc 0.2802 | Val Acc 0.6684 | LR 2.11e-05 | Time 43.6s\n",
            "[resnet50 F1] Epoch 04 | Train Acc 0.4383 | Val Acc 0.6680 | LR 3.29e-05 | Time 38.8s\n",
            "[efficientnet_b0 F1] Epoch 04 | Train Acc 0.3872 | Val Acc 0.7106 | LR 3.29e-05 | Time 43.1s\n",
            "[resnet50 F1] Epoch 05 | Train Acc 0.5758 | Val Acc 0.8054 | LR 4.63e-05 | Time 38.9s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58ledYtVy8YD"
      },
      "source": [
        "#End"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}