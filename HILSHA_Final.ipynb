{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran012x/Transfer-Models/blob/main/HILSHA_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Co-Lab -->> Drive"
      ],
      "metadata": {
        "id": "WrRU5QMl0UZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "# # Upload a file\n",
        "# uploaded = files.upload()\n",
        "# # Get the file name\n",
        "# file_name = list(uploaded.keys())[0]\n",
        "# print(f\"Uploaded file: {file_name}\")\n",
        "\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# # with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_224_11k.zip', 'r') as zip_ref:\n",
        "# #     zip_ref.extractall('')\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')"
      ],
      "metadata": {
        "id": "uaVTAQGY0a4A",
        "outputId": "f79d94a1-c5af-4c17-8e14-13826e46e718",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocess and Save"
      ],
      "metadata": {
        "id": "bIrUcpjq0P9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import gc\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import threading\n",
        "import zipfile\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "# Define fish classes and dataset paths\n",
        "fish_classes = ['ilish', 'chandana', 'sardin', 'sardinella', 'punctatus'] #0,1,2,3,4\n",
        "zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip').extractall('/content/.hidden_fish')\n",
        "data_dir = '/content/.hidden_fish'\n",
        "\n",
        "image_limits = {\n",
        "    'ilish': 3000,\n",
        "    'chandana': 1185,\n",
        "    'sardin': 2899,\n",
        "    'sardinella': 370,\n",
        "    'punctatus': 953\n",
        "}\n",
        "\n",
        "# Settings\n",
        "total_images = sum(image_limits.values())\n",
        "batch_size = 100\n",
        "num_threads = 4\n",
        "\n",
        "\n",
        "# Output paths\n",
        "output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "xdata_file = os.path.join(output_dir, 'X_data.npy')\n",
        "\n",
        "save_lock = threading.Lock()  # for thread-safe writes -> Prevents race conditions when multiple threads write to the same list.\n",
        "\n",
        "# Function to gather image paths\n",
        "def get_image_paths(class_name, max_images):\n",
        "    path = os.path.join(data_dir, class_name)\n",
        "    files = sorted(os.listdir(path))\n",
        "    random.shuffle(files)\n",
        "    return [os.path.join(path, f) for f in files[:max_images]]\n",
        "\n",
        "# Load and preprocess batch\n",
        "def load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "    end_idx = min(start_idx + batch_size, len(image_paths))\n",
        "    batch_paths = image_paths[start_idx:end_idx]\n",
        "    batch_images = []\n",
        "\n",
        "    for img_path in batch_paths:\n",
        "        img = Image.open(img_path).resize((224, 224)).convert('RGB')\n",
        "        img_tensor = torch.tensor(np.array(img), dtype=torch.uint8).permute(2, 0, 1)  # C x H x W\n",
        "        batch_images.append(img_tensor)\n",
        "\n",
        "    batch_tensor = torch.stack(batch_images)  # B x C x H x W\n",
        "    batch_labels = np.full((len(batch_images),), class_idx, dtype=np.int32)\n",
        "    return batch_tensor, batch_labels\n",
        "\n",
        "# Process one batch and return tensors & labels (no file saving)\n",
        "def process_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "    return load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx)\n",
        "\n",
        "def preprocess_and_save_all(overwrite=True):\n",
        "    if os.path.exists(labels_file) and os.path.exists(xdata_file) and not overwrite:\n",
        "        print(\"Preprocessed data already exists. Set overwrite=True to reprocess.\")\n",
        "        return\n",
        "\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "    processed_count = 0\n",
        "\n",
        "    for idx, class_name in enumerate(fish_classes):\n",
        "        print(f\"\\nProcessing class: {class_name}\")\n",
        "        image_paths = get_image_paths(class_name, image_limits[class_name])\n",
        "        total_batches = (len(image_paths) + batch_size - 1) // batch_size\n",
        "        #It ensures ceiling division ‚Äî rounding up, not down.\n",
        "        # Normal division: 103 / 20 = 5.15 ‚Üí floor division // 20 = 5 (‚ùå missing last 3 images)\n",
        "        # This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ‚úÖ\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "            futures = []\n",
        "            for start in range(0, len(image_paths), batch_size):\n",
        "                futures.append(executor.submit(process_batch, image_paths, start, batch_size, idx))\n",
        "\n",
        "            for future in tqdm(as_completed(futures), total=total_batches, desc=class_name):#taqaddum (ÿ™ŸÇÿØŸëŸÖ) ‚Äì Arabic for \"progress\".\n",
        "                # futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\n",
        "                # as_completed(futures): Yields each future as it finishes (not in order).\n",
        "\n",
        "                batch_tensor, batch_labels = future.result()\n",
        "                with save_lock: #Locks this section so that only one thread can update the shared lists safely.\n",
        "                    all_images.append(batch_tensor)\n",
        "                    all_labels.append(batch_labels)\n",
        "                    processed_count += batch_tensor.size(0)\n",
        "                    print(f\"Processed batch with {batch_tensor.size(0)} images, total processed: {processed_count}/{total_images}\")\n",
        "                gc.collect()\n",
        "\n",
        "    # Combine all tensors and labels\n",
        "    X = torch.cat(all_images, dim=0).numpy()\n",
        "    Y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "    # Save final arrays\n",
        "    np.save(xdata_file, X, allow_pickle=False)#Malicious .npy -> import os;os.system(\"rm -rf /\")  # ‚Üê Dangerous command\n",
        "    np.save(labels_file, Y, allow_pickle=False)\n",
        "\n",
        "    print(f\"\\n‚úÖ Done! Saved {processed_count} images in {xdata_file}\")\n",
        "    print(f\"X_data shape: {X.shape}, Y_labels shape: {Y.shape}\")\n",
        "\n",
        "    if processed_count != total_images:\n",
        "        raise ValueError(f\"Expected {total_images} images, but processed {processed_count}\")\n",
        "\n",
        "# Run preprocessing and save directly to X_data.npy and Y_labels.npy\n",
        "preprocess_and_save_all(overwrite=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k9WJIX0qbYSw",
        "outputId": "598d0a82-93b4-43d2-f5bf-692c7e16ced4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n",
            "GPU Name: NVIDIA L4\n",
            "\n",
            "Processing class: ilish\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ilish:   3%|‚ñé         | 1/30 [00:46<22:39, 46.88s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 100/8407\n",
            "Processed batch with 100 images, total processed: 200/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ilish:  13%|‚ñà‚ñé        | 4/30 [00:47<03:30,  8.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 300/8407\n",
            "Processed batch with 100 images, total processed: 400/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  17%|‚ñà‚ñã        | 5/30 [01:30<08:14, 19.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 500/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  20%|‚ñà‚ñà        | 6/30 [01:31<05:29, 13.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 600/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  23%|‚ñà‚ñà‚ñé       | 7/30 [01:32<03:39,  9.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 700/8407\n",
            "Processed batch with 100 images, total processed: 800/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ilish:  30%|‚ñà‚ñà‚ñà       | 9/30 [02:14<06:08, 17.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 900/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  33%|‚ñà‚ñà‚ñà‚ñé      | 10/30 [02:16<04:12, 12.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 1000/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  37%|‚ñà‚ñà‚ñà‚ñã      | 11/30 [02:16<02:49,  8.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 1100/8407\n",
            "Processed batch with 100 images, total processed: 1200/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 13/30 [03:01<04:19, 15.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 1300/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 14/30 [03:03<03:12, 12.04s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 1400/8407\n",
            "Processed batch with 100 images, total processed: 1500/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ilish:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 16/30 [03:04<01:32,  6.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 1600/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 17/30 [03:49<03:44, 17.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 1700/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 18/30 [03:50<02:34, 12.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 1800/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 19/30 [03:51<01:41,  9.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 1900/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 20/30 [03:52<01:08,  6.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 2000/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 21/30 [04:35<02:38, 17.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 2100/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 22/30 [04:36<01:41, 12.69s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 2200/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 23/30 [04:37<01:03,  9.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 2300/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 24/30 [04:39<00:41,  6.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 2400/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 25/30 [05:23<01:29, 17.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 2500/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 26/30 [05:24<00:52, 13.06s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 2600/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 27/30 [05:26<00:28,  9.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 2700/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 28/30 [05:27<00:14,  7.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 2800/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rilish:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 29/30 [05:55<00:13, 13.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 2900/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ilish: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 30/30 [05:56<00:00, 11.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 3000/8407\n",
            "\n",
            "Processing class: chandana\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "chandana:   8%|‚ñä         | 1/12 [00:31<05:41, 31.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 3100/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rchandana:  17%|‚ñà‚ñã        | 2/12 [00:34<02:27, 14.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 3200/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rchandana:  25%|‚ñà‚ñà‚ñå       | 3/12 [00:35<01:16,  8.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 3300/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rchandana:  33%|‚ñà‚ñà‚ñà‚ñé      | 4/12 [00:37<00:46,  5.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 3400/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rchandana:  42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 5/12 [01:04<01:34, 13.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 3500/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rchandana:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 6/12 [01:10<01:06, 11.17s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 3600/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rchandana:  58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 7/12 [01:12<00:39,  7.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 3700/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rchandana:  67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 8/12 [01:12<00:22,  5.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 3800/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rchandana:  75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 9/12 [01:37<00:34, 11.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 3900/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rchandana:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 10/12 [01:39<00:17,  8.78s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 85 images, total processed: 3985/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rchandana:  92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 11/12 [01:44<00:07,  7.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 4085/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "chandana: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [01:45<00:00,  8.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 4185/8407\n",
            "\n",
            "Processing class: sardin\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sardin:   3%|‚ñé         | 1/29 [00:30<14:05, 30.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 4285/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:   7%|‚ñã         | 2/29 [00:33<06:26, 14.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 4385/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  10%|‚ñà         | 3/29 [00:35<03:43,  8.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 4485/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  14%|‚ñà‚ñç        | 4/29 [00:35<02:17,  5.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 4585/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  17%|‚ñà‚ñã        | 5/29 [01:02<05:18, 13.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 4685/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  21%|‚ñà‚ñà        | 6/29 [01:08<04:05, 10.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 4785/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  24%|‚ñà‚ñà‚ñç       | 7/29 [01:10<02:54,  7.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 4885/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  28%|‚ñà‚ñà‚ñä       | 8/29 [01:11<01:59,  5.68s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 4985/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  31%|‚ñà‚ñà‚ñà       | 9/29 [01:41<04:23, 13.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 5085/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  34%|‚ñà‚ñà‚ñà‚ñç      | 10/29 [01:46<03:23, 10.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 5185/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  38%|‚ñà‚ñà‚ñà‚ñä      | 11/29 [01:47<02:18,  7.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 5285/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  41%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 12/29 [01:52<01:57,  6.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 5385/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  45%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 13/29 [02:18<03:24, 12.76s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 5485/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 14/29 [02:25<02:43, 10.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 5585/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 15/29 [02:26<01:52,  8.05s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 5685/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 16/29 [02:31<01:29,  6.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 5785/8407\n",
            "Processed batch with 100 images, total processed: 5885/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sardin:  62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 18/29 [03:03<01:57, 10.67s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 5985/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 19/29 [03:07<01:27,  8.80s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 6085/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 20/29 [03:09<00:59,  6.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 6185/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 21/29 [03:39<01:48, 13.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 6285/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 22/29 [03:42<01:14, 10.65s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 6385/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sardin:  83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 24/29 [03:48<00:31,  6.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 6485/8407\n",
            "Processed batch with 100 images, total processed: 6585/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 25/29 [04:18<00:54, 13.52s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 6685/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 26/29 [04:23<00:33, 11.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 6785/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 27/29 [04:25<00:16,  8.30s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 6885/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rsardin:  97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 28/29 [04:25<00:05,  5.90s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 6985/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sardin: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [04:44<00:00,  9.81s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 99 images, total processed: 7084/8407\n",
            "\n",
            "Processing class: sardinella\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sardinella:  25%|‚ñà‚ñà‚ñå       | 1/4 [00:30<01:31, 30.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 70 images, total processed: 7154/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sardinella: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:42<00:00, 10.52s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 7254/8407\n",
            "Processed batch with 100 images, total processed: 7354/8407\n",
            "Processed batch with 100 images, total processed: 7454/8407\n",
            "\n",
            "Processing class: punctatus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "punctatus:  10%|‚ñà         | 1/10 [00:34<05:09, 34.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 7554/8407\n",
            "Processed batch with 100 images, total processed: 7654/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "punctatus:  30%|‚ñà‚ñà‚ñà       | 3/10 [00:35<00:58,  8.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 7754/8407\n",
            "Processed batch with 100 images, total processed: 7854/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "punctatus:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 5/10 [01:11<01:19, 15.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 7954/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rpunctatus:  60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 6/10 [01:12<00:43, 10.82s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 8054/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rpunctatus:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 7/10 [01:12<00:22,  7.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 8154/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rpunctatus:  80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 8/10 [01:13<00:10,  5.26s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 8254/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rpunctatus:  90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 9/10 [01:25<00:07,  7.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 53 images, total processed: 8307/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "punctatus: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [01:35<00:00,  9.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed batch with 100 images, total processed: 8407/8407\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Done! Saved 8407 images in /content/drive/MyDrive/Hilsha/X_data.npy\n",
            "X_data shape: (8407, 3, 224, 224), Y_labels shape: (8407,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DATA LOADING...."
      ],
      "metadata": {
        "id": "qz9kAvggeF0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Your data path\n",
        "output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "data_file = os.path.join(output_dir, 'X_data.npy')\n",
        "labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "\n",
        "# Readable size format\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    for unit in ['', 'K', 'M', 'G', 'T']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return f\"{num:3.2f} {unit}{suffix}\"\n",
        "        num /= 1024.0\n",
        "    return f\"{num:.2f} T{suffix}\"\n",
        "\n",
        "# Main loader\n",
        "def load_preprocessed_data(as_torch=True, normalize=True, to_device=None):\n",
        "    # Check file existence #cpu,cuda (CUDA stands for Compute Unified Device Architecture.)\n",
        "    for path in [data_file, labels_file]:\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Missing: {path}\")\n",
        "\n",
        "    # Print file sizes\n",
        "    print(f\"üìÅ X_data.npy: {sizeof_fmt(os.path.getsize(data_file))}\")\n",
        "    print(f\"üìÅ Y_labels.npy: {sizeof_fmt(os.path.getsize(labels_file))}\")\n",
        "\n",
        "    # Load with mmap\n",
        "    X = np.load(data_file, mmap_mode='r')\n",
        "    Y = np.load(labels_file, mmap_mode='r')\n",
        "\n",
        "    print(f\"‚úÖ X shape: {X.shape}, dtype: {X.dtype}\")\n",
        "    print(f\"‚úÖ Y shape: {Y.shape}, dtype: {Y.dtype}\")\n",
        "\n",
        "    # Sanity check\n",
        "    if len(X) != len(Y):\n",
        "        raise ValueError(\"Mismatch between number of samples in X and Y\")\n",
        "\n",
        "    # Convert to torch\n",
        "    if as_torch:\n",
        "        X = torch.from_numpy(X)\n",
        "        Y = torch.from_numpy(Y)\n",
        "\n",
        "        if normalize and X.dtype == torch.uint8:\n",
        "            X = X.float() / 255.0\n",
        "\n",
        "        if to_device:\n",
        "            X = X.to(to_device)\n",
        "            Y = Y.to(to_device)\n",
        "\n",
        "        print(f\"üß† Torch tensors ready on {to_device or 'CPU'}\")\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# üîÅ Example call\n",
        "X, Y = load_preprocessed_data(\n",
        "    as_torch=True,\n",
        "    normalize=True,\n",
        "    to_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlSz9YmOB1iW",
        "outputId": "de1f0f8f-51bc-4710-9d5f-ea3d05513db9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ X_data.npy: 1.18 GB\n",
            "üìÅ Y_labels.npy: 32.96 KB\n",
            "‚úÖ X shape: (8407, 3, 224, 224), dtype: uint8\n",
            "‚úÖ Y shape: (8407,), dtype: int32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614331559.py:42: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  X = torch.from_numpy(X)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Torch tensors ready on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# XAI ENSEMBLE (ONE CELL) ‚Äî TRAIN + HPO + EVALUATE + EXPLAIN\n",
        "# Q1-ready visualizations + .keras saving\n",
        "# =========================\n",
        "\n",
        "# ---------- Install ----------\n",
        "!pip -q install imbalanced-learn\n",
        "\n",
        "# ---------- Imports ----------\n",
        "import os, gc, cv2, random, warnings, itertools\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import mixed_precision\n",
        "from tensorflow.keras.applications import ResNet50, EfficientNetB0\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, LeakyReLU, BatchNormalization\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (classification_report, accuracy_score, f1_score, confusion_matrix,\n",
        "                             roc_curve, auc, precision_recall_curve)\n",
        "from sklearn.calibration import calibration_curve\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from collections import Counter\n",
        "\n",
        "# ---------- Colab: Drive Mount ----------\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# ---------- Reproducibility ----------\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# ---------- Mixed Precision & GPU Growth ----------\n",
        "try:\n",
        "    mixed_precision.set_global_policy('mixed_float16')\n",
        "except Exception as e:\n",
        "    print(\"Mixed precision not set:\", e)\n",
        "\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        try:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "        except:\n",
        "            pass\n",
        "    print(f\"{len(gpus)} GPU(s) detected.\")\n",
        "else:\n",
        "    print(\"No GPU detected. Running on CPU.\")\n",
        "\n",
        "# ---------- USER PATHS ----------\n",
        "DATA_FILE   = '/content/drive/MyDrive/Hilsha/X_data.npy'\n",
        "LABELS_FILE = '/content/drive/MyDrive/Hilsha/Y_labels.npy'\n",
        "\n",
        "# ---------- Core Params ----------\n",
        "input_shape  = (224, 224, 3)\n",
        "num_classes  = 5\n",
        "class_labels = ['Ilish', 'Chandana', 'Sardin', 'Sardinella', 'Punctatus']\n",
        "\n",
        "# Training knobs (increase later for final runs)\n",
        "epochs       = 10         # start small; increase to 30-100 for final paper runs\n",
        "batch_size   = 16\n",
        "k_folds      = 5\n",
        "\n",
        "# Data strategy\n",
        "USE_SMOTE                = False  # ‚ö†Ô∏è For images, SMOTE on flattened pixels is not ideal; prefer class weights\n",
        "AUG_MIXUP_CUTOOUT        = False  # keep False for stability; can replace with tf.image mixup/cutout later\n",
        "\n",
        "# ---------- Load Data ----------\n",
        "if not (os.path.exists(DATA_FILE) and os.path.exists(LABELS_FILE)):\n",
        "    raise FileNotFoundError(\"Preprocessed data files not found. Please check DATA_FILE and LABELS_FILE.\")\n",
        "\n",
        "X = np.load(DATA_FILE, mmap_mode='r')  # expect (N, H, W, C)\n",
        "Y = np.load(LABELS_FILE, mmap_mode='r')  # integer labels 0..num_classes-1\n",
        "print(f\"Loaded X: {X.shape}, Y: {Y.shape}, dtype={X.dtype}\")\n",
        "\n",
        "# Fix CHW->HWC if needed\n",
        "if len(X.shape) != 4:\n",
        "    raise ValueError(f\"X must be 4D (N,H,W,C), got {X.shape}\")\n",
        "if X.shape[1] == 3 and X.shape[-1] != 3:\n",
        "    X = np.transpose(X, (0,2,3,1))\n",
        "    print(\"Transposed to HWC:\", X.shape)\n",
        "elif X.shape[-1] != 3:\n",
        "    raise ValueError(f\"Expected 3 channels, got last dim: {X.shape[-1]}\")\n",
        "\n",
        "# Ensure float32\n",
        "if X.dtype != np.float32:\n",
        "    X = X.astype(np.float32)\n",
        "\n",
        "# ---------- Train/Test Split ----------\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "    X, Y, test_size=0.2, stratify=Y, random_state=SEED\n",
        ")\n",
        "\n",
        "# Normalize [0,1] if still 0-255\n",
        "if X_train.max() > 1.5:\n",
        "    X_train /= 255.0\n",
        "    X_test  /= 255.0\n",
        "\n",
        "# ---------- Class Weights (preferable to SMOTE for images) ----------\n",
        "def compute_class_weights(y):\n",
        "    counts = Counter(y)\n",
        "    total  = sum(counts.values())\n",
        "    weights = {cls: total/(num_classes*count) for cls, count in counts.items()}\n",
        "    return weights\n",
        "\n",
        "class_weights_full = compute_class_weights(Y_train)\n",
        "print(\"Class weights:\", class_weights_full)\n",
        "\n",
        "# ---------- Optional SMOTE (Not recommended for images; keep off unless needed) ----------\n",
        "if USE_SMOTE:\n",
        "    print(\"Applying SMOTE (may harm image structure; use with caution)...\")\n",
        "    X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
        "    X_train_resampled_flat, Y_train_resampled = SMOTE(random_state=SEED).fit_resample(X_train_flat, Y_train)\n",
        "    X_train = X_train_resampled_flat.reshape(-1, *input_shape).astype(np.float32)\n",
        "    Y_train = Y_train_resampled\n",
        "    print(\"After SMOTE:\", X_train.shape, Counter(Y_train))\n",
        "\n",
        "# ---------- Data Augmentation ----------\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20, width_shift_range=0.2, height_shift_range=0.2,\n",
        "    shear_range=0.15, zoom_range=0.2, horizontal_flip=True, fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "def batch_generator(X, Y, batch_size=32):\n",
        "    size = X.shape[0]\n",
        "    while True:\n",
        "        idx = np.random.permutation(size)\n",
        "        for start in range(0, size, batch_size):\n",
        "            batch_idx = idx[start:min(start+batch_size, size)]\n",
        "            Xb, Yb = X[batch_idx], Y[batch_idx]\n",
        "            Yb_oh = to_categorical(Yb, num_classes)\n",
        "            Xb_aug = next(datagen.flow(Xb, batch_size=len(Xb), shuffle=False))\n",
        "            yield Xb_aug, Yb_oh\n",
        "\n",
        "# ---------- Model Factory with HPO ----------\n",
        "def create_base_model(model_type='ResNet', lr=1e-3, dropout1=0.5, dropout2=0.5,\n",
        "                      label_smoothing=0.0, unfreeze_last_n=10):\n",
        "    if model_type == 'ResNet':\n",
        "        base = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    else:\n",
        "        base = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    # Freeze all then unfreeze last N\n",
        "    for layer in base.layers:\n",
        "        layer.trainable = False\n",
        "    if unfreeze_last_n > 0:\n",
        "        for layer in base.layers[-unfreeze_last_n:]:\n",
        "            layer.trainable = True\n",
        "\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    x = Dense(256)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(negative_slope=0.1)(x)\n",
        "    x = Dropout(dropout1)(x)\n",
        "\n",
        "    x = Dense(128)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(negative_slope=0.1)(x)\n",
        "    x = Dropout(dropout2)(x)\n",
        "\n",
        "    # Important with mixed precision: final head outputs float32\n",
        "    out = Dense(num_classes, activation='softmax', dtype='float32')(x)\n",
        "\n",
        "    model = Model(inputs=base.input, outputs=out)\n",
        "    # label smoothing\n",
        "    loss = tf.keras.losses.CategoricalCrossentropy(label_smoothing=label_smoothing)\n",
        "    opt  = tf.keras.optimizers.Adam(learning_rate=lr)\n",
        "    model.compile(optimizer=opt, loss=loss, metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Small, practical HPO grid per fold (expand for final paper runs)\n",
        "HPO_GRID = {\n",
        "    \"lr\":              [5e-4, 1e-3, 2e-3],\n",
        "    \"dropout1\":        [0.4, 0.5],\n",
        "    \"dropout2\":        [0.3, 0.5],\n",
        "    \"label_smoothing\": [0.0, 0.05, 0.1],\n",
        "    \"unfreeze_last_n\": [10, 20]\n",
        "}\n",
        "def hpo_param_combinations(grid):\n",
        "    keys = list(grid.keys())\n",
        "    for values in itertools.product(*[grid[k] for k in keys]):\n",
        "        yield dict(zip(keys, values))\n",
        "\n",
        "# ---------- Ensemble Logic ----------\n",
        "def get_ensemble_predictions(resnet_probs, efficientnet_probs):\n",
        "    r_conf = np.max(resnet_probs, axis=1)\n",
        "    e_conf = np.max(efficientnet_probs, axis=1)\n",
        "    total  = r_conf + e_conf + 1e-9\n",
        "    rw = r_conf / total\n",
        "    ew = e_conf / total\n",
        "    ensemble = rw[:, None]*resnet_probs + ew[:, None]*efficientnet_probs\n",
        "    return ensemble, np.argmax(ensemble, axis=1)\n",
        "\n",
        "# ---------- K-Fold Training + HPO (picks best config per fold) ----------\n",
        "def train_with_kfold_hpo(Xall, Yall, k=5, batch_size=16, epochs=10):\n",
        "    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=SEED)\n",
        "    best_fold = None\n",
        "    best_fold_acc = -1\n",
        "    best_fold_assets = None\n",
        "\n",
        "    fold_summaries = []\n",
        "    fold_idx = 0\n",
        "    for tr_idx, val_idx in skf.split(Xall, Yall):\n",
        "        fold_idx += 1\n",
        "        print(f\"\\n===== Fold {fold_idx}/{k} =====\")\n",
        "\n",
        "        Xtr, Xval = Xall[tr_idx], Xall[val_idx]\n",
        "        Ytr, Yval = Yall[tr_idx], Yall[val_idx]\n",
        "\n",
        "        # Per-fold class weights\n",
        "        class_weights = compute_class_weights(Ytr)\n",
        "\n",
        "        train_gen = batch_generator(Xtr, Ytr, batch_size)\n",
        "        val_gen   = batch_generator(Xval, Yval, batch_size)\n",
        "        steps_per_epoch  = max(1, len(Xtr)//batch_size)\n",
        "        val_steps        = max(1, len(Xval)//batch_size)\n",
        "\n",
        "        best_cfg, best_acc, best_models, best_histories = None, -1, None, None\n",
        "\n",
        "        # Hyperparameter search\n",
        "        for cfg in hpo_param_combinations(HPO_GRID):\n",
        "            print(f\" HPO trial: {cfg}\")\n",
        "            resnet = create_base_model('ResNet', **cfg)\n",
        "            effnet = create_base_model('EfficientNet', **cfg)\n",
        "\n",
        "            callbacks = [\n",
        "                ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=0),\n",
        "                EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True, verbose=0)\n",
        "            ]\n",
        "\n",
        "            hist_r = resnet.fit(\n",
        "                train_gen, validation_data=val_gen, epochs=epochs,\n",
        "                steps_per_epoch=steps_per_epoch, validation_steps=val_steps,\n",
        "                # class_weight=class_weights,\n",
        "                verbose=0, callbacks=callbacks\n",
        "            )\n",
        "            hist_e = effnet.fit(\n",
        "                train_gen, validation_data=val_gen, epochs=epochs,\n",
        "                steps_per_epoch=steps_per_epoch, validation_steps=val_steps,\n",
        "                # class_weight=class_weights,\n",
        "                verbose=0, callbacks=callbacks\n",
        "            )\n",
        "\n",
        "            # Eval on raw val (no aug)\n",
        "            r_probs = resnet.predict(Xval, batch_size=batch_size, verbose=0)\n",
        "            e_probs = effnet.predict(Xval, batch_size=batch_size, verbose=0)\n",
        "            ens_probs, ens_pred = get_ensemble_predictions(r_probs, e_probs)\n",
        "            acc = accuracy_score(Yval, ens_pred)\n",
        "            print(f\"  ‚Üí Val ACC: {acc:.4f}\")\n",
        "\n",
        "            if acc > best_acc:\n",
        "                best_acc = acc\n",
        "                best_cfg = cfg\n",
        "                best_models = (resnet, effnet)\n",
        "                best_histories = (hist_r.history, hist_e.history)\n",
        "\n",
        "        print(f\"Best HPO for fold {fold_idx}: ACC={best_acc:.4f}, CFG={best_cfg}\")\n",
        "        fold_summaries.append((fold_idx, best_acc, best_cfg))\n",
        "\n",
        "        # Track global best fold\n",
        "        if best_acc > best_fold_acc:\n",
        "            best_fold_acc = best_acc\n",
        "            best_fold = fold_idx\n",
        "            best_fold_assets = (best_models, (Xval, Yval), best_histories)\n",
        "\n",
        "        # clear graphs between folds except the best fold assets (kept by reference)\n",
        "        tf.keras.backend.clear_session()\n",
        "        gc.collect()\n",
        "\n",
        "    print(f\"\\n==> Best fold overall: {best_fold} with Val ACC={best_fold_acc:.4f}\")\n",
        "\n",
        "    # Save best fold models as .keras\n",
        "    (resnet_best, effnet_best), (Xval_best, Yval_best), best_histories = best_fold_assets\n",
        "    save_resnet_path = \"/content/resnet_fish_model.keras\"\n",
        "    save_eff_path    = \"/content/efficientnet_fish_model.keras\"\n",
        "    resnet_best.save(save_resnet_path)\n",
        "    effnet_best.save(save_eff_path)\n",
        "    print(f\"Saved best fold models:\\n  {save_resnet_path}\\n  {save_eff_path}\")\n",
        "\n",
        "    return save_resnet_path, save_eff_path, (Xval_best, Yval_best), best_histories, fold_summaries\n",
        "\n",
        "# ---------- Train + HPO + Save ----------\n",
        "save_resnet_path, save_eff_path, (Xval_best, Yval_best), best_histories, fold_summaries = train_with_kfold_hpo(\n",
        "    X_train, Y_train, k=k_folds, batch_size=batch_size, epochs=epochs\n",
        ")\n",
        "\n",
        "# ---------- Final Test Evaluation ----------\n",
        "resnet_model = load_model(save_resnet_path)\n",
        "eff_model    = load_model(save_eff_path)\n",
        "\n",
        "r_probs = resnet_model.predict(X_test, batch_size=batch_size, verbose=0)\n",
        "e_probs = eff_model.predict(X_test, batch_size=batch_size, verbose=0)\n",
        "ens_probs, ens_pred = get_ensemble_predictions(r_probs, e_probs)\n",
        "\n",
        "test_acc = accuracy_score(Y_test, ens_pred)\n",
        "test_f1  = f1_score(Y_test, ens_pred, average='weighted')\n",
        "print(f\"\\nTEST ‚Äî Ensemble Accuracy: {test_acc:.4f} | F1 (weighted): {test_f1:.4f}\")\n",
        "print(\"\\nClassification Report (Ensemble on Test):\\n\",\n",
        "      classification_report(Y_test, ens_pred, target_names=class_labels))\n",
        "\n",
        "# =========================\n",
        "# Q1 VISUALIZATIONS\n",
        "# =========================\n",
        "\n",
        "# --- 1) Training Curves from Best Fold ---\n",
        "def plot_training_curves(hist_r, hist_e, title_suffix=\"(Best Fold)\"):\n",
        "    fig, axes = plt.subplots(1, 2, figsize=(14,5))\n",
        "    # Accuracy\n",
        "    axes[0].plot(hist_r.get('accuracy', []), label='ResNet Train')\n",
        "    axes[0].plot(hist_r.get('val_accuracy', []), label='ResNet Val')\n",
        "    axes[0].plot(hist_e.get('accuracy', []), label='EffNet Train', linestyle='--')\n",
        "    axes[0].plot(hist_e.get('val_accuracy', []), label='EffNet Val', linestyle='--')\n",
        "    axes[0].set_title(f'Accuracy {title_suffix}')\n",
        "    axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Accuracy'); axes[0].grid(); axes[0].legend()\n",
        "\n",
        "    # Loss\n",
        "    axes[1].plot(hist_r.get('loss', []), label='ResNet Train')\n",
        "    axes[1].plot(hist_r.get('val_loss', []), label='ResNet Val')\n",
        "    axes[1].plot(hist_e.get('loss', []), label='EffNet Train', linestyle='--')\n",
        "    axes[1].plot(hist_e.get('val_loss', []), label='EffNet Val', linestyle='--')\n",
        "    axes[1].set_title(f'Loss {title_suffix}')\n",
        "    axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('Loss'); axes[1].grid(); axes[1].legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_training_curves(best_histories[0], best_histories[1])\n",
        "\n",
        "# --- 2) Confusion Matrix, Per-class metrics ---\n",
        "cm = confusion_matrix(Y_test, ens_pred)\n",
        "plt.figure(figsize=(7,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)\n",
        "plt.title('Confusion Matrix ‚Äî Test'); plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.show()\n",
        "\n",
        "report = classification_report(Y_test, ens_pred, target_names=class_labels, output_dict=True)\n",
        "df_metrics = pd.DataFrame(report).transpose().loc[class_labels, ['precision','recall','f1-score']]\n",
        "ax = df_metrics.plot(kind='bar', figsize=(8,5))\n",
        "plt.title('Per-Class Metrics ‚Äî Test'); plt.ylabel('Score'); plt.grid(axis='y')\n",
        "for p in ax.patches:\n",
        "    ax.annotate(f'{p.get_height():.2f}', (p.get_x()+p.get_width()/2, p.get_height()), ha='center', va='bottom', fontsize=9)\n",
        "plt.xticks(rotation=45); plt.show()\n",
        "\n",
        "# --- 3) ROC + PR Curves (One-vs-Rest) ---\n",
        "plt.figure(figsize=(7,6))\n",
        "for i, cls in enumerate(class_labels):\n",
        "    fpr, tpr, _ = roc_curve((Y_test==i).astype(int), ens_probs[:, i])\n",
        "    plt.plot(fpr, tpr, label=f'{cls} (AUC={auc(fpr,tpr):.2f})')\n",
        "plt.plot([0,1],[0,1],'k--')\n",
        "plt.title('ROC Curves ‚Äî Test'); plt.xlabel('FPR'); plt.ylabel('TPR'); plt.legend(); plt.grid(); plt.show()\n",
        "\n",
        "plt.figure(figsize=(7,6))\n",
        "for i, cls in enumerate(class_labels):\n",
        "    prec, rec, _ = precision_recall_curve((Y_test==i).astype(int), ens_probs[:, i])\n",
        "    plt.plot(rec, prec, label=cls)\n",
        "plt.title('Precision-Recall Curves ‚Äî Test'); plt.xlabel('Recall'); plt.ylabel('Precision'); plt.legend(); plt.grid(); plt.show()\n",
        "\n",
        "# --- 4) Calibration / Reliability Diagram ---\n",
        "def plot_reliability(probs, y_true, n_bins=10):\n",
        "    conf = np.max(probs, axis=1)\n",
        "    preds = np.argmax(probs, axis=1)\n",
        "    correct = (preds == y_true).astype(int)\n",
        "    prob_true, prob_pred = calibration_curve(correct, conf, n_bins=n_bins, strategy='uniform')\n",
        "    plt.figure(figsize=(6,6))\n",
        "    plt.plot([0,1],[0,1],'k--', label='Perfectly Calibrated')\n",
        "    plt.plot(prob_pred, prob_true, marker='o', label='Model')\n",
        "    plt.title('Reliability Diagram (Top-1 Confidence)')\n",
        "    plt.xlabel('Predicted probability'); plt.ylabel('Empirical accuracy'); plt.legend(); plt.grid(); plt.show()\n",
        "\n",
        "plot_reliability(ens_probs, Y_test)\n",
        "\n",
        "# =========================\n",
        "# EXPLAINABLE AI (GRAD-CAM)\n",
        "# =========================\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "def _last_conv_name_resnet(model):\n",
        "    try:\n",
        "        model.get_layer(\"conv5_block3_out\")\n",
        "        return \"conv5_block3_out\"\n",
        "    except:\n",
        "        # fallback\n",
        "        for layer in reversed(model.layers):\n",
        "            try:\n",
        "                if len(layer.output_shape) == 4:\n",
        "                    return layer.name\n",
        "            except: pass\n",
        "        raise ValueError(\"No conv layer found in ResNet.\")\n",
        "\n",
        "def _last_conv_name_effnet(model):\n",
        "    try:\n",
        "        model.get_layer(\"top_conv\")\n",
        "        return \"top_conv\"\n",
        "    except:\n",
        "        for layer in reversed(model.layers):\n",
        "            try:\n",
        "                if len(layer.output_shape) == 4:\n",
        "                    return layer.name\n",
        "            except: pass\n",
        "        raise ValueError(\"No conv layer found in EfficientNet.\")\n",
        "\n",
        "def get_gradcam_heatmap(model, img_array, last_conv_layer_name, pred_index=None):\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs],\n",
        "        [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "    with tf.GradientTape() as tape:\n",
        "        conv_out, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        target = preds[:, pred_index]\n",
        "    grads = tape.gradient(target, conv_out)\n",
        "    pooled = tf.reduce_mean(grads, axis=(0,1,2))\n",
        "    conv_out = conv_out[0]\n",
        "    heatmap = conv_out @ pooled[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = np.maximum(heatmap, 0)\n",
        "    denom = np.max(heatmap) if np.max(heatmap)>0 else 1e-9\n",
        "    heatmap = heatmap / denom\n",
        "    return heatmap\n",
        "\n",
        "def overlay_heatmap(heatmap, original_rgb, alpha=0.4):\n",
        "    h,w = original_rgb.shape[:2]\n",
        "    hm = cv2.resize(heatmap, (w,h))\n",
        "    hm = np.uint8(255*hm)\n",
        "    hm = cv2.applyColorMap(hm, cv2.COLORMAP_JET)\n",
        "    out = cv2.addWeighted(original_rgb, 1-alpha, hm, alpha, 0)\n",
        "    return out\n",
        "\n",
        "def predict_with_explanations(img_path, resnet_path=save_resnet_path, eff_path=save_eff_path, show=True):\n",
        "    # Load models\n",
        "    resnet = load_model(resnet_path)\n",
        "    effnet = load_model(eff_path)\n",
        "\n",
        "    # Load & preprocess\n",
        "    img = image.load_img(img_path, target_size=input_shape[:2])\n",
        "    img_arr = image.img_to_array(img).astype(np.float32) / 255.0\n",
        "    img_batch = np.expand_dims(img_arr, axis=0)\n",
        "\n",
        "    # Predict\n",
        "    r_probs = resnet.predict(img_batch, verbose=0)\n",
        "    e_probs = effnet.predict(img_batch, verbose=0)\n",
        "    ens_probs, _ = get_ensemble_predictions(r_probs, e_probs)\n",
        "\n",
        "    pred_idx = int(np.argmax(ens_probs[0]))\n",
        "    pred_label = class_labels[pred_idx]\n",
        "    probs_dict = {class_labels[i]: float(ens_probs[0, i]) for i in range(num_classes)}\n",
        "\n",
        "    # Grad-CAM\n",
        "    res_last = _last_conv_name_resnet(resnet)\n",
        "    eff_last = _last_conv_name_effnet(effnet)\n",
        "    r_heat = get_gradcam_heatmap(resnet, img_batch, res_last, pred_index=pred_idx)\n",
        "    e_heat = get_gradcam_heatmap(effnet, img_batch, eff_last, pred_index=pred_idx)\n",
        "\n",
        "    # Original image RGB\n",
        "    orig = cv2.imread(img_path)\n",
        "    if orig is None:\n",
        "        orig = (img_arr*255).astype(np.uint8)\n",
        "    else:\n",
        "        orig = cv2.cvtColor(orig, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    r_overlay = overlay_heatmap(r_heat, orig)\n",
        "    e_overlay = overlay_heatmap(e_heat, orig)\n",
        "\n",
        "    if show:\n",
        "        plt.figure(figsize=(16,6))\n",
        "        plt.subplot(1,3,1); plt.imshow(orig); plt.axis('off'); plt.title(\"Original\")\n",
        "        plt.subplot(1,3,2); plt.imshow(r_overlay); plt.axis('off'); plt.title(f\"ResNet Grad-CAM ‚Üí {pred_label}\")\n",
        "        plt.subplot(1,3,3); plt.imshow(e_overlay); plt.axis('off'); plt.title(f\"EfficientNet Grad-CAM ‚Üí {pred_label}\")\n",
        "        plt.show()\n",
        "\n",
        "    print(\"Predicted:\", pred_label)\n",
        "    print(\"Class Probabilities:\")\n",
        "    for k,v in probs_dict.items():\n",
        "        print(f\"  {k:12s}: {v:.4f}\")\n",
        "\n",
        "    # Simple textual rationale\n",
        "    print(\"\\nWhy this prediction? Grad-CAM highlights image regions that most influenced the decision.\\n\"\n",
        "          \"Bright (red/yellow) zones are the most discriminative features for the predicted class.\\n\"\n",
        "          \"Compare ResNet vs EfficientNet overlays to ensure consistency of highlighted anatomical cues \"\n",
        "          \"(e.g., belly patterning, fin edges, head/eye region).\")\n",
        "\n",
        "    return {\"predicted_label\": pred_label,\n",
        "            \"probabilities\": probs_dict,\n",
        "            \"resnet_gradcam\": r_overlay,\n",
        "            \"efficientnet_gradcam\": e_overlay}\n",
        "\n",
        "# =========================\n",
        "# USAGE EXAMPLE:\n",
        "# test_img_path = \"/content/drive/MyDrive/Hilsha/test_ilish.jpg\"\n",
        "# result = predict_with_explanations(test_img_path)\n",
        "# =========================\n",
        "\n",
        "# -------------------------\n",
        "# Notes for Q1 submission:\n",
        "# - Increase k_folds (5‚Üí10) and epochs (e.g., 50‚Äì100), widen HPO grid.\n",
        "# - Report mean¬±std across folds on an untouched test split or via nested CV.\n",
        "# - Consider external validation if available.\n",
        "# - Optionally add temperature scaling on validation for improved calibration.\n",
        "# - Archive checkpoints and training logs; ensure full reproducibility (seed, versions).\n",
        "# -------------------------\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4FoHfS26HoOq",
        "outputId": "2d397735-0875-4f1b-9e5b-4422a87df085"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "1 GPU(s) detected.\n",
            "Loaded X: (8407, 3, 224, 224), Y: (8407,), dtype=uint8\n",
            "Transposed to HWC: (8407, 224, 224, 3)\n",
            "Class weights: {np.int32(1): 1.4187763713080168, np.int32(0): 0.5604166666666667, np.int32(3): 4.543918918918919, np.int32(2): 0.579991375592928, np.int32(4): 1.7650918635170603}\n",
            "\n",
            "===== Fold 1/5 =====\n",
            " HPO trial: {'lr': 0.0005, 'dropout1': 0.4, 'dropout2': 0.3, 'label_smoothing': 0.0, 'unfreeze_last_n': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58ledYtVy8YD"
      },
      "source": [
        "#End"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}