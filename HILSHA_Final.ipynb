{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran012x/Transfer-Models/blob/main/HILSHA_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Co-Lab -->> Drive"
      ],
      "metadata": {
        "id": "WrRU5QMl0UZD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "\n",
        "# # Upload a file\n",
        "# uploaded = files.upload()\n",
        "# # Get the file name\n",
        "# file_name = list(uploaded.keys())[0]\n",
        "# print(f\"Uploaded file: {file_name}\")\n",
        "\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# # with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_224_11k.zip', 'r') as zip_ref:\n",
        "# #     zip_ref.extractall('')\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')"
      ],
      "metadata": {
        "id": "uaVTAQGY0a4A",
        "outputId": "478012e8-5e9b-487c-a831-ffdd8e6192cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Preprocess and Save"
      ],
      "metadata": {
        "id": "bIrUcpjq0P9i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import gc\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "import threading\n",
        "import zipfile\n",
        "\n",
        "# Check GPU availability\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n",
        "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "# Define fish classes and dataset paths\n",
        "fish_classes = ['ilish', 'chandana', 'sardin', 'sardinella', 'punctatus'] #0,1,2,3,4\n",
        "zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip').extractall('/content/.hidden_fish')\n",
        "data_dir = '/content/.hidden_fish'\n",
        "\n",
        "image_limits = {\n",
        "    'ilish': 3000,\n",
        "    'chandana': 1185,\n",
        "    'sardin': 2899,\n",
        "    'sardinella': 370,\n",
        "    'punctatus': 953\n",
        "}\n",
        "\n",
        "# Settings\n",
        "total_images = sum(image_limits.values())\n",
        "batch_size = 100\n",
        "num_threads = 4\n",
        "\n",
        "\n",
        "# Output paths\n",
        "output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "xdata_file = os.path.join(output_dir, 'X_data.npy')\n",
        "\n",
        "save_lock = threading.Lock()  # for thread-safe writes -> Prevents race conditions when multiple threads write to the same list.\n",
        "\n",
        "# Function to gather image paths\n",
        "def get_image_paths(class_name, max_images):\n",
        "    path = os.path.join(data_dir, class_name)\n",
        "    files = sorted(os.listdir(path))\n",
        "    random.shuffle(files)\n",
        "    return [os.path.join(path, f) for f in files[:max_images]]\n",
        "\n",
        "# Load and preprocess batch\n",
        "def load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "    end_idx = min(start_idx + batch_size, len(image_paths))\n",
        "    batch_paths = image_paths[start_idx:end_idx]\n",
        "    batch_images = []\n",
        "\n",
        "    for img_path in batch_paths:\n",
        "        img = Image.open(img_path).resize((224, 224)).convert('RGB')\n",
        "        img_tensor = torch.tensor(np.array(img), dtype=torch.uint8).permute(2, 0, 1)  # C x H x W\n",
        "        batch_images.append(img_tensor)\n",
        "\n",
        "    batch_tensor = torch.stack(batch_images)  # B x C x H x W\n",
        "    batch_labels = np.full((len(batch_images),), class_idx, dtype=np.int32)\n",
        "    return batch_tensor, batch_labels\n",
        "\n",
        "# Process one batch and return tensors & labels (no file saving)\n",
        "def process_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "    return load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx)\n",
        "\n",
        "def preprocess_and_save_all(overwrite=True):\n",
        "    if os.path.exists(labels_file) and os.path.exists(xdata_file) and not overwrite:\n",
        "        print(\"Preprocessed data already exists. Set overwrite=True to reprocess.\")\n",
        "        return\n",
        "\n",
        "    all_images = []\n",
        "    all_labels = []\n",
        "    processed_count = 0\n",
        "\n",
        "    for idx, class_name in enumerate(fish_classes):\n",
        "        print(f\"\\nProcessing class: {class_name}\")\n",
        "        image_paths = get_image_paths(class_name, image_limits[class_name])\n",
        "        total_batches = (len(image_paths) + batch_size - 1) // batch_size\n",
        "        #It ensures ceiling division ‚Äî rounding up, not down.\n",
        "        # Normal division: 103 / 20 = 5.15 ‚Üí floor division // 20 = 5 (‚ùå missing last 3 images)\n",
        "        # This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ‚úÖ\n",
        "\n",
        "        with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "            futures = []\n",
        "            for start in range(0, len(image_paths), batch_size):\n",
        "                futures.append(executor.submit(process_batch, image_paths, start, batch_size, idx))\n",
        "\n",
        "            for future in tqdm(as_completed(futures), total=total_batches, desc=class_name):#taqaddum (ÿ™ŸÇÿØŸëŸÖ) ‚Äì Arabic for \"progress\".\n",
        "                # futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\n",
        "                # as_completed(futures): Yields each future as it finishes (not in order).\n",
        "\n",
        "                batch_tensor, batch_labels = future.result()\n",
        "                with save_lock: #Locks this section so that only one thread can update the shared lists safely.\n",
        "                    all_images.append(batch_tensor)\n",
        "                    all_labels.append(batch_labels)\n",
        "                    processed_count += batch_tensor.size(0)\n",
        "                    print(f\"Processed batch with {batch_tensor.size(0)} images, total processed: {processed_count}/{total_images}\")\n",
        "                gc.collect()\n",
        "\n",
        "    # Combine all tensors and labels\n",
        "    X = torch.cat(all_images, dim=0).numpy()\n",
        "    Y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "    # Save final arrays\n",
        "    np.save(xdata_file, X, allow_pickle=False)#Malicious .npy -> import os;os.system(\"rm -rf /\")  # ‚Üê Dangerous command\n",
        "    np.save(labels_file, Y, allow_pickle=False)\n",
        "\n",
        "    print(f\"\\n‚úÖ Done! Saved {processed_count} images in {xdata_file}\")\n",
        "    print(f\"X_data shape: {X.shape}, Y_labels shape: {Y.shape}\")\n",
        "\n",
        "    if processed_count != total_images:\n",
        "        raise ValueError(f\"Expected {total_images} images, but processed {processed_count}\")\n",
        "\n",
        "# Run preprocessing and save directly to X_data.npy and Y_labels.npy\n",
        "preprocess_and_save_all(overwrite=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "k9WJIX0qbYSw",
        "outputId": "ccb2bfe6-3c06-4597-d9b6-7bf553f6aee5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Available: True\n",
            "GPU Name: NVIDIA L4\n",
            "\n",
            "Processing class: ilish\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ilish:   0%|          | 0/30 [00:32<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-580223829.py\u001b[0m in \u001b[0;36mpreprocess_and_save_all\u001b[0;34m(overwrite)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfuture\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mas_completed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m#taqaddum (ÿ™ŸÇÿØŸëŸÖ) ‚Äì Arabic for \"progress\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m                 \u001b[0;31m# futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mas_completed\u001b[0;34m(fs, timeout)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait_timeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    628\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 629\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    630\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    326\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-580223829.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m# Run preprocessing and save directly to X_data.npy and Y_labels.npy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m \u001b[0mpreprocess_and_save_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-580223829.py\u001b[0m in \u001b[0;36mpreprocess_and_save_all\u001b[0;34m(overwrite)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ‚úÖ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_threads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexecutor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0mfutures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/_base.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, exc_type, exc_val, exc_tb)\u001b[0m\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 647\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    648\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    649\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/concurrent/futures/thread.py\u001b[0m in \u001b[0;36mshutdown\u001b[0;34m(self, wait, cancel_futures)\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshutdown\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m                 \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####DATA LOADING...."
      ],
      "metadata": {
        "id": "qz9kAvggeF0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Your data path\n",
        "output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "data_file = os.path.join(output_dir, 'X_data.npy')\n",
        "labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "\n",
        "# Readable size format\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    for unit in ['', 'K', 'M', 'G', 'T']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return f\"{num:3.2f} {unit}{suffix}\"\n",
        "        num /= 1024.0\n",
        "    return f\"{num:.2f} T{suffix}\"\n",
        "\n",
        "# Main loader\n",
        "def load_preprocessed_data(as_torch=True, normalize=True, to_device=None):\n",
        "    # Check file existence #cpu,cuda (CUDA stands for Compute Unified Device Architecture.)\n",
        "    for path in [data_file, labels_file]:\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Missing: {path}\")\n",
        "\n",
        "    # Print file sizes\n",
        "    print(f\"üìÅ X_data.npy: {sizeof_fmt(os.path.getsize(data_file))}\")\n",
        "    print(f\"üìÅ Y_labels.npy: {sizeof_fmt(os.path.getsize(labels_file))}\")\n",
        "\n",
        "    # Load with mmap\n",
        "    X = np.load(data_file, mmap_mode='r')\n",
        "    Y = np.load(labels_file, mmap_mode='r')\n",
        "\n",
        "    print(f\"‚úÖ X shape: {X.shape}, dtype: {X.dtype}\")\n",
        "    print(f\"‚úÖ Y shape: {Y.shape}, dtype: {Y.dtype}\")\n",
        "\n",
        "    # Sanity check\n",
        "    if len(X) != len(Y):\n",
        "        raise ValueError(\"Mismatch between number of samples in X and Y\")\n",
        "\n",
        "    # Convert to torch\n",
        "    if as_torch:\n",
        "        X = torch.from_numpy(X)\n",
        "        Y = torch.from_numpy(Y)\n",
        "\n",
        "        if normalize and X.dtype == torch.uint8:\n",
        "            X = X.float() / 255.0\n",
        "\n",
        "        if to_device:\n",
        "            X = X.to(to_device)\n",
        "            Y = Y.to(to_device)\n",
        "\n",
        "        print(f\"üß† Torch tensors ready on {to_device or 'CPU'}\")\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# üîÅ Example call\n",
        "X, Y = load_preprocessed_data(\n",
        "    as_torch=True,\n",
        "    normalize=True,\n",
        "    to_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlSz9YmOB1iW",
        "outputId": "2a300e7f-eba4-4f4d-e67a-c4e2ad4d52cd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ X_data.npy: 1.18 GB\n",
            "üìÅ Y_labels.npy: 32.96 KB\n",
            "‚úÖ X shape: (8407, 3, 224, 224), dtype: uint8\n",
            "‚úÖ Y shape: (8407,), dtype: int32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614331559.py:42: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  X = torch.from_numpy(X)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Torch tensors ready on cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Enhanced Fish Species Classification with Hyperparameter Tuning & XAI\n",
        "=====================================================================\n",
        "Author: Enhanced Fish Classification System\n",
        "Version: 2.0 - Journal Ready\n",
        "\"\"\"\n",
        "\n",
        "import os, warnings, cv2, json, random, numpy as np, pandas as pd, matplotlib.pyplot as plt, seaborn as sns\n",
        "from pathlib import Path\n",
        "from typing import Dict, List\n",
        "import torch, torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import optuna\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use('default')\n",
        "\n",
        "# =========================\n",
        "# CONFIGURATION & SETUP\n",
        "# =========================\n",
        "class Config:\n",
        "    DATA_FILE = '/content/drive/MyDrive/Hilsha/X_data.npy'\n",
        "    LABELS_FILE = '/content/drive/MyDrive/Hilsha/Y_labels.npy'\n",
        "    OUTPUT_DIR = '/content/outputs'\n",
        "    INPUT_SIZE = 224\n",
        "    NUM_CLASSES = 5\n",
        "    CLASS_LABELS = ['Ilish', 'Chandana', 'Sardin', 'Sardinella', 'Punctatus']\n",
        "    BATCH_SIZE = 32\n",
        "    MAX_EPOCHS = 50\n",
        "    PATIENCE = 10\n",
        "    HP_SPACE = {\n",
        "        'learning_rate': [1e-4, 5e-4, 1e-3, 2e-3],\n",
        "        'weight_decay': [1e-5, 1e-4, 1e-3],\n",
        "        'dropout_rate': [0.2, 0.3, 0.4, 0.5],\n",
        "        'optimizer': ['adam', 'adamw', 'sgd'],\n",
        "        'scheduler': ['cosine', 'step', 'plateau'],\n",
        "        'augmentation_strength': ['light', 'medium', 'heavy']\n",
        "    }\n",
        "    K_FOLDS = 5\n",
        "    TEST_SIZE = 0.2\n",
        "    SEED = 42\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    N_TRIALS = 30\n",
        "\n",
        "def setup_environment():\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "    random.seed(Config.SEED)\n",
        "    Path(Config.OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        print(\"üíª Using CPU\")\n",
        "setup_environment()\n",
        "\n",
        "# =========================\n",
        "# DATA HANDLING\n",
        "# =========================\n",
        "class FishDataset(Dataset):\n",
        "    def __init__(self, images: np.ndarray, labels: np.ndarray, transform=None):\n",
        "        self.images = self._preprocess_images(images)\n",
        "        self.labels = labels.astype(np.int64)\n",
        "        self.transform = transform\n",
        "\n",
        "    def _preprocess_images(self, images):\n",
        "        if images.max() > 1.5:\n",
        "            images = images / 255.0\n",
        "        if len(images.shape) == 4 and images.shape[1] == 3:\n",
        "            images = np.transpose(images, (0, 2, 3, 1))\n",
        "        return images.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image, label = self.images[idx], self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "        else:\n",
        "            image = torch.from_numpy(image).permute(2,0,1)\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class DataManager:\n",
        "    @staticmethod\n",
        "    def get_transforms(augmentation_strength='medium', is_training=True):\n",
        "        base = [A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                A.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]), ToTensorV2()]\n",
        "        if not is_training: return A.Compose(base)\n",
        "        aug_cfg = {\n",
        "            'light':[A.HorizontalFlip(p=0.5), A.RandomRotate90(p=0.3), A.RandomBrightnessContrast(p=0.3)],\n",
        "            'medium':[A.HorizontalFlip(p=0.5), A.RandomRotate90(p=0.5), A.ShiftScaleRotate(0.1,0.1,15,p=0.5),\n",
        "                      A.RandomBrightnessContrast(0.2,0.2,p=0.5), A.OneOf([A.GaussNoise(),A.GaussianBlur()],p=0.3)],\n",
        "            'heavy':[A.HorizontalFlip(p=0.6), A.RandomRotate90(p=0.6), A.ShiftScaleRotate(0.2,0.2,30,p=0.6),\n",
        "                     A.RandomBrightnessContrast(0.3,0.3,p=0.6), A.OneOf([A.GaussNoise(),A.GaussianBlur()],p=0.4),\n",
        "                     A.CoarseDropout(\n",
        "    max_holes=8,           # maximum number of holes\n",
        "    max_height=32,         # can also use tuple (min,max)\n",
        "    max_width=32,          # can also use tuple (min,max)\n",
        "    min_holes=8,           # minimum number of holes\n",
        "    min_height=32,\n",
        "    min_width=32,\n",
        "    p=0.4\n",
        ")\n",
        "]\n",
        "        }\n",
        "        return A.Compose(aug_cfg[augmentation_strength]+base)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_and_balance_data():\n",
        "        X = np.load(Config.DATA_FILE, mmap_mode='r').copy()\n",
        "        Y = np.load(Config.LABELS_FILE, allow_pickle=True)\n",
        "        print(f\"üìä Original data: {X.shape}, Classes: {np.bincount(Y)}\")\n",
        "        X_flat = X.reshape(X.shape[0],-1)\n",
        "        smote = SMOTE(random_state=Config.SEED, k_neighbors=3)\n",
        "        X_bal, Y_bal = smote.fit_resample(X_flat,Y)\n",
        "        X_bal = X_bal.reshape(-1,*X.shape[1:])\n",
        "        print(f\"üìä Balanced data: {X_bal.shape}, Classes: {np.bincount(Y_bal)}\")\n",
        "        return X_bal, Y_bal\n",
        "\n",
        "# =========================\n",
        "# MODEL ARCHITECTURE\n",
        "# =========================\n",
        "class FishClassifier(nn.Module):\n",
        "    def __init__(self, backbone='resnet50', num_classes=5, dropout_rate=0.3):\n",
        "        super().__init__()\n",
        "        self.backbone_name = backbone\n",
        "        if backbone=='resnet50':\n",
        "            self.backbone = models.resnet50(weights='IMAGENET1K_V2')\n",
        "            self.feature_dim = self.backbone.fc.in_features\n",
        "            self.backbone.fc = nn.Identity()\n",
        "            self.target_layer = self.backbone.layer4[-1]\n",
        "        elif backbone=='efficientnet_b0':\n",
        "            self.backbone = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "            self.feature_dim = self.backbone.classifier[1].in_features\n",
        "            self.backbone.classifier = nn.Identity()\n",
        "            self.target_layer = self.backbone.features[-1]\n",
        "        else: raise ValueError(f\"Unsupported backbone: {backbone}\")\n",
        "\n",
        "        self.attention = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n",
        "            nn.Linear(self.feature_dim,self.feature_dim//16),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(self.feature_dim//16,self.feature_dim),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(dropout_rate),\n",
        "            nn.Linear(self.feature_dim,self.feature_dim//2),\n",
        "            nn.BatchNorm1d(self.feature_dim//2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_rate/2),\n",
        "            nn.Linear(self.feature_dim//2,num_classes)\n",
        "        )\n",
        "        self.gradients=None\n",
        "        self.activations=None\n",
        "\n",
        "    def forward(self,x):\n",
        "        features = self.backbone(x)\n",
        "        if len(features.shape)==4:\n",
        "            att_w = self.attention(features).view(features.size(0),features.size(1),1,1)\n",
        "            features = nn.functional.adaptive_avg_pool2d(features*att_w,1).flatten(1)\n",
        "        return self.classifier(features)\n",
        "\n",
        "    def forward_with_cam(self,x):\n",
        "        def save_activation(module,input,output): self.activations=output\n",
        "        def save_gradient(module,grad_input,grad_output): self.gradients=grad_output[0]\n",
        "        h1 = self.target_layer.register_forward_hook(save_activation)\n",
        "        h2 = self.target_layer.register_backward_hook(save_gradient)\n",
        "        out = self.forward(x)\n",
        "        h1.remove(); h2.remove()\n",
        "        return out\n",
        "\n",
        "# =========================\n",
        "# BUILT-IN XAI\n",
        "# =========================\n",
        "class BuiltInXAI:\n",
        "    def __init__(self, model, class_labels):\n",
        "        self.model = model.eval()\n",
        "        self.class_labels = class_labels\n",
        "        self.device = next(model.parameters()).device\n",
        "\n",
        "    def generate_grad_cam(self,input_tensor,target_class=None):\n",
        "        out = self.model.forward_with_cam(input_tensor)\n",
        "        if target_class is None: target_class = out.argmax(dim=1)\n",
        "        self.model.zero_grad()\n",
        "        out[0,target_class].backward()\n",
        "        grads = self.model.gradients\n",
        "        acts = self.model.activations\n",
        "        weights = torch.mean(grads,dim=(2,3))\n",
        "        cam = torch.zeros(acts.shape[2:],dtype=torch.float32,device=self.device)\n",
        "        for i,w in enumerate(weights[0]): cam+=w*acts[0,i,:,:]\n",
        "        cam = torch.relu(cam)\n",
        "        cam = (cam-cam.min())/(cam.max()-cam.min()+1e-8)\n",
        "        return cam.detach().cpu().numpy()\n",
        "\n",
        "    def generate_attention_map(self,input_tensor):\n",
        "        with torch.no_grad():\n",
        "            f = self.model.backbone(input_tensor)\n",
        "            if len(f.shape)==4:\n",
        "                att_w = self.model.attention(f).view(f.shape[2],f.shape[3])\n",
        "                att_w = (att_w-att_w.min())/(att_w.max()-att_w.min()+1e-8)\n",
        "                return att_w.cpu().numpy()\n",
        "        return None\n",
        "\n",
        "    def denormalize_image(self,tensor):\n",
        "        mean,std = np.array([0.485,0.456,0.406]), np.array([0.229,0.224,0.225])\n",
        "        img = tensor.cpu().permute(1,2,0).numpy()\n",
        "        img = img*std+mean\n",
        "        return np.clip(img,0,1)\n",
        "\n",
        "    def overlay_heatmap(self,img,heatmap,alpha=0.4):\n",
        "        heatmap_resized = cv2.resize(heatmap,(img.shape[1],img.shape[0]))\n",
        "        heatmap_colored = plt.cm.jet(heatmap_resized)[:,:,:3]\n",
        "        return (1-alpha)*img + alpha*heatmap_colored\n",
        "\n",
        "# =========================\n",
        "# TRAINER\n",
        "# =========================\n",
        "class Trainer:\n",
        "    def __init__(self, model, hyperparams):\n",
        "        self.model = model.to(Config.DEVICE)\n",
        "        self.hyperparams = hyperparams\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
        "        self.best_val_acc=0.0; self.patience_counter=0; self.best_model_state=None\n",
        "        if hyperparams['optimizer']=='adam': self.optimizer = optim.Adam(model.parameters(), lr=hyperparams['learning_rate'], weight_decay=hyperparams['weight_decay'])\n",
        "        elif hyperparams['optimizer']=='adamw': self.optimizer = optim.AdamW(model.parameters(), lr=hyperparams['learning_rate'], weight_decay=hyperparams['weight_decay'])\n",
        "        else: self.optimizer = optim.SGD(model.parameters(), lr=hyperparams['learning_rate'], weight_decay=hyperparams['weight_decay'], momentum=0.9)\n",
        "        if hyperparams['scheduler']=='cosine': self.scheduler=optim.lr_scheduler.CosineAnnealingLR(self.optimizer,T_max=Config.MAX_EPOCHS)\n",
        "        elif hyperparams['scheduler']=='step': self.scheduler=optim.lr_scheduler.StepLR(self.optimizer,step_size=15,gamma=0.1)\n",
        "        else: self.scheduler=optim.lr_scheduler.ReduceLROnPlateau(self.optimizer,mode='max',patience=5)\n",
        "\n",
        "    def train_epoch(self,loader):\n",
        "        self.model.train(); total_loss=0; correct=0; total=0\n",
        "        for images,labels in loader:\n",
        "            images,labels=images.to(Config.DEVICE),labels.to(Config.DEVICE)\n",
        "            self.optimizer.zero_grad(); outputs=self.model(images)\n",
        "            loss=self.criterion(outputs,labels); loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(),1.0); self.optimizer.step()\n",
        "            total_loss+=loss.item(); correct+=(outputs.argmax(1)==labels).sum().item(); total+=labels.size(0)\n",
        "        return total_loss/len(loader), correct/total\n",
        "\n",
        "    def validate(self,loader):\n",
        "        self.model.eval(); total_loss=0; correct=0; total=0\n",
        "        with torch.no_grad():\n",
        "            for images,labels in loader:\n",
        "                images,labels=images.to(Config.DEVICE),labels.to(Config.DEVICE)\n",
        "                outputs=self.model(images); loss=self.criterion(outputs,labels)\n",
        "                total_loss+=loss.item(); correct+=(outputs.argmax(1)==labels).sum().item(); total+=labels.size(0)\n",
        "        return total_loss/len(loader), correct/total\n",
        "\n",
        "    def quick_train(self,train_loader,val_loader,epochs=10):\n",
        "        for _ in range(epochs):\n",
        "            self.train_epoch(train_loader); _,val_acc=self.validate(val_loader)\n",
        "            if val_acc>self.best_val_acc: self.best_val_acc=val_acc; self.patience_counter=0\n",
        "            else: self.patience_counter+=1;\n",
        "            if self.patience_counter>=3: break\n",
        "        return self.best_val_acc\n",
        "\n",
        "    def full_train(self,train_loader,val_loader):\n",
        "        history={'train_loss':[],'train_acc':[],'val_loss':[],'val_acc':[]}\n",
        "        for epoch in range(Config.MAX_EPOCHS):\n",
        "            train_loss,train_acc=self.train_epoch(train_loader)\n",
        "            val_loss,val_acc=self.validate(val_loader)\n",
        "            history['train_loss'].append(train_loss); history['train_acc'].append(train_acc)\n",
        "            history['val_loss'].append(val_loss); history['val_acc'].append(val_acc)\n",
        "            print(f\"Epoch {epoch+1}: Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "            if val_acc>self.best_val_acc: self.best_val_acc=val_acc; self.patience_counter=0; self.best_model_state=self.model.state_dict().copy()\n",
        "            else: self.patience_counter+=1;\n",
        "            if self.patience_counter>=Config.PATIENCE: print(f\"Early stopping at epoch {epoch+1}\"); break\n",
        "            if self.hyperparams['scheduler']=='plateau': self.scheduler.step(val_acc)\n",
        "            else: self.scheduler.step()\n",
        "        if self.best_model_state: self.model.load_state_dict(self.best_model_state)\n",
        "        return history\n",
        "\n",
        "# =========================\n",
        "# HYPERPARAMETER OPTIMIZER\n",
        "# =========================\n",
        "class HyperparameterOptimizer:\n",
        "    def __init__(self,X,Y): self.X_data=X; self.Y_data=Y; self.study=None; self.best_params=None\n",
        "    def objective(self,trial):\n",
        "        params={'learning_rate':trial.suggest_categorical('learning_rate',Config.HP_SPACE['learning_rate']),\n",
        "                'weight_decay':trial.suggest_categorical('weight_decay',Config.HP_SPACE['weight_decay']),\n",
        "                'dropout_rate':trial.suggest_categorical('dropout_rate',Config.HP_SPACE['dropout_rate']),\n",
        "                'optimizer':trial.suggest_categorical('optimizer',Config.HP_SPACE['optimizer']),\n",
        "                'scheduler':trial.suggest_categorical('scheduler',Config.HP_SPACE['scheduler']),\n",
        "                'augmentation_strength':trial.suggest_categorical('augmentation_strength',Config.HP_SPACE['augmentation_strength']),\n",
        "                'backbone':trial.suggest_categorical('backbone',['resnet50','efficientnet_b0'])}\n",
        "        return np.mean(self._cross_validate(params))\n",
        "    def _cross_validate(self,params,k_folds=3):\n",
        "        skf=StratifiedKFold(n_splits=k_folds,shuffle=True,random_state=Config.SEED)\n",
        "        scores=[]\n",
        "        for train_idx,val_idx in skf.split(self.X_data,self.Y_data):\n",
        "            X_train,X_val=self.X_data[train_idx],self.X_data[val_idx]\n",
        "            Y_train,Y_val=self.Y_data[train_idx],self.Y_data[val_idx]\n",
        "            train_transform=DataManager.get_transforms(params['augmentation_strength'],True)\n",
        "            val_transform=DataManager.get_transforms('light',False)\n",
        "            train_loader=DataLoader(FishDataset(X_train,Y_train,train_transform),batch_size=Config.BATCH_SIZE,shuffle=True,num_workers=2,pin_memory=True)\n",
        "            val_loader=DataLoader(FishDataset(X_val,Y_val,val_transform),batch_size=Config.BATCH_SIZE*2,shuffle=False,num_workers=2,pin_memory=True)\n",
        "            model=FishClassifier(params['backbone'],Config.NUM_CLASSES,params['dropout_rate'])\n",
        "            trainer=Trainer(model,params)\n",
        "            val_acc=trainer.quick_train(train_loader,val_loader,epochs=10)\n",
        "            scores.append(val_acc)\n",
        "            del model, trainer; torch.cuda.empty_cache()\n",
        "        return scores\n",
        "    def optimize(self,n_trials=30):\n",
        "        self.study=optuna.create_study(direction='maximize',sampler=optuna.samplers.TPESampler(seed=Config.SEED))\n",
        "        self.study.optimize(self.objective,n_trials=n_trials)\n",
        "        self.best_params=self.study.best_params; return self.best_params\n",
        "\n",
        "# =========================\n",
        "# Example Usage\n",
        "# =========================\n",
        "if __name__==\"__main__\":\n",
        "    X_bal,Y_bal=DataManager.load_and_balance_data()\n",
        "    optimizer=HyperparameterOptimizer(X_bal,Y_bal)\n",
        "    best_params=optimizer.optimize(n_trials=5)\n",
        "    print(\"üèÜ Best Hyperparameters:\",best_params)\n",
        "\n",
        "    # Full Training\n",
        "    train_transform=DataManager.get_transforms(best_params['augmentation_strength'],True)\n",
        "    val_transform=DataManager.get_transforms('light',False)\n",
        "    split=int(len(X_bal)*0.8)\n",
        "    train_loader=DataLoader(FishDataset(X_bal[:split],Y_bal[:split],train_transform),batch_size=Config.BATCH_SIZE,shuffle=True)\n",
        "    val_loader=DataLoader(FishDataset(X_bal[split:],Y_bal[split:],val_transform),batch_size=Config.BATCH_SIZE*2,shuffle=False)\n",
        "    final_model=FishClassifier(best_params['backbone'],Config.NUM_CLASSES,best_params['dropout_rate'])\n",
        "    trainer=Trainer(final_model,best_params)\n",
        "    history=trainer.full_train(train_loader,val_loader)\n",
        "\n",
        "    # XAI Example\n",
        "    xai=BuiltInXAI(final_model,Config.CLASS_LABELS)\n",
        "    sample_img,_=val_loader.dataset[0]\n",
        "    cam=xai.generate_grad_cam(sample_img.unsqueeze(0).to(Config.DEVICE))\n",
        "    overlay=xai.overlay_heatmap(xai.denormalize_image(sample_img),cam)\n",
        "    plt.imshow(overlay); plt.title(\"Grad-CAM Overlay\"); plt.axis('off'); plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L1yZDbo5xTsB",
        "outputId": "cc7caeae-32d9-4f4a-f702-9aa9af95c816"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ GPU: NVIDIA L4\n",
            "üìä Original data: (8407, 3, 224, 224), Classes: [3000 1185 2899  370  953]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-17 21:10:42,405] A new study created in memory with name: no-name-4d81a2b4-e906-47db-8072-f76481631b17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Balanced data: (15000, 3, 224, 224), Classes: [3000 3000 3000 3000 3000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 232MB/s]\n",
            "[I 2025-08-17 21:26:45,947] Trial 0 finished with value: 0.20000000000000004 and parameters: {'learning_rate': 0.0005, 'weight_decay': 1e-05, 'dropout_rate': 0.2, 'optimizer': 'adam', 'scheduler': 'plateau', 'augmentation_strength': 'light', 'backbone': 'resnet50'}. Best is trial 0 with value: 0.20000000000000004.\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 225MB/s]\n",
            "[I 2025-08-17 21:39:42,083] Trial 1 finished with value: 0.4640666666666666 and parameters: {'learning_rate': 0.002, 'weight_decay': 0.001, 'dropout_rate': 0.3, 'optimizer': 'adamw', 'scheduler': 'plateau', 'augmentation_strength': 'heavy', 'backbone': 'efficientnet_b0'}. Best is trial 1 with value: 0.4640666666666666.\n",
            "[I 2025-08-17 21:53:46,048] Trial 2 finished with value: 0.5444666666666667 and parameters: {'learning_rate': 0.0005, 'weight_decay': 0.001, 'dropout_rate': 0.3, 'optimizer': 'adam', 'scheduler': 'plateau', 'augmentation_strength': 'medium', 'backbone': 'efficientnet_b0'}. Best is trial 2 with value: 0.5444666666666667.\n",
            "[I 2025-08-17 22:12:49,920] Trial 3 finished with value: 0.21846666666666667 and parameters: {'learning_rate': 0.002, 'weight_decay': 1e-05, 'dropout_rate': 0.2, 'optimizer': 'adamw', 'scheduler': 'cosine', 'augmentation_strength': 'heavy', 'backbone': 'resnet50'}. Best is trial 2 with value: 0.5444666666666667.\n",
            "[I 2025-08-17 22:42:27,045] Trial 4 finished with value: 0.3836 and parameters: {'learning_rate': 0.0001, 'weight_decay': 0.001, 'dropout_rate': 0.3, 'optimizer': 'sgd', 'scheduler': 'plateau', 'augmentation_strength': 'heavy', 'backbone': 'resnet50'}. Best is trial 2 with value: 0.5444666666666667.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üèÜ Best Hyperparameters: {'learning_rate': 0.0005, 'weight_decay': 0.001, 'dropout_rate': 0.3, 'optimizer': 'adam', 'scheduler': 'plateau', 'augmentation_strength': 'medium', 'backbone': 'efficientnet_b0'}\n",
            "Epoch 1: Train Acc: 0.8696, Val Acc: 0.1957\n",
            "Epoch 2: Train Acc: 0.9234, Val Acc: 0.2730\n",
            "Epoch 3: Train Acc: 0.9341, Val Acc: 0.0007\n",
            "Epoch 4: Train Acc: 0.9394, Val Acc: 0.4103\n",
            "Epoch 5: Train Acc: 0.9434, Val Acc: 0.1837\n",
            "Epoch 6: Train Acc: 0.9478, Val Acc: 0.1600\n",
            "Epoch 7: Train Acc: 0.9453, Val Acc: 0.1770\n",
            "Epoch 8: Train Acc: 0.9483, Val Acc: 0.0090\n",
            "Epoch 9: Train Acc: 0.9517, Val Acc: 0.0000\n",
            "Epoch 10: Train Acc: 0.9553, Val Acc: 0.0240\n",
            "Epoch 11: Train Acc: 0.9775, Val Acc: 0.4077\n",
            "Epoch 12: Train Acc: 0.9832, Val Acc: 0.5223\n",
            "Epoch 13: Train Acc: 0.9848, Val Acc: 0.0440\n",
            "Epoch 14: Train Acc: 0.9848, Val Acc: 0.6173\n",
            "Epoch 15: Train Acc: 0.9871, Val Acc: 0.3527\n",
            "Epoch 16: Train Acc: 0.9902, Val Acc: 0.6290\n",
            "Epoch 17: Train Acc: 0.9892, Val Acc: 0.5627\n",
            "Epoch 18: Train Acc: 0.9886, Val Acc: 0.3323\n",
            "Epoch 19: Train Acc: 0.9904, Val Acc: 0.5333\n",
            "Epoch 20: Train Acc: 0.9896, Val Acc: 0.7477\n",
            "Epoch 21: Train Acc: 0.9889, Val Acc: 0.0373\n",
            "Epoch 22: Train Acc: 0.9879, Val Acc: 0.1567\n",
            "Epoch 23: Train Acc: 0.9902, Val Acc: 0.5293\n",
            "Epoch 24: Train Acc: 0.9905, Val Acc: 0.5957\n",
            "Epoch 25: Train Acc: 0.9898, Val Acc: 0.7010\n",
            "Epoch 26: Train Acc: 0.9893, Val Acc: 0.4973\n",
            "Epoch 27: Train Acc: 0.9913, Val Acc: 0.8213\n",
            "Epoch 28: Train Acc: 0.9942, Val Acc: 0.7787\n",
            "Epoch 29: Train Acc: 0.9918, Val Acc: 0.7830\n",
            "Epoch 30: Train Acc: 0.9933, Val Acc: 0.7547\n",
            "Epoch 31: Train Acc: 0.9941, Val Acc: 0.7700\n",
            "Epoch 32: Train Acc: 0.9929, Val Acc: 0.7537\n",
            "Epoch 33: Train Acc: 0.9932, Val Acc: 0.7450\n",
            "Epoch 34: Train Acc: 0.9930, Val Acc: 0.7340\n",
            "Epoch 35: Train Acc: 0.9939, Val Acc: 0.7617\n",
            "Epoch 36: Train Acc: 0.9942, Val Acc: 0.7783\n",
            "Epoch 37: Train Acc: 0.9946, Val Acc: 0.7593\n",
            "Early stopping at epoch 37\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ==============================================================\n",
        "# Enhanced Fish Species Classification (Journal-Ready, Segmented)\n",
        "# ==============================================================\n",
        "\n",
        "\"\"\"\n",
        "Enhanced Fish Species Classification with Hyperparameter Tuning & XAI\n",
        "=====================================================================\n",
        "Author: Enhanced Fish Classification System\n",
        "Version: 2.1 - Journal Ready (Segmented) - Overfitting Fixed\n",
        "\"\"\"\n",
        "\n",
        "!pip install optuna\n",
        "\n",
        "# -------------------------\n",
        "# Common Imports & Setup\n",
        "# -------------------------\n",
        "import os, sys, subprocess, warnings, json, random, gc\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "plt.style.use(\"default\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "\n",
        "import torchvision.models as models\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, f1_score,\n",
        "                             accuracy_score, precision_recall_fscore_support)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "import optuna\n",
        "\n",
        "# -------------------------\n",
        "# Configuration\n",
        "# -------------------------\n",
        "class Config:\n",
        "    # ---- Paths ----\n",
        "    DATA_FILE   = '/content/drive/MyDrive/Hilsha/X_data.npy'\n",
        "    LABELS_FILE = '/content/drive/MyDrive/Hilsha/Y_labels.npy'\n",
        "    OUTPUT_DIR  = '/content/outputs'\n",
        "\n",
        "    # ---- Data / Classes ----\n",
        "    INPUT_SIZE   = 224\n",
        "    NUM_CLASSES  = 5\n",
        "    CLASS_LABELS = ['Ilish', 'Chandana', 'Sardin', 'Sardinella', 'Punctatus']\n",
        "\n",
        "    # ---- Training ----\n",
        "    BATCH_SIZE  = 32\n",
        "    MAX_EPOCHS  = 40\n",
        "    PATIENCE    = 7\n",
        "    SEED        = 42\n",
        "    DEVICE      = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # ---- HPO (Colab L4-safe) ----\n",
        "    N_TRIALS    = 8       # keep small\n",
        "    TIMEOUT_S   = 20*60   # 20 min safety\n",
        "    PRUNE_PATIENCE = 3    # early prune in CV\n",
        "\n",
        "    # ---- CV / Split ----\n",
        "    K_FOLDS     = 5\n",
        "    TEST_SIZE   = 0.2\n",
        "\n",
        "    # ---- HPO Space (FIXED: Lower LR, Higher Dropout, Added Weight Decay) ----\n",
        "    HP_SPACE = {\n",
        "        'learning_rate': [1e-5, 5e-5, 1e-4],  # FIXED: Much lower LR for fine-tuning\n",
        "        'weight_decay': [1e-4, 5e-4, 1e-3],   # FIXED: Higher weight decay for regularization\n",
        "        'dropout_rate': [0.4, 0.5, 0.6],      # FIXED: Higher dropout to prevent overfitting\n",
        "        'optimizer': ['adamw'],                # FIXED: Use AdamW for better weight decay\n",
        "        'scheduler': ['plateau', 'cosine'],\n",
        "        'augmentation_strength': ['medium', 'heavy']  # FIXED: Remove light augmentation\n",
        "    }\n",
        "\n",
        "    # ---- Ensemble backbones (memory-safe set) ----\n",
        "    ENSEMBLE_BACKBONES = ['resnet50', 'efficientnet_b0', 'mobilenet_v3_large']\n",
        "\n",
        "def setup_environment():\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "    random.seed(Config.SEED)\n",
        "    Path(Config.OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        print(f\"üöÄ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    else:\n",
        "        print(\"üíª Using CPU\")\n",
        "setup_environment()\n",
        "\n",
        "# ==============================================================\n",
        "# PART 1 ‚Äî Data Loading, SMOTE Balancing, Augmentation, Splits\n",
        "# ==============================================================\n",
        "\n",
        "class FishDataset(Dataset):\n",
        "    def __init__(self, images: np.ndarray, labels: np.ndarray, transform=None):\n",
        "        self.images = self._preprocess_images(images)\n",
        "        self.labels = labels.astype(np.int64)\n",
        "        self.transform = transform\n",
        "\n",
        "    def _preprocess_images(self, images):\n",
        "        if images.max() > 1.5:\n",
        "            images = images / 255.0\n",
        "        # To HWC\n",
        "        if len(images.shape) == 4 and images.shape[1] == 3:\n",
        "            images = np.transpose(images, (0, 2, 3, 1))\n",
        "        return images.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img, label = self.images[idx], self.labels[idx]\n",
        "        if self.transform:\n",
        "            img = self.transform(image=img)['image']\n",
        "        else:\n",
        "            img = torch.from_numpy(img).permute(2, 0, 1)\n",
        "        return img, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class DataManager:\n",
        "    @staticmethod\n",
        "    def get_transforms(augmentation_strength='medium', is_training=True):\n",
        "        base = [\n",
        "            A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "            A.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225]),\n",
        "            ToTensorV2()\n",
        "        ]\n",
        "        if not is_training:\n",
        "            return A.Compose(base)\n",
        "\n",
        "        # FIXED: Much stronger augmentation to prevent overfitting\n",
        "        aug_cfg = {\n",
        "            'medium': [\n",
        "                A.HorizontalFlip(p=0.5),\n",
        "                A.RandomRotate90(p=0.5),\n",
        "                A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "                A.RandomBrightnessContrast(0.2, 0.2, p=0.5),\n",
        "                A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1, p=0.4),  # FIXED: Added ColorJitter\n",
        "                A.OneOf([A.GaussNoise(), A.GaussianBlur()], p=0.3)\n",
        "            ],\n",
        "            'heavy': [\n",
        "                A.HorizontalFlip(p=0.6),\n",
        "                A.RandomRotate90(p=0.6),\n",
        "                A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.6),\n",
        "                A.RandomBrightnessContrast(0.3, 0.3, p=0.6),\n",
        "                A.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.15, p=0.5),  # FIXED: Added stronger ColorJitter\n",
        "                A.OneOf([A.GaussNoise(), A.GaussianBlur()], p=0.4),\n",
        "                A.CoarseDropout(\n",
        "                    min_holes=6, max_holes=10,\n",
        "                    min_height=16, max_height=32,\n",
        "                    min_width=16,  max_width=32,\n",
        "                    fill_value=0, mask_fill_value=None, p=0.4\n",
        "                ),\n",
        "                A.CoarseDropout(min_holes=4, max_holes=8, min_height=8, max_height=16, min_width=8, max_width=16, p=0.3)  # FIXED: Use CoarseDropout instead\n",
        "                # A.Cutout(num_holes=8, max_h_size=16, max_w_size=16, p=0.3)  # FIXED: Added Cutout\n",
        "            ]\n",
        "        }\n",
        "        return A.Compose(aug_cfg[augmentation_strength] + base)\n",
        "\n",
        "    @staticmethod\n",
        "    def load_and_balance_data():\n",
        "        X = np.load(Config.DATA_FILE, mmap_mode='r').copy()\n",
        "        Y = np.load(Config.LABELS_FILE, allow_pickle=True)\n",
        "        print(f\"üìä Original data: {X.shape}, Class dist: {np.bincount(Y)}\")\n",
        "        # SMOTE on flattened\n",
        "        X_flat = X.reshape(X.shape[0], -1)\n",
        "        smote = SMOTE(random_state=Config.SEED, k_neighbors=3)\n",
        "        X_bal, Y_bal = smote.fit_resample(X_flat, Y)\n",
        "        X_bal = X_bal.reshape(-1, *X.shape[1:])\n",
        "        print(f\"üìä Balanced data: {X_bal.shape}, Class dist: {np.bincount(Y_bal)}\")\n",
        "        return X_bal, Y_bal\n",
        "\n",
        "# FIXED: Helper for balanced sampling\n",
        "def create_balanced_sampler(labels):\n",
        "    \"\"\"Create WeightedRandomSampler for balanced training\"\"\"\n",
        "    class_weights = compute_class_weight(\"balanced\", classes=np.unique(labels), y=labels)\n",
        "    sample_weights = [class_weights[y] for y in labels]\n",
        "    return WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "# Helper: deterministic split for final train/val\n",
        "def make_train_val_loaders(X, Y, aug_strength='medium'):\n",
        "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "        X, Y, test_size=Config.TEST_SIZE, random_state=Config.SEED, stratify=Y\n",
        "    )\n",
        "    ttr = DataManager.get_transforms(aug_strength, True)\n",
        "    tval = DataManager.get_transforms('medium', False)  # FIXED: Use medium aug for validation too\n",
        "\n",
        "    train_ds = FishDataset(X_tr, y_tr, ttr)\n",
        "    val_ds   = FishDataset(X_val, y_val, tval)\n",
        "\n",
        "    # FIXED: Add balanced sampler for training\n",
        "    train_sampler = create_balanced_sampler(y_tr)\n",
        "\n",
        "    train_loader = DataLoader(train_ds, batch_size=Config.BATCH_SIZE, sampler=train_sampler,  # FIXED: Use sampler instead of shuffle\n",
        "                              num_workers=2, pin_memory=torch.cuda.is_available(), drop_last=True)  # FIXED: drop_last=True\n",
        "    val_loader   = DataLoader(val_ds, batch_size=Config.BATCH_SIZE*2, shuffle=False,\n",
        "                              num_workers=2, pin_memory=torch.cuda.is_available(), drop_last=False)\n",
        "    return train_loader, val_loader, (X_tr, y_tr, X_val, y_val)\n",
        "\n",
        "# ==============================================================\n",
        "# PART 2 ‚Äî Models, Training, K-Fold CV, Lightweight HPO, Ensemble\n",
        "# ==============================================================\n",
        "\n",
        "# --------- Backbones ----------\n",
        "def build_backbone(backbone: str, dropout: float, num_classes: int):\n",
        "    if backbone == 'resnet50':\n",
        "        m = models.resnet50(weights='IMAGENET1K_V2')\n",
        "        feat_dim = m.fc.in_features\n",
        "        m.fc = nn.Identity()\n",
        "        target_layer = m.layer4[-1]\n",
        "\n",
        "        # FIXED: Freeze early layers to prevent overfitting\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"layer4\" not in name and \"layer3\" not in name:  # Only train layer3 and layer4\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif backbone == 'efficientnet_b0':\n",
        "        m = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "        feat_dim = m.classifier[1].in_features\n",
        "        m.classifier = nn.Identity()\n",
        "        target_layer = m.features[-1]\n",
        "\n",
        "        # FIXED: Freeze early layers\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"features.6\" not in name and \"features.7\" not in name:  # Only train last 2 feature blocks\n",
        "                param.requires_grad = False\n",
        "\n",
        "    elif backbone == 'mobilenet_v3_large':\n",
        "        m = models.mobilenet_v3_large(weights='IMAGENET1K_V2')\n",
        "        feat_dim = m.classifier[0].in_features\n",
        "        m.classifier = nn.Identity()\n",
        "        target_layer = m.features[-1]\n",
        "\n",
        "        # FIXED: Freeze early layers\n",
        "        for name, param in m.named_parameters():\n",
        "            if \"features.14\" not in name and \"features.15\" not in name and \"features.16\" not in name:\n",
        "                param.requires_grad = False\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported backbone: {backbone}\")\n",
        "\n",
        "    # Lightweight attention head + classifier\n",
        "    attn = nn.Sequential(\n",
        "        nn.AdaptiveAvgPool2d(1), nn.Flatten(),\n",
        "        nn.Linear(feat_dim, feat_dim//16), nn.ReLU(inplace=True),\n",
        "        nn.Linear(feat_dim//16, feat_dim), nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "    # FIXED: More regularized classifier\n",
        "    clf  = nn.Sequential(\n",
        "        nn.Dropout(dropout),\n",
        "        nn.Linear(feat_dim, feat_dim//2),\n",
        "        nn.BatchNorm1d(feat_dim//2),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(dropout),  # FIXED: Same dropout rate for both layers\n",
        "        nn.Linear(feat_dim//2, feat_dim//4),  # FIXED: Added intermediate layer\n",
        "        nn.BatchNorm1d(feat_dim//4),\n",
        "        nn.ReLU(inplace=True),\n",
        "        nn.Dropout(dropout/2),\n",
        "        nn.Linear(feat_dim//4, num_classes)\n",
        "    )\n",
        "\n",
        "    return m, feat_dim, attn, clf, target_layer\n",
        "\n",
        "class FishClassifier(nn.Module):\n",
        "    def __init__(self, backbone='resnet50', num_classes=5, dropout_rate=0.5):  # FIXED: Higher default dropout\n",
        "        super().__init__()\n",
        "        self.backbone_name = backbone\n",
        "        self.backbone, self.feature_dim, self.attention, self.classifier, self.target_layer = \\\n",
        "            build_backbone(backbone, dropout_rate, num_classes)\n",
        "\n",
        "        # CAM buffers\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        feat = self.backbone(x)\n",
        "        if len(feat.shape) == 4:\n",
        "            att_w = self.attention(feat).view(feat.size(0), feat.size(1), 1, 1)\n",
        "            feat  = torch.nn.functional.adaptive_avg_pool2d(feat * att_w, 1).flatten(1)\n",
        "        return self.classifier(feat)\n",
        "\n",
        "    def forward_with_hook(self, x):\n",
        "        def save_activation(module, inp, out): self.activations = out\n",
        "        def save_gradient(module, gin, gout): self.gradients = gout[0]\n",
        "        hf = self.target_layer.register_forward_hook(save_activation)\n",
        "        hb = self.target_layer.register_backward_hook(save_gradient)\n",
        "        out = self.forward(x)\n",
        "        hf.remove(); hb.remove()\n",
        "        return out\n",
        "\n",
        "# --------- Trainer ----------\n",
        "class Trainer:\n",
        "    def __init__(self, model, hyperparams):\n",
        "        self.model = model.to(Config.DEVICE)\n",
        "        self.hp = hyperparams\n",
        "        # FIXED: Added label smoothing to prevent overconfident predictions\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=0.15)  # FIXED: Label smoothing\n",
        "        self.best_val = 0.0\n",
        "        self.patience = 0\n",
        "        self.best_state = None\n",
        "\n",
        "        # FIXED: Only use AdamW with proper weight decay\n",
        "        self.opt = optim.AdamW(self.model.parameters(),\n",
        "                               lr=self.hp['learning_rate'],\n",
        "                               weight_decay=self.hp['weight_decay'])\n",
        "\n",
        "        # Scheduler\n",
        "        if self.hp['scheduler'] == 'cosine':\n",
        "            self.sched = optim.lr_scheduler.CosineAnnealingLR(self.opt, T_max=Config.MAX_EPOCHS)\n",
        "        elif self.hp['scheduler'] == 'step':\n",
        "            self.sched = optim.lr_scheduler.StepLR(self.opt, step_size=12, gamma=0.3)  # FIXED: More aggressive step decay\n",
        "        else:\n",
        "            # FIXED: More aggressive plateau scheduler\n",
        "            self.sched = optim.lr_scheduler.ReduceLROnPlateau(self.opt, mode='max', patience=2, factor=0.5, min_lr=1e-7)\n",
        "\n",
        "    def _epoch(self, loader, train=True):\n",
        "        if train:\n",
        "            self.model.train()\n",
        "        else:\n",
        "            self.model.eval()\n",
        "\n",
        "        total_loss, total_correct, total = 0.0, 0, 0\n",
        "        with torch.set_grad_enabled(train):\n",
        "            for x, y in loader:\n",
        "                x, y = x.to(Config.DEVICE), y.to(Config.DEVICE)\n",
        "                if train: self.opt.zero_grad()\n",
        "                out  = self.model(x)\n",
        "                loss = self.criterion(out, y)\n",
        "                if train:\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), 0.5)  # FIXED: More aggressive grad clipping\n",
        "                    self.opt.step()\n",
        "                total_loss    += loss.item()\n",
        "                total_correct += (out.argmax(1) == y).sum().item()\n",
        "                total         += y.size(0)\n",
        "        return total_loss/len(loader), total_correct/total\n",
        "\n",
        "    def fit(self, train_loader, val_loader, max_epochs=Config.MAX_EPOCHS, log_prefix=\"\"):\n",
        "        history = {'train_acc': [], 'val_acc': [], 'train_loss': [], 'val_loss': []}\n",
        "        for ep in range(1, max_epochs+1):\n",
        "            tr_loss, tr_acc = self._epoch(train_loader, train=True)\n",
        "            va_loss, va_acc = self._epoch(val_loader, train=False)\n",
        "\n",
        "            history['train_loss'].append(tr_loss); history['val_loss'].append(va_loss)\n",
        "            history['train_acc'].append(tr_acc);   history['val_acc'].append(va_acc)\n",
        "\n",
        "            # FIXED: Better early stopping logic\n",
        "            improved = va_acc > self.best_val + 1e-5  # Small threshold for improvement\n",
        "            if improved:\n",
        "                self.best_val = va_acc\n",
        "                self.patience = 0\n",
        "                self.best_state = {k: v.cpu().clone() for k, v in self.model.state_dict().items()}\n",
        "            else:\n",
        "                self.patience += 1\n",
        "\n",
        "            # Scheduler step\n",
        "            if isinstance(self.sched, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                self.sched.step(va_acc)\n",
        "            else:\n",
        "                self.sched.step()\n",
        "\n",
        "            print(f\"{log_prefix}Epoch {ep:02d} | Train Acc {tr_acc:.4f} | Val Acc {va_acc:.4f} | LR {self.opt.param_groups[0]['lr']:.2e}\")\n",
        "\n",
        "            # FIXED: Stop if validation accuracy doesn't improve and gap is too large\n",
        "            if self.patience >= Config.PATIENCE or (tr_acc - va_acc > 0.3 and ep > 10):  # FIXED: Stop if overfitting gap > 30%\n",
        "                print(f\"{log_prefix}‚èπÔ∏è Early stopping at epoch {ep} (overfitting detected)\")\n",
        "                break\n",
        "\n",
        "        # Load best\n",
        "        if self.best_state is not None:\n",
        "            self.model.load_state_dict(self.best_state)\n",
        "        return history\n",
        "\n",
        "# --------- K-Fold CV (returns metrics) ----------\n",
        "def cross_validate_model(X, Y, backbone, hp, folds=3, epochs=12):  # FIXED: Reduced epochs for HPO speed\n",
        "    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=Config.SEED)\n",
        "    accs, f1s = [], []\n",
        "    for fi, (tr_idx, va_idx) in enumerate(skf.split(X, Y), 1):\n",
        "        Xtr, Xva = X[tr_idx], X[va_idx]\n",
        "        Ytr, Yva = Y[tr_idx], Y[va_idx]\n",
        "        ttr = DataManager.get_transforms(hp['augmentation_strength'], True)\n",
        "        tva = DataManager.get_transforms('medium', False)  # FIXED: Medium aug for validation too\n",
        "\n",
        "        # FIXED: Add balanced sampling\n",
        "        train_sampler = create_balanced_sampler(Ytr)\n",
        "        tr_loader = DataLoader(FishDataset(Xtr, Ytr, ttr), batch_size=Config.BATCH_SIZE, sampler=train_sampler,\n",
        "                               num_workers=2, pin_memory=torch.cuda.is_available(), drop_last=True)\n",
        "        va_loader = DataLoader(FishDataset(Xva, Yva, tva), batch_size=Config.BATCH_SIZE*2, shuffle=False,\n",
        "                               num_workers=2, pin_memory=torch.cuda.is_available(), drop_last=False)\n",
        "\n",
        "        model = FishClassifier(backbone, Config.NUM_CLASSES, hp['dropout_rate'])\n",
        "        trainer = Trainer(model, hp)\n",
        "        _ = trainer.fit(tr_loader, va_loader, max_epochs=epochs, log_prefix=f\"[{backbone} F{fi}] \")\n",
        "\n",
        "        # Evaluate\n",
        "        y_true, y_pred = [], []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in va_loader:\n",
        "                logits = model(xb.to(Config.DEVICE))\n",
        "                y_true.extend(yb.numpy().tolist())\n",
        "                y_pred.extend(logits.argmax(1).cpu().numpy().tolist())\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        f1 = f1_score(y_true, y_pred, average='macro')\n",
        "        accs.append(acc); f1s.append(f1)\n",
        "\n",
        "        # cleanup\n",
        "        del model, trainer, tr_loader, va_loader\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "    return np.mean(accs), np.mean(f1s)\n",
        "\n",
        "# --------- Lightweight HPO (per backbone) ----------\n",
        "def hpo_for_backbone(X, Y, backbone: str, n_trials=Config.N_TRIALS):\n",
        "    def objective(trial):\n",
        "        hp = {\n",
        "            'learning_rate': trial.suggest_categorical('learning_rate', Config.HP_SPACE['learning_rate']),\n",
        "            'weight_decay' : trial.suggest_categorical('weight_decay',  Config.HP_SPACE['weight_decay']),\n",
        "            'dropout_rate' : trial.suggest_categorical('dropout_rate',  Config.HP_SPACE['dropout_rate']),\n",
        "            'optimizer'    : 'adamw',  # FIXED: Only use AdamW\n",
        "            'scheduler'    : trial.suggest_categorical('scheduler',     Config.HP_SPACE['scheduler']),\n",
        "            'augmentation_strength': trial.suggest_categorical('augmentation_strength', Config.HP_SPACE['augmentation_strength']),\n",
        "        }\n",
        "        # 3-fold CV, short epochs ‚Äî prune aggressively\n",
        "        acc, f1 = cross_validate_model(X, Y, backbone, hp, folds=3, epochs=10)\n",
        "\n",
        "        # FIXED: Optimize for F1 score instead of just accuracy\n",
        "        score = 0.7 * acc + 0.3 * f1  # Weighted combination\n",
        "        trial.report(score, step=0)\n",
        "        return score\n",
        "\n",
        "    pruner = optuna.pruners.MedianPruner(n_warmup_steps=1)\n",
        "    study = optuna.create_study(direction='maximize', pruner=pruner, sampler=optuna.samplers.TPESampler(seed=Config.SEED))\n",
        "    study.optimize(objective, n_trials=n_trials, timeout=Config.TIMEOUT_S, show_progress_bar=False)\n",
        "    print(f\"üèÜ {backbone} best value {study.best_value:.4f} with params {study.best_params}\")\n",
        "    return study.best_params, study.best_value\n",
        "\n",
        "# --------- Train final models & Ensemble ----------\n",
        "def train_final_models(X, Y, best_hp_per_backbone: Dict[str, Dict]):\n",
        "    trained_models = {}\n",
        "    metrics = {}\n",
        "    for backbone, hp in best_hp_per_backbone.items():\n",
        "        print(f\"\\n======== Training final {backbone} ========\")\n",
        "        tr_loader, va_loader, (Xtr, ytr, Xva, yva) = make_train_val_loaders(X, Y, aug_strength=hp['augmentation_strength'])\n",
        "        model = FishClassifier(backbone, Config.NUM_CLASSES, hp['dropout_rate'])\n",
        "        trainer = Trainer(model, hp)\n",
        "        history = trainer.fit(tr_loader, va_loader, max_epochs=Config.MAX_EPOCHS, log_prefix=f\"[{backbone}] \")\n",
        "\n",
        "        # Evaluate on held-out val\n",
        "        y_true, y_pred = [], []\n",
        "        y_proba = []\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for xb, yb in va_loader:\n",
        "                logits = model(xb.to(Config.DEVICE))\n",
        "                probs  = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "                y_proba.append(probs)\n",
        "                y_true.extend(yb.numpy().tolist())\n",
        "                y_pred.extend(logits.argmax(1).cpu().numpy().tolist())\n",
        "        y_proba = np.concatenate(y_proba, axis=0)\n",
        "        acc = accuracy_score(y_true, y_pred)\n",
        "        f1  = f1_score(y_true, y_pred, average='macro')\n",
        "\n",
        "        # Save model\n",
        "        save_path = os.path.join(Config.OUTPUT_DIR, f\"best_{backbone}.pt\")\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        print(f\"üíæ Saved {backbone} to {save_path} | Val Acc={acc:.4f} F1={f1:.4f}\")\n",
        "\n",
        "        trained_models[backbone] = model\n",
        "        metrics[backbone] = {'acc': acc, 'f1': f1, 'history': history, 'val_true': np.array(y_true),\n",
        "                             'val_pred': np.array(y_pred), 'val_proba': y_proba}\n",
        "        # cleanup loaders\n",
        "        del tr_loader, va_loader\n",
        "        torch.cuda.empty_cache(); gc.collect()\n",
        "    return trained_models, metrics\n",
        "\n",
        "def ensemble_predict_proba(models: Dict[str, nn.Module], X_val: np.ndarray, transform):\n",
        "    ds = FishDataset(X_val, np.zeros((len(X_val),), dtype=np.int64), transform)\n",
        "    loader = DataLoader(ds, batch_size=Config.BATCH_SIZE*2, shuffle=False, num_workers=2,\n",
        "                        pin_memory=torch.cuda.is_available())\n",
        "    # collect per-model probabilities and average\n",
        "    all_probs = []\n",
        "    with torch.no_grad():\n",
        "        for xb, _ in loader:\n",
        "            xb = xb.to(Config.DEVICE)\n",
        "            probs_list = []\n",
        "            for model in models.values():\n",
        "                logits = model(xb)\n",
        "                probs  = torch.softmax(logits, dim=1)\n",
        "                probs_list.append(probs)\n",
        "            avg_probs = torch.stack(probs_list, dim=0).mean(dim=0)  # simple soft-vote\n",
        "            all_probs.append(avg_probs.cpu().numpy())\n",
        "    return np.concatenate(all_probs, axis=0)\n",
        "\n",
        "# ==============================================================\n",
        "# PART 3 ‚Äî Publication-ready Visualizations (Q1 journal style)\n",
        "# ==============================================================\n",
        "\n",
        "def plot_learning_curves(histories: Dict[str, Dict], outdir: str):\n",
        "    plt.figure(figsize=(12,8))\n",
        "\n",
        "    # FIXED: Plot both train and val curves to show overfitting\n",
        "    plt.subplot(2,2,1)\n",
        "    for name, m in histories.items():\n",
        "        plt.plot(m['history']['train_acc'], label=f'{name} Train', alpha=0.7, linestyle='--')\n",
        "        plt.plot(m['history']['val_acc'], label=f'{name} Val', linewidth=2)\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.title('Training vs Validation Accuracy')\n",
        "    plt.grid(alpha=0.3); plt.legend()\n",
        "\n",
        "    plt.subplot(2,2,2)\n",
        "    for name, m in histories.items():\n",
        "        plt.plot(m['history']['train_loss'], label=f'{name} Train', alpha=0.7, linestyle='--')\n",
        "        plt.plot(m['history']['val_loss'], label=f'{name} Val', linewidth=2)\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Training vs Validation Loss')\n",
        "    plt.grid(alpha=0.3); plt.legend()\n",
        "\n",
        "    plt.subplot(2,2,3)\n",
        "    for name, m in histories.items():\n",
        "        gap = np.array(m['history']['train_acc']) - np.array(m['history']['val_acc'])\n",
        "        plt.plot(gap, label=f'{name} Gap', linewidth=2)\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Accuracy Gap'); plt.title('Overfitting Gap (Train - Val)')\n",
        "    plt.grid(alpha=0.3); plt.legend()\n",
        "\n",
        "    plt.subplot(2,2,4)\n",
        "    for name, m in histories.items():\n",
        "        plt.plot(m['history']['val_acc'], label=f'{name}', linewidth=2)\n",
        "    plt.xlabel('Epoch'); plt.ylabel('Validation Accuracy'); plt.title('Validation Accuracy Only')\n",
        "    plt.grid(alpha=0.3); plt.legend()\n",
        "\n",
        "    p = os.path.join(outdir, 'learning_curves.png')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(p, dpi=300, bbox_inches='tight'); plt.show()\n",
        "    print(f\"üìà Saved learning curves to {p}\")\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, labels, title, outpath):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=list(range(len(labels))))\n",
        "    cmn = cm.astype('float')/cm.sum(axis=1, keepdims=True)\n",
        "    plt.figure(figsize=(8,7))\n",
        "    sns.heatmap(cmn, annot=True, fmt=\".2f\", xticklabels=labels, yticklabels=labels,\n",
        "                cmap='Blues', cbar_kws={'label': 'Normalized Count'})\n",
        "    plt.ylabel('True Label'); plt.xlabel('Predicted Label'); plt.title(title)\n",
        "    plt.tight_layout(); plt.savefig(outpath, dpi=300); plt.show()\n",
        "    print(f\"üìä Saved confusion matrix to {outpath}\")\n",
        "\n",
        "def plot_per_class_f1(y_true, y_pred, labels, outpath, title=\"Per-Class F1\"):\n",
        "    pr, rc, f1, _ = precision_recall_fscore_support(y_true, y_pred, average=None, labels=list(range(len(labels))))\n",
        "    plt.figure(figsize=(10,6))\n",
        "    x = np.arange(len(labels))\n",
        "    width = 0.25\n",
        "\n",
        "    plt.bar(x - width, pr, width, label='Precision', alpha=0.8)\n",
        "    plt.bar(x, rc, width, label='Recall', alpha=0.8)\n",
        "    plt.bar(x + width, f1, width, label='F1-Score', alpha=0.8)\n",
        "\n",
        "    plt.xlabel('Fish Species'); plt.ylabel('Score'); plt.title(title)\n",
        "    plt.xticks(x, labels, rotation=45); plt.ylim(0,1.05)\n",
        "    plt.legend(); plt.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for i, (p, r, f) in enumerate(zip(pr, rc, f1)):\n",
        "        plt.text(i-width, p+0.02, f\"{p:.2f}\", ha='center', fontsize=9)\n",
        "        plt.text(i, r+0.02, f\"{r:.2f}\", ha='center', fontsize=9)\n",
        "        plt.text(i+width, f+0.02, f\"{f:.2f}\", ha='center', fontsize=9)\n",
        "\n",
        "    plt.tight_layout(); plt.savefig(outpath, dpi=300, bbox_inches='tight'); plt.show()\n",
        "    print(f\"üìä Saved per-class metrics to {outpath}\")\n",
        "\n",
        "def plot_model_comparison(metrics: Dict[str, Dict], outdir: str):\n",
        "    names = list(metrics.keys())\n",
        "    accs  = [metrics[n]['acc'] for n in names]\n",
        "    f1s   = [metrics[n]['f1'] for n in names]\n",
        "    plt.figure(figsize=(10,6))\n",
        "    x = np.arange(len(names))\n",
        "    w = 0.35\n",
        "    plt.bar(x-w/2, accs, width=w, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "    plt.bar(x+w/2, f1s,  width=w, label='Macro-F1', alpha=0.8, color='lightcoral')\n",
        "    plt.xticks(x, names, rotation=20); plt.ylim(0,1.05)\n",
        "    for i,v in enumerate(accs): plt.text(i-w/2, v+0.02, f\"{v:.3f}\", ha='center', fontweight='bold')\n",
        "    for i,v in enumerate(f1s):  plt.text(i+w/2, v+0.02, f\"{v:.3f}\", ha='center', fontweight='bold')\n",
        "    plt.title('Backbone Performance Comparison'); plt.legend(); plt.grid(axis='y', alpha=0.3)\n",
        "    plt.ylabel('Score')\n",
        "    p = os.path.join(outdir, 'model_comparison.png')\n",
        "    plt.tight_layout(); plt.savefig(p, dpi=300, bbox_inches='tight'); plt.show()\n",
        "    print(f\"üìä Saved model comparison to {p}\")\n",
        "\n",
        "# ==============================================================\n",
        "# PART 4 ‚Äî Explainable AI: Grad-CAM++ and LRP (Captum)\n",
        "# ==============================================================\n",
        "\n",
        "# ---- Grad-CAM++ ----\n",
        "def grad_cam_plus_plus(model: FishClassifier, input_tensor: torch.Tensor, target_class: int = None):\n",
        "    \"\"\"\n",
        "    Minimal Grad-CAM++ implementation.\n",
        "    input_tensor: (1, C, H, W)\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    input_tensor = input_tensor.to(Config.DEVICE)\n",
        "    input_tensor.requires_grad = True\n",
        "\n",
        "    logits = model.forward_with_hook(input_tensor)\n",
        "    if target_class is None:\n",
        "        target_class = logits.argmax(dim=1).item()\n",
        "\n",
        "    loss = logits[0, target_class]\n",
        "    model.zero_grad()\n",
        "    loss.backward(retain_graph=True)\n",
        "\n",
        "    A = model.activations           # [B, K, u, v]\n",
        "    dYdA = model.gradients          # first grad\n",
        "    if A is None or dYdA is None:\n",
        "        return None\n",
        "\n",
        "    # Second & third derivatives approximations\n",
        "    # grad_cam++ weights: a_k = sum_{i,j} (alpha_{ij}^k * ReLU(dY/dA_ij^k))\n",
        "    # alpha_{ij}^k ~ d2Y/dA^2 / (2*d2Y/dA^2 + sum_{a,b} A^k_{ab} * d3Y/dA^3)\n",
        "    # Practical impl: use stabilized version from paper with eps\n",
        "    eps = 1e-8\n",
        "    d2 = dYdA ** 2\n",
        "    d3 = d2 * dYdA\n",
        "\n",
        "    # sum spatial over channel for denominator term\n",
        "    sumA = torch.sum(A, dim=(2,3), keepdim=True)\n",
        "\n",
        "    alpha_num = d2\n",
        "    alpha_den = 2*d2 + sumA * d3\n",
        "    alpha_den = torch.where(alpha_den != 0.0, alpha_den, torch.tensor(eps, device=alpha_den.device))\n",
        "    alphas = alpha_num / (alpha_den + eps)\n",
        "    relu_dYdA = torch.relu(dYdA)\n",
        "    weights = torch.sum(alphas * relu_dYdA, dim=(2,3))  # [B, K]\n",
        "\n",
        "    # CAM\n",
        "    cam = torch.zeros(A.shape[2:], dtype=torch.float32, device=A.device)\n",
        "    for k in range(A.shape[1]):\n",
        "        cam += weights[0, k] * A[0, k, :, :]\n",
        "    cam = torch.relu(cam)\n",
        "    cam = (cam - cam.min()) / (cam.max() - cam.min() + eps)\n",
        "    return cam.detach().cpu().numpy()\n",
        "\n",
        "# ---- LRP via Captum (with auto-install + safe fallback to GradCAM++) ----\n",
        "def ensure_captum():\n",
        "    try:\n",
        "        import captum  # noqa\n",
        "        return True\n",
        "    except Exception:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"captum\"])\n",
        "            import captum  # noqa\n",
        "            return True\n",
        "        except Exception as e:\n",
        "            print(\"‚ö†Ô∏è Captum install failed; will skip LRP and fall back to Grad-CAM++ only.\", e)\n",
        "            return False\n",
        "\n",
        "def lrp_relevance(model: FishClassifier, input_tensor: torch.Tensor, target_class: int = None):\n",
        "    ok = ensure_captum()\n",
        "    if not ok:\n",
        "        return None\n",
        "    from captum.attr import LRP\n",
        "    model.eval()\n",
        "    input_tensor = input_tensor.to(Config.DEVICE)\n",
        "    if target_class is None:\n",
        "        with torch.no_grad():\n",
        "            target_class = model(input_tensor).argmax(1).item()\n",
        "    lrp = LRP(model)\n",
        "    attr = lrp.attribute(inputs=input_tensor, target=target_class)\n",
        "    # Aggregate over channels to heatmap\n",
        "    heat = attr[0].detach().cpu().numpy()\n",
        "    heat = np.maximum(heat, 0)  # ReLU-like\n",
        "    heat = heat.mean(axis=0)    # channel average\n",
        "    heat = (heat - heat.min()) / (heat.max() - heat.min() + 1e-8)\n",
        "    return heat\n",
        "\n",
        "def denorm_to_img(tensor):\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std  = np.array([0.229, 0.224, 0.225])\n",
        "    img = tensor.detach().cpu().permute(1,2,0).numpy()\n",
        "    img = img * std + mean\n",
        "    return np.clip(img, 0, 1)\n",
        "\n",
        "def overlay_heatmap(img, heatmap, alpha=0.4):\n",
        "    import cv2\n",
        "    h, w = img.shape[:2]\n",
        "    heatmap_resized = cv2.resize(heatmap, (w, h))\n",
        "    cmap = plt.cm.jet(heatmap_resized)[..., :3]\n",
        "    return (1-alpha)*img + alpha*cmap\n",
        "\n",
        "def visualize_xai_comparison(model: FishClassifier, loader: DataLoader, outdir: str, n_samples=4):\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    for xb, yb in loader:\n",
        "        for i in range(xb.size(0)):\n",
        "            if count >= n_samples: return\n",
        "            sample = xb[i:i+1].to(Config.DEVICE)\n",
        "            true_y = yb[i].item()\n",
        "            with torch.no_grad():\n",
        "                logits = model(sample)\n",
        "                pred = logits.argmax(1).item()\n",
        "                confidence = torch.softmax(logits, dim=1).max().item()\n",
        "\n",
        "            # Grad-CAM++\n",
        "            campp = grad_cam_plus_plus(model, sample, target_class=pred)\n",
        "            # LRP\n",
        "            lrpmap = lrp_relevance(model, sample, target_class=pred)\n",
        "\n",
        "            img = denorm_to_img(xb[i])\n",
        "            fig, axs = plt.subplots(1, 4, figsize=(16,4))\n",
        "\n",
        "            # Original image with prediction info\n",
        "            axs[0].imshow(img)\n",
        "            axs[0].set_title(f\"Original\\nTrue: {Config.CLASS_LABELS[true_y]}\\nPred: {Config.CLASS_LABELS[pred]}\\nConf: {confidence:.3f}\")\n",
        "            axs[0].axis('off')\n",
        "\n",
        "            if campp is not None:\n",
        "                im1 = axs[1].imshow(campp, cmap='hot')\n",
        "                axs[1].set_title('Grad-CAM++')\n",
        "                axs[1].axis('off')\n",
        "                plt.colorbar(im1, ax=axs[1], fraction=0.046, pad=0.04)\n",
        "\n",
        "                axs[2].imshow(overlay_heatmap(img, campp))\n",
        "                axs[2].set_title('Grad-CAM++ Overlay')\n",
        "                axs[2].axis('off')\n",
        "            else:\n",
        "                axs[1].text(0.5, 0.5, 'No Grad-CAM++', ha='center', va='center')\n",
        "                axs[1].axis('off')\n",
        "                axs[2].axis('off')\n",
        "\n",
        "            if lrpmap is not None:\n",
        "                axs[3].imshow(overlay_heatmap(img, lrpmap))\n",
        "                axs[3].set_title('LRP Overlay')\n",
        "                axs[3].axis('off')\n",
        "            else:\n",
        "                axs[3].text(0.5, 0.5, 'LRP Unavailable', ha='center', va='center')\n",
        "                axs[3].axis('off')\n",
        "\n",
        "            p = os.path.join(outdir, f\"xai_cmp_{count+1}.png\")\n",
        "            plt.tight_layout(); plt.savefig(p, dpi=300, bbox_inches='tight'); plt.show()\n",
        "            print(f\"üß† Saved XAI comparison #{count+1} -> {p}\")\n",
        "            count += 1\n",
        "\n",
        "# ==============================================================\n",
        "# MAIN ‚Äî Run the whole pipeline\n",
        "# ==============================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"üêü Starting Enhanced Fish Classification Pipeline...\")\n",
        "    print(f\"üìä Configuration: {Config.NUM_CLASSES} classes, {Config.N_TRIALS} HPO trials\")\n",
        "\n",
        "    # ---- Load & Balance ----\n",
        "    X_bal, Y_bal = DataManager.load_and_balance_data()\n",
        "\n",
        "    # FIXED: Print class distribution to verify balance\n",
        "    print(f\"üìä Final class distribution: {dict(zip(Config.CLASS_LABELS, np.bincount(Y_bal)))}\")\n",
        "\n",
        "    # ---- Lightweight HPO per backbone (L4-safe) ----\n",
        "    print(\"\\nüîç Starting Hyperparameter Optimization...\")\n",
        "    best_hp = {}\n",
        "    backbone_scores = {}\n",
        "    for bb in Config.ENSEMBLE_BACKBONES:\n",
        "        print(f\"\\n--- Optimizing {bb} ---\")\n",
        "        params, score = hpo_for_backbone(X_bal, Y_bal, bb, n_trials=Config.N_TRIALS)\n",
        "        best_hp[bb] = params\n",
        "        backbone_scores[bb] = score\n",
        "\n",
        "    # Print HPO summary\n",
        "    print(\"\\nüèÜ HPO Results Summary:\")\n",
        "    for bb, score in backbone_scores.items():\n",
        "        print(f\"  {bb}: {score:.4f}\")\n",
        "\n",
        "    # ---- Train final models with best HPO settings ----\n",
        "    print(\"\\nüöÄ Training final models with optimized hyperparameters...\")\n",
        "    trained_models, metrics = train_final_models(X_bal, Y_bal, best_hp)\n",
        "\n",
        "    # ---- Ensemble evaluation on same held-out (from any trained model split) ----\n",
        "    # Use the last trained model's held-out split to evaluate ensemble fairly\n",
        "    any_backbone  = next(iter(metrics.keys()))\n",
        "    y_true_val    = metrics[any_backbone]['val_true']\n",
        "    # Build a val transform (medium instead of light for consistency)\n",
        "    val_transform = DataManager.get_transforms('medium', False)\n",
        "    # We don't have direct X_val; rebuild via split to align with y_true_val length\n",
        "    # -> Safely regenerate a consistent split identical to train_final_models' make_train_val_loaders()\n",
        "    _, _, (Xtr_, ytr_, Xva_, yva_) = make_train_val_loaders(X_bal, Y_bal, aug_strength=best_hp[any_backbone]['augmentation_strength'])\n",
        "    # align length with stored y_true_val if any shuffling difference\n",
        "    X_val_for_ens = Xva_[:len(y_true_val)]\n",
        "\n",
        "    print(\"\\nüéØ Evaluating ensemble...\")\n",
        "    ens_proba = ensemble_predict_proba(trained_models, X_val_for_ens, val_transform)\n",
        "    ens_pred  = ens_proba.argmax(1)\n",
        "    ens_acc   = accuracy_score(y_true_val[:len(ens_pred)], ens_pred)\n",
        "    ens_f1    = f1_score(y_true_val[:len(ens_pred)], ens_pred, average='macro')\n",
        "    print(f\"\\nüåü Ensemble Results | Val Acc={ens_acc:.4f}, Macro-F1={ens_f1:.4f}\")\n",
        "\n",
        "    # FIXED: Compare ensemble vs best single model\n",
        "    best_single = max(metrics.items(), key=lambda kv: kv[1]['f1'])\n",
        "    best_name   = best_single[0]\n",
        "    print(f\"üèÖ Best single model: {best_name} | Acc={metrics[best_name]['acc']:.4f} | F1={metrics[best_name]['f1']:.4f}\")\n",
        "    print(f\"üìà Ensemble improvement: Acc +{ens_acc - metrics[best_name]['acc']:.4f}, F1 +{ens_f1 - metrics[best_name]['f1']:.4f}\")\n",
        "\n",
        "    # Save ensemble meta\n",
        "    ensemble_summary = {\n",
        "        \"backbones\": list(trained_models.keys()),\n",
        "        \"best_params\": best_hp,\n",
        "        \"hpo_scores\": backbone_scores,\n",
        "        \"single_model_scores\": {k: {\"acc\": v[\"acc\"], \"f1\": v[\"f1\"]} for k, v in metrics.items()},\n",
        "        \"ensemble\": {\"acc\": float(ens_acc), \"f1\": float(ens_f1)},\n",
        "        \"best_single_model\": best_name\n",
        "    }\n",
        "\n",
        "    with open(os.path.join(Config.OUTPUT_DIR, \"ensemble_summary.json\"), \"w\") as f:\n",
        "        json.dump(ensemble_summary, f, indent=2)\n",
        "    print(f\"üíæ Saved ensemble summary to {os.path.join(Config.OUTPUT_DIR, 'ensemble_summary.json')}\")\n",
        "\n",
        "    # ==================================================\n",
        "    # Part 3 ‚Äî Visualizations (Q1-ready)\n",
        "    # ==================================================\n",
        "    print(\"\\nüìä Generating publication-ready visualizations...\")\n",
        "\n",
        "    # Learning curves for all trained models\n",
        "    plot_learning_curves({k: v for k, v in metrics.items()}, Config.OUTPUT_DIR)\n",
        "\n",
        "    # Confusion matrices and per-class metrics for best single model\n",
        "    plot_confusion_matrix(metrics[best_name]['val_true'], metrics[best_name]['val_pred'],\n",
        "                          Config.CLASS_LABELS,\n",
        "                          title=f'Confusion Matrix ‚Äî {best_name}',\n",
        "                          outpath=os.path.join(Config.OUTPUT_DIR, f'cm_{best_name}.png'))\n",
        "\n",
        "    plot_per_class_f1(metrics[best_name]['val_true'], metrics[best_name]['val_pred'],\n",
        "                      Config.CLASS_LABELS,\n",
        "                      outpath=os.path.join(Config.OUTPUT_DIR, f'per_class_metrics_{best_name}.png'),\n",
        "                      title=f'Per-Class Metrics ‚Äî {best_name}')\n",
        "\n",
        "    # FIXED: Also plot ensemble confusion matrix\n",
        "    plot_confusion_matrix(y_true_val[:len(ens_pred)], ens_pred,\n",
        "                          Config.CLASS_LABELS,\n",
        "                          title='Confusion Matrix ‚Äî Ensemble',\n",
        "                          outpath=os.path.join(Config.OUTPUT_DIR, 'cm_ensemble.png'))\n",
        "\n",
        "    # Backbone comparison chart (acc & f1)\n",
        "    plot_model_comparison(metrics, Config.OUTPUT_DIR)\n",
        "\n",
        "    # ==================================================\n",
        "    # Part 4 ‚Äî XAI: Grad-CAM++ vs LRP (side-by-side)\n",
        "    # ==================================================\n",
        "    # Build a small loader from the same validation split for the best model\n",
        "    print(\"\\nüîç Generating explainability visualizations...\")\n",
        "    tva = DataManager.get_transforms('medium', False)\n",
        "    xai_ds = FishDataset(X_val_for_ens, y_true_val[:len(X_val_for_ens)], tva)\n",
        "    xai_loader = DataLoader(xai_ds, batch_size=4, shuffle=False, num_workers=2, pin_memory=torch.cuda.is_available())\n",
        "\n",
        "    print(f\"üß† XAI comparisons on {best_name}\")\n",
        "    visualize_xai_comparison(trained_models[best_name], xai_loader, Config.OUTPUT_DIR, n_samples=4)\n",
        "\n",
        "    # ==================================================\n",
        "    # FINAL SUMMARY REPORT\n",
        "    # ==================================================\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"üìã FINAL PERFORMANCE SUMMARY\")\n",
        "    print(\"=\"*60)\n",
        "    print(f\"üéØ Dataset: {len(X_bal)} samples, {Config.NUM_CLASSES} classes\")\n",
        "    print(f\"üîß HPO Trials: {Config.N_TRIALS} per backbone\")\n",
        "    print(f\"\\nüìä Individual Model Results:\")\n",
        "    for name, metric in metrics.items():\n",
        "        print(f\"  {name:20} | Acc: {metric['acc']:.4f} | F1: {metric['f1']:.4f}\")\n",
        "    print(f\"\\nüåü Ensemble Results:\")\n",
        "    print(f\"  {'Ensemble':20} | Acc: {ens_acc:.4f} | F1: {ens_f1:.4f}\")\n",
        "    print(f\"\\nüèÜ Best Approach: {'Ensemble' if ens_f1 > metrics[best_name]['f1'] else best_name}\")\n",
        "\n",
        "    # FIXED: Performance improvement analysis\n",
        "    original_acc = 0.20  # Your reported stuck validation accuracy\n",
        "    improvement = max(ens_acc, metrics[best_name]['acc']) - original_acc\n",
        "    print(f\"üìà Improvement over original: +{improvement:.1%} accuracy\")\n",
        "\n",
        "    print(\"\\n‚úÖ Pipeline complete. Check /content/outputs/ for all visualizations and models.\")\n",
        "    print(f\"üíæ Models saved: {list(trained_models.keys())}\")\n",
        "    print(f\"üìà Plots generated: learning_curves.png, model_comparison.png, confusion matrices, XAI comparisons\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAav3Li_QNnd",
        "outputId": "a65a9162-39ac-4a9a-def0-6aa6f544c1af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (4.5.0)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (1.16.4)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "üöÄ GPU: NVIDIA L4\n",
            "üêü Starting Enhanced Fish Classification Pipeline...\n",
            "üìä Configuration: 5 classes, 8 HPO trials\n",
            "üìä Original data: (8407, 3, 224, 224), Class dist: [3000 1185 2899  370  953]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-18 08:36:28,149] A new study created in memory with name: no-name-7d7a65de-7094-464d-b7ef-5960123072dd\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Balanced data: (15000, 3, 224, 224), Class dist: [3000 3000 3000 3000 3000]\n",
            "üìä Final class distribution: {'Ilish': np.int64(3000), 'Chandana': np.int64(3000), 'Sardin': np.int64(3000), 'Sardinella': np.int64(3000), 'Punctatus': np.int64(3000)}\n",
            "\n",
            "üîç Starting Hyperparameter Optimization...\n",
            "\n",
            "--- Optimizing resnet50 ---\n",
            "[resnet50 F1] Epoch 01 | Train Acc 0.5125 | Val Acc 0.8456 | LR 5.00e-05\n",
            "[resnet50 F1] Epoch 02 | Train Acc 0.7719 | Val Acc 0.9604 | LR 5.00e-05\n",
            "[resnet50 F1] Epoch 03 | Train Acc 0.8487 | Val Acc 0.9768 | LR 5.00e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58ledYtVy8YD"
      },
      "source": [
        "#End"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}