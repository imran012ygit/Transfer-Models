{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran012x/Transfer-Models/blob/main/Hilsha_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01bea336",
      "metadata": {
        "id": "01bea336"
      },
      "source": [
        "#Colab-connect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "344965bc",
      "metadata": {
        "id": "344965bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33872f1a-2e70-4ea2-d396-3965e5b827be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# # Upload a file\n",
        "# uploaded = files.upload()\n",
        "# # Get the file name\n",
        "# file_name = list(uploaded.keys())[0]\n",
        "# print(f\"Uploaded file: {file_name}\")\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# # with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_224_11k.zip', 'r') as zip_ref:\n",
        "# #     zip_ref.extractall('')\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de009928",
      "metadata": {
        "id": "de009928"
      },
      "source": [
        "#Data Preprocess and Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6f95c03b",
      "metadata": {
        "id": "6f95c03b"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "# from tqdm import tqdm\n",
        "# import random\n",
        "# import gc\n",
        "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "# import threading\n",
        "# import zipfile\n",
        "\n",
        "# # Check GPU availability\n",
        "# print(\"GPU Available:\", torch.cuda.is_available())\n",
        "# print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "# # Define fish classes and dataset paths\n",
        "# fish_classes = ['ilish', 'chandana', 'sardin', 'sardinella', 'punctatus'] #0,1,2,3,4\n",
        "# zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip').extractall('/content/.hidden_fish')\n",
        "# data_dir = '/content/.hidden_fish'\n",
        "\n",
        "# image_limits = {\n",
        "#     'ilish': 3000,\n",
        "#     'chandana': 1185,\n",
        "#     'sardin': 2899,\n",
        "#     'sardinella': 370,\n",
        "#     'punctatus': 953\n",
        "# }\n",
        "\n",
        "# # Settings\n",
        "# total_images = sum(image_limits.values())\n",
        "# batch_size = 100\n",
        "# num_threads = 4\n",
        "\n",
        "\n",
        "# # Output paths\n",
        "# output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "# labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "# xdata_file = os.path.join(output_dir, 'X_data.npy')\n",
        "\n",
        "# save_lock = threading.Lock()  # for thread-safe writes -> Prevents race conditions when multiple threads write to the same list.\n",
        "\n",
        "# # Function to gather image paths\n",
        "# def get_image_paths(class_name, max_images):\n",
        "#     path = os.path.join(data_dir, class_name)\n",
        "#     files = sorted(os.listdir(path))\n",
        "#     random.shuffle(files)\n",
        "#     return [os.path.join(path, f) for f in files[:max_images]]\n",
        "\n",
        "# # Load and preprocess batch\n",
        "# def load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     end_idx = min(start_idx + batch_size, len(image_paths))\n",
        "#     batch_paths = image_paths[start_idx:end_idx]\n",
        "#     batch_images = []\n",
        "\n",
        "#     for img_path in batch_paths:\n",
        "#         img = Image.open(img_path).resize((224, 224)).convert('RGB')\n",
        "#         img_tensor = torch.tensor(np.array(img), dtype=torch.uint8).permute(2, 0, 1)  # C x H x W\n",
        "#         batch_images.append(img_tensor)\n",
        "\n",
        "#     batch_tensor = torch.stack(batch_images)  # B x C x H x W\n",
        "#     batch_labels = np.full((len(batch_images),), class_idx, dtype=np.int32)\n",
        "#     return batch_tensor, batch_labels\n",
        "\n",
        "# # Process one batch and return tensors & labels (no file saving)\n",
        "# def process_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     return load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx)\n",
        "\n",
        "# def preprocess_and_save_all(overwrite=True):\n",
        "#     if os.path.exists(labels_file) and os.path.exists(xdata_file) and not overwrite:\n",
        "#         print(\"Preprocessed data already exists. Set overwrite=True to reprocess.\")\n",
        "#         return\n",
        "\n",
        "#     all_images = []\n",
        "#     all_labels = []\n",
        "#     processed_count = 0\n",
        "\n",
        "#     for idx, class_name in enumerate(fish_classes):\n",
        "#         print(f\"\\nProcessing class: {class_name}\")\n",
        "#         image_paths = get_image_paths(class_name, image_limits[class_name])\n",
        "#         total_batches = (len(image_paths) + batch_size - 1) // batch_size\n",
        "#         #It ensures ceiling division ‚Äî rounding up, not down.\n",
        "#         # Normal division: 103 / 20 = 5.15 ‚Üí floor division // 20 = 5 (‚ùå missing last 3 images)\n",
        "#         # This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ‚úÖ\n",
        "\n",
        "#         with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "#             futures = []\n",
        "#             for start in range(0, len(image_paths), batch_size):\n",
        "#                 futures.append(executor.submit(process_batch, image_paths, start, batch_size, idx))\n",
        "\n",
        "#             for future in tqdm(as_completed(futures), total=total_batches, desc=class_name):#taqaddum (ÿ™ŸÇÿØŸëŸÖ) ‚Äì Arabic for \"progress\".\n",
        "#                 # futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\n",
        "#                 # as_completed(futures): Yields each future as it finishes (not in order).\n",
        "\n",
        "#                 batch_tensor, batch_labels = future.result()\n",
        "#                 with save_lock: #Locks this section so that only one thread can update the shared lists safely.\n",
        "#                     all_images.append(batch_tensor)\n",
        "#                     all_labels.append(batch_labels)\n",
        "#                     processed_count += batch_tensor.size(0)\n",
        "#                     print(f\"Processed batch with {batch_tensor.size(0)} images, total processed: {processed_count}/{total_images}\")\n",
        "#                 gc.collect()\n",
        "\n",
        "#     # Combine all tensors and labels\n",
        "#     X = torch.cat(all_images, dim=0).numpy()\n",
        "#     Y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "#     # Save final arrays\n",
        "#     np.save(xdata_file, X, allow_pickle=False)#Malicious .npy -> import os;os.system(\"rm -rf /\")  # ‚Üê Dangerous command\n",
        "#     np.save(labels_file, Y, allow_pickle=False)\n",
        "\n",
        "#     print(f\"\\n‚úÖ Done! Saved {processed_count} images in {xdata_file}\")\n",
        "#     print(f\"X_data shape: {X.shape}, Y_labels shape: {Y.shape}\")\n",
        "\n",
        "#     if processed_count != total_images:\n",
        "#         raise ValueError(f\"Expected {total_images} images, but processed {processed_count}\")\n",
        "\n",
        "# # Run preprocessing and save directly to X_data.npy and Y_labels.npy\n",
        "# preprocess_and_save_all(overwrite=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0fbbeb4",
      "metadata": {
        "id": "c0fbbeb4"
      },
      "source": [
        "####DATA LOADING...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "23d9c0c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23d9c0c0",
        "outputId": "5cb6877f-b720-4b24-8226-b24cbf7bc037"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ X_data.npy: 1.18 GB\n",
            "üìÅ Y_labels.npy: 32.96 KB\n",
            "‚úÖ X shape: (8407, 3, 224, 224), dtype: uint8\n",
            "‚úÖ Y shape: (8407,), dtype: int32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614331559.py:42: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  X = torch.from_numpy(X)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Torch tensors ready on cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Your data path\n",
        "output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "data_file = os.path.join(output_dir, 'X_data.npy')\n",
        "labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "\n",
        "# Readable size format\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    for unit in ['', 'K', 'M', 'G', 'T']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return f\"{num:3.2f} {unit}{suffix}\"\n",
        "        num /= 1024.0\n",
        "    return f\"{num:.2f} T{suffix}\"\n",
        "\n",
        "# Main loader\n",
        "def load_preprocessed_data(as_torch=True, normalize=True, to_device=None):\n",
        "    # Check file existence #cpu,cuda (CUDA stands for Compute Unified Device Architecture.)\n",
        "    for path in [data_file, labels_file]:\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Missing: {path}\")\n",
        "\n",
        "    # Print file sizes\n",
        "    print(f\"üìÅ X_data.npy: {sizeof_fmt(os.path.getsize(data_file))}\")\n",
        "    print(f\"üìÅ Y_labels.npy: {sizeof_fmt(os.path.getsize(labels_file))}\")\n",
        "\n",
        "    # Load with mmap\n",
        "    X = np.load(data_file, mmap_mode='r')\n",
        "    Y = np.load(labels_file, mmap_mode='r')\n",
        "\n",
        "    print(f\"‚úÖ X shape: {X.shape}, dtype: {X.dtype}\")\n",
        "    print(f\"‚úÖ Y shape: {Y.shape}, dtype: {Y.dtype}\")\n",
        "\n",
        "    # Sanity check\n",
        "    if len(X) != len(Y):\n",
        "        raise ValueError(\"Mismatch between number of samples in X and Y\")\n",
        "\n",
        "    # Convert to torch\n",
        "    if as_torch:\n",
        "        X = torch.from_numpy(X)\n",
        "        Y = torch.from_numpy(Y)\n",
        "\n",
        "        if normalize and X.dtype == torch.uint8:\n",
        "            X = X.float() / 255.0\n",
        "\n",
        "        if to_device:\n",
        "            X = X.to(to_device)\n",
        "            Y = Y.to(to_device)\n",
        "\n",
        "        print(f\"üß† Torch tensors ready on {to_device or 'CPU'}\")\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# üîÅ Example call\n",
        "X, Y = load_preprocessed_data(\n",
        "    as_torch=True,\n",
        "    normalize=True,\n",
        "    to_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from enum import auto\n",
        "# 1. IMPORTS AND INITIAL SETUP\n",
        "# =============================================================================\n",
        "# Purpose: Import all required libraries and set up warnings to suppress unnecessary messages.\n",
        "\n",
        "#!pip install pytorch-gradcam optuna captum  # Uncomment if running in a new environment\n",
        "#!pip install --upgrade captum\n",
        "\n",
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "\n",
        "# def monitor_resources():\n",
        "#     while True:\n",
        "print(subprocess.getoutput('nvidia-smi'))\n",
        "print(subprocess.getoutput('free -h'))\n",
        "time.sleep(30)  # Check every 30s\n",
        "\n",
        "# monitor_thread = threading.Thread(target=monitor_resources, daemon=True)\n",
        "# monitor_thread.start()\n",
        "\n",
        "import gc\n",
        "import random\n",
        "import pynvml\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from itertools import combinations\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, f1_score,\n",
        "                             accuracy_score, precision_score, recall_score)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Augmentation\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "import traceback\n",
        "from tqdm import tqdm  # Import tqdm for reliable progress bar\n",
        "\n",
        "# Hyperparameter optimization\n",
        "try:\n",
        "    import optuna\n",
        "    OPTUNA_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPTUNA_AVAILABLE = False\n",
        "    print(\"Warning: Optuna not available. Using default hyperparameters.\")\n",
        "\n",
        "# XAI dependencies\n",
        "import torch.autograd as autograd\n",
        "\n",
        "# from captum._utils.lrp_rules import EpsilonRule\n",
        "# from captum.attr import EpsilonLRP\n",
        "from captum.attr import LRP\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import cv2\n",
        "import psutil\n",
        "import pynvml\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class NpEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, torch.Tensor):\n",
        "            return obj.cpu().detach().numpy().tolist()  # Convert tensor to NumPy array, then to list\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return super(NpEncoder, self).default(obj)\n",
        "\n",
        "\n",
        "# ---\n",
        "# 2. CONFIGURATION\n",
        "# =============================================================================\n",
        "# Purpose: Define configuration settings and initialize the environment.\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration settings\"\"\"\n",
        "    # Paths - UPDATE THESE TO YOUR ACTUAL PATHS\n",
        "    DATA_FILE = '/content/drive/MyDrive/Hilsha/X_data.npy'\n",
        "    LABELS_FILE = '/content/drive/MyDrive/Hilsha/Y_labels.npy'\n",
        "    OUTPUT_DIR = './fish_classification_results'\n",
        "\n",
        "    # Dataset parameters\n",
        "    NUM_CLASSES = 5\n",
        "    CLASS_LABELS = ['Ilish', 'Chandana', 'Sardin', 'Sardinella', 'Punctatus']\n",
        "    INPUT_SIZE = 224\n",
        "\n",
        "    # Training parameters\n",
        "    BATCH_SIZE = 32 #64\n",
        "    EPOCHS = 15\n",
        "    DATALOADER_NUM_WORKERS = 4\n",
        "    PIN_MEMORY = True\n",
        "    USE_MIXED_PRECISION = True #True\n",
        "    COMPILE_MODEL = True\n",
        "    PATIENCE = 4 #15\n",
        "    LEARNING_RATE = 1e-5  #1e-4\n",
        "    WEIGHT_DECAY = 1e-4\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    OPTUNA_TRIALS = 7\n",
        "    OPTUNA_EPOCHS = 10\n",
        "\n",
        "    # Models to train\n",
        "    MODELS = ['resnet50', 'cnn','efficientnet_b0','mobilenet_v3_large','vgg16', 'densenet121']\n",
        "\n",
        "    # Ensemble methods\n",
        "    ENSEMBLE_METHODS = ['simple_average', 'weighted_average', 'confidence_based', 'learnable_weighted']\n",
        "\n",
        "    # Device\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    SEED = 42\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_available_cpu_memory():\n",
        "    \"\"\"Get available CPU memory in GB.\"\"\"\n",
        "    mem = psutil.virtual_memory()\n",
        "    return mem.available / 1024**3  # Convert bytes to GB\n",
        "\n",
        "def get_available_gpu_memory():\n",
        "    \"\"\"Get available GPU memory in GB.\"\"\"\n",
        "    pynvml.nvmlInit()\n",
        "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "    mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
        "    return mem_info.free / 1024**3  # Convert bytes to GB\n",
        "\n",
        "def adjust_batch_size_and_workers(base_batch_size, base_num_workers):\n",
        "    gpu_memory = get_available_gpu_memory()\n",
        "\n",
        "    # Prioritize GPU memory for batch size\n",
        "    if gpu_memory > 24:  # High-end GPU\n",
        "        batch_size = base_batch_size * 4\n",
        "        num_workers = min(8, psutil.cpu_count())  # Use more workers for high GPU memory\n",
        "    elif gpu_memory > 12:  # Mid-range GPU\n",
        "        batch_size = base_batch_size * 2\n",
        "        num_workers = min(4, psutil.cpu_count())  # Moderate workers\n",
        "    elif gpu_memory > 6:  # Lower-end GPU\n",
        "        batch_size = base_batch_size\n",
        "        num_workers = min(2, psutil.cpu_count())  # Minimal workers\n",
        "    else:  # Very low GPU memory\n",
        "        batch_size = max(8, base_batch_size // 2)\n",
        "        num_workers = 0  # Disable workers to minimize CPU load\n",
        "\n",
        "    print(f\"Adjusted batch_size: {batch_size}, num_workers: {num_workers} \"\n",
        "          f\"(GPU memory: {gpu_memory:.2f} GB)\")\n",
        "    return batch_size, num_workers\n",
        "\n",
        "\n",
        "def setup_environment():\n",
        "\n",
        "    \"\"\"Setup random seeds, directories, and dynamically adjust batch size and workers\"\"\"\n",
        "    import random\n",
        "    import os\n",
        "\n",
        "    os.environ['PYTHONHASHSEED'] = str(Config.SEED)  # For hash seed reproducibility\n",
        "    random.seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    torch.cuda.manual_seed_all(Config.SEED)  # For multi-GPU if applicable\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "\n",
        "    directories = [\n",
        "        Config.OUTPUT_DIR,\n",
        "        f\"{Config.OUTPUT_DIR}/models\",\n",
        "        f\"{Config.OUTPUT_DIR}/visualizations\",\n",
        "        f\"{Config.OUTPUT_DIR}/reports\",\n",
        "        f\"{Config.OUTPUT_DIR}/xai_visualizations\"\n",
        "    ]\n",
        "\n",
        "    for directory in directories:\n",
        "        Path(directory).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Dynamically adjust batch size and workers\n",
        "    Config.BATCH_SIZE, Config.DATALOADER_NUM_WORKERS = adjust_batch_size_and_workers(\n",
        "        Config.BATCH_SIZE, Config.DATALOADER_NUM_WORKERS\n",
        "    )\n",
        "\n",
        "    print(f\"Using device: {Config.DEVICE}\")\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"Dynamic BATCH_SIZE: {Config.BATCH_SIZE}, DATALOADER_NUM_WORKERS: {Config.DATALOADER_NUM_WORKERS}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    np.random.seed(Config.SEED + worker_id)\n",
        "    random.seed(Config.SEED + worker_id)\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 3. TRAINING PROGRESS TRACKER\n",
        "# =============================================================================\n",
        "# Purpose: Track and display training progress with progress bars and epoch summaries.\n",
        "\n",
        "class TrainingProgressTracker:\n",
        "    \"\"\"Track and display detailed training progress\"\"\"\n",
        "\n",
        "    def __init__(self, model_name, total_epochs, total_batches_per_epoch):\n",
        "        self.model_name = model_name\n",
        "        self.total_epochs = total_epochs\n",
        "        self.total_batches_per_epoch = total_batches_per_epoch\n",
        "        self.start_time = time.time()\n",
        "        self.epoch_start_time = None\n",
        "        self.batch_times = []\n",
        "\n",
        "    def start_epoch(self, epoch):\n",
        "        \"\"\"Start tracking an epoch\"\"\"\n",
        "        self.current_epoch = epoch\n",
        "        self.epoch_start_time = time.time()\n",
        "        self.batch_times = []\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Model: {self.model_name.upper()} | Epoch: {epoch+1}/{self.total_epochs}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "    def update_batch(self, batch_idx, batch_loss, batch_acc, is_training=True,total_batches=None):\n",
        "        \"\"\"Update progress for current batch\"\"\"\n",
        "        batch_time = time.time()\n",
        "        self.batch_times.append(batch_time)\n",
        "\n",
        "        # Calculate timing estimates\n",
        "        if len(self.batch_times) > 1:\n",
        "            avg_batch_time = np.mean(np.diff(self.batch_times[-10:]))\n",
        "        else:\n",
        "            avg_batch_time = 1.0\n",
        "\n",
        "        total_batches = total_batches if total_batches is not None else self.total_batches_per_epoch\n",
        "        remaining_batches = total_batches - (batch_idx + 1)\n",
        "        # remaining_batches = self.total_batches_per_epoch - (batch_idx + 1)\n",
        "        eta_epoch = remaining_batches * avg_batch_time\n",
        "\n",
        "        # Progress bar\n",
        "        # progress_pct = (batch_idx + 1) / self.total_batches_per_epoch * 100\n",
        "        progress_pct = (batch_idx + 1) / total_batches * 100\n",
        "        bar_length = 30\n",
        "        # filled_length = int(bar_length * (batch_idx + 1) // self.total_batches_per_epoch)\n",
        "        filled_length = int(bar_length * (batch_idx + 1) // total_batches)\n",
        "        bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "        # Format time\n",
        "        eta_str = str(timedelta(seconds=int(eta_epoch)))\n",
        "\n",
        "        # Display progress\n",
        "        mode = \"TRAIN\" if is_training else \"VAL  \"\n",
        "\n",
        "        print(f\"\\r{mode} |{bar}| {progress_pct:5.1f}% | \"\n",
        "              f\"Batch: {batch_idx+1:4d}/{total_batches} | \"\n",
        "              f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
        "              f\"ETA: {eta_str}\", end='', flush=True)\n",
        "\n",
        "\n",
        "\n",
        "    def finish_epoch(self, train_loss, train_acc, val_loss, val_acc, val_f1,\n",
        "                    is_best=False, lr=None):\n",
        "        \"\"\"Finish epoch and display summary\"\"\"\n",
        "        epoch_time = time.time() - self.epoch_start_time\n",
        "        total_time = time.time() - self.start_time\n",
        "\n",
        "        print(f\"\\n{'-'*60}\")\n",
        "        print(f\"EPOCH SUMMARY:\")\n",
        "        print(f\"  Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"  Val Loss:   {val_loss:.6f} | Val Acc:   {val_acc:.4f}\")\n",
        "        print(f\"  Val F1:     {val_f1:.4f} | Epoch Time: {epoch_time:.1f}s\")\n",
        "        if lr:\n",
        "            print(f\"  Learning Rate: {lr:.2e}\")\n",
        "\n",
        "        if is_best:\n",
        "            print(f\"  ‚òÖ NEW BEST MODEL! (F1: {val_f1:.4f})\")\n",
        "\n",
        "        print(f\"  Total Time: {str(timedelta(seconds=int(total_time)))}\")\n",
        "        print(f\"{'-'*60}\")\n",
        "\n",
        "# ---\n",
        "# 4. DATA LOADING AND PREPROCESSING\n",
        "# =============================================================================\n",
        "# Purpose: Handle dataset creation, data loading, balancing with SMOTE, and data augmentation.\n",
        "\n",
        "class FishDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = self._preprocess_images(images)\n",
        "        self.labels = labels.astype(np.int64)\n",
        "        self.transform = transform\n",
        "\n",
        "    def _preprocess_images(self, images):\n",
        "        if images.max() > 1.5:\n",
        "            images = images.astype(np.float32) / 255.0\n",
        "        if len(images.shape) == 4 and images.shape[1] == 3:\n",
        "            images = np.transpose(images, (0, 2, 3, 1))\n",
        "        return images.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "        else:\n",
        "            image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class DataManager:\n",
        "    @staticmethod\n",
        "    def get_transforms(is_training=True, augmentation_strength='medium'):\n",
        "        \"\"\"Get data transforms with configurable augmentation strength\"\"\"\n",
        "        if is_training:\n",
        "            if augmentation_strength == 'light':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.3),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            elif augmentation_strength == 'heavy':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.7),\n",
        "                    A.VerticalFlip(p=0.5),\n",
        "                    A.RandomRotate90(p=0.7),\n",
        "                    # A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, p=0.8),\n",
        "                    # A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.8),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
        "                    A.HueSaturationValue(hue_shift_limit=30, sat_shift_limit=40, val_shift_limit=30, p=0.7),\n",
        "                    A.GaussianBlur(blur_limit=(3, 9), p=0.5),\n",
        "                    A.GaussNoise(var_limit=(10.0, 80.0), p=0.4),\n",
        "                    A.CoarseDropout(max_holes=12, max_height=25, max_width=25, p=0.5),\n",
        "                    A.ElasticTransform(p=0.3),\n",
        "                    A.GridDistortion(p=0.3),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "                    A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3, p=0.3),\n",
        "                    A.RandomRain(blur_value=3, p=0.2),\n",
        "                    A.ColorJitter(hue=0.1, p=0.5),\n",
        "\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            else:  # medium\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.5),\n",
        "                    A.VerticalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.5),\n",
        "                    # A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.7),\n",
        "                    # A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.1),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
        "                    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.6),\n",
        "                    A.GaussianBlur(blur_limit=(3, 7), p=0.4),\n",
        "                    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "                    A.CoarseDropout(max_holes=8, max_height=20, max_width=20, p=0.4),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "        else:\n",
        "            return A.Compose([\n",
        "                A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "\n",
        "    @staticmethod\n",
        "    def load_and_balance_data():\n",
        "        \"\"\"Load data and apply SMOTE\"\"\"\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "\n",
        "        X = np.load(Config.DATA_FILE)\n",
        "        Y = np.load(Config.LABELS_FILE)\n",
        "\n",
        "        print(f\"Original data shape: {X.shape}\")\n",
        "        print(f\"Original class distribution: {np.bincount(Y)}\")\n",
        "\n",
        "\n",
        "        # print(\"Applying SMOTE for class balancing...\")\n",
        "        # X_flat = X.reshape(X.shape[0], -1)\n",
        "        # smote = SMOTE(random_state=Config.SEED, k_neighbors=min(5, np.bincount(Y).min()-1))\n",
        "        # X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y)\n",
        "        # X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "        # print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        # print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "        # return X_balanced, Y_balanced\n",
        "\n",
        "\n",
        "        # # Remove SMOTE completely and use WeightedRandomSampler only\n",
        "        # # Just return original data\n",
        "        # print(\"Using WeightedRandomSampler for class balancing instead of SMOTE...\")\n",
        "        # return X, Y\n",
        "\n",
        "\n",
        "        print(\"Applying SMOTE for class balancing...\")\n",
        "        # Apply SMOTE with reduced k_neighbors and combine with WeightedRandomSampler\n",
        "        X_flat = X.reshape(X.shape[0], -1)\n",
        "        # smote = SMOTE(random_state=Config.SEED, k_neighbors=3, sampling_strategy='not majority')\n",
        "        smote = SMOTE(random_state=Config.SEED, k_neighbors=2, sampling_strategy= 'auto')\n",
        "        X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y)\n",
        "        X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "        # Ensure WeightedRandomSampler is still used in DataLoader\n",
        "        print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "        return X_balanced, Y_balanced\n",
        "        # Benefit: Using a smaller k_neighbors=3 reduces the risk of generating unnatural\n",
        "        # image artifacts, while sampling_strategy='not majority' balances classes more conservatively.\n",
        "        # Retaining WeightedRandomSampler in the DataLoader further ensures balanced sampling during\n",
        "        # training, maintaining smoothness and preventing accuracy drops by avoiding over-reliance\n",
        "        # on SMOTE-generated samples.\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def create_data_loaders(X, Y, test_size=0.2, batch_size=None, augmentation_strength='medium'):\n",
        "        if batch_size is None:\n",
        "            if torch.cuda.is_available():\n",
        "                gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "                if gpu_memory_gb >= 24:\n",
        "                    batch_size = 128\n",
        "                elif gpu_memory_gb >= 12:\n",
        "                    batch_size = 96\n",
        "                elif gpu_memory_gb >= 8:\n",
        "                    batch_size = 64\n",
        "                else:\n",
        "                    batch_size = 48\n",
        "            else:\n",
        "                batch_size = Config.BATCH_SIZE\n",
        "\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "            X, Y, test_size=test_size, random_state=Config.SEED, stratify=Y\n",
        "        )\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=0.25, random_state=Config.SEED, stratify=y_temp\n",
        "        )\n",
        "\n",
        "        # print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "        # print(f\"Using optimized batch size: {batch_size}\")\n",
        "\n",
        "\n",
        "\n",
        "        train_dataset = FishDataset(X_train, y_train,\n",
        "                                  DataManager.get_transforms(True, augmentation_strength))\n",
        "        val_dataset = FishDataset(X_val, y_val, DataManager.get_transforms(False))\n",
        "        test_dataset = FishDataset(X_test, y_test, DataManager.get_transforms(False))\n",
        "\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "        sample_weights = [class_weights[y] for y in y_train]\n",
        "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "\n",
        "\n",
        "        # Conditionally set prefetch_factor based on num_workers\n",
        "        prefetch_factor = 2 if Config.DATALOADER_NUM_WORKERS > 0 else None\n",
        "\n",
        "        # train_loader = DataLoader(\n",
        "        #     train_dataset,\n",
        "        #     batch_size=batch_size,\n",
        "        #     sampler=sampler,\n",
        "        #     num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "        #     pin_memory=Config.PIN_MEMORY,\n",
        "        #     # prefetch_factor=2,\n",
        "        #     # persistent_workers=False\n",
        "        #     prefetch_factor=prefetch_factor,\n",
        "        #     persistent_workers=Config.DATALOADER_NUM_WORKERS > 0\n",
        "        # )\n",
        "        # val_loader = DataLoader(\n",
        "        #     val_dataset,\n",
        "        #     batch_size=batch_size,\n",
        "        #     shuffle=False,\n",
        "        #     num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "        #     pin_memory=Config.PIN_MEMORY,\n",
        "        #     prefetch_factor=prefetch_factor,\n",
        "        #     persistent_workers=Config.DATALOADER_NUM_WORKERS > 0\n",
        "        # )\n",
        "        # test_loader = DataLoader(\n",
        "        #     test_dataset,\n",
        "        #     batch_size=batch_size,\n",
        "        #     shuffle=False,\n",
        "        #     num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "        #     pin_memory=Config.PIN_MEMORY,\n",
        "        #     prefetch_factor=prefetch_factor,\n",
        "        #     persistent_workers=Config.DATALOADER_NUM_WORKERS > 0\n",
        "        # )\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=sampler,\n",
        "            num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            prefetch_factor=prefetch_factor,\n",
        "            persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            prefetch_factor=prefetch_factor,\n",
        "            persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            prefetch_factor=prefetch_factor,\n",
        "            persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "\n",
        "        return train_loader, val_loader, test_loader, (X_val, y_val), (X_test, y_test)\n",
        "\n",
        "# ---\n",
        "# 5. MODEL FACTORY\n",
        "# =============================================================================\n",
        "# Purpose: Create different neural network models with customizable architectures.\n",
        "\n",
        "class ModelFactory:\n",
        "    @staticmethod\n",
        "    def create_model(model_name, num_classes=Config.NUM_CLASSES, dropout_rate=0.5,\n",
        "                    hidden_dim_multiplier=0.5):\n",
        "        \"\"\"Create model with configurable architecture\"\"\"\n",
        "\n",
        "        if model_name == 'resnet50':\n",
        "            model = models.resnet50(weights='IMAGENET1K_V2')\n",
        "            # Partial unfreeze for better accuracy: unfreeze layer4 and fc\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                # if \"layer4\" in name or \"fc\" in name:\n",
        "                if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'efficientnet_b0':\n",
        "            model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: last blocks\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"_blocks.15\" in name or \"_blocks.16\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = model.classifier[1].in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'mobilenet_v3_large':\n",
        "            model = models.mobilenet_v3_large(weights='IMAGENET1K_V2')\n",
        "            # Partial unfreeze: last features\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"features.12\" in name or \"features.13\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = 960\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'vgg16':\n",
        "            model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: classifier and last features\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"classifier\" in name or \"features.28\" in name:\n",
        "                    param.requires_grad = True\n",
        "            hidden_dim = int(4096 * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Linear(512 * 7 * 7, 4096),\n",
        "                nn.ReLU(True),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(4096, hidden_dim),\n",
        "                nn.ReLU(True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'densenet121':\n",
        "            model = models.densenet121(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: denseblock4 and classifier\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"denseblock4\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = model.classifier.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'cnn':\n",
        "            class SimpleCNN(nn.Module):\n",
        "                def __init__(self, num_classes, dropout_rate=0.5):\n",
        "                    super(SimpleCNN, self).__init__()\n",
        "                    self.features = nn.Sequential(\n",
        "                        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.MaxPool2d(2, 2),\n",
        "\n",
        "                        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.MaxPool2d(2, 2),\n",
        "\n",
        "                        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.MaxPool2d(2, 2)\n",
        "                    )\n",
        "                    self.classifier = nn.Sequential(\n",
        "                        nn.Dropout(dropout_rate),\n",
        "                        nn.Linear(128 * 28 * 28, 512),  # for 224x224 input\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.BatchNorm1d(512),\n",
        "                        nn.Dropout(dropout_rate / 2),\n",
        "                        nn.Linear(512, num_classes)\n",
        "                    )\n",
        "\n",
        "                def forward(self, x):\n",
        "                    x = self.features(x)\n",
        "                    x = torch.flatten(x, 1)\n",
        "                    x = self.classifier(x)\n",
        "                    return x\n",
        "\n",
        "            model = SimpleCNN(num_classes=num_classes, dropout_rate=dropout_rate)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 6. LEARNABLE WEIGHTED ENSEMBLE MODEL\n",
        "# =============================================================================\n",
        "# Purpose: Define a neural network for learning optimal ensemble weights.\n",
        "\n",
        "class LearnableWeightedEnsemble(nn.Module):\n",
        "    \"\"\"Neural network for learning optimal ensemble weights\"\"\"\n",
        "    def __init__(self, num_models, num_classes, hidden_dim=64):\n",
        "        super(LearnableWeightedEnsemble, self).__init__()\n",
        "        self.num_models = num_models\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.weight_network = nn.Sequential(\n",
        "            nn.Linear(num_models * num_classes, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim // 2, num_models),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "        self.prediction_head = nn.Sequential(\n",
        "            nn.Linear(num_classes, num_classes * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(num_classes * 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, model_predictions):\n",
        "        batch_size = model_predictions.shape[0]\n",
        "\n",
        "        flattened_preds = model_predictions.view(batch_size, -1)\n",
        "\n",
        "        weights = self.weight_network(flattened_preds)\n",
        "\n",
        "        weighted_avg = torch.sum(model_predictions * weights.unsqueeze(-1), dim=1)\n",
        "\n",
        "        final_predictions = self.prediction_head(weighted_avg)\n",
        "\n",
        "        return final_predictions, weights\n",
        "\n",
        "# ---\n",
        "# 7. HYPERPARAMETER OPTIMIZATION\n",
        "# =============================================================================\n",
        "# Purpose: Tune model hyperparameters using Optuna.\n",
        "import optuna.logging\n",
        "import logging\n",
        "\n",
        "\n",
        "class ExpandedHyperparameterOptimizer:\n",
        "    def __init__(self, model_name, train_loader, val_loader):\n",
        "        self.model_name = model_name\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.total_batches_per_epoch = len(train_loader)\n",
        "        self.batch_times = []\n",
        "        self.best_val_acc = 0.0\n",
        "        self.best_val_f1 = 0.0\n",
        "        self.best_trial = -1\n",
        "        self.val_f1 = 0.0\n",
        "\n",
        "    def _update_progress(self, batch_idx, batch_loss, batch_acc, trial_params, is_training=True):\n",
        "        \"\"\"Display progress during hyperparameter tuning\"\"\"\n",
        "        batch_time = time.time()\n",
        "        self.batch_times.append(batch_time)\n",
        "\n",
        "        if len(self.batch_times) > 1:\n",
        "            avg_batch_time = np.mean(np.diff(self.batch_times[-10:]))\n",
        "        else:\n",
        "            avg_batch_time = 1.0\n",
        "\n",
        "        remaining_batches = self.total_batches_per_epoch - (batch_idx + 1)\n",
        "        eta_epoch = remaining_batches * avg_batch_time\n",
        "\n",
        "        progress_pct = (batch_idx + 1) / self.total_batches_per_epoch * 100\n",
        "        bar_length = 30\n",
        "        filled_length = int(bar_length * (batch_idx + 1) // self.total_batches_per_epoch)\n",
        "        bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "        eta_str = str(timedelta(seconds=int(eta_epoch)))\n",
        "\n",
        "        mode = \"TRAIN\" if is_training else \"VAL  \"\n",
        "        print(f\"\\r{mode} |{bar}| {progress_pct:5.1f}% | \"\n",
        "              f\"Batch: {batch_idx+1:4d}/{self.total_batches_per_epoch} | \"\n",
        "              f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
        "              f\"ETA: {eta_str} | Params: {self._format_params(trial_params)}\", end='', flush=True)\n",
        "\n",
        "    def _format_params(self, params):\n",
        "        \"\"\"Format hyperparameters for display\"\"\"\n",
        "        formatted = []\n",
        "        for key, value in params.items():\n",
        "            if key in ['lr', 'weight_decay']:\n",
        "                formatted.append(f\"{key}: {value:.4f}\")\n",
        "            elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                formatted.append(f\"{key}: {value:.4f}\")\n",
        "            else:\n",
        "                formatted.append(f\"{key}: {value}\")\n",
        "        return \", \".join(formatted)\n",
        "\n",
        "\n",
        "    # best_val_f1 = 0.0  # Track best F1 in this trial                        # Added\n",
        "    # best_val_acc = 0.0  # Track corresponding acc for the best F1           # Added\n",
        "    # patience_counter = 0  # Local patience for early stopping in trial      # Added\n",
        "\n",
        "\n",
        "    def objective(self, trial):\n",
        "        # \"\"\"Optuna objective function with hyperparameters\"\"\"\n",
        "        # lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n",
        "        # weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
        "        # dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
        "        # hidden_dim_multiplier = trial.suggest_float('hidden_dim_multiplier', 0.25, 1.0)\n",
        "        # augmentation_strength = trial.suggest_categorical('augmentation_strength',\n",
        "        #                                                 ['light', 'medium', 'heavy'])\n",
        "\n",
        "\n",
        "        # batch_size = trial.suggest_categorical('batch_size', [32, 64, 96, 128])\n",
        "        # optimizer_type = trial.suggest_categorical('optimizer_type', ['adamw'])#, 'adam', 'sgd'])\n",
        "        # scheduler_type = trial.suggest_categorical('scheduler_type',\n",
        "        #                                         ['cosine'])#, 'plateau', 'step', 'exponential'])\n",
        "        # label_smoothing = trial.suggest_float('label_smoothing', 0.1, 0.2)\n",
        "        gpu_memory = get_available_gpu_memory()\n",
        "        if gpu_memory > 24:\n",
        "            batch_size_options = [32, 64, 96, 128]\n",
        "        elif gpu_memory > 12:\n",
        "            batch_size_options = [32, 64, 96]\n",
        "        elif gpu_memory > 6:\n",
        "            batch_size_options = [32, 64]\n",
        "        else:\n",
        "            batch_size_options = [16, 32]\n",
        "\n",
        "        lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n",
        "        weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
        "        dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
        "        hidden_dim_multiplier = trial.suggest_float('hidden_dim_multiplier', 0.25, 1.0)\n",
        "        augmentation_strength = trial.suggest_categorical('augmentation_strength', ['light', 'medium', 'heavy'])\n",
        "        batch_size = trial.suggest_categorical('batch_size', batch_size_options)  # Use dynamic options\n",
        "        optimizer_type = trial.suggest_categorical('optimizer_type', ['adamw'])\n",
        "        scheduler_type = trial.suggest_categorical('scheduler_type', ['cosine'])\n",
        "        label_smoothing = trial.suggest_float('label_smoothing', 0.1, 0.2)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        trial_params = {\n",
        "            'lr': lr, 'weight_decay': weight_decay, 'dropout': dropout,\n",
        "            'hidden_dim_multiplier': hidden_dim_multiplier, 'augmentation_strength': augmentation_strength,\n",
        "            'batch_size': batch_size, 'optimizer_type': optimizer_type, 'scheduler_type': scheduler_type,\n",
        "            'label_smoothing': label_smoothing\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            print(f\"\\nTrial {trial.number+1}/{Config.OPTUNA_TRIALS} parameters for {self.model_name}:\")\n",
        "            for key, value in trial_params.items():\n",
        "                if key in ['lr', 'weight_decay']:\n",
        "                    print(f\"  {key}: {value:.4f}\")\n",
        "                elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                    print(f\"  {key}: {value:.4f}\")\n",
        "                else:\n",
        "                    print(f\"  {key}: {value}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Create DataLoaders with trial-specific batch size\n",
        "            # temp_train_loader = DataLoader(\n",
        "            #     self.train_loader.dataset,\n",
        "            #     batch_size=batch_size,\n",
        "            #     sampler=self.train_loader.sampler,\n",
        "            #     num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            #     pin_memory=Config.PIN_MEMORY\n",
        "            # )\n",
        "            # temp_val_loader = DataLoader(\n",
        "            #     self.val_loader.dataset,\n",
        "            #     batch_size=batch_size,\n",
        "            #     shuffle=False,\n",
        "            #     num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            #     pin_memory=Config.PIN_MEMORY\n",
        "            # )\n",
        "            temp_train_loader = DataLoader(\n",
        "                self.train_loader.dataset,\n",
        "                batch_size=batch_size,\n",
        "                sampler=self.train_loader.sampler,\n",
        "                num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "                pin_memory=Config.PIN_MEMORY,\n",
        "                worker_init_fn=worker_init_fn  # Add this\n",
        "            )\n",
        "            temp_val_loader = DataLoader(\n",
        "                self.val_loader.dataset,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=False,\n",
        "                num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "                pin_memory=Config.PIN_MEMORY,\n",
        "                worker_init_fn=worker_init_fn  # Add this\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            model = ModelFactory.create_model(\n",
        "                self.model_name,\n",
        "                dropout_rate=dropout,\n",
        "                hidden_dim_multiplier=hidden_dim_multiplier\n",
        "            )\n",
        "            model = model.to(Config.DEVICE)\n",
        "\n",
        "            if optimizer_type == 'adam':\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "            elif optimizer_type == 'adamw':\n",
        "                optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "            else:\n",
        "                optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                                    momentum=0.9, nesterov=True)\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "            if scheduler_type == 'cosine':\n",
        "                scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.OPTUNA_EPOCHS)\n",
        "            elif scheduler_type == 'step':\n",
        "                scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.7)\n",
        "            else:\n",
        "                scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "            best_val_acc = 0.0  # Local variable for trial-specific best accuracy\n",
        "            best_val_f1 = 0.0   # Local variable for trial-specific best F1 score\n",
        "            patience_counter = 0\n",
        "\n",
        "            for optuna_epoch in range(Config.OPTUNA_EPOCHS):\n",
        "                self.batch_times = []\n",
        "                model.train()\n",
        "                train_correct = 0\n",
        "                train_total = 0\n",
        "                train_loss = 0\n",
        "\n",
        "                train_pbar = tqdm(temp_train_loader, desc=f\"Optuna Epoch {optuna_epoch+1}/{Config.OPTUNA_EPOCHS} Training\", leave=False)\n",
        "                for batch_idx, (images, labels) in enumerate(train_pbar):\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "\n",
        "                    batch_loss = loss.item()\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    train_total += labels.size(0)\n",
        "                    train_correct += (predicted == labels).sum().item()\n",
        "                    train_loss += batch_loss\n",
        "\n",
        "                    batch_acc = train_correct / train_total\n",
        "                    train_pbar.set_postfix({'loss': f'{batch_loss:.4f}', 'acc': f'{batch_acc:.4f}'})\n",
        "\n",
        "                model.eval()\n",
        "                val_correct = 0\n",
        "                val_total = 0\n",
        "                val_loss = 0\n",
        "                val_predictions = []\n",
        "                val_labels = []\n",
        "\n",
        "                val_pbar = tqdm(temp_val_loader, desc=f\"Optuna Epoch {optuna_epoch+1}/{Config.OPTUNA_EPOCHS} Validation\", total=len(temp_val_loader), leave=False)\n",
        "                with torch.no_grad():\n",
        "                    for batch_idx, (images, labels) in enumerate(val_pbar):\n",
        "                        images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                        outputs = model(images)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        batch_loss = loss.item()\n",
        "                        val_loss += batch_loss\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "                        val_total += labels.size(0)\n",
        "                        val_correct += (predicted == labels).sum().item()\n",
        "                        val_predictions.extend(predicted.cpu().numpy())\n",
        "                        val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                        batch_acc = val_correct / val_total\n",
        "                        val_pbar.set_postfix({'loss': f'{batch_loss:.4f}', 'acc': f'{batch_acc:.4f}'})\n",
        "\n",
        "                train_acc = train_correct / train_total\n",
        "                val_acc = val_correct / val_total\n",
        "                val_f1 = f1_score(val_labels, val_predictions, average='macro')\n",
        "                scheduler.step()\n",
        "\n",
        "                print(f\"\\nTrial {trial.number+1} Optuna Epoch {optuna_epoch+1} completed for Model: {self.model_name}\"\n",
        "                      f\"\\nOptuna Epoch {optuna_epoch+1}/{Config.OPTUNA_EPOCHS} Summary: \"\n",
        "                      f\"TL: {train_loss/len(temp_train_loader):.6f}, \"\n",
        "                      f\"VL: {val_loss/len(temp_val_loader):.6f}, \"\n",
        "                      f\"TA: {train_acc:.4f}, \"\n",
        "                      f\"VA: {val_acc:.4f}, \"\n",
        "                      f\"VF1: {val_f1:.4f}\\n\")\n",
        "\n",
        "                is_best = False\n",
        "                best_val_f1 = 0.0  # Local variable for trial-specific best F1 score\n",
        "                best_val_acc = 0.0  # Local variable for trial-specific best accuracy\n",
        "                patience_counter = 0  # Initialize patience counter\n",
        "                if val_f1 >= self.best_val_f1 * 1.001:  # Use self.best_val_f1 for class-level tracking\n",
        "                    # self.best_val_f1 = val_f1\n",
        "                    # self.best_val_acc = val_acc\n",
        "                    # self.best_trial = trial.number + 1\n",
        "                    # best_val_f1 = val_f1  # Update local best_val_f1\n",
        "                    # best_val_acc = val_acc\n",
        "                    best_val_f1 = val_f1\n",
        "                    best_val_acc = val_acc\n",
        "                    patience_counter = 0\n",
        "                    is_best = True\n",
        "                    # Optional: Save model checkpoint if needed\n",
        "                    # torch.save(model.state_dict(), f\"{Config.OUTPUT_DIR}/models/trial_{trial.number}_best.pt\")\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "                if patience_counter >= Config.PATIENCE:\n",
        "                    print(f\"Early stopping at epoch {optuna_epoch + 1}: No improvement >= 0.1% in val_f1 for {Config.PATIENCE} validations\")\n",
        "                    break\n",
        "\n",
        "                # if optuna_epoch >= 5:\n",
        "                #     trial.report(val_f1, optuna_epoch)\n",
        "                #     if trial.should_prune():\n",
        "                #         print(f\"\\nTrial {trial.number+1} pruned at Optuna Epoch {optuna_epoch+1}\")\n",
        "                #         raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "                if optuna_epoch >= 4:\n",
        "                    trial.report(val_f1, optuna_epoch)\n",
        "                    if trial.should_prune():\n",
        "                        best_f1 = max([t.value for t in trial.study.trials if t.value is not None], default=val_f1)\n",
        "                        logging.info(\n",
        "                            f\"Trial {trial.number + 1} (epoch {optuna_epoch + 1}) \"\n",
        "                            f\"val_f1={val_f1:.4f} is unpromising compared to best_f1={best_f1:.4f}. \"\n",
        "                            f\"Pruning trial to focus on better candidates.\"\n",
        "                        )\n",
        "\n",
        "\n",
        "\n",
        "            # Update class-level tracking\n",
        "            if best_val_f1 > self.best_val_f1  :\n",
        "                if (trial.number+1>1):\n",
        "                    self.best_val_f1 = best_val_f1\n",
        "                    self.best_val_acc = best_val_acc\n",
        "                    self.best_trial = trial.number + 1\n",
        "\n",
        "                    # print(f\"\\n\\033[1;31mNew best result found for Trial {self.best_trial}:\\033[0m\")\n",
        "                    print(f\"\\nNew best result found for Trial {self.best_trial}\")\n",
        "                    print(f\"Validation Accuracy: {self.best_val_acc:.4f}\")\n",
        "                    print(f\"Validation F1 Score: {self.best_val_f1:.4f}\")\n",
        "                else:\n",
        "                    print(f\"\\n\\033[1;31mThis is the First Trial. So No Scope for Improvement Judgement.\\033[0m\")\n",
        "                    # print(f\"\\nThis is the First Trial.So No Scope for Improvement Judgement.\")\n",
        "            else:\n",
        "                if (trial.number+1>1):\n",
        "                    print(f\"\\nTrial {trial.number+1} did not improved the accuracy.\") # overall best (Current best F1: {self.best_val_f1:.4f})\")\n",
        "                else:\n",
        "                    print(f\"\\n\\033[1;31mThis is the First Trial. So No Scope for Improvement Judgement.\\033[0m\")\n",
        "                    #print(f\"\\nThis is the First Trial.So No Scope for Improvement Judgement.\")\n",
        "\n",
        "            if (trial.number+1>1):\n",
        "                print(f\"\\n\\033[1;31mTrial {self.best_trial} holds best result up to this:\\033[0m\")\n",
        "                print(f\"  Validation Accuracy: {self.best_val_acc:.4f}\")\n",
        "                print(f\"  Validation F1 Score: {self.best_val_f1:.4f}\")\n",
        "\n",
        "            return val_f1  # Return the last epoch's F1 for Optuna to maximize\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nTrial {trial.number+1} failed with error: {str(e)}\\n{traceback.format_exc()}\")\n",
        "            return 0.0\n",
        "\n",
        "    def optimize(self):\n",
        "        print(f\"Optimizing hyperparameters for {self.model_name}...\")\n",
        "\n",
        "        if not OPTUNA_AVAILABLE:\n",
        "            return {\n",
        "                'lr': Config.LEARNING_RATE,\n",
        "                'dropout': 0.5,\n",
        "                'weight_decay': Config.WEIGHT_DECAY,\n",
        "                'hidden_dim_multiplier': 0.5,\n",
        "                'augmentation_strength': 'medium',\n",
        "                'batch_size': Config.BATCH_SIZE,\n",
        "                'optimizer_type': 'adamw',\n",
        "                'scheduler_type': 'cosine',\n",
        "                'label_smoothing': 0.1\n",
        "            }\n",
        "\n",
        "        # study = optuna.create_study(direction='maximize')\n",
        "        # study.optimize(self.objective, n_trials=Config.OPTUNA_TRIALS, timeout=1200)\n",
        "        # study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner())\n",
        "        # study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner(n_warmup_steps=20))\n",
        "        study = optuna.create_study(direction='maximize', pruner=optuna.pruners.NopPruner())\n",
        "        # study = optuna.create_study(direction='maximize', pruner=optuna.pruners.SuccessiveHalvingPruner(min_resource=1, reduction_factor=4))\n",
        "        # study.optimize(self.objective, n_trials=Config.OPTUNA_TRIALS, timeout=3600\n",
        "        optuna.logging.set_verbosity(optuna.logging.WARNING)  # Suppress info-level logs\n",
        "        study.optimize(self.objective, n_trials=Config.OPTUNA_TRIALS, timeout=3600)#, callbacks=[callback])\n",
        "\n",
        "\n",
        "\n",
        "        best_params = study.best_trial.params\n",
        "        # print(f\"\\nBest params for {self.model_name}:\")\n",
        "        # for key, value in best_params.items():\n",
        "        #     if key in ['lr', 'weight_decay']:\n",
        "        #         print(f\"  {key}: {value:.4f}\")\n",
        "        #     elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "        #         print(f\"  {key}: {value:.6f}\")\n",
        "        #     else:\n",
        "        #         print(f\"  {key}: {value}\")\n",
        "        # print(f\"Best validation accuracy: {study.best_trial.value:.4f}\")\n",
        "\n",
        "        return best_params\n",
        "\n",
        "# ---\n",
        "# 8. MODEL TRAINING\n",
        "# =============================================================================\n",
        "# Purpose: Train individual models with optimized hyperparameters.\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
        "\n",
        "class EnhancedModelTrainer:\n",
        "    def __init__(self, model, model_name, hyperparameters):\n",
        "        self.model = model.to(Config.DEVICE)\n",
        "        self.model_name = model_name\n",
        "        self.hyperparameters = hyperparameters\n",
        "        self.best_val_acc = 0.0\n",
        "        self.best_val_f1 = 0.0\n",
        "        self.patience_counter = 0\n",
        "        self.history = {\n",
        "            'train_loss': [], 'train_acc': [],\n",
        "            'val_loss': [], 'val_acc': [], 'val_f1': [],\n",
        "            'learning_rates': []\n",
        "        }\n",
        "        # Create model directory\n",
        "        os.makedirs(f\"{Config.OUTPUT_DIR}/models\", exist_ok=True)\n",
        "        self._setup_training_components()\n",
        "\n",
        "\n",
        "    def _setup_training_components(self):\n",
        "        lr = self.hyperparameters.get('lr', Config.LEARNING_RATE)\n",
        "        weight_decay = self.hyperparameters.get('weight_decay', Config.WEIGHT_DECAY)\n",
        "        optimizer_type = self.hyperparameters.get('optimizer_type', 'adamw')\n",
        "\n",
        "        if optimizer_type == 'adam':\n",
        "            self.optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay, fused=True)  # Use fused=True\n",
        "        elif optimizer_type == 'adamw':\n",
        "            self.optimizer = optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay, fused=True)  # Use fused=True\n",
        "        else:\n",
        "            self.optimizer = optim.SGD(self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                                    momentum=0.9, nesterov=True)\n",
        "\n",
        "\n",
        "\n",
        "        label_smoothing = self.hyperparameters.get('label_smoothing', 0.1)\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "\n",
        "        scheduler_type = self.hyperparameters.get('scheduler_type', 'cosine')\n",
        "        if scheduler_type == 'cosine':\n",
        "            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "                self.optimizer, T_max=Config.EPOCHS,eta_min=1e-6)\n",
        "\n",
        "        elif scheduler_type == 'plateau':\n",
        "            self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                self.optimizer, mode='min', factor=0.5, patience=5\n",
        "            )\n",
        "        # elif scheduler_type == 'step':\n",
        "        #     self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.5)\n",
        "        else:\n",
        "            self.scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.95)\n",
        "\n",
        "\n",
        "\n",
        "    def train_epoch(self, train_loader, progress_tracker):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        batch_losses = []\n",
        "        batch_accuracies = []\n",
        "        scaler = torch.cuda.amp.GradScaler(enabled=Config.USE_MIXED_PRECISION)  # Add scaler for mixed precision\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(Config.DEVICE, non_blocking=True), labels.to(Config.DEVICE, non_blocking=True)  # Use non_blocking=True\n",
        "            self.optimizer.zero_grad(set_to_none=True)  # Optimize zero_grad\n",
        "            with torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):  # Enable mixed precision\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "            scaler.scale(loss).backward()  # Scale loss for mixed precision\n",
        "            scaler.unscale_(self.optimizer)  # Unscale gradients before clipping\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "            scaler.step(self.optimizer)  # Step with scaler\n",
        "            scaler.update()  # Update scaler\n",
        "\n",
        "\n",
        "            batch_loss = loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            batch_total = labels.size(0)\n",
        "            batch_correct = (predicted == labels).sum().item()\n",
        "            batch_acc = batch_correct / batch_total\n",
        "\n",
        "            total_loss += batch_loss\n",
        "            total += batch_total\n",
        "            correct += batch_correct\n",
        "            batch_losses.append(batch_loss)\n",
        "            batch_accuracies.append(batch_acc)\n",
        "\n",
        "            progress_tracker.update_batch(batch_idx, batch_loss, batch_acc, is_training=True)\n",
        "\n",
        "            # Memory cleanup\n",
        "            del outputs, loss, predicted  # Free tensor memory after use\n",
        "            torch.cuda.empty_cache()     # Clear CUDA memory cache\n",
        "            gc.collect()                 # Force garbage collection to release memory\n",
        "\n",
        "        return total_loss / len(train_loader), correct / total\n",
        "\n",
        "\n",
        "\n",
        "    def validate_epoch(self, val_loader, progress_tracker):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (images, labels) in enumerate(val_loader):\n",
        "                images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "\n",
        "\n",
        "                batch_loss = loss.item()\n",
        "                total_loss += batch_loss\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                batch_acc = (predicted == labels).float().mean().item()\n",
        "\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                progress_tracker.update_batch(batch_idx, batch_loss, batch_acc, is_training=False ,total_batches=len(val_loader))\n",
        "\n",
        "                # Memory cleanup\n",
        "                del outputs, loss, predicted  # Free tensor memory after use\n",
        "                torch.cuda.empty_cache()     # Clear CUDA memory cache\n",
        "                gc.collect()                 # Force garbage collection to release memory\n",
        "\n",
        "        if not all_labels:\n",
        "            print(f\"Warning: No validation data processed for {self.model_name}\")\n",
        "            return float('inf'), 0.0, 0.0\n",
        "\n",
        "        accuracy = accuracy_score(all_labels, all_predictions)\n",
        "        f1 = f1_score(all_labels, all_predictions, average='macro')\n",
        "        return total_loss / len(val_loader), accuracy, f1\n",
        "\n",
        "    def train(self, train_loader, val_loader, test_loader=None, visualizer=None):\n",
        "        \"\"\"Enhanced train method with immediate plotting\"\"\"\n",
        "\n",
        "        print(f\"Training {self.model_name} with hyperparameters:\")\n",
        "        for key, value in self.hyperparameters.items():\n",
        "            if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                print(f\"  {key}: {value:.4f}\")\n",
        "            else:\n",
        "                print(f\"  {key}: {value}\")\n",
        "\n",
        "        progress_tracker = TrainingProgressTracker(\n",
        "            self.model_name, Config.EPOCHS, len(train_loader)\n",
        "        )\n",
        "\n",
        "\n",
        "         # Add this before the training loop\n",
        "        last_val_loss, last_val_acc, last_val_f1 = float('inf'), 0.0, 0.0\n",
        "        for epoch in range(Config.EPOCHS):\n",
        "            progress_tracker.start_epoch(epoch)\n",
        "            train_loss, train_acc = self.train_epoch(train_loader, progress_tracker)\n",
        "\n",
        "            # Only validate every n epochs\n",
        "            if epoch % self.validate_every_n_epochs() == 0 or epoch == Config.EPOCHS - 1:\n",
        "                val_loss, val_acc, val_f1 = self.validate_epoch(val_loader, progress_tracker)\n",
        "                last_val_loss, last_val_acc, last_val_f1 = val_loss, val_acc, val_f1\n",
        "\n",
        "                # Step the scheduler only when validation is performed\n",
        "                if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                    self.scheduler.step(val_loss)  # Step based on validation loss for plateau\n",
        "                else:\n",
        "                    self.scheduler.step()  # Step for cosine, step, or exponential\n",
        "            else:\n",
        "                # Use last validation results\n",
        "                val_loss, val_acc, val_f1 = last_val_loss, last_val_acc, last_val_f1\n",
        "            # self.scheduler.step()\n",
        "\n",
        "\n",
        "            current_lr = self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "            self.history['val_f1'].append(val_f1)\n",
        "            self.history['learning_rates'].append(current_lr)\n",
        "\n",
        "            # is_best = False\n",
        "            # if epoch % self.validate_every_n_epochs() == 0 or epoch == Config.EPOCHS - 1:\n",
        "            #     val_loss, val_acc, val_f1 = self.validate_epoch(val_loader, progress_tracker)\n",
        "            #     last_val_loss, last_val_acc, last_val_f1 = val_loss, val_acc, val_f1\n",
        "\n",
        "            #     # Step the scheduler only when validation is performed\n",
        "            #     if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "            #         self.scheduler.step(val_loss)  # Step based on validation loss for plateau\n",
        "            #     else:\n",
        "            #         self.scheduler.step()\n",
        "\n",
        "\n",
        "            # New early stopping logic: Check for 0.1% relative improvement\n",
        "            is_best = False\n",
        "            if val_f1 >= self.best_val_f1 * 1.001:  # 0.1% improvement threshold\n",
        "                self.best_val_f1 = val_f1\n",
        "                self.best_val_acc = val_acc\n",
        "                self.patience_counter = 0  # Reset patience on significant improvement\n",
        "                is_best = True\n",
        "                torch.save(self.model.state_dict(),\n",
        "                          f\"{Config.OUTPUT_DIR}/models/{self.model_name}_best.pt\")\n",
        "            else:\n",
        "                self.patience_counter += 1  # Increment only when improvement < 0.1%\n",
        "\n",
        "            # Stop training if patience is exceeded (4 consecutive validations without 0.1% improvement)\n",
        "            if self.patience_counter >= Config.PATIENCE:\n",
        "                print(f\"Early stopping at epoch {epoch + 1}: No improvement >= 0.1% in val_f1 for {Config.PATIENCE} validations\")\n",
        "                break\n",
        "        else:\n",
        "            # Skip early stopping updates when validation is not performed\n",
        "            val_loss, val_acc, val_f1 = last_val_loss, last_val_acc, last_val_f1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Load best model\n",
        "        self.model.load_state_dict(\n",
        "            torch.load(f\"{Config.OUTPUT_DIR}/models/{self.model_name}_best.pt\")\n",
        "        )\n",
        "\n",
        "        # IMMEDIATE PLOTTING AFTER TRAINING\n",
        "        if visualizer:\n",
        "            # Plot training history\n",
        "            visualizer.plot_single_model_history(self.history, self.model_name)\n",
        "\n",
        "            # Evaluate and plot results\n",
        "            if test_loader:\n",
        "                evaluator = ModelEvaluator()\n",
        "                result = evaluator.evaluate_model(self.model, test_loader, self.model_name)\n",
        "\n",
        "                # Plot ROC curves, confusion matrix, and XAI\n",
        "                visualizer.plot_roc_curves(result, self.model_name)\n",
        "                visualizer.plot_confusion_matrix(result, self.model_name)\n",
        "                visualizer.plot_misclassified_images(result['misclassified'], self.model_name)  # NEW: Plot misclassified images\n",
        "                visualizer.plot_single_model_xai(self.model, self.model_name, test_loader)\n",
        "\n",
        "                return self.history, result\n",
        "\n",
        "        print(f\"\\n‚úì {self.model_name} training completed!\")\n",
        "        print(f\"  Best Validation F1: {self.best_val_f1:.4f}\")\n",
        "        print(f\"  Best Validation Accuracy: {self.best_val_acc:.4f}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return self.history, None\n",
        "\n",
        "        # [Previous methods like train, validate_epoch, etc.]\n",
        "\n",
        "\n",
        "    def validate_every_n_epochs(self):\n",
        "        \"\"\"Return the number of epochs between validations.\"\"\"\n",
        "        return 1  # Validate every epoch by default\n",
        "\n",
        "# ---\n",
        "# 9. ENSEMBLE METHODS\n",
        "# =============================================================================\n",
        "# Purpose: Implement ensemble methods (simple, weighted, confidence-based, learnable).\n",
        "\n",
        "class EnsembleManager:\n",
        "    def __init__(self, models_dict, val_data):\n",
        "        self.models = models_dict\n",
        "        self.X_val, self.y_val = val_data\n",
        "        self.model_predictions = self._get_predictions()\n",
        "        self.histories = {}\n",
        "\n",
        "    def _get_predictions(self):\n",
        "        print(\"Getting model predictions for ensemble...\")\n",
        "        predictions = {}\n",
        "\n",
        "        val_dataset = FishDataset(self.X_val, self.y_val, DataManager.get_transforms(False))\n",
        "        val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            model.eval()\n",
        "            all_preds = []\n",
        "            all_probs = []\n",
        "            all_losses = []\n",
        "            all_labels = []\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    outputs = model(images)\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    loss = criterion(outputs, labels).item()\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    all_preds.extend(predicted.cpu().numpy())\n",
        "                    all_probs.extend(probabilities.cpu().numpy())\n",
        "                    all_losses.append(loss)\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = correct / total\n",
        "            f1 = f1_score(self.y_val, all_preds, average='macro')\n",
        "            avg_loss = np.mean(all_losses)\n",
        "\n",
        "            predictions[name] = {\n",
        "                'predictions': np.array(all_preds),\n",
        "                'probabilities': np.array(all_probs),\n",
        "                'loss': avg_loss,\n",
        "                'accuracy': accuracy,\n",
        "                'f1': f1,\n",
        "                'true_labels': np.array(all_labels)\n",
        "            }\n",
        "\n",
        "            print(f\"  {name}: F1 = {f1:.4f}, Acc = {accuracy:.4f}, Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def simple_average_ensemble(self, model_combo):\n",
        "        selected_probs = [self.model_predictions[name]['probabilities'] for name in model_combo]\n",
        "        avg_probs = np.mean(selected_probs, axis=0)\n",
        "        predictions = np.argmax(avg_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'probabilities': avg_probs,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def weighted_average_ensemble(self, model_combo):\n",
        "        weights = []\n",
        "        selected_probs = []\n",
        "\n",
        "        for name in model_combo:\n",
        "            f1 = self.model_predictions[name]['f1']\n",
        "            weights.append(f1)\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        weights = np.array(weights) / np.sum(weights)\n",
        "        weighted_probs = np.average(selected_probs, axis=0, weights=weights)\n",
        "        predictions = np.argmax(weighted_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.average([self.model_predictions[name]['loss'] for name in model_combo], weights=weights)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'weights': weights,\n",
        "            'models': model_combo,\n",
        "            'probabilities': weighted_probs,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def confidence_based_ensemble(self, model_combo):\n",
        "        final_predictions = []\n",
        "        all_probs = []\n",
        "\n",
        "        for i in range(len(self.y_val)):\n",
        "            confidences = []\n",
        "            probs = []\n",
        "\n",
        "            for name in model_combo:\n",
        "                prob = self.model_predictions[name]['probabilities'][i]\n",
        "                confidence = np.max(prob)\n",
        "                confidences.append(confidence)\n",
        "                probs.append(prob)\n",
        "\n",
        "            confidences = np.array(confidences)\n",
        "            weights = confidences / np.sum(confidences) if np.sum(confidences) > 0 else np.ones(len(confidences)) / len(confidences)\n",
        "\n",
        "            final_prob = np.average(probs, axis=0, weights=weights)\n",
        "            final_predictions.append(np.argmax(final_prob))\n",
        "            all_probs.append(final_prob)\n",
        "\n",
        "        predictions = np.array(final_predictions)\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'probabilities': np.array(all_probs),\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def learnable_weighted_ensemble(self, model_combo, epochs=30):\n",
        "        print(f\"Training learnable weighted ensemble with {len(model_combo)} models...\")\n",
        "\n",
        "        selected_probs = []\n",
        "        for name in model_combo:\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        ensemble_input = np.stack(selected_probs, axis=1)\n",
        "\n",
        "        X_ensemble = torch.FloatTensor(ensemble_input).to(Config.DEVICE)\n",
        "        y_ensemble = torch.LongTensor(self.y_val).to(Config.DEVICE)\n",
        "\n",
        "        ensemble_model = LearnableWeightedEnsemble(\n",
        "            num_models=len(model_combo),\n",
        "            num_classes=Config.NUM_CLASSES\n",
        "        ).to(Config.DEVICE)\n",
        "\n",
        "        optimizer = optim.AdamW(ensemble_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "        history = {'train_loss': [], 'train_acc': [], 'val_f1': []}\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            ensemble_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions, weights = ensemble_model(X_ensemble)\n",
        "            loss = criterion(predictions, y_ensemble)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            accuracy = accuracy_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy())\n",
        "            f1 = f1_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy(), average='macro')\n",
        "\n",
        "            history['train_loss'].append(loss.item())\n",
        "            history['train_acc'].append(accuracy)\n",
        "            history['val_f1'].append(f1)\n",
        "\n",
        "            print(f\"Ensemble Epoch {epoch+1}/{epochs}: Loss = {loss.item():.4f}, \"\n",
        "                  f\"Acc = {accuracy:.4f}, F1 = {f1:.4f}\")\n",
        "\n",
        "            if loss.item() < best_loss:\n",
        "                best_loss = loss.item()\n",
        "                torch.save(ensemble_model.state_dict(), f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\")\n",
        "\n",
        "        ensemble_model.load_state_dict(torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\"))\n",
        "        ensemble_model.eval()\n",
        "        with torch.no_grad():\n",
        "            final_predictions, learned_weights = ensemble_model(X_ensemble)\n",
        "            predictions = final_predictions.argmax(dim=1).cpu().numpy()\n",
        "            probabilities = torch.softmax(final_predictions, dim=1).cpu().numpy()\n",
        "            avg_weights = learned_weights.mean(dim=0).cpu().numpy()\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        self.histories[f\"learnable_weighted_{'+'.join(model_combo)}\"] = history\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'learned_weights': avg_weights,\n",
        "            'probabilities': probabilities,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def test_ensemble_combinations(self):\n",
        "        print(\"Testing ensemble combinations...\")\n",
        "\n",
        "        model_names = list(self.models.keys())\n",
        "        all_results = {}\n",
        "        best_result = None\n",
        "        best_score = 0\n",
        "\n",
        "        for size in range(2, min(len(model_names) + 1, 5)):\n",
        "            print(f\"Testing {size}-model combinations...\")\n",
        "\n",
        "            for combo in list(combinations(model_names, size))[:5]:\n",
        "                combo_name = f\"combo_{size}_{'+'.join(combo)}\"\n",
        "\n",
        "                for method_name in Config.ENSEMBLE_METHODS:\n",
        "                    full_name = f\"{combo_name}_{method_name}\"\n",
        "\n",
        "                    try:\n",
        "                        if method_name == 'simple_average':\n",
        "                            result = self.simple_average_ensemble(combo)\n",
        "                        elif method_name == 'weighted_average':\n",
        "                            result = self.weighted_average_ensemble(combo)\n",
        "                        elif method_name == 'confidence_based':\n",
        "                            result = self.confidence_based_ensemble(combo)\n",
        "                        elif method_name == 'learnable_weighted':\n",
        "                            result = self.learnable_weighted_ensemble(combo)\n",
        "\n",
        "                        # Verify result contains required keys\n",
        "                        required_keys = ['accuracy', 'f1', 'loss', 'predictions', 'models', 'probabilities', 'true_labels']\n",
        "                        if not all(key in result for key in required_keys):\n",
        "                            missing = [key for key in required_keys if key not in result]\n",
        "                            print(f\"  {full_name}: Missing keys {missing}\")\n",
        "                            continue\n",
        "\n",
        "                        all_results[full_name] = result\n",
        "                        print(f\"  {full_name}: F1 = {result['f1']:.4f}, Acc = {result['accuracy']:.4f}, \"\n",
        "                              f\"Loss = {result['loss']:.4f}, True Labels Shape = {result['true_labels'].shape}\")\n",
        "\n",
        "                        if result['f1'] > best_score:\n",
        "                            best_score = result['f1']\n",
        "                            best_result = (full_name, result)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"  {full_name}: FAILED - {str(e)}\")\n",
        "\n",
        "        if best_result:\n",
        "            print(f\"\\n‚úì Best ensemble: {best_result[0]} (F1: {best_result[1]['f1']:.4f})\")\n",
        "        else:\n",
        "            print(\"\\nNo valid ensemble results generated.\")\n",
        "\n",
        "        return all_results, best_result\n",
        "\n",
        "# ---\n",
        "# 10. MODEL EVALUATION\n",
        "# =============================================================================\n",
        "# Purpose: Evaluate models on test data.\n",
        "\n",
        "class ModelEvaluator:\n",
        "    def evaluate_model(self, model, test_loader, model_name):\n",
        "        print(f\"Evaluating {model_name}...\")\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "        misclassified = []  # List to store misclassified images and metadata\n",
        "        total_loss = 0\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # with torch.no_grad():\n",
        "        with torch.no_grad(), torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "            for images, labels in test_loader:\n",
        "                # images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                images, labels = images.to(Config.DEVICE, non_blocking=True), labels.to(Config.DEVICE, non_blocking=True)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels).item()\n",
        "                probabilities = torch.softmax(outputs, dim=1)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "\n",
        "                # Identify misclassified images\n",
        "                incorrect_mask = predicted != labels\n",
        "                if incorrect_mask.any():\n",
        "                    incorrect_images = images[incorrect_mask].cpu()\n",
        "                    incorrect_labels = labels[incorrect_mask].cpu().numpy()\n",
        "                    incorrect_preds = predicted[incorrect_mask].cpu().numpy()\n",
        "                    for img, true_label, pred_label in zip(incorrect_images, incorrect_labels, incorrect_preds):\n",
        "                        misclassified.append({\n",
        "                            'image': img,\n",
        "                            'true_label': true_label,\n",
        "                            'pred_label': pred_label\n",
        "                        })\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_probs.extend(probabilities.cpu().numpy())\n",
        "                total_loss += loss\n",
        "\n",
        "        if not all_labels:\n",
        "            print(f\"Warning: No test data processed for {model_name}\")\n",
        "            return {\n",
        "                'model_name': model_name,\n",
        "                'accuracy': 0.0,\n",
        "                'f1_macro': 0.0,\n",
        "                'f1_weighted': 0.0,\n",
        "                'precision_macro': 0.0,\n",
        "                'recall_macro': 0.0,\n",
        "                'f1_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "                'precision_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "                'recall_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "                'predictions': np.array([]),\n",
        "                'true_labels': np.array([]),\n",
        "                'probabilities': np.array([]),\n",
        "                'loss': float('inf'),\n",
        "                'misclassified': []\n",
        "\n",
        "            }\n",
        "\n",
        "        accuracy = accuracy_score(all_labels, all_preds)\n",
        "        f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "        f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "        precision_macro = precision_score(all_labels, all_preds, average='macro')\n",
        "        recall_macro = recall_score(all_labels, all_preds, average='macro')\n",
        "        f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "        precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "        recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "        print(f\"{model_name} Evaluation: Acc = {accuracy:.4f}, F1 (Macro) = {f1_macro:.4f}, Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        return {\n",
        "            'model_name': model_name,\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_weighted': f1_weighted,\n",
        "            'precision_macro': precision_macro,\n",
        "            'recall_macro': recall_macro,\n",
        "            'f1_per_class': f1_per_class,\n",
        "            'precision_per_class': precision_per_class,\n",
        "            'recall_per_class': recall_per_class,\n",
        "            'predictions': np.array(all_preds),\n",
        "            'true_labels': np.array(all_labels),\n",
        "            'probabilities': np.array(all_probs),\n",
        "            'loss': avg_loss,\n",
        "            'misclassified': misclassified\n",
        "\n",
        "        }\n",
        "\n",
        "# ---\n",
        "# 11. ENHANCED VISUALIZATIONS\n",
        "# =============================================================================\n",
        "# Purpose: Generate visualizations for training history, ROC curves, confusion matrices, model comparisons, and XAI visualizations.\n",
        "\n",
        "class EnhancedVisualizations:\n",
        "    def __init__(self):\n",
        "        self.viz_dir = f\"{Config.OUTPUT_DIR}/visualizations\"\n",
        "        Path(self.viz_dir).mkdir(parents=True, exist_ok=True)\n",
        "        # Set better matplotlib parameters for spacing\n",
        "        plt.rcParams.update({\n",
        "            'figure.autolayout': True,\n",
        "            'axes.titlepad': 20,\n",
        "            'axes.labelpad': 10,\n",
        "            'xtick.major.pad': 8,\n",
        "            'ytick.major.pad': 8\n",
        "        })\n",
        "\n",
        "\n",
        "    def plot_single_model_history(self, history, model_name, alpha=0.2):  # (range: 0.1‚Äì0.3; lower = smoother, higher = more responsive)\n",
        "        \"\"\"Plot training history for individual model with better spacing\"\"\"\n",
        "        if not history['train_loss']:\n",
        "            print(f\"Skipping {model_name}: No training data available\")\n",
        "            return\n",
        "\n",
        "        def smooth_ema(values, alpha):\n",
        "            \"\"\"Apply exponential moving average (EMA) smoothing to a list of values.\"\"\"\n",
        "            if not values:\n",
        "                return values\n",
        "            smoothed = [values[0]]\n",
        "            for val in values[1:]:\n",
        "                smoothed.append(alpha * val + (1 - alpha) * smoothed[-1])\n",
        "            return smoothed\n",
        "\n",
        "        epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "        # Create subplot with more space\n",
        "        fig = plt.figure(figsize=(16, 10))\n",
        "        gs = fig.add_gridspec(2, 2, hspace=0.4, wspace=0.3)\n",
        "\n",
        "        # Loss plot\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        smoothed_train_loss = smooth_ema(history['train_loss'], alpha)\n",
        "        smoothed_val_loss = smooth_ema(history.get('val_loss', []), alpha)\n",
        "        ax1.plot(epochs, smoothed_train_loss, 'b-', linewidth=2, label='Train Loss', marker='o', markersize=4)\n",
        "        if smoothed_val_loss:\n",
        "            ax1.plot(epochs, smoothed_val_loss, 'r-', linewidth=2, label='Val Loss', marker='s', markersize=4)\n",
        "        ax1.set_title(f'{model_name} - Loss vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "        ax1.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
        "        ax1.legend(frameon=True, shadow=True, fontsize=11)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.tick_params(labelsize=10)\n",
        "\n",
        "        # Accuracy plot\n",
        "        ax2 = fig.add_subplot(gs[0, 1])\n",
        "        ax2.plot(epochs, history['train_acc'], 'g-', linewidth=2, label='Train Acc', marker='o', markersize=4)\n",
        "        if history.get('val_acc', []):\n",
        "            ax2.plot(epochs, history['val_acc'], 'm-', linewidth=2, label='Val Acc', marker='s', markersize=4)\n",
        "        ax2.set_title(f'{model_name} - Accuracy vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax2.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "        ax2.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "        ax2.legend(frameon=True, shadow=True, fontsize=11)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.tick_params(labelsize=10)\n",
        "\n",
        "        # F1 Score plot\n",
        "        ax3 = fig.add_subplot(gs[1, 0])\n",
        "        smoothed_val_f1 = smooth_ema(history.get('val_f1', []), alpha)\n",
        "        if smoothed_val_f1:\n",
        "            ax3.plot(epochs, smoothed_val_f1, 'orange', linewidth=2, label='Val F1', marker='d', markersize=4)\n",
        "            ax3.set_title(f'{model_name} - F1 Score vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "            ax3.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "            ax3.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
        "            ax3.legend(frameon=True, shadow=True, fontsize=11)\n",
        "            ax3.grid(True, alpha=0.3)\n",
        "            ax3.tick_params(labelsize=10)\n",
        "\n",
        "        # Learning Rate plot\n",
        "        ax4 = fig.add_subplot(gs[1, 1])\n",
        "        smoothed_lr = smooth_ema(history.get('learning_rates', []), alpha)\n",
        "        if smoothed_lr:\n",
        "            ax4.plot(epochs, smoothed_lr, 'purple', linewidth=2, label='Learning Rate', marker='x', markersize=6)\n",
        "            ax4.set_title(f'{model_name} - Learning Rate vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "            ax4.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "            ax4.set_ylabel('Learning Rate', fontsize=12, fontweight='bold')\n",
        "            ax4.legend(frameon=True, shadow=True, fontsize=11)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.tick_params(labelsize=10)\n",
        "            ax4.set_yscale('log')\n",
        "\n",
        "        plt.suptitle(f'{model_name} Training Progress', fontsize=18, fontweight='bold', y=0.98)\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_individual_training_history.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Individual training history saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "    def plot_single_model_xai(self, model, model_name, test_loader, max_images=5):\n",
        "        \"\"\"Generate XAI visualizations for a single model using Grad-CAM++, Integrated Gradients, and LRP\"\"\"\n",
        "        print(f\"Generating XAI visualizations for {model_name}...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # # Get sample images\n",
        "        # sample_images, sample_labels = next(iter(test_loader))\n",
        "        # sample_images = sample_images[:max_images].to(Config.DEVICE)\n",
        "        # sample_labels = sample_labels[:max_images].numpy()\n",
        "\n",
        "        # Get sample images\n",
        "        sample_images = []\n",
        "        sample_labels = []\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            class_mask = np.where(test_loader.dataset.labels == i)[0]\n",
        "            if len(class_mask) > 0:\n",
        "                idx = np.random.choice(class_mask)\n",
        "                image, label = test_loader.dataset[idx]\n",
        "                if image.dim() == 4:\n",
        "                    image = image.squeeze(0)\n",
        "                sample_images.append(image.to(Config.DEVICE))\n",
        "                sample_labels.append(label)\n",
        "\n",
        "\n",
        "        for idx, (image, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
        "            try:\n",
        "                # Create figure with larger size for clearer images\n",
        "                fig = plt.figure(figsize=(24, 8))  # Standard size for clear visualization\n",
        "                gs = fig.add_gridspec(1, 4, wspace=0.15, hspace=0.2)  # 4 columns: Original, Grad-CAM++, Integrated Gradients, LRP\n",
        "\n",
        "                # Prepare original image\n",
        "                image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                # Plot original image\n",
        "                ax_orig = fig.add_subplot(gs[0, 0])\n",
        "                ax_orig.imshow(image_np)\n",
        "                ax_orig.set_title(f'Original Image\\nTrue: {Config.CLASS_LABELS[true_label]}',\n",
        "                                 fontsize=14, fontweight='bold', pad=15)\n",
        "                ax_orig.axis('off')\n",
        "\n",
        "                # Forward pass for prediction\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(image.unsqueeze(0))\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    predicted_class = outputs.argmax(dim=1).item()\n",
        "                    confidence = probabilities[0, predicted_class].item()\n",
        "                    predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                # Generate Grad-CAM++ visualization\n",
        "                gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(model, image, predicted_class)\n",
        "                ax_gradcam = fig.add_subplot(gs[0, 1])\n",
        "                ax_gradcam.imshow(gradcam_img)\n",
        "                ax_gradcam.set_title(f'{model_name}\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                    fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_gradcam.axis('off')\n",
        "\n",
        "                # Generate Integrated Gradients visualization\n",
        "                ig_img, _ = xai_visualizer.integrated_gradients(model, image, predicted_class)\n",
        "                ax_ig = fig.add_subplot(gs[0, 2])\n",
        "                ax_ig.imshow(ig_img)\n",
        "                ax_ig.set_title(f'{model_name}\\nIntegrated Gradients', fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_ig.axis('off')\n",
        "\n",
        "                # Generate LRP visualization\n",
        "                lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, image, predicted_class)\n",
        "                ax_lrp = fig.add_subplot(gs[0, 3])\n",
        "                # ax_lrp.imshow(lrp_img)\n",
        "                ax_lrp.imshow(cv2.cvtColor(lrp_img, cv2.COLOR_BGR2RGB))\n",
        "                ax_lrp.set_title(f'{model_name}\\nLRP', fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_lrp.axis('off')\n",
        "\n",
        "                plt.suptitle(f'XAI Analysis for {model_name} - Image {idx+1}', fontsize=16, fontweight='bold', y=0.95)\n",
        "                save_path = f\"{self.viz_dir}/{model_name}_xai_image_{idx+1}.png\"\n",
        "                plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "                plt.show()\n",
        "                print(f\"XAI visualization saved: {save_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating XAI for {model_name}, image {idx+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "    def plot_confusion_matrix(self, results, model_name):\n",
        "        \"\"\"Enhanced confusion matrix with better spacing\"\"\"\n",
        "        if 'true_labels' not in results or 'predictions' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'predictions' in results for {model_name}\")\n",
        "            return\n",
        "\n",
        "        cm = confusion_matrix(results['true_labels'], results['predictions'])\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        # Create figure with better spacing\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "        # Use better color scheme and formatting\n",
        "        sns.heatmap(cm_normalized, annot=cm, fmt='d', cmap='Blues',\n",
        "                    xticklabels=Config.CLASS_LABELS, yticklabels=Config.CLASS_LABELS,\n",
        "                    cbar_kws={'label': 'Normalized Count', 'shrink': 0.8},\n",
        "                    square=True, linewidths=0.5, annot_kws={'size': 12})\n",
        "\n",
        "        # === Move colorbar label to the top ===\n",
        "        cbar = ax.collections[0].colorbar\n",
        "        cbar.ax.yaxis.set_label_position('left')   # keep label aligned left of bar\n",
        "        cbar.set_label(\"Normalized Count\", rotation=0, labelpad=15)\n",
        "        cbar.ax.yaxis.set_label_coords(-1.2, 1.02)  # fine-tune position (x, y)\n",
        "\n",
        "        ax.set_title(f'Confusion Matrix: {model_name}', fontsize=16, fontweight='bold', pad=25)\n",
        "        ax.set_xlabel('Predicted Label', fontsize=14, fontweight='bold', labelpad=15)\n",
        "        ax.set_ylabel('True Label', fontsize=14, fontweight='bold', labelpad=15)\n",
        "\n",
        "        # Rotate labels for better readability\n",
        "        plt.xticks(rotation=45, ha='right', fontsize=12)\n",
        "        plt.yticks(rotation=0, fontsize=12)\n",
        "\n",
        "        # Add performance metrics as text\n",
        "        accuracy = accuracy_score(results['true_labels'], results['predictions'])\n",
        "        f1_macro = f1_score(results['true_labels'], results['predictions'], average='macro')\n",
        "        f1_weighted = f1_score(results['true_labels'], results['predictions'], average='weighted')\n",
        "\n",
        "        metrics_text = f'Accuracy: {accuracy:.4f}\\nF1 (Macro): {f1_macro:.4f}\\nF1 (Weighted): {f1_weighted:.4f}'\n",
        "        ax.text(1.15, 0.5, metrics_text, transform=ax.transAxes, fontsize=12,\n",
        "                verticalalignment='center', bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_enhanced_confusion_matrix.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced confusion matrix saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_roc_curves(self, results, model_name):\n",
        "        \"\"\"Enhanced ROC curves with better spacing and styling for multiclass\"\"\"\n",
        "        if 'true_labels' not in results or 'probabilities' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'probabilities' in results for {model_name}\")\n",
        "            return\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, Config.NUM_CLASSES))\n",
        "\n",
        "        # Convert labels to binary format for each class (one-vs-rest)\n",
        "        for i, color in zip(range(Config.NUM_CLASSES), colors):\n",
        "            # Binarize the labels for the current class\n",
        "            y_true_bin = (np.array(results['true_labels']) == i).astype(int)\n",
        "            y_score = results['probabilities'][:, i]\n",
        "\n",
        "            # Compute ROC curve and AUC\n",
        "            fpr, tpr, _ = roc_curve(y_true_bin, y_score)\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            ax.plot(fpr, tpr, color=color, linewidth=2,\n",
        "                    label=f'{Config.CLASS_LABELS[i]} (AUC = {roc_auc:.4f})')\n",
        "\n",
        "        # Diagonal line\n",
        "        ax.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.6, label='Random Classifier')\n",
        "\n",
        "        ax.set_title(f'{model_name} - ROC Curves', fontsize=16, fontweight='bold', pad=20)\n",
        "        ax.set_xlabel('False Positive Rate', fontsize=14, fontweight='bold', labelpad=10)\n",
        "        ax.set_ylabel('True Positive Rate', fontsize=14, fontweight='bold', labelpad=10)\n",
        "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', frameon=True, shadow=True, fontsize=11)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_xlim([0.0, 1.0])\n",
        "        ax.set_ylim([0.0, 1.05])\n",
        "\n",
        "        # Compute micro-average ROC curve\n",
        "        y_true_bin = label_binarize(results['true_labels'], classes=range(Config.NUM_CLASSES))\n",
        "        fpr_micro, tpr_micro, _ = roc_curve(y_true_bin.ravel(), results['probabilities'].ravel())\n",
        "        roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
        "        ax.plot(fpr_micro, tpr_micro, 'deeppink', linestyle=':', linewidth=4,\n",
        "                label=f'Micro-average (AUC = {roc_auc_micro:.4f})')\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_enhanced_roc_curves.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced ROC curves saved: {save_path}\")\n",
        "\n",
        "\n",
        "    def plot_misclassified_images(self, misclassified, model_name):\n",
        "        \"\"\"Plot up to 4 misclassified images in a 2x2 grid.\"\"\"\n",
        "        if not misclassified:\n",
        "            print(f\"No misclassified images for {model_name}\")\n",
        "            return\n",
        "\n",
        "        # Select up to 4 misclassified images\n",
        "        misclassified = misclassified[:4]\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(8, 8))  # Larger size for clarity\n",
        "        axes = axes.flatten() if len(misclassified) > 1 else [axes]\n",
        "\n",
        "        for idx, item in enumerate(misclassified):\n",
        "            if idx >= 4:\n",
        "                break\n",
        "\n",
        "            image = item['image'].permute(1, 2, 0).numpy()  # Convert CHW to HWC\n",
        "            print(f\"Image shape: {image.shape}, min: {image.min()}, max: {image.max()}\")  # Debug values\n",
        "            # Normalize to [0, 1] based on data range (handles uint8 or float inputs)\n",
        "            if image.max() > 1.0:  # Likely uint8 (0-255)\n",
        "                image = image / 255.0\n",
        "            else:  # Already float, but ensure [0, 1] if not normalized\n",
        "                image = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
        "            image = np.clip(image, 0, 1)  # Ensure values in [0, 1]\n",
        "\n",
        "            if image.shape[2] == 1:  # Handle grayscale images\n",
        "                image = image.squeeze()\n",
        "                axes[idx].imshow(image, cmap='gray')\n",
        "            else:\n",
        "                # Convert from BGR to RGB if colors appear swapped (common if OpenCV was involved, but adjust based on PIL RGB loading)\n",
        "                # Since preprocessing uses PIL (RGB), but if colors are swapped in display, enable this:\n",
        "                # image = image[..., [2, 1, 0]]  # Uncomment if colors still appear incorrect (red-blue swap)\n",
        "                axes[idx].imshow(image)\n",
        "\n",
        "            axes[idx].set_title(f\"True: {Config.CLASS_LABELS[item['true_label']]}\\nPred: {Config.CLASS_LABELS[item['pred_label']]}\",\n",
        "                                fontsize=12, fontweight='bold', pad=15)  # Added padding for better spacing\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "        # Turn off unused axes\n",
        "        for idx in range(len(misclassified), 4):\n",
        "            axes[idx].axis('off')\n",
        "\n",
        "        plt.suptitle(f\"Misclassified Images for {model_name}\", fontsize=16, fontweight='bold', y=0.98)\n",
        "        plt.tight_layout()\n",
        "        save_path = f\"{self.viz_dir}/misclassified_{model_name}.png\"\n",
        "        plt.savefig(save_path, bbox_inches='tight', dpi=300, facecolor='white', edgecolor='none')\n",
        "        plt.show()  # Show the plot immediately after training\n",
        "        plt.close()\n",
        "        print(f\"Saved misclassified images plot for {model_name} at {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def generate_comprehensive_report(self, single_results, ensemble_results, best_ensemble):\n",
        "        \"\"\"Generate a comprehensive visual report\"\"\"\n",
        "        # fig = plt.figure(figsize=(24, 16))\n",
        "        fig = plt.figure(figsize=(30, 20))\n",
        "        gs = fig.add_gridspec(3, 4, hspace=0.4, wspace=0.3, top=0.92, bottom=0.08, left=0.05, right=0.95)\n",
        "\n",
        "        # Title\n",
        "        fig.suptitle('Fish Species Classification - Comprehensive Analysis Report',\n",
        "                    fontsize=24, fontweight='bold', y=0.96)\n",
        "\n",
        "        # 1. Model Performance Comparison\n",
        "        ax1 = fig.add_subplot(gs[0, :2])\n",
        "        model_names = list(single_results.keys())\n",
        "        accuracies = [single_results[name]['accuracy'] for name in model_names]\n",
        "        f1_scores = [single_results[name]['f1_macro'] for name in model_names]\n",
        "\n",
        "        x = np.arange(len(model_names))\n",
        "        width = 0.35\n",
        "\n",
        "        bars1 = ax1.bar(x - width/2, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "        bars2 = ax1.bar(x + width/2, f1_scores, width, label='F1 Score', alpha=0.8, color='lightcoral')\n",
        "\n",
        "        ax1.set_xlabel('Models', fontweight='bold', fontsize=12)\n",
        "        ax1.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "        ax1.set_title('Individual Model Performance', fontweight='bold', fontsize=14, pad=15)\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "        ax1.legend(fontsize=11)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, 1.1)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar in bars1 + bars2:\n",
        "            height = bar.get_height()\n",
        "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                    f'{height:.4f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        # 2. Best vs Worst Model Comparison\n",
        "        ax2 = fig.add_subplot(gs[0, 2:])\n",
        "        if ensemble_results and best_ensemble:\n",
        "            best_single_f1 = max(f1_scores)\n",
        "            worst_single_f1 = min(f1_scores)\n",
        "            best_ensemble_f1 = best_ensemble[1]['f1']\n",
        "\n",
        "            categories = ['Worst Single', 'Best Single', 'Best Ensemble']\n",
        "            values = [worst_single_f1, best_single_f1, best_ensemble_f1]\n",
        "            colors = ['lightcoral', 'lightblue', 'gold']\n",
        "\n",
        "            bars = ax2.bar(categories, values, color=colors, alpha=0.8)\n",
        "            ax2.set_ylabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax2.set_title('Performance Comparison', fontweight='bold', fontsize=14, pad=15)\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.set_ylim(0, max(values) * 1.1)\n",
        "\n",
        "            for bar, value in zip(bars, values):\n",
        "                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                        f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "        # 3. Per-class Performance Heatmap\n",
        "        ax3 = fig.add_subplot(gs[1, :2])\n",
        "        per_class_f1 = []\n",
        "        for model_name in model_names:\n",
        "            per_class_f1.append(single_results[model_name]['f1_per_class'])\n",
        "\n",
        "        per_class_f1 = np.array(per_class_f1)\n",
        "        im = ax3.imshow(per_class_f1, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "        ax3.set_xticks(range(len(Config.CLASS_LABELS)))\n",
        "        ax3.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right')\n",
        "        ax3.set_yticks(range(len(model_names)))\n",
        "        ax3.set_yticklabels(model_names)\n",
        "        ax3.set_title('Per-Class F1 Scores Heatmap', fontweight='bold', fontsize=14, pad=15)\n",
        "\n",
        "        # Add colorbar\n",
        "        cbar = plt.colorbar(im, ax=ax3, shrink=0.8)\n",
        "        cbar.set_label('F1 Score', rotation=270, labelpad=15)\n",
        "\n",
        "        # Add text annotations\n",
        "        for i in range(len(model_names)):\n",
        "            for j in range(len(Config.CLASS_LABELS)):\n",
        "                text_color = 'white' if per_class_f1[i, j] < 0.5 else 'black'\n",
        "                ax3.text(j, i, f'{per_class_f1[i, j]:.2f}',\n",
        "                        ha=\"center\", va=\"center\", color=text_color, fontsize=8, fontweight='bold')\n",
        "\n",
        "        # 4. Ensemble Methods Performance\n",
        "        ax4 = fig.add_subplot(gs[1, 2:])\n",
        "        if ensemble_results:\n",
        "            ensemble_items = list(ensemble_results.items())\n",
        "            ensemble_items.sort(key=lambda x: x[1]['f1'], reverse=True)\n",
        "            top_ensembles = ensemble_items[:8]\n",
        "\n",
        "            ensemble_names = [name.split('_')[-1] for name, _ in top_ensembles]\n",
        "            ensemble_f1s = [result['f1'] for _, result in top_ensembles]\n",
        "\n",
        "            bars = ax4.barh(range(len(ensemble_names)), ensemble_f1s, alpha=0.8, color='lightgreen')\n",
        "            ax4.set_yticks(range(len(ensemble_names)))\n",
        "            ax4.set_yticklabels(ensemble_names)\n",
        "            ax4.set_xlabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax4.set_title('Top Ensemble Methods', fontweight='bold', fontsize=14, pad=15)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "\n",
        "            for bar, value in zip(bars, ensemble_f1s):\n",
        "                ax4.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,\n",
        "                        f'{value:.4f}', ha='left', va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "        # 5. Summary Statistics Table\n",
        "        ax5 = fig.add_subplot(gs[2, :])\n",
        "        ax5.axis('off')\n",
        "\n",
        "        # Create summary data\n",
        "        summary_data = []\n",
        "        for model_name in model_names:\n",
        "            result = single_results[model_name]\n",
        "            summary_data.append([\n",
        "                model_name,\n",
        "                f\"{result['accuracy']:.4f}\",\n",
        "                f\"{result['f1_macro']:.4f}\",\n",
        "                f\"{result['f1_weighted']:.4f}\",\n",
        "                f\"{result['precision_macro']:.4f}\",\n",
        "                f\"{result['recall_macro']:.4f}\"\n",
        "            ])\n",
        "\n",
        "        if ensemble_results and best_ensemble:\n",
        "            best_result = best_ensemble[1]\n",
        "            summary_data.append([\n",
        "                f\"Best Ensemble\\n({best_ensemble[0]})\",\n",
        "                f\"{best_result['accuracy']:.4f}\",\n",
        "                f\"{best_result['f1']:.4f}\",\n",
        "                \"N/A\",\n",
        "                \"N/A\",\n",
        "                \"N/A\"\n",
        "            ])\n",
        "\n",
        "        columns = ['Model', 'Accuracy', 'F1 (Macro)', 'F1 (Weighted)', 'Precision', 'Recall']\n",
        "\n",
        "        table = ax5.table(cellText=summary_data, colLabels=columns, loc='center', cellLoc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1.2, 2)\n",
        "\n",
        "        # Style the table\n",
        "        for i in range(len(columns)):\n",
        "            table[(0, i)].set_facecolor('#4CAF50')\n",
        "            table[(0, i)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "        for i in range(1, len(summary_data) + 1):\n",
        "            for j in range(len(columns)):\n",
        "                if i % 2 == 0:\n",
        "                    table[(i, j)].set_facecolor('#f0f0f0')\n",
        "                else:\n",
        "                    table[(i, j)].set_facecolor('white')\n",
        "\n",
        "        ax5.set_title('Model Performance Summary', fontweight='bold', fontsize=16, pad=20)\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/comprehensive_report.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Comprehensive report saved: {save_path}\")\n",
        "        return save_path\n",
        "\n",
        "    def plot_model_comparison(self, single_results, ensemble_results):\n",
        "        \"\"\"Enhanced model comparison with better spacing\"\"\"\n",
        "        # fig = plt.figure(figsize=(20, 16))\n",
        "        fig = plt.figure(figsize=(30, 20))\n",
        "        gs = fig.add_gridspec(2, 2, hspace=0.4, wspace=0.3, top=0.92, bottom=0.08)\n",
        "\n",
        "        model_names = list(single_results.keys())\n",
        "        accuracies = [single_results[name]['accuracy'] for name in model_names]\n",
        "        f1_scores = [single_results[name]['f1_macro'] for name in model_names]\n",
        "        f1_weighted = [single_results[name]['f1_weighted'] for name in model_names]\n",
        "        losses = [single_results[name]['loss'] for name in model_names]\n",
        "\n",
        "        x = np.arange(len(model_names))\n",
        "        width = 0.2\n",
        "\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        bars1 = ax1.bar(x - width*1.5, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "        bars2 = ax1.bar(x - width/2, f1_scores, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "        bars3 = ax1.bar(x + width/2, f1_weighted, width, label='F1 (Weighted)', alpha=0.8, color='lightgreen')\n",
        "        bars4 = ax1.bar(x + width*1.5, losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "        ax1.set_xlabel('Models', fontweight='bold', fontsize=12)\n",
        "        ax1.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "        ax1.set_title('Individual Model Performance', fontweight='bold', fontsize=14, pad=20)\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(model_names, rotation=45, ha='right', fontsize=10)\n",
        "        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, max(max(accuracies), max(f1_scores), max(f1_weighted), max(losses)) * 1.1)\n",
        "\n",
        "        if ensemble_results:\n",
        "            ensemble_items = list(ensemble_results.items())\n",
        "            ensemble_items.sort(key=lambda x: x[1]['f1'], reverse=True)\n",
        "            top_ensembles = ensemble_items[:10]\n",
        "\n",
        "            ensemble_names = [name.split('_')[-1] for name, _ in top_ensembles]\n",
        "            ensemble_f1s = [result['f1'] for _, result in top_ensembles]\n",
        "            ensemble_accs = [result['accuracy'] for _, result in top_ensembles]\n",
        "            ensemble_losses = [result['loss'] for _, result in top_ensembles]\n",
        "\n",
        "            x = np.arange(len(ensemble_names))\n",
        "            ax2 = fig.add_subplot(gs[0, 1])\n",
        "            ax2.bar(x - width, ensemble_accs, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "            ax2.bar(x, ensemble_f1s, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "            ax2.bar(x + width, ensemble_losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "            ax2.set_xticks(x)\n",
        "            ax2.set_xticklabels([f\"{name}\" for name in ensemble_names], rotation=45, ha='right', fontsize=10)\n",
        "            ax2.set_xlabel('Ensemble Methods', fontweight='bold', fontsize=12)\n",
        "            ax2.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "            ax2.set_title('Top Ensemble Methods', fontweight='bold', fontsize=14, pad=20)\n",
        "            ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.set_ylim(0, max(max(ensemble_accs), max(ensemble_f1s), max(ensemble_losses)) * 1.1)\n",
        "\n",
        "        if single_results:\n",
        "            per_class_f1 = []\n",
        "            for model_name in model_names:\n",
        "                per_class_f1.append(single_results[model_name]['f1_per_class'])\n",
        "\n",
        "            per_class_f1 = np.array(per_class_f1)\n",
        "            ax3 = fig.add_subplot(gs[1, 0])\n",
        "            im = ax3.imshow(per_class_f1, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "            ax3.set_xticks(range(len(Config.CLASS_LABELS)))\n",
        "            ax3.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right', fontsize=10)\n",
        "            ax3.set_yticks(range(len(model_names)))\n",
        "            ax3.set_yticklabels(model_names, fontsize=10)\n",
        "            ax3.set_title('Per-Class F1 Scores', fontweight='bold', fontsize=14, pad=20)\n",
        "\n",
        "            cbar = plt.colorbar(im, ax=ax3, shrink=0.8)\n",
        "            cbar.set_label('F1 Score', rotation=270, labelpad=15)\n",
        "\n",
        "            for i in range(len(model_names)):\n",
        "                for j in range(len(Config.CLASS_LABELS)):\n",
        "                    text_color = 'white' if per_class_f1[i, j] < 0.5 else 'black'\n",
        "                    ax3.text(j, i, f'{per_class_f1[i, j]:.2f}',\n",
        "                            ha=\"center\", va=\"center\", color=text_color, fontsize=8)\n",
        "\n",
        "        if ensemble_results:\n",
        "            best_single_f1 = max(f1_scores)\n",
        "            best_single_name = model_names[f1_scores.index(best_single_f1)]\n",
        "            best_ensemble_f1 = max([result['f1'] for result in ensemble_results.values()])\n",
        "            best_ensemble_name = max(ensemble_results.items(), key=lambda x: x[1]['f1'])[0]\n",
        "\n",
        "            ax4 = fig.add_subplot(gs[1, 1])\n",
        "            categories = ['Best Single\\nModel', 'Best Ensemble']\n",
        "            values = [best_single_f1, best_ensemble_f1]\n",
        "            colors = ['lightblue', 'gold']\n",
        "\n",
        "            bars = ax4.bar(categories, values, color=colors, alpha=0.8, width=0.6)\n",
        "            ax4.set_ylabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax4.set_title('Single vs Ensemble Comparison', fontweight='bold', fontsize=14, pad=20)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.set_ylim(0, 1)\n",
        "\n",
        "            for bar, value in zip(bars, values):\n",
        "                ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "                        f'{value:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
        "\n",
        "            improvement = ((best_ensemble_f1 - best_single_f1) / best_single_f1) * 100\n",
        "            ax4.text(0.5, 0.5, f'Improvement:\\n{improvement:.2f}%',\n",
        "                    transform=ax4.transAxes, ha='center', va='center',\n",
        "                    fontsize=14, fontweight='bold',\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"yellow\", alpha=0.8))\n",
        "\n",
        "        plt.suptitle('Fish Species Classification - Model Comparison Analysis',\n",
        "                    fontsize=18, fontweight='bold', y=0.96)\n",
        "        save_path = f\"{self.viz_dir}/enhanced_model_comparison.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced model comparison saved: {save_path}\")\n",
        "        return save_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_lrp_grid(self, single_models, test_loader):\n",
        "        print(\"Generating LRP grid visualization for TP, TN, FP, FN...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # Compute predictions and confusion matrix\n",
        "        model = list(single_models.values())[0]\n",
        "        model.eval()\n",
        "        true_labels = []\n",
        "        pred_labels = []\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                # images, labels = batch['image'].to(Config.DEVICE), batch['label'].to(Config.DEVICE)\n",
        "                images, labels = batch[0].to(Config.DEVICE), batch[1].to(Config.DEVICE)  # Access tuple elements\n",
        "                outputs = model(images)\n",
        "                preds = outputs.argmax(dim=1) if outputs.dim() > 1 else (outputs > 0.5).float()\n",
        "                true_labels.extend(labels.cpu().numpy())\n",
        "                pred_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "        cm = confusion_matrix(true_labels, pred_labels)\n",
        "        classes = Config.CLASS_LABELS\n",
        "        tp = np.diag(cm)\n",
        "        fp = cm.sum(axis=0) - tp\n",
        "        fn = cm.sum(axis=1) - tp\n",
        "        tn = cm.sum() - (fp + fn + tp)\n",
        "        metrics = [tp, tn, fp, fn]\n",
        "\n",
        "        # Collect one image per class per category (TP, TN, FP, FN)\n",
        "        sample_images = {cls: {\"TP\": None, \"TN\": None, \"FP\": None, \"FN\": None} for cls in range(5)}\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                # images, labels = batch['image'].to(Config.DEVICE), batch['label'].to(Config.DEVICE)\n",
        "                images, labels = batch[0].to(Config.DEVICE), batch[1].to(Config.DEVICE)  # Access tuple elements\n",
        "                outputs = model(images)\n",
        "                preds = outputs.argmax(dim=1) if outputs.dim() > 1 else (outputs > 0.5).float()\n",
        "                for img, true, pred in zip(images, labels, preds):\n",
        "                    cls = int(true.item())\n",
        "                    pred_cls = int(pred.item())\n",
        "                    for i in range(5):  # Check for each class\n",
        "                        category = {\n",
        "                            (1, 1): \"TP\",  # Predicted class i, true class i\n",
        "                            (0, 0): \"TN\",  # Predicted not i, true not i\n",
        "                            (1, 0): \"FP\",  # Predicted i, true not i\n",
        "                            (0, 1): \"FN\"   # Predicted not i, true i\n",
        "                        }[(1 if pred_cls == i else 0, 1 if cls == i else 0)]\n",
        "                        if sample_images[cls][category] is None:\n",
        "                            sample_images[cls][category] = (img, true)\n",
        "                    if all(sample_images[c][cat] is not None for c in range(5) for cat in [\"TP\", \"TN\", \"FP\", \"FN\"]):\n",
        "                        break\n",
        "                if all(sample_images[c][cat] is not None for c in range(5) for cat in [\"TP\", \"TN\", \"FP\", \"FN\"]):\n",
        "                    break\n",
        "\n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(5, 4, figsize=(30, 35))  # Large figure for clarity\n",
        "        for i in range(5):  # Classes\n",
        "            for j, category in enumerate([\"TP\", \"TN\", \"FP\", \"FN\"]):\n",
        "                ax = axes[i, j]\n",
        "                if sample_images[i][category] is not None:\n",
        "                    img, true = sample_images[i][category]\n",
        "                    img = img.squeeze().cpu()\n",
        "                    lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, img, i)\n",
        "                    img = img.permute(1, 2, 0).numpy()\n",
        "                    img = np.clip(img, 0, 1)\n",
        "                    img = img[..., [2, 1, 0]] if img.shape[2] == 3 else img  # Convert BGR to RGB\n",
        "                    img = (img * 255).astype(np.uint8)\n",
        "                    ax.imshow(img)\n",
        "                    lrp_img = (lrp_img - lrp_img.min()) / (lrp_img.max() - lrp_img.min() + 1e-8)  # Normalize heatmap\n",
        "                    ax.imshow(lrp_img, cmap='jet', alpha=0.4, vmin=0, vmax=np.percentile(lrp_img, 95))\n",
        "                    ax.set_title(f'{classes[i]} - {category}: {metrics[j][i]}', fontsize=16, fontweight='bold', pad=10)\n",
        "                ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        save_path = f\"{self.viz_dir}/lrp_fish_metrics_grid.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"LRP grid visualization saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_comparative_xai(self, single_models, ensemble_results, test_loader, max_images=5):\n",
        "        \"\"\"Generate comparative XAI visualizations with Grad-CAM++, Integrated Gradients, and LRP in the same row\"\"\"\n",
        "        print(f\"Generating comparative XAI visualizations for {max_images} images...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # Get sample images\n",
        "        # sample_images, sample_labels = next(iter(test_loader))\n",
        "        # sample_images = sample_images[:max_images].to(Config.DEVICE)\n",
        "        # sample_labels = sample_labels[:max_images].numpy()\n",
        "        sample_images = []\n",
        "        sample_labels = []\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            class_mask = np.where(test_loader.dataset.labels == i)[0]\n",
        "            if len(class_mask) > 0:\n",
        "                idx = np.random.choice(class_mask)\n",
        "                image, label = test_loader.dataset[idx]\n",
        "                if image.dim() == 4:\n",
        "                    image = image.squeeze(0)\n",
        "                sample_images.append(image.to(Config.DEVICE))\n",
        "                sample_labels.append(label)\n",
        "        sample_images = sample_images[:max_images]\n",
        "        sample_labels = sample_labels[:max_images]\n",
        "\n",
        "        # Get best ensemble if available\n",
        "        best_ensemble_name = max(ensemble_results.items(), key=lambda x: x[1]['f1'])[0] if ensemble_results else None\n",
        "        best_ensemble = ensemble_results.get(best_ensemble_name, None) if best_ensemble_name else None\n",
        "\n",
        "        for idx, (image, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
        "            try:\n",
        "                # Adjusted figure size with more height per row to prevent text cropping\n",
        "                num_rows = len(single_models) + (1 if best_ensemble else 0)\n",
        "                fig = plt.figure(figsize=(36, 14 * num_rows))  # Increased width and height per row\n",
        "                gs = fig.add_gridspec(num_rows, 4, wspace=0.3, hspace=0.5)  # Increased wspace and hspace for better spacing\n",
        "\n",
        "                # Prepare original image\n",
        "                image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                # Plot original image spanning all rows in first column\n",
        "                ax_orig = fig.add_subplot(gs[:, 0])\n",
        "                ax_orig.imshow(image_np)\n",
        "                ax_orig.set_title(f'Original Image\\nTrue: {Config.CLASS_LABELS[true_label]}',\n",
        "                                fontsize=16, fontweight='bold', pad=30)  # Increased pad for title\n",
        "                ax_orig.axis('off')\n",
        "\n",
        "                # Plot XAI for single models\n",
        "                for row, (model_name, model) in enumerate(single_models.items()):\n",
        "                    model.eval()\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(image.unsqueeze(0))\n",
        "                        probabilities = torch.softmax(outputs, dim=1)\n",
        "                        predicted_class = outputs.argmax(dim=1).item()\n",
        "                        confidence = probabilities[0, predicted_class].item()\n",
        "                        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                    # Generate Grad-CAM++ visualization\n",
        "                    gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(model, image, predicted_class)\n",
        "\n",
        "                    # Plot Grad-CAM++ in second column\n",
        "                    ax_gradcam = fig.add_subplot(gs[row, 1])\n",
        "                    ax_gradcam.imshow(gradcam_img)\n",
        "                    ax_gradcam.set_title(f'{model_name}\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                        fontsize=14, fontweight='bold', pad=30)  # Increased pad\n",
        "                    ax_gradcam.axis('off')\n",
        "\n",
        "                    # Generate Integrated Gradients visualization\n",
        "                    ig_img, _ = xai_visualizer.integrated_gradients(model, image, predicted_class)\n",
        "\n",
        "                    # Plot Integrated Gradients in third column\n",
        "                    ax_ig = fig.add_subplot(gs[row, 2])\n",
        "                    ax_ig.imshow(ig_img)\n",
        "                    ax_ig.set_title(f'{model_name}\\nIntegrated Gradients', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_ig.axis('off')\n",
        "\n",
        "                    # Generate LRP visualization\n",
        "                    lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, image, predicted_class)\n",
        "\n",
        "                    # Plot LRP in fourth column\n",
        "                    ax_lrp = fig.add_subplot(gs[row, 3])\n",
        "                    # ax_lrp.imshow(lrp_img)\n",
        "                    ax_lrp.imshow(cv2.cvtColor(lrp_img, cv2.COLOR_BGR2RGB))\n",
        "                    ax_lrp.set_title(f'{model_name}\\nLRP', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_lrp.axis('off')\n",
        "\n",
        "                # Plot XAI for best ensemble (if available)\n",
        "                if best_ensemble:\n",
        "                    ensemble_models = best_ensemble['models']\n",
        "                    with torch.no_grad():\n",
        "                        model_probs = []\n",
        "                        for model_name in ensemble_models:\n",
        "                            model = single_models[model_name]\n",
        "                            outputs = model(image.unsqueeze(0))\n",
        "                            probs = torch.softmax(outputs, dim=1)\n",
        "                            model_probs.append(probs)\n",
        "                        model_probs = torch.stack(model_probs, dim=1)\n",
        "\n",
        "                        # Load learnable ensemble model if applicable\n",
        "                        if 'learnable_weighted' in best_ensemble_name:\n",
        "                            ensemble_model = LearnableWeightedEnsemble(\n",
        "                                num_models=len(ensemble_models),\n",
        "                                num_classes=Config.NUM_CLASSES\n",
        "                            ).to(Config.DEVICE)\n",
        "                            ensemble_model.load_state_dict(\n",
        "                                torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(ensemble_models)}.pt\")\n",
        "                            )\n",
        "                            ensemble_model.eval()\n",
        "                            outputs, _ = ensemble_model(model_probs)\n",
        "                        else:\n",
        "                            weights = best_ensemble.get('weights', np.ones(len(ensemble_models)) / len(ensemble_models))\n",
        "                            outputs = torch.sum(model_probs * torch.tensor(weights, device=Config.DEVICE).view(1, -1, 1), dim=1)\n",
        "\n",
        "                        predicted_class = outputs.argmax(dim=1).item()\n",
        "                        confidence = torch.softmax(outputs, dim=1)[0, predicted_class].item()\n",
        "                        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                    # Approximate ensemble Grad-CAM++ by averaging\n",
        "                    gradcam_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(single_models[model_name], image, predicted_class)\n",
        "                        gradcam_imgs.append(gradcam_img)\n",
        "                    ensemble_gradcam = np.mean(gradcam_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble Grad-CAM++ in second column\n",
        "                    ax_gradcam = fig.add_subplot(gs[num_rows-1, 1])\n",
        "                    ax_gradcam.imshow(ensemble_gradcam)\n",
        "                    ax_gradcam.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                        fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_gradcam.axis('off')\n",
        "\n",
        "                    # Approximate ensemble Integrated Gradients by averaging\n",
        "                    ig_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        ig_img, _ = xai_visualizer.integrated_gradients(single_models[model_name], image, predicted_class)\n",
        "                        ig_imgs.append(ig_img)\n",
        "                    ensemble_ig = np.mean(ig_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble Integrated Gradients in third column\n",
        "                    ax_ig = fig.add_subplot(gs[num_rows-1, 2])\n",
        "                    ax_ig.imshow(ensemble_ig)\n",
        "                    ax_ig.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nIntegrated Gradients', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_ig.axis('off')\n",
        "\n",
        "                    # Approximate ensemble LRP by averaging\n",
        "                    lrp_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(single_models[model_name], image, predicted_class)\n",
        "                        lrp_imgs.append(lrp_img)\n",
        "                    ensemble_lrp = np.mean(lrp_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble LRP in fourth column\n",
        "                    ax_lrp = fig.add_subplot(gs[num_rows-1, 3])\n",
        "                    ax_lrp.imshow(ensemble_lrp)\n",
        "                    ax_lrp.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nLRP', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_lrp.axis('off')\n",
        "\n",
        "                # Adjusted suptitle with increased padding\n",
        "                plt.suptitle(f'Comparative XAI Analysis - Image {idx+1}', fontsize=18, fontweight='bold', y=0.97)\n",
        "                plt.tight_layout(rect=[0, 0, 1, 0.95])  # Added rect to ensure suptitle is not cropped\n",
        "                save_path = f\"{self.viz_dir}/comparative_xai_image_{idx+1}.png\"\n",
        "                plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "                plt.show()\n",
        "                print(f\"Comparative XAI visualization saved: {save_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating comparative XAI for image {idx+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 12. FULLY FIXED XAI VISUALIZATIONS\n",
        "# =============================================================================\n",
        "# Purpose: Implement corrected Grad-CAM++ and LRP with proper tensor handling.\n",
        "\n",
        "class XAIVisualizer:\n",
        "    @staticmethod\n",
        "    def grad_cam_plus_plus(model, image, target_class):\n",
        "        \"\"\"Implement Grad-CAM++ for visualizing important image regions.\"\"\"\n",
        "        if image.dim() == 4:\n",
        "            image = image.squeeze(0)  # Normalize to (C, H, W)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Find the last convolutional layer\n",
        "        target_layer = None\n",
        "        for name, module in model.named_modules():  # Corrected: removed redundant reversed\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                target_layer = module\n",
        "\n",
        "        if target_layer is None:\n",
        "            raise ValueError(\"No convolutional layer found in the model\")\n",
        "\n",
        "        # Hook to capture gradients and activations\n",
        "        gradients = []\n",
        "        activations = []\n",
        "\n",
        "        def forward_hook(module, input, output):\n",
        "            activations.append(output.detach())\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            gradients.append(grad_output[0].detach())\n",
        "\n",
        "        # Register hooks\n",
        "        forward_handle = target_layer.register_forward_hook(forward_hook)\n",
        "        backward_handle = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "        try:\n",
        "            # Forward pass\n",
        "            image_tensor = image.unsqueeze(0).requires_grad_(True)\n",
        "            output = model(image_tensor)\n",
        "\n",
        "            # Backward pass\n",
        "            model.zero_grad()\n",
        "            score = output[0, target_class]\n",
        "            score.backward()\n",
        "\n",
        "            # Get gradients and activations\n",
        "            if not gradients or not activations:\n",
        "                raise ValueError(\"No gradients or activations captured\")\n",
        "\n",
        "            grad = gradients[0]  # Shape: (1, C, H, W)\n",
        "            act = activations[0]  # Shape: (1, C, H, W)\n",
        "\n",
        "            # Grad-CAM++ calculations\n",
        "            alpha_num = grad.pow(2)\n",
        "            alpha_denom = 2.0 * grad.pow(2) + (act * grad.pow(3)).sum(dim=(2, 3), keepdim=True)\n",
        "            alpha_denom = torch.where(alpha_denom != 0, alpha_denom, torch.ones_like(alpha_denom))\n",
        "            alpha = alpha_num / alpha_denom\n",
        "\n",
        "            weights = (alpha * F.relu(grad)).sum(dim=(2, 3))  # Shape: (1, C)\n",
        "            cam = (weights.unsqueeze(-1).unsqueeze(-1) * act).sum(dim=1, keepdim=True)  # Shape: (1, 1, H, W)\n",
        "            cam = F.relu(cam)\n",
        "\n",
        "            # Normalize\n",
        "            cam = cam - cam.min()\n",
        "            cam = cam / (cam.max() + 1e-8)\n",
        "\n",
        "            # Resize to input image size\n",
        "            cam = F.interpolate(cam, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "            cam = cam.squeeze().detach().cpu().numpy()\n",
        "\n",
        "            # Apply colormap\n",
        "            cam = (cam * 255).astype(np.uint8)\n",
        "            heatmap = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
        "\n",
        "            # Convert original image for visualization\n",
        "            image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "            image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "            image_np = np.clip(image_np, 0, 1)\n",
        "            image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "            # Superimpose heatmap\n",
        "            superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "            # superimposed_img = cv2.addWeighted(image_np[:, :, ::-1], 0.6, heatmap, 0.4, 0)  # Convert image_np to BGR for cv2\n",
        "            # superimposed_img = superimposed_img[:, :, ::-1]  # Back to RGB for display\n",
        "\n",
        "        finally:\n",
        "            # Remove hooks\n",
        "            forward_handle.remove()\n",
        "            backward_handle.remove()\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "    @staticmethod\n",
        "    def integrated_gradients(model, image, target_class):\n",
        "        \"\"\"Integrated Gradients implementation.\"\"\"\n",
        "        if image.dim() == 4:\n",
        "            image = image.squeeze(0)  # Normalize to (C, H, W)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Detach the image first to avoid gradient issues\n",
        "        image_detached = image.detach()\n",
        "\n",
        "        # Create baseline (black image)\n",
        "        baseline = torch.zeros_like(image_detached)\n",
        "\n",
        "        # Generate path from baseline to image\n",
        "        num_steps = 30\n",
        "        alphas = torch.linspace(0, 1, num_steps).to(image_detached.device)\n",
        "\n",
        "        gradients = []\n",
        "        for alpha in alphas:\n",
        "            interpolated = baseline + alpha * (image_detached - baseline)\n",
        "            interpolated = interpolated.requires_grad_(True)\n",
        "\n",
        "            output = model(interpolated.unsqueeze(0))\n",
        "            score = output[0, target_class]\n",
        "\n",
        "            # Clear gradients\n",
        "            model.zero_grad()\n",
        "            if interpolated.grad is not None:\n",
        "                interpolated.grad.zero_()\n",
        "\n",
        "            score.backward()\n",
        "\n",
        "            # Detach gradient before storing\n",
        "            if interpolated.grad is not None:\n",
        "                gradients.append(interpolated.grad.detach().clone())\n",
        "\n",
        "            # Clear the gradient to free memory\n",
        "            interpolated.grad = None\n",
        "\n",
        "        if not gradients:\n",
        "            # Fallback: simple gradient\n",
        "            image_grad = image_detached.requires_grad_(True)\n",
        "            output = model(image_grad.unsqueeze(0))\n",
        "            score = output[0, target_class]\n",
        "            model.zero_grad()\n",
        "            score.backward()\n",
        "            gradients = [image_grad.grad.detach().clone()]\n",
        "\n",
        "        # Average gradients\n",
        "        avg_gradients = torch.stack(gradients).mean(dim=0)\n",
        "\n",
        "        # Compute integrated gradients\n",
        "        integrated_gradients = (image_detached - baseline) * avg_gradients\n",
        "\n",
        "        # Sum across color channels\n",
        "        relevance = integrated_gradients.abs().sum(dim=0).cpu().numpy()\n",
        "\n",
        "        # Normalize\n",
        "        relevance = relevance / (relevance.max() + 1e-8)\n",
        "\n",
        "        # Apply colormap\n",
        "        relevance = (relevance * 255).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(relevance, cv2.COLORMAP_JET)\n",
        "\n",
        "        # Convert original image for visualization\n",
        "        image_np = image_detached.permute(1, 2, 0).cpu().numpy()\n",
        "        image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "        # Superimpose heatmap\n",
        "        superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def layer_wise_relevance_propagation(model, image, target_class, epsilon=1e-6):\n",
        "        \"\"\"Layer-wise Relevance Propagation (LRP) using Captum with robust fallback.\"\"\"\n",
        "        import torch\n",
        "        import numpy as np\n",
        "        import cv2\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Validate and prepare input tensor\n",
        "        if image.dim() == 4:\n",
        "            image = image.squeeze(0)\n",
        "        if image.dim() != 3:\n",
        "            raise ValueError(f\"Expected 3D image tensor (C, H, W), got shape {image.shape}\")\n",
        "        image_tensor = image.unsqueeze(0).requires_grad_(True).to(Config.DEVICE)\n",
        "\n",
        "        # Determine target class if not provided\n",
        "        if target_class is None:\n",
        "            with torch.no_grad():\n",
        "                output = model(image_tensor)\n",
        "                target_class = output.argmax(dim=1).item()\n",
        "\n",
        "        # Attempt Captum LRP\n",
        "        try:\n",
        "            from captum.attr import LRP\n",
        "\n",
        "            lrp = LRP(model)\n",
        "\n",
        "            # Compute LRP attributions\n",
        "            attributions = lrp.attribute(\n",
        "                image_tensor,\n",
        "                target=target_class,\n",
        "                additional_forward_args=None,\n",
        "                return_convergence_delta=False\n",
        "            )\n",
        "            if attributions is None:\n",
        "                raise ValueError(\"LRP attribution returned None\")\n",
        "\n",
        "            # Process attributions\n",
        "            relevance = attributions.detach().cpu().squeeze(0)  # Shape: (C, H, W)\n",
        "            if relevance.dim() == 3:\n",
        "                relevance = relevance.sum(dim=0)  # Shape: (H, W)\n",
        "            relevance = relevance.clamp(min=0)  # Clip negative relevance\n",
        "            relevance = relevance / (relevance.max() + epsilon)  # Normalize to [0, 1]\n",
        "\n",
        "            # Convert to numpy for visualization\n",
        "            relevance_map = relevance.numpy()\n",
        "\n",
        "            # Resize to match input image size if needed\n",
        "            if relevance_map.shape != (Config.INPUT_SIZE, Config.INPUT_SIZE):\n",
        "                relevance_map = cv2.resize(relevance_map, (Config.INPUT_SIZE, Config.INPUT_SIZE))\n",
        "\n",
        "            # Apply colormap\n",
        "            relevance_map = (relevance_map * 255).astype(np.uint8)\n",
        "            heatmap = cv2.applyColorMap(relevance_map, cv2.COLORMAP_JET)\n",
        "\n",
        "            # Prepare original image for visualization\n",
        "            image_np = image_tensor.detach().squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "            image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "            image_np = np.clip(image_np, 0, 1)\n",
        "            image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "            # Superimpose heatmap\n",
        "            superimposed_img = cv2.addWeighted(image_np, 0.7, heatmap, 0.3, 0.0)\n",
        "\n",
        "            return superimposed_img, heatmap\n",
        "\n",
        "        except Exception as e:\n",
        "            # print(f\"Captum LRP failed: {str(e)}\")\n",
        "            # print(\"Falling back to gradient-based relevance propagation...\")\n",
        "\n",
        "            # Fallback: Gradient-based relevance propagation\n",
        "            try:\n",
        "                # Ensure model is in a state to compute gradients\n",
        "                model.zero_grad()\n",
        "                image_tensor.grad = None  # Clear any existing gradients\n",
        "                image_tensor = image_tensor.detach().requires_grad_(True)\n",
        "\n",
        "                # Check if model parameters allow gradients\n",
        "                if not any(p.requires_grad for p in model.parameters()):\n",
        "                    raise ValueError(\"No model parameters have requires_grad=True; gradient computation not possible\")\n",
        "\n",
        "                # Forward pass\n",
        "                output = model(image_tensor)\n",
        "                if output.shape[0] != 1:\n",
        "                    raise ValueError(f\"Expected batch size of 1, got {output.shape[0]}\")\n",
        "                target_score = output[0, target_class]\n",
        "\n",
        "                # Backward pass to compute gradients\n",
        "                target_score.backward()\n",
        "                if image_tensor.grad is None:\n",
        "                    raise ValueError(f\"Gradient computation failed during LRP fallback. Output shape: {output.shape}, Target class: {target_class}\")\n",
        "\n",
        "                # Use positive gradients for relevance\n",
        "                relevance_input = image_tensor.grad.detach().cpu().squeeze(0)\n",
        "                relevance_input = relevance_input.clamp(min=0)  # Keep positive contributions\n",
        "                if relevance_input.dim() == 3:\n",
        "                    relevance_input = relevance_input.sum(dim=0)  # Sum across channels\n",
        "\n",
        "                # Normalize\n",
        "                relevance_map = relevance_input.numpy()\n",
        "                if relevance_map.max() > 0:\n",
        "                    relevance_map = relevance_map / (relevance_map.max() + epsilon)\n",
        "\n",
        "                # Resize if necessary\n",
        "                if relevance_map.shape != (Config.INPUT_SIZE, Config.INPUT_SIZE):\n",
        "                    relevance_map = cv2.resize(relevance_map, (Config.INPUT_SIZE, Config.INPUT_SIZE))\n",
        "\n",
        "                # Apply colormap\n",
        "                relevance_map = (relevance_map * 255).astype(np.uint8)\n",
        "                heatmap = cv2.applyColorMap(relevance_map, cv2.COLORMAP_JET)\n",
        "\n",
        "                # Prepare original image\n",
        "                image_np = image_tensor.detach().squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                # Superimpose heatmap\n",
        "                superimposed_img = cv2.addWeighted(image_np, 0.7, heatmap, 0.3, 0.0)\n",
        "\n",
        "                return superimposed_img, heatmap\n",
        "\n",
        "            except Exception as fallback_e:\n",
        "                print(f\"Fallback LRP also failed: {str(fallback_e)}\")\n",
        "                print(f\"Debug info: Input shape: {image_tensor.shape}, Target class: {target_class}\")\n",
        "                # Last resort: Return original image with blank heatmap\n",
        "                image_np = image_tensor.detach().squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "                heatmap = np.zeros_like(image_np, dtype=np.uint8)\n",
        "                return image_np, heatmap\n",
        "\n",
        "# ---\n",
        "# 13. MAIN EXECUTION\n",
        "# =============================================================================\n",
        "# Purpose: Orchestrate the entire pipeline: data loading, model training, ensemble creation, evaluation, and visualization.\n",
        "\n",
        "def main():\n",
        "    print(\"Starting Fish Species Classification Pipeline...\")\n",
        "    print(\"=\"*70)\n",
        "    # Clear cached .pyc files and __pycache__ directories\n",
        "    import os\n",
        "    os.system('find . -name \"*.pyc\" -delete')\n",
        "    os.system('find . -name \"__pycache__\" -type d -exec rm -rf {} +')\n",
        "\n",
        "    setup_environment()\n",
        "\n",
        "    # Load and balance data\n",
        "    X, Y = DataManager.load_and_balance_data()   #Augmentation,Smote,Data Loader,Train-Val-Test Loader,\n",
        "    train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(X, Y)\n",
        "\n",
        "    # Initialize components\n",
        "    single_models = {}\n",
        "    single_results = {}\n",
        "    histories = {}\n",
        "    visualizer = EnhancedVisualizations()\n",
        "\n",
        "    # # Train individual models with immediate plotting\n",
        "    # for model_name in Config.MODELS:\n",
        "    #     print(f\"\\nTraining {model_name}...\")\n",
        "    #     print(\"-\"*50)\n",
        "\n",
        "    #     # Optimize hyperparameters\n",
        "    #     optimizer = ExpandedHyperparameterOptimizer(model_name, train_loader, val_loader)\n",
        "    #     best_params = optimizer.optimize()\n",
        "\n",
        "    #     # Print bold red announcement with best parameters\n",
        "    #     print(f\"\\n\\033[1;31m{'='*70}\\033[0m\")\n",
        "    #     print(f\"\\033[1;31m{model_name.upper()} TRAINING WITH BEST PARAMETERS:\\033[0m\")\n",
        "    #     for key, value in best_params.items():\n",
        "    #         if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "    #             print(f\"\\033[1;31m  {key}: {value:.4f}\\033[0m\")\n",
        "    #         else:\n",
        "    #             print(f\"\\033[1;31m  {key}: {value}\\033[0m\")\n",
        "    #     print(f\"\\033[1;31m{'='*70}\\033[0m\")\n",
        "\n",
        "    #     train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(\n",
        "    #         X, Y,\n",
        "    #         test_size=0.2,\n",
        "    #         batch_size=best_params['batch_size'],\n",
        "    #         augmentation_strength=best_params['augmentation_strength']\n",
        "    #     )\n",
        "    #     # Create and train model with immediate visualization\n",
        "    #     model = ModelFactory.create_model(\n",
        "    #         model_name,\n",
        "    #         dropout_rate=best_params.get('dropout', 0.5),\n",
        "    #         hidden_dim_multiplier=best_params.get('hidden_dim_multiplier', 0.5)\n",
        "    #     )\n",
        "    #     trainer = EnhancedModelTrainer(model, model_name, best_params)\n",
        "\n",
        "    #     # Train with immediate plotting (includes training history, ROC, confusion matrix, XAI)\n",
        "    #     train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(X, Y, test_size=0.2, batch_size=best_params['batch_size'], augmentation_strength=best_params['augmentation_strength'])\n",
        "    #     history, result = trainer.train(train_loader, val_loader, test_loader, visualizer)\n",
        "    #     histories[model_name] = history\n",
        "    #     single_models[model_name] = model\n",
        "    #     single_results[model_name] = result  # Ensure result contains test set metrics\n",
        "\n",
        "    #     if result:\n",
        "    #         single_results[model_name] = result\n",
        "    #     # Clear memory: delete model, trainer, and optimizer\n",
        "    #     del model\n",
        "    #     del trainer\n",
        "    #     del optimizer\n",
        "    #     torch.cuda.empty_cache()\n",
        "    #     gc.collect()\n",
        "    for model_name in Config.MODELS:\n",
        "        print(f\"\\nTraining {model_name}...\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        # Optimize hyperparameters\n",
        "        optimizer = ExpandedHyperparameterOptimizer(model_name, train_loader, val_loader)\n",
        "        best_params = optimizer.optimize()\n",
        "\n",
        "        # Re-adjust batch_size and num_workers based on current GPU memory to prevent OOM in final training\n",
        "        best_params['batch_size'], Config.DATALOADER_NUM_WORKERS = adjust_batch_size_and_workers(\n",
        "            best_params['batch_size'], Config.DATALOADER_NUM_WORKERS\n",
        "        )\n",
        "        if best_params['batch_size'] < 32:  # Further reduce workers if batch is small\n",
        "            Config.DATALOADER_NUM_WORKERS = max(0, Config.DATALOADER_NUM_WORKERS // 2)\n",
        "        print(f\"Final adjusted batch_size: {best_params['batch_size']}, num_workers: {Config.DATALOADER_NUM_WORKERS} to avoid OOM.\")\n",
        "\n",
        "\n",
        "        # Print bold red announcement with best parameters\n",
        "        print(f\"\\n\\033[1;31m{'='*70}\\033[0m\")\n",
        "        print(f\"\\033[1;31m{model_name.upper()} TRAINING WITH BEST PARAMETERS:\\033[0m\")\n",
        "        for key, value in best_params.items():\n",
        "            if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                print(f\"\\033[1;31m  {key}: {value:.4f}\\033[0m\")\n",
        "            else:\n",
        "                print(f\"\\033[1;31m  {key}: {value}\\033[0m\")\n",
        "        print(f\"\\033[1;31m{'='*70}\\033[0m\")\n",
        "\n",
        "\n",
        "        # Recreate loaders with adjusted batch_size\n",
        "        train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(\n",
        "            X, Y,\n",
        "            test_size=0.2,\n",
        "            batch_size=best_params['batch_size'],\n",
        "            augmentation_strength=best_params['augmentation_strength']\n",
        "        )\n",
        "\n",
        "        # Create and train model\n",
        "        model = ModelFactory.create_model(\n",
        "            model_name,\n",
        "            dropout_rate=best_params.get('dropout', 0.5),\n",
        "            hidden_dim_multiplier=best_params.get('hidden_dim_multiplier', 0.5)\n",
        "        )\n",
        "        trainer = EnhancedModelTrainer(model, model_name, best_params)\n",
        "        history, result = trainer.train(train_loader, val_loader, test_loader, visualizer)\n",
        "        histories[model_name] = history\n",
        "        single_models[model_name] = model\n",
        "        single_results[model_name] = result\n",
        "\n",
        "        # Clear memory more aggressively after each model\n",
        "        del model\n",
        "        del trainer\n",
        "        del optimizer\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        print(\"Memory cleared after training.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # If some models didn't get evaluated during training, evaluate them now\n",
        "    evaluator = ModelEvaluator()\n",
        "    for model_name, model in single_models.items():\n",
        "        if model_name not in single_results:\n",
        "            result = evaluator.evaluate_model(model, test_loader, model_name)\n",
        "            single_results[model_name] = result\n",
        "        # Clear memory: delete model\n",
        "        del model\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # Create and evaluate ensembles\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ENSEMBLE ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    ensemble_manager = EnsembleManager(single_models, val_data)\n",
        "    ensemble_results, best_ensemble = ensemble_manager.test_ensemble_combinations()\n",
        "\n",
        "    # Generate visualizations for all ensemble methods\n",
        "    print(\"\\nGenerating visualizations for all ensemble methods...\")\n",
        "    for ensemble_name, ensemble_result in ensemble_results.items():\n",
        "        visualizer.plot_roc_curves(ensemble_result, ensemble_name)\n",
        "        visualizer.plot_confusion_matrix(ensemble_result, ensemble_name)\n",
        "        # Plot F1 scores per class for the ensemble\n",
        "        f1_per_class = f1_score(ensemble_result['true_labels'], ensemble_result['predictions'], average=None)\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        ax.bar(range(Config.NUM_CLASSES), f1_per_class, color='lightgreen', alpha=0.8)\n",
        "        ax.set_xticks(range(Config.NUM_CLASSES))\n",
        "        ax.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right')\n",
        "        ax.set_title(f'F1 Scores per Class - {ensemble_name}', fontsize=14, fontweight='bold', pad=15)\n",
        "        ax.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
        "        ax.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        for i, v in enumerate(f1_per_class):\n",
        "            ax.text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom', fontsize=10)\n",
        "        save_path = f\"{Config.OUTPUT_DIR}/visualizations/{ensemble_name}_f1_per_class.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"F1 scores per class saved: {save_path}\")\n",
        "        # Clear memory: delete ensemble_result\n",
        "        del ensemble_result\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "    # Evaluate best ensemble on test set\n",
        "    if best_ensemble:\n",
        "        ensemble_name, ensemble_result = best_ensemble\n",
        "        ensemble_models = ensemble_result['models']\n",
        "        ensemble_method = ensemble_name.split('_')[-1]\n",
        "        print(f\"\\nEvaluating best ensemble ({ensemble_name}) on test set...\")\n",
        "\n",
        "        test_dataset = FishDataset(test_data[0], test_data[1], DataManager.get_transforms(False))\n",
        "        test_loader_ensemble = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        if ensemble_method == 'learnable_weighted':\n",
        "            ensemble_model = LearnableWeightedEnsemble(\n",
        "                num_models=len(ensemble_models),\n",
        "                num_classes=Config.NUM_CLASSES\n",
        "            ).to(Config.DEVICE)\n",
        "            ensemble_model.load_state_dict(\n",
        "                torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(ensemble_models)}.pt\")\n",
        "            )\n",
        "            ensemble_model.eval()\n",
        "\n",
        "            all_preds = []\n",
        "            all_probs = []\n",
        "            all_labels = []\n",
        "            total_loss = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in test_loader_ensemble:\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    model_probs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        model = single_models[model_name]\n",
        "                        outputs = model(images)\n",
        "                        probs = torch.softmax(outputs, dim=1)\n",
        "                        model_probs.append(probs)\n",
        "                    model_probs = torch.stack(model_probs, dim=1)\n",
        "                    outputs, _ = ensemble_model(model_probs)\n",
        "                    loss = criterion(outputs, labels).item()\n",
        "                    total_loss += loss\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    all_preds.extend(predicted.cpu().numpy())\n",
        "                    all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = accuracy_score(all_labels, all_preds)\n",
        "            f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "            avg_loss = total_loss / len(test_loader_ensemble)\n",
        "\n",
        "            ensemble_results[ensemble_name]['test_accuracy'] = accuracy\n",
        "            ensemble_results[ensemble_name]['test_f1'] = f1\n",
        "            ensemble_results[ensemble_name]['test_loss'] = avg_loss\n",
        "            ensemble_results[ensemble_name]['test_predictions'] = np.array(all_preds)\n",
        "            ensemble_results[ensemble_name]['test_probabilities'] = np.array(all_probs)\n",
        "            ensemble_results[ensemble_name]['test_true_labels'] = np.array(all_labels)\n",
        "\n",
        "            print(f\"Best Ensemble ({ensemble_name}) Test Results:\")\n",
        "            print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "            print(f\"  F1 Score (Macro): {f1:.4f}\")\n",
        "            print(f\"  Loss: {avg_loss:.4f}\")\n",
        "\n",
        "            # Plot best ensemble results\n",
        "            visualizer.plot_roc_curves(ensemble_results[ensemble_name], ensemble_name)\n",
        "            visualizer.plot_confusion_matrix(ensemble_results[ensemble_name], ensemble_name)\n",
        "            # Clear memory: delete ensemble_model and test_loader_ensemble\n",
        "            if ensemble_method == 'learnable_weighted':\n",
        "                del ensemble_model\n",
        "            del test_loader_ensemble\n",
        "            del ensemble_result\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "    # Generate comprehensive visualizations\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"GENERATING COMPREHENSIVE ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Plot overall model comparison\n",
        "    visualizer.plot_model_comparison(single_results, ensemble_results)\n",
        "\n",
        "    # Generate comprehensive report\n",
        "    visualizer.generate_comprehensive_report(single_results, ensemble_results, best_ensemble)\n",
        "\n",
        "    # Generate comparative XAI visualizations\n",
        "    visualizer.plot_comparative_xai(single_models, ensemble_results, test_loader, max_images=2)\n",
        "\n",
        "    # For LRP Grid View\n",
        "    visualizer.plot_lrp_grid(single_models, test_loader)\n",
        "    # Clear memory: delete single_models and test_loader\n",
        "    del single_models\n",
        "    del test_loader\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    results = {\n",
        "        'single_results': {\n",
        "            k: {\n",
        "                kk: vv.cpu().detach().numpy().tolist() if isinstance(vv, torch.Tensor) else\n",
        "                    vv.tolist() if isinstance(vv, np.ndarray) else vv\n",
        "                for kk, vv in v.items()\n",
        "            } for k, v in single_results.items()\n",
        "        },\n",
        "        'ensemble_results': {\n",
        "            k: {\n",
        "                kk: vv.cpu().detach().numpy().tolist() if isinstance(vv, torch.Tensor) else\n",
        "                    vv.tolist() if isinstance(vv, np.ndarray) else vv\n",
        "                for kk, vv in v.items() if not kk.startswith('test_')\n",
        "            } for k, v in ensemble_results.items()\n",
        "        },\n",
        "        'best_ensemble': best_ensemble[0] if best_ensemble else None,\n",
        "        'best_ensemble_f1': best_ensemble[1]['f1'] if best_ensemble else None\n",
        "    }\n",
        "\n",
        "    print(f\"Results saved to {Config.OUTPUT_DIR}/results.json\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nGenerated Files:\")\n",
        "    print(f\"- Misclassified images plots: {Config.OUTPUT_DIR}/visualizations/misclassified_*.png\")  # NEW\n",
        "    print(f\"- Individual model training histories: {Config.OUTPUT_DIR}/visualizations/*_individual_training_history.png\")\n",
        "    print(f\"- Individual model XAI visualizations: {Config.OUTPUT_DIR}/visualizations/*_xai_image_*.png\")\n",
        "    print(f\"- Enhanced confusion matrices: {Config.OUTPUT_DIR}/visualizations/*_enhanced_confusion_matrix.png\")\n",
        "    print(f\"- Enhanced ROC curves: {Config.OUTPUT_DIR}/visualizations/*_enhanced_roc_curves.png\")\n",
        "    print(f\"- Model comparison analysis: {Config.OUTPUT_DIR}/visualizations/enhanced_model_comparison.png\")\n",
        "    print(f\"- Comprehensive report: {Config.OUTPUT_DIR}/visualizations/comprehensive_report.png\")\n",
        "    print(f\"- Comparative XAI: {Config.OUTPUT_DIR}/visualizations/comparative_xai_image_*.png\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXcdgsbTh2ED",
        "outputId": "e38775fd-e16a-4cd8-b734-026b427806cc"
      },
      "id": "eXcdgsbTh2ED",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Aug 29 21:54:55 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  NVIDIA L4                      Off |   00000000:00:03.0 Off |                    0 |\n",
            "| N/A   73C    P0             36W /   72W |    5019MiB /  23034MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            52Gi       1.9Gi        42Gi        16Mi       8.9Gi        50Gi\n",
            "Swap:             0B          0B          0B\n",
            "Starting Fish Species Classification Pipeline...\n",
            "======================================================================\n",
            "Adjusted batch_size: 64, num_workers: 4 (GPU memory: 17.26 GB)\n",
            "Using device: cuda\n",
            "PyTorch version: 2.8.0+cu126\n",
            "Dynamic BATCH_SIZE: 64, DATALOADER_NUM_WORKERS: 4\n",
            "----------------------------------------------------------------------\n",
            "Loading and preprocessing data...\n",
            "Original data shape: (8407, 3, 224, 224)\n",
            "Original class distribution: [3000 1185 2899  370  953]\n",
            "Applying SMOTE for class balancing...\n",
            "Balanced data shape: (15000, 3, 224, 224)\n",
            "Balanced class distribution: [3000 3000 3000 3000 3000]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-08-29 21:55:53,721] A new study created in memory with name: no-name-ceba686f-c887-4b39-b7a0-fa0cb85d0c94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training resnet50...\n",
            "--------------------------------------------------\n",
            "Optimizing hyperparameters for resnet50...\n",
            "\n",
            "Trial 1/7 parameters for resnet50:\n",
            "  lr: 0.0001\n",
            "  weight_decay: 0.0000\n",
            "  dropout: 0.4725\n",
            "  hidden_dim_multiplier: 0.8113\n",
            "  augmentation_strength: heavy\n",
            "  batch_size: 96\n",
            "  optimizer_type: adamw\n",
            "  scheduler_type: cosine\n",
            "  label_smoothing: 0.1192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1 Optuna Epoch 1 completed for Model: resnet50\n",
            "Optuna Epoch 1/10 Summary: TL: 1.254444, VL: 0.846274, TA: 0.5553, VA: 0.8223, VF1: 0.8209\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1 Optuna Epoch 2 completed for Model: resnet50\n",
            "Optuna Epoch 2/10 Summary: TL: 0.959838, VL: 0.608504, TA: 0.7410, VA: 0.9580, VF1: 0.9578\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1 Optuna Epoch 3 completed for Model: resnet50\n",
            "Optuna Epoch 3/10 Summary: TL: 0.834203, VL: 0.559053, TA: 0.8138, VA: 0.9713, VF1: 0.9714\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1 Optuna Epoch 4 completed for Model: resnet50\n",
            "Optuna Epoch 4/10 Summary: TL: 0.764393, VL: 0.520205, TA: 0.8547, VA: 0.9783, VF1: 0.9783\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1 Optuna Epoch 5 completed for Model: resnet50\n",
            "Optuna Epoch 5/10 Summary: TL: 0.719045, VL: 0.515912, TA: 0.8732, VA: 0.9783, VF1: 0.9784\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Optuna Epoch 6/10 Training:  70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 66/94 [00:18<00:07,  3.66it/s, loss=0.6455, acc=0.8924]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd48bb6",
      "metadata": {
        "id": "cdd48bb6"
      },
      "source": [
        "#End"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}