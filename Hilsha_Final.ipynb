{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran012x/Transfer-Models/blob/main/Hilsha_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 1: Colab-Setup\n"
      ],
      "metadata": {
        "id": "k1SaijPsU_az"
      },
      "id": "k1SaijPsU_az"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive_path = '/content/drive'\n",
        "\n",
        "if os.path.exists(drive_path) and os.path.ismount(drive_path):\n",
        "    print(\"Google Drive is already connected ‚úÖ\")\n",
        "else:\n",
        "    drive.mount(drive_path)\n",
        "    print(\"Google Drive connection done ‚úÖ\")\n",
        "\n",
        "\n",
        "# # Upload a file\n",
        "# uploaded = files.upload()\n",
        "# # Get the file name\n",
        "# file_name = list(uploaded.keys())[0]\n",
        "# print(f\"Uploaded file: {file_name}\")\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# # with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_224_11k.zip', 'r') as zip_ref:\n",
        "# #     zip_ref.extractall('')\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo8MKzRhJHqC",
        "outputId": "9ba6d9f0-7654-4093-8b3b-4f994bb2dc87"
      },
      "id": "Bo8MKzRhJHqC",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive is already connected ‚úÖ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 2: Import & Config & Env Setup"
      ],
      "metadata": {
        "id": "HiFbgREXbGzn"
      },
      "id": "HiFbgREXbGzn"
    },
    {
      "cell_type": "code",
      "source": [
        "#1. IMPORTS AND INITIAL SETUP\n",
        "# ================================================================================================================================\n",
        "# Purpose: Import all required libraries and set up warnings to suppress unnecessary messages.\n",
        "\n",
        "\n",
        "\n",
        "!pip install pytorch-gradcam optuna captum -q  # Uncomment if running in a new environment\n",
        "\n",
        "\n",
        "import sys\n",
        "import numpy\n",
        "import pandas\n",
        "import seaborn as sns\n",
        "\n",
        "print(f\"python_version: {sys.version.split()[0]}\")\n",
        "print(f\"numpy_version: {numpy.__version__}\")\n",
        "print(f\"pandas_version: {pandas.__version__}\")\n",
        "print(f\"seaborn_version: {sns.__version__}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Standard Library\n",
        "# ============================================================\n",
        "import os\n",
        "import sys\n",
        "import gc\n",
        "import time\n",
        "import json\n",
        "import zipfile\n",
        "import logging\n",
        "import random\n",
        "import warnings\n",
        "import traceback\n",
        "import logging\n",
        "import subprocess\n",
        "import threading\n",
        "import traceback\n",
        "from pathlib import Path\n",
        "from threading import Lock\n",
        "import multiprocessing as mp\n",
        "from itertools import combinations\n",
        "from datetime import datetime, timedelta\n",
        "from collections import Counter, defaultdict\n",
        "from typing import Tuple, Dict, Any, Optional\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# ============================================================\n",
        "# Data Handling & Utilities\n",
        "# ============================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================\n",
        "# Visualization\n",
        "# ============================================================\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# ============================================================\n",
        "# System & Resource Monitoring\n",
        "# ============================================================\n",
        "import psutil\n",
        "import pynvml\n",
        "\n",
        "# ============================================================\n",
        "# Machine Learning\n",
        "# ============================================================\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, f1_score, accuracy_score,\n",
        "    precision_score, recall_score, roc_curve, auc\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Imbalanced data handling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ============================================================\n",
        "# Deep Learning - PyTorch\n",
        "# ============================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, SubsetRandomSampler\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# ============================================================\n",
        "# Augmentation\n",
        "# ============================================================\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Explainable AI (XAI)\n",
        "# ============================================================\n",
        "\n",
        "import torch.autograd as autograd\n",
        "from captum.attr import LRP\n",
        "\n",
        "# Optuna\n",
        "import optuna\n",
        "import optuna.logging\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Hyperparameter Optimization\n",
        "# ============================================================\n",
        "try:\n",
        "    OPTUNA_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPTUNA_AVAILABLE = False\n",
        "    print(\"Warning: Optuna not available. Using default hyperparameters.\")\n",
        "\n",
        "\n",
        "\n",
        "#For DeprecationWarning / FutureWarning specifically:\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
        "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Hide all pip warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "\n",
        "# ---\n",
        "# 2. CONFIGURATION\n",
        "# ================================================================================================================================\n",
        "# Purpose: Define configuration settings and initialize the environment.\n",
        "\n",
        "class Config:\n",
        "\n",
        "\n",
        "    OUTPUT_DIR = '/content/drive/MyDrive/Hilsha'\n",
        "\n",
        "    # Dataset parameters\n",
        "    NUM_CLASSES = 5\n",
        "    CLASS_NAMES = ['Ilish', 'Chandana', 'Sardin', 'Sardinella', 'Punctatus']\n",
        "    INPUT_SIZE = 224\n",
        "\n",
        "    # Training parameters\n",
        "    BATCH_SIZE = 32 #Will Change Dynamically\n",
        "    DATALOADER_NUM_WORKERS = 1 #Will Change Dynamically\n",
        "    # Dynamically adjust batch size and workers\n",
        "    EPOCHS = 40\n",
        "    PIN_MEMORY = True\n",
        "    USE_MIXED_PRECISION = True #True\n",
        "    COMPILE_MODEL = True\n",
        "    PATIENCE = 4\n",
        "    LEARNING_RATE = 1e-5\n",
        "    WEIGHT_DECAY = 1e-4\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    OPTUNA_TRIALS = 100\n",
        "    OPTUNA_EPOCHS = 10\n",
        "\n",
        "    # Models to train\n",
        "    # MODELS = ['resnet50','efficientnet_b0','mobilenet_v3_large','vgg16', 'densenet121']\n",
        "    MODELS = [\n",
        "        'resnet50',\n",
        "        'efficientnet_b0'\n",
        "        # # 'mobilenet_v3_large',\n",
        "        # 'vgg16',\n",
        "        # 'densenet121',\n",
        "        # 'inception_v3',\n",
        "        # 'vit_b_16',\n",
        "        # 'convnext_base',\n",
        "        # 'regnet_y_32gf'\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Ensemble methods\n",
        "    ENSEMBLE_METHODS = ['simple_average', 'weighted_average', 'confidence_based', 'learnable_weighted']\n",
        "\n",
        "    # Device\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    SEED = 42\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"Setup random seeds, directories, and dynamically adjust batch size and workers\"\"\"\n",
        "\n",
        "    os.environ['PYTHONHASHSEED'] = str(Config.SEED)  # For hash seed reproducibility\n",
        "    random.seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    torch.cuda.manual_seed_all(Config.SEED)  # For multi-GPU if applicable\n",
        "    #Guard for GPU determinism (optional, but helpful if you want exact reproducibility across runs):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "\n",
        "    directories = [\n",
        "        Config.OUTPUT_DIR,\n",
        "        f\"{Config.OUTPUT_DIR}/models\",\n",
        "        f\"{Config.OUTPUT_DIR}/visualizations\",\n",
        "        f\"{Config.OUTPUT_DIR}/reports\",\n",
        "        f\"{Config.OUTPUT_DIR}/xai_visualizations\"\n",
        "    ]\n",
        "\n",
        "    for directory in directories:\n",
        "        Path(directory).mkdir(parents=True, exist_ok=True)#With exist_ok=True:Python will not raise an error if already exists.Or else raise a FileExistsError\n",
        "        #& parents=True ‚Üí creates all missing parent directories in the path.\n",
        "\n",
        "    # Ensure all output directories exist\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/best_model\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/model_results\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/kfold_results\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/visualizations\", exist_ok=True)\n",
        "\n",
        "    print(f\"Using device: {Config.DEVICE}\")\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"Dynamic BATCH_SIZE: {Config.BATCH_SIZE}, DATALOADER_NUM_WORKERS: {Config.DATALOADER_NUM_WORKERS}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    seed = Config.SEED + worker_id\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tVhsrE2bL5w",
        "outputId": "48bda274-4753-4244-a67b-8bb2208c2237"
      },
      "id": "5tVhsrE2bL5w",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python_version: 3.12.11\n",
            "numpy_version: 1.26.4\n",
            "pandas_version: 2.2.2\n",
            "seaborn_version: 0.13.2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 3: Pre-processing & Save"
      ],
      "metadata": {
        "id": "M9g_LvnMZ1Rs"
      },
      "id": "M9g_LvnMZ1Rs"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Check GPU availability\n",
        "# print(\"GPU Available:\", torch.cuda.is_available())\n",
        "# print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "\n",
        "# # Define fish classes and dataset paths\n",
        "# fish_classes = ['ilish', 'chandana', 'sardin', 'sardinella', 'punctatus'] #0,1,2,3,4\n",
        "# zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip').extractall('/content/.hidden_fish')\n",
        "# data_dir = '/content/.hidden_fish'\n",
        "\n",
        "# image_limits = {\n",
        "#     'ilish': 3000,\n",
        "#     'chandana': 1185,\n",
        "#     'sardin': 2899,\n",
        "#     'sardinella': 370,\n",
        "#     'punctatus': 953\n",
        "# }\n",
        "\n",
        "# # Settings\n",
        "# total_images = sum(image_limits.values())\n",
        "# batch_size = 100\n",
        "# num_threads = 4\n",
        "\n",
        "\n",
        "# # Output paths\n",
        "# output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "# labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "# xdata_file = os.path.join(output_dir, 'X_data.npy')\n",
        "\n",
        "# save_lock = threading.Lock()  # for thread-safe writes -> Prevents race conditions when multiple threads write to the same list.\n",
        "\n",
        "# # Function to gather image paths\n",
        "# def get_image_paths(class_name, max_images):\n",
        "#     path = os.path.join(data_dir, class_name)\n",
        "#     files = sorted(os.listdir(path))\n",
        "#     random.shuffle(files)\n",
        "#     return [os.path.join(path, f) for f in files[:max_images]]\n",
        "\n",
        "# # Load and preprocess batch\n",
        "# def load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     end_idx = min(start_idx + batch_size, len(image_paths))\n",
        "#     batch_paths = image_paths[start_idx:end_idx]\n",
        "#     batch_images = []\n",
        "\n",
        "#     for img_path in batch_paths:\n",
        "#         img = Image.open(img_path).resize((224, 224)).convert('RGB')\n",
        "#         img_tensor = torch.tensor(np.array(img), dtype=torch.uint8).permute(2, 0, 1)  # C x H x W\n",
        "#         batch_images.append(img_tensor)\n",
        "\n",
        "#     batch_tensor = torch.stack(batch_images)  # B x C x H x W\n",
        "#     batch_labels = np.full((len(batch_images),), class_idx, dtype=np.int32)\n",
        "#     return batch_tensor, batch_labels\n",
        "\n",
        "# # Process one batch and return tensors & labels (no file saving)\n",
        "# def process_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     return load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx)\n",
        "\n",
        "# def preprocess_and_save_all(overwrite=True):\n",
        "#     if os.path.exists(labels_file) and os.path.exists(xdata_file) and not overwrite:\n",
        "#         print(\"Preprocessed data already exists. Set overwrite=True to reprocess.\")\n",
        "#         return\n",
        "\n",
        "#     all_images = []\n",
        "#     all_labels = []\n",
        "#     processed_count = 0\n",
        "\n",
        "#     for idx, class_name in enumerate(fish_classes):\n",
        "#         print(f\"\\nProcessing class: {class_name}\")\n",
        "#         image_paths = get_image_paths(class_name, image_limits[class_name])\n",
        "#         total_batches = (len(image_paths) + batch_size - 1) // batch_size\n",
        "#         #It ensures ceiling division ‚Äî rounding up, not down.\n",
        "#         # Normal division: 103 / 20 = 5.15 ‚Üí floor division // 20 = 5 (‚ùå missing last 3 images)\n",
        "#         # This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ‚úÖ\n",
        "\n",
        "#         with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "#             futures = []\n",
        "#             for start in range(0, len(image_paths), batch_size):\n",
        "#                 futures.append(executor.submit(process_batch, image_paths, start, batch_size, idx))\n",
        "\n",
        "#             for future in tqdm(as_completed(futures), total=total_batches, desc=class_name):#taqaddum (ÿ™ŸÇÿØŸëŸÖ) ‚Äì Arabic for \"progress\".\n",
        "#                 # futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\n",
        "#                 # as_completed(futures): Yields each future as it finishes (not in order).\n",
        "\n",
        "#                 batch_tensor, batch_labels = future.result()\n",
        "#                 with save_lock: #Locks this section so that only one thread can update the shared lists safely.\n",
        "#                     all_images.append(batch_tensor)\n",
        "#                     all_labels.append(batch_labels)\n",
        "#                     processed_count += batch_tensor.size(0)\n",
        "#                     print(f\"Processed batch with {batch_tensor.size(0)} images, total processed: {processed_count}/{total_images}\")\n",
        "#                 gc.collect()\n",
        "\n",
        "#     # Combine all tensors and labels\n",
        "#     X = torch.cat(all_images, dim=0).numpy()\n",
        "#     Y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "#     # Save final arrays\n",
        "#     np.save(xdata_file, X, allow_pickle=False)#Malicious .npy -> import os;os.system(\"rm -rf /\")  # ‚Üê Dangerous command\n",
        "#     np.save(labels_file, Y, allow_pickle=False)\n",
        "\n",
        "#     print(f\"\\n‚úÖ Done! Saved {processed_count} images in {xdata_file}\")\n",
        "#     print(f\"X_data shape: {X.shape}, Y_labels shape: {Y.shape}\")\n",
        "\n",
        "#     if processed_count != total_images:\n",
        "#         raise ValueError(f\"Expected {total_images} images, but processed {processed_count}\")\n",
        "\n",
        "# # Run preprocessing and save directly to X_data.npy and Y_labels.npy\n",
        "# preprocess_and_save_all(overwrite=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class FishDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "\n",
        "        self.images = self._preprocess_images(images)\n",
        "        self.labels = labels.astype(np.int64)\n",
        "        self.transform = transform #Here means: Medium,Heavy or Any\n",
        "\n",
        "    def _preprocess_images(self, images):\n",
        "        \"\"\"Preprocess images to ensure proper format and normalization\"\"\"\n",
        "        if images.max() > 1.5: #üëâ The threshold 1.5 is just a safe cutoff to distinguish between the two cases.\n",
        "            #Because some normalized images can have values slightly above 1.0 (e.g., after augmentations, rounding, or scaling bugs).\n",
        "            images = images.astype(np.float32) / 255.0\n",
        "\n",
        "        if len(images.shape) == 4 and images.shape[1] == 3: #If input is (batch, channels, height, width) ‚Üí convert to (batch, height, width, channels) (common for TensorFlow).\n",
        "            images = np.transpose(images, (0, 2, 3, 1))\n",
        "        return images.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the total number of samples in the dataset\"\"\"\n",
        "        return len(self.images)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:  #Applies an Albumentations transform pipeline (it returns a dict, so you take ['image']).\n",
        "            image = self.transform(image=image)['image'] #\n",
        "        else:\n",
        "            image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "        #With transform ‚Üí advanced augmentations.\n",
        "        #Without transform ‚Üí just convert to PyTorch format.\n",
        "\n",
        "\n",
        "        # Convert label to plain Python int to avoid CUDA tensor creation in workers.That wastes memory and slows down training.\n",
        "        if isinstance(label, np.ndarray):\n",
        "            label = int(label.item())\n",
        "        elif hasattr(label, 'item'):\n",
        "            label = int(label.item())\n",
        "        else:\n",
        "            label = int(label)\n",
        "\n",
        "\n",
        "        return image, label  # Plain Python int, not torch.tensor\n",
        "        # return image, torch.tensor(int(label), dtype=torch.long)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def __getitem__(self, idx):\n",
        "    #     image = self.images[idx]  # H x W x C\n",
        "    #     label = self.labels[idx]\n",
        "\n",
        "    #     # Ensure image has 3 channels\n",
        "    #     if image.ndim == 2:  # grayscale H x W\n",
        "    #         image = np.stack([image]*3, axis=-1)\n",
        "    #     elif image.shape[-1] == 4:  # RGBA\n",
        "    #         image = image[:, :, :3]\n",
        "\n",
        "    #     # Apply Albumentations transform if any\n",
        "    #     if self.transform:\n",
        "    #         image = self.transform(image=image)['image']  # may already be tensor\n",
        "\n",
        "    #     # Convert to PyTorch tensor C x H x W if it's a numpy array\n",
        "    #     if isinstance(image, np.ndarray):\n",
        "    #         image = torch.from_numpy(image).permute(2, 0, 1).float()\n",
        "    #     elif isinstance(image, torch.Tensor) and image.ndim == 3 and image.shape[0] != 3:\n",
        "    #         # If transform returns H x W x C tensor, permute to C x H x W\n",
        "    #         image = image.permute(2, 0, 1).float()\n",
        "    #     # else assume it's already C x H x W\n",
        "\n",
        "    #     # Convert label to tensor\n",
        "    #     label = int(label) if not isinstance(label, torch.Tensor) else label.long()\n",
        "\n",
        "    #     return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # class MyClass:\n",
        "        #     def greet(self):\n",
        "        #         print(\"Hello!\")\n",
        "        # obj = MyClass()\n",
        "        # print(hasattr(obj, 'greet'))   # True, because obj has a method greet\n",
        "        # print(hasattr(obj, 'name'))    # False, no attribute called name\n",
        "        # # Using hasattr with .item()\n",
        "        # import torch\n",
        "        # x = torch.tensor(5)  # scalar tensor\n",
        "        # print(hasattr(x, 'item'))      # True\n",
        "        # print(x.item())                # 5\n",
        "\n",
        "        # return image, torch.tensor(label, dtype=torch.long)  # <-- ensure label is tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DataManager:\n",
        "    @staticmethod  #In Python, @staticmethod is used to define a method that belongs to a class but doesn‚Äôt access self or cls.\n",
        "\n",
        "    # class DataManager:\n",
        "    # staticmethod\n",
        "    # def greet(name):\n",
        "    #     return f\"Hello, {name}!\"\n",
        "    # # Call without creating an instance\n",
        "    # print(DataManager.greet(\"Imran\"))  # Output: Hello, Imran!\n",
        "    # # Call with an instance\n",
        "    # dm = DataManager()\n",
        "    # print(dm.greet(\"Imran\"))           # Output: Hello, Imran!\n",
        "\n",
        "    # class MyClass:\n",
        "    #     count = 0\n",
        "\n",
        "    #     staticmethod\n",
        "    #     def greet(name):\n",
        "    #         return f\"Hello, {name}!\"\n",
        "\n",
        "    #     classmethod\n",
        "    #     def increment_count(cls):\n",
        "    #         cls.count += 1\n",
        "    #         return cls.count\n",
        "\n",
        "    # # Static method\n",
        "    # print(MyClass.greet(\"Imran\"))      # Hello, Imran!\n",
        "    # # Class method\n",
        "    # print(MyClass.increment_count())   # 1\n",
        "    # print(MyClass.increment_count())   # 2\n",
        "    #Static method ‚Üí independent of class/instance.\n",
        "    #Class method ‚Üí works with the class itself (cls), can modify class variables.\n",
        "\n",
        "\n",
        "    def get_transforms(is_training=True, augmentation_strength='medium'):\n",
        "        \"\"\"Get data transforms with configurable augmentation strength\"\"\"\n",
        "        if is_training:\n",
        "            if augmentation_strength == 'light':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.3),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            elif augmentation_strength == 'heavy':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.7),\n",
        "                    A.VerticalFlip(p=0.5),\n",
        "                    A.RandomRotate90(p=0.7),\n",
        "                    # A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, p=0.8),\n",
        "                    # A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.8),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
        "                    # A.HueSaturationValue(hue_shift_limit=30, sat_shift_limit=40, val_shift_limit=30, p=0.7),\n",
        "                    A.GaussianBlur(blur_limit=(3, 9), p=0.5),\n",
        "                    A.GaussNoise(var_limit=(10.0, 80.0), p=0.4),\n",
        "                    A.CoarseDropout(max_holes=12, max_height=25, max_width=25, p=0.5),\n",
        "                    A.ElasticTransform(p=0.3),\n",
        "                    A.GridDistortion(p=0.3),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "                    A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3, p=0.3),\n",
        "                    A.RandomRain(blur_value=3, p=0.2),\n",
        "                    A.ColorJitter(hue=0.1, p=0.5),\n",
        "\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            else:  # medium\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.5),\n",
        "                    A.VerticalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.5),\n",
        "                    # A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.7),\n",
        "                    # A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.1),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
        "                    # A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.6),\n",
        "                    A.GaussianBlur(blur_limit=(3, 7), p=0.4),\n",
        "                    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "                    A.CoarseDropout(max_holes=8, max_height=20, max_width=20, p=0.4),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "        else:\n",
        "            return A.Compose([\n",
        "                A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def load_and_balance_data():\n",
        "        \"\"\"Load data and apply SMOTE\"\"\"\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "\n",
        "        # # Check GPU availability\n",
        "        # print(\"GPU Available:\", torch.cuda.is_available())\n",
        "        # print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "\n",
        "        # # Define fish classes and dataset paths\n",
        "        # fish_classes = ['ilish', 'chandana', 'sardin', 'sardinella', 'punctatus'] #0,1,2,3,4\n",
        "        # zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip').extractall('/content/.hidden_fish')\n",
        "        # data_dir = '/content/.hidden_fish'\n",
        "\n",
        "        # image_limits = {\n",
        "        #     'ilish': 3000,\n",
        "        #     'chandana': 1185,\n",
        "        #     'sardin': 2899,\n",
        "        #     'sardinella': 370,\n",
        "        #     'punctatus': 953\n",
        "        # }\n",
        "\n",
        "        # # Settings\n",
        "        # total_images = sum(image_limits.values())\n",
        "        # batch_size = 100\n",
        "        # num_threads = 4\n",
        "\n",
        "\n",
        "        # # Output paths\n",
        "        # output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "        # os.makedirs(output_dir, exist_ok=True)\n",
        "        # labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "        # xdata_file = os.path.join(output_dir, 'X_data.npy')\n",
        "\n",
        "        # save_lock = threading.Lock()  # for thread-safe writes -> Prevents race conditions when multiple threads write to the same list.\n",
        "\n",
        "        # # Function to gather image paths\n",
        "        # def get_image_paths(class_name, max_images):\n",
        "        #     path = os.path.join(data_dir, class_name)\n",
        "        #     files = sorted(os.listdir(path))\n",
        "        #     random.shuffle(files)\n",
        "        #     return [os.path.join(path, f) for f in files[:max_images]]\n",
        "\n",
        "        # # Load and preprocess batch\n",
        "        # def load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "        #     end_idx = min(start_idx + batch_size, len(image_paths))\n",
        "        #     batch_paths = image_paths[start_idx:end_idx]\n",
        "        #     batch_images = []\n",
        "\n",
        "        #     for img_path in batch_paths:\n",
        "        #         img = Image.open(img_path).resize((224, 224)).convert('RGB')\n",
        "        #         img_tensor = torch.tensor(np.array(img), dtype=torch.uint8).permute(2, 0, 1)  # C x H x W\n",
        "        #         batch_images.append(img_tensor)\n",
        "\n",
        "        #     batch_tensor = torch.stack(batch_images)  # B x C x H x W\n",
        "        #     batch_labels = np.full((len(batch_images),), class_idx, dtype=np.int32)\n",
        "        #     return batch_tensor, batch_labels\n",
        "\n",
        "        # # Process one batch and return tensors & labels (no file saving)\n",
        "        # def process_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "        #     return load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx)\n",
        "\n",
        "        # def preprocess_and_save_all(overwrite=True):\n",
        "        #     if os.path.exists(labels_file) and os.path.exists(xdata_file) and not overwrite:\n",
        "        #         print(\"Preprocessed data already exists. Set overwrite=True to reprocess.\")\n",
        "        #         return\n",
        "\n",
        "        #     all_images = []\n",
        "        #     all_labels = []\n",
        "        #     processed_count = 0\n",
        "\n",
        "        #     for idx, class_name in enumerate(fish_classes):\n",
        "        #         print(f\"\\nProcessing class: {class_name}\")\n",
        "        #         image_paths = get_image_paths(class_name, image_limits[class_name])\n",
        "        #         total_batches = (len(image_paths) + batch_size - 1) // batch_size\n",
        "        #         #It ensures ceiling division ‚Äî rounding up, not down.\n",
        "        #         # Normal division: 103 / 20 = 5.15 ‚Üí floor division // 20 = 5 (‚ùå missing last 3 images)\n",
        "        #         # This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ‚úÖ\n",
        "\n",
        "        #         with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "        #             futures = []\n",
        "        #             for start in range(0, len(image_paths), batch_size):\n",
        "        #                 futures.append(executor.submit(process_batch, image_paths, start, batch_size, idx))\n",
        "\n",
        "        #             for future in tqdm(as_completed(futures), total=total_batches, desc=class_name):#taqaddum (ÿ™ŸÇÿØŸëŸÖ) ‚Äì Arabic for \"progress\".\n",
        "        #                 # futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\n",
        "        #                 # as_completed(futures): Yields each future as it finishes (not in order).\n",
        "\n",
        "        #                 batch_tensor, batch_labels = future.result()\n",
        "        #                 with save_lock: #Locks this section so that only one thread can update the shared lists safely.\n",
        "        #                     all_images.append(batch_tensor)\n",
        "        #                     all_labels.append(batch_labels)\n",
        "        #                     processed_count += batch_tensor.size(0)\n",
        "        #                     print(f\"Processed batch with {batch_tensor.size(0)} images, total processed: {processed_count}/{total_images}\")\n",
        "        #                 gc.collect()\n",
        "\n",
        "        #     # Combine all tensors and labels\n",
        "        #     X = torch.cat(all_images, dim=0).numpy()\n",
        "        #     Y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "        #     # Save final arrays\n",
        "        #     np.save(xdata_file, X, allow_pickle=False)#Malicious .npy -> import os;os.system(\"rm -rf /\")  # ‚Üê Dangerous command\n",
        "        #     np.save(labels_file, Y, allow_pickle=False)\n",
        "\n",
        "        #     print(f\"\\n‚úÖ Done! Saved {processed_count} images in {xdata_file}\")\n",
        "        #     print(f\"X_data shape: {X.shape}, Y_labels shape: {Y.shape}\")\n",
        "\n",
        "        #     if processed_count != total_images:\n",
        "        #         raise ValueError(f\"Expected {total_images} images, but processed {processed_count}\")\n",
        "\n",
        "        # # Run preprocessing and save directly to X_data.npy and Y_labels.npy\n",
        "        # preprocess_and_save_all(overwrite=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # X = np.load(Config.DATA_FILE)\n",
        "        # Y = np.load(Config.LABELS_FILE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # # Your data path\n",
        "        # output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "        # data_file = os.path.join(output_dir, 'X_data.npy')\n",
        "        # labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "\n",
        "        # # Readable size format\n",
        "        # def sizeof_fmt(num, suffix='B'):\n",
        "        #     for unit in ['', 'K', 'M', 'G', 'T']:\n",
        "        #         if abs(num) < 1024.0:\n",
        "        #             return f\"{num:3.2f} {unit}{suffix}\"\n",
        "        #         num /= 1024.0\n",
        "        #     return f\"{num:.2f} T{suffix}\"\n",
        "\n",
        "        # # Main loader\n",
        "        # def load_preprocessed_data(as_torch=True, normalize=True, to_device=None):\n",
        "        #     # Check file existence #cpu,cuda (CUDA stands for Compute Unified Device Architecture.)\n",
        "        #     for path in [data_file, labels_file]:\n",
        "        #         if not os.path.exists(path):\n",
        "        #             raise FileNotFoundError(f\"Missing: {path}\")\n",
        "\n",
        "        #     # Print file sizes\n",
        "        #     print(f\"üìÅ X_data.npy: {sizeof_fmt(os.path.getsize(data_file))}\")\n",
        "        #     print(f\"üìÅ Y_labels.npy: {sizeof_fmt(os.path.getsize(labels_file))}\")\n",
        "\n",
        "        #     # Load with mmap\n",
        "        #     X = np.load(data_file, mmap_mode='r')\n",
        "        #     Y = np.load(labels_file, mmap_mode='r')\n",
        "\n",
        "        #     print(f\"‚úÖ X shape: {X.shape}, dtype: {X.dtype}\")\n",
        "        #     print(f\"‚úÖ Y shape: {Y.shape}, dtype: {Y.dtype}\")\n",
        "\n",
        "        #     # Sanity check\n",
        "        #     if len(X) != len(Y):\n",
        "        #         raise ValueError(\"Mismatch between number of samples in X and Y\")\n",
        "\n",
        "        #     # Convert to torch\n",
        "        #     if as_torch:\n",
        "        #         X = torch.from_numpy(X)\n",
        "        #         Y = torch.from_numpy(Y)\n",
        "\n",
        "        #         if normalize and X.dtype == torch.uint8:\n",
        "        #             X = X.float() / 255.0\n",
        "\n",
        "        #         if to_device:\n",
        "        #             X = X.to(to_device)\n",
        "        #             Y = Y.to(to_device)\n",
        "\n",
        "        #         print(f\"üß† Torch tensors ready on {to_device or 'CPU'}\")\n",
        "\n",
        "        #     return X, Y\n",
        "\n",
        "        # # üîÅ Example call\n",
        "        # X, Y = load_preprocessed_data(\n",
        "        #     as_torch=True,\n",
        "        #     normalize=True,\n",
        "        #     to_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        # )\n",
        "\n",
        "        # print(f\"\\nOriginal data shape: {X.shape}\")\n",
        "        # # print(f\"Original class distribution: {np.bincount(Y)}\")\n",
        "        # class_dist = np.bincount(Y.cpu().numpy()) if torch.is_tensor(Y) else np.bincount(Y)\n",
        "        # print(f\"Original class distribution: {class_dist}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # print(\"Applying SMOTE for class balancing...\")\n",
        "        # X_flat = X.reshape(X.shape[0], -1)\n",
        "        # smote = SMOTE(random_state=Config.SEED, k_neighbors=min(5, np.bincount(Y).min()-1))\n",
        "        # X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y)\n",
        "        # X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "        # print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        # print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "        # return X_balanced, Y_balanced\n",
        "\n",
        "\n",
        "\n",
        "        # Remove SMOTE completely and use WeightedRandomSampler only\n",
        "        # Using WeightedRandomSampler instead of SMOTE\n",
        "        # Compute weights and create sampler during DataLoader, not here\n",
        "        # return X, Y\n",
        "        # # Example data\n",
        "        # X = torch.randn(100, 3, 32, 32)  # 100 images\n",
        "        # Y = torch.randint(0, 5, (100,))  # 5 classes, imbalanced\n",
        "        # # Compute class weights\n",
        "        # class_counts = torch.bincount(Y)\n",
        "        # class_weights = 1.0 / class_counts.float()\n",
        "        # sample_weights = class_weights[Y]  # assign weight to each sample\n",
        "        # # Create sampler\n",
        "        # sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "        # # Create DataLoader\n",
        "        # dataset = TensorDataset(X, Y)\n",
        "        # loader = DataLoader(dataset, batch_size=16, sampler=sampler)\n",
        "\n",
        "\n",
        "\n",
        "        print(\"Applying SMOTE for class balancing...\")\n",
        "        # Apply SMOTE with reduced k_neighbors and combine with WeightedRandomSampler\n",
        "        X_flat = X.reshape(X.shape[0], -1)\n",
        "        smote = SMOTE(random_state=Config.SEED, k_neighbors=3, sampling_strategy='not majority')\n",
        "        # smote = SMOTE(random_state=Config.SEED, k_neighbors=2, sampling_strategy= 'auto')\n",
        "        X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y)\n",
        "        X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "        # Ensures WeightedRandomSampler is still used in DataLoader\n",
        "        print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "        return X_balanced, Y_balanced\n",
        "        # Benefit: Using a smaller k_neighbors=3 reduces the risk of generating unnatural\n",
        "        # image artifacts, while sampling_strategy='not majority' balances classes more conservatively.\n",
        "        # Retaining WeightedRandomSampler in the DataLoader further ensures balanced sampling during\n",
        "        # training, maintaining smoothness and preventing accuracy drops by avoiding over-reliance\n",
        "        # on SMOTE-generated samples.\n",
        "\n",
        "\n",
        "\n",
        "        # print(\"Applying SMOTE for class balancing...\")\n",
        "\n",
        "        # X_flat = X.cpu().numpy().reshape(X.shape[0], -1) if torch.is_tensor(X) else X.reshape(X.shape[0], -1)\n",
        "        # Y_np = Y.cpu().numpy() if torch.is_tensor(Y) else Y\n",
        "\n",
        "        # smote = SMOTE(random_state=Config.SEED, k_neighbors=3, sampling_strategy='not majority')\n",
        "        # X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y_np)\n",
        "        # X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "\n",
        "        # print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        # print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "        # return X_balanced, Y_balanced\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def create_data_loaders(X, Y, test_size=0.2, batch_size=None, augmentation_strength='medium'):\n",
        "\n",
        "\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(X, Y, test_size=test_size, random_state=Config.SEED, stratify=Y)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=Config.SEED, stratify=y_temp)\n",
        "\n",
        "        print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "        print(f\"Using optimized batch size: {batch_size}\")\n",
        "\n",
        "\n",
        "\n",
        "        train_dataset = FishDataset(X_train, y_train,DataManager.get_transforms(True, augmentation_strength))\n",
        "        val_dataset = FishDataset(X_val, y_val, DataManager.get_transforms(False))\n",
        "        test_dataset = FishDataset(X_test, y_test, DataManager.get_transforms(False))\n",
        "\n",
        "\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "        #compute_class_weight('balanced', ...) gives higher weight to minority classes.\n",
        "        sample_weights = [class_weights[y] for y in y_train]\n",
        "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "        # Samples with higher weights are more likely to be picked in each batch.\n",
        "        # replacement=True allows oversampling of minority classes. ‚úÖ\n",
        "\n",
        "\n",
        "        # Conditionally set prefetch_factor based on num_workers\n",
        "        prefetch_factor = 2 if Config.DATALOADER_NUM_WORKERS > 0 else None\n",
        "        pin_memory=Config.PIN_MEMORY if 'cuda' in Config.DEVICE else False\n",
        "        num_workers = Config.DATALOADER_NUM_WORKERS if torch.cuda.is_available() else 0\n",
        "        use_prefetch = num_workers > 0\n",
        "\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            # sampler=sampler, #Imbalanced dataset ‚Üí use sampler.Balanced dataset ‚Üí use shuffle=True.\n",
        "            shuffle=True,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "            # persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            # persistent_workers=False,\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "            # persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            # persistent_workers=False,\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "            # persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            # persistent_workers=False, #False is slow but exact reproductivity ensures & workers reset each epoch).\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "\n",
        "        return train_loader, val_loader, test_loader, (X_val, y_val), (X_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "-UojpedIZ-Ra"
      },
      "id": "-UojpedIZ-Ra",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 4: Loading"
      ],
      "metadata": {
        "id": "MIZ9EajaYfPQ"
      },
      "id": "MIZ9EajaYfPQ"
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FILE = '/content/drive/MyDrive/Hilsha/X_data.npy'\n",
        "LABEL_FILE = '/content/drive/MyDrive/Hilsha/Y_labels.npy'\n",
        "\n",
        "\n",
        "X = np.load(DATA_FILE)\n",
        "Y = np.load(LABEL_FILE)"
      ],
      "metadata": {
        "id": "EItOc1z5MANu"
      },
      "id": "EItOc1z5MANu",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 5:Data Visualization [From Processed Image]\n"
      ],
      "metadata": {
        "id": "xz03W0wETvEH"
      },
      "id": "xz03W0wETvEH"
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import pandas as pd\n",
        "# from collections import Counter\n",
        "# import os\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.manifold import TSNE\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# # Scientific plotting setup\n",
        "# plt.style.use('seaborn-v0_8')\n",
        "# sns.set_palette(\"husl\")\n",
        "# plt.rcParams['figure.dpi'] = 300\n",
        "# plt.rcParams['savefig.dpi'] = 300\n",
        "# plt.rcParams['font.size'] = 12\n",
        "# plt.rcParams['axes.titlesize'] = 14\n",
        "# plt.rcParams['axes.labelsize'] = 12\n",
        "# plt.rcParams['xtick.labelsize'] = 10\n",
        "# plt.rcParams['ytick.labelsize'] = 10\n",
        "# plt.rcParams['legend.fontsize'] = 10\n",
        "# plt.rcParams['figure.titlesize'] = 16\n",
        "\n",
        "# class FishDatasetNumpyAnalyzer:\n",
        "#     \"\"\"Comprehensive analysis suite for fish species dataset from NumPy arrays\"\"\"\n",
        "\n",
        "#     def __init__(self, X_data, Y_labels, output_dir='./fish_classification_results'):\n",
        "#         self.X_data = X_data\n",
        "#         self.Y_labels = Y_labels\n",
        "#         self.output_dir = output_dir\n",
        "#         self.create_output_dirs()\n",
        "\n",
        "#         # Dataset metadata\n",
        "#         self.n_samples = X_data.shape[0]\n",
        "#         self.image_shape = X_data.shape[1:]\n",
        "#         self.unique_labels = np.unique(Y_labels)\n",
        "#         self.n_classes = len(self.unique_labels)\n",
        "\n",
        "#         # Determine image format (channels first vs channels last)\n",
        "#         self.channels_first = self._detect_channels_first()\n",
        "\n",
        "#         # Create label mapping if labels are numeric\n",
        "#         if np.issubdtype(Y_labels.dtype, np.number):\n",
        "#             self.label_names = [f\"Species_{i}\" for i in self.unique_labels]\n",
        "#             self.label_to_name = dict(zip(self.unique_labels, self.label_names))\n",
        "#         else:\n",
        "#             self.label_names = self.unique_labels.tolist()\n",
        "#             self.label_to_name = dict(zip(self.unique_labels, self.label_names))\n",
        "\n",
        "#         print(f\"Dataset loaded: {self.n_samples} samples, {self.n_classes} classes\")\n",
        "#         print(f\"Image shape: {self.image_shape}\")\n",
        "#         print(f\"Data type: {X_data.dtype}\")\n",
        "#         print(f\"Channels first format: {self.channels_first}\")\n",
        "\n",
        "#     def _detect_channels_first(self):\n",
        "#         \"\"\"Detect if images are in channels-first format\"\"\"\n",
        "#         if len(self.image_shape) == 3:\n",
        "#             # If first dimension is small (1-4), likely channels first\n",
        "#             # If last dimension is small (1-4), likely channels last\n",
        "#             if self.image_shape[0] <= 4 and self.image_shape[0] < min(self.image_shape[1], self.image_shape[2]):\n",
        "#                 return True\n",
        "#             elif self.image_shape[2] <= 4 and self.image_shape[2] < min(self.image_shape[0], self.image_shape[1]):\n",
        "#                 return False\n",
        "#             else:\n",
        "#                 # Default assumption based on common formats\n",
        "#                 return self.image_shape[0] <= 4\n",
        "#         return False\n",
        "\n",
        "#     def _prepare_image_for_display(self, img):\n",
        "#         \"\"\"Convert image to proper format for matplotlib display\"\"\"\n",
        "#         if len(img.shape) == 3:\n",
        "#             if self.channels_first:\n",
        "#                 # Convert from (C, H, W) to (H, W, C)\n",
        "#                 img = np.transpose(img, (1, 2, 0))\n",
        "\n",
        "#             # Handle different channel counts\n",
        "#             if img.shape[2] == 1:  # Grayscale with channel dimension\n",
        "#                 img = img.squeeze(axis=2)\n",
        "#                 return img, 'gray'\n",
        "#             elif img.shape[2] == 3:  # RGB\n",
        "#                 return img, None\n",
        "#             elif img.shape[2] == 4:  # RGBA\n",
        "#                 return img[:, :, :3], None  # Drop alpha channel\n",
        "#             else:\n",
        "#                 # Multi-channel, use first channel as grayscale\n",
        "#                 return img[:, :, 0], 'gray'\n",
        "#         else:  # 2D grayscale\n",
        "#             return img, 'gray'\n",
        "\n",
        "#     def create_output_dirs(self):\n",
        "#         \"\"\"Create organized output directory structure\"\"\"\n",
        "#         dirs = [\n",
        "#             self.output_dir,\n",
        "#             f\"{self.output_dir}/figures\",\n",
        "#             f\"{self.output_dir}/statistics\",\n",
        "#             f\"{self.output_dir}/sample_images\",\n",
        "#             f\"{self.output_dir}/reports\"\n",
        "#         ]\n",
        "#         for dir_path in dirs:\n",
        "#             os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "#     def analyze_data_properties(self):\n",
        "#         \"\"\"Analyze basic properties of the loaded data\"\"\"\n",
        "#         print(\"Analyzing data properties...\")\n",
        "\n",
        "#         properties = {\n",
        "#             'dataset_size': self.n_samples,\n",
        "#             'n_classes': self.n_classes,\n",
        "#             'image_shape': self.image_shape,\n",
        "#             'channels_first': self.channels_first,\n",
        "#             'data_type': str(self.X_data.dtype),\n",
        "#             'data_range': {\n",
        "#                 'min': float(self.X_data.min()),\n",
        "#                 'max': float(self.X_data.max()),\n",
        "#                 'mean': float(self.X_data.mean()),\n",
        "#                 'std': float(self.X_data.std())\n",
        "#             },\n",
        "#             'class_distribution': dict(Counter(self.Y_labels)),\n",
        "#             'memory_usage_mb': self.X_data.nbytes / (1024 * 1024)\n",
        "#         }\n",
        "\n",
        "#         # Per-class statistics\n",
        "#         class_stats = {}\n",
        "#         for label in self.unique_labels:\n",
        "#             mask = self.Y_labels == label\n",
        "#             class_data = self.X_data[mask]\n",
        "#             class_stats[self.label_to_name[label]] = {\n",
        "#                 'count': int(np.sum(mask)),\n",
        "#                 'mean_intensity': float(class_data.mean()),\n",
        "#                 'std_intensity': float(class_data.std()),\n",
        "#                 'min_intensity': float(class_data.min()),\n",
        "#                 'max_intensity': float(class_data.max())\n",
        "#             }\n",
        "\n",
        "#         properties['class_statistics'] = class_stats\n",
        "#         self.data_properties = properties\n",
        "\n",
        "#         return properties\n",
        "\n",
        "#     def plot_class_distribution(self, figsize=(15, 8)):\n",
        "#         \"\"\"Visualize class distribution\"\"\"\n",
        "#         class_counts = Counter(self.Y_labels)\n",
        "#         class_names = [self.label_to_name[label] for label in class_counts.keys()]\n",
        "#         counts = list(class_counts.values())\n",
        "\n",
        "#         fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
        "\n",
        "#         # Bar plot\n",
        "#         bars = ax1.bar(range(len(class_names)), counts, color='skyblue', alpha=0.7)\n",
        "#         ax1.set_title('Class Distribution', fontweight='bold')\n",
        "#         ax1.set_xlabel('Species')\n",
        "#         ax1.set_ylabel('Number of Samples')\n",
        "#         ax1.set_xticks(range(len(class_names)))\n",
        "#         ax1.set_xticklabels(class_names, rotation=45, ha='right')\n",
        "\n",
        "#         # Add value labels on bars\n",
        "#         for bar, count in zip(bars, counts):\n",
        "#             height = bar.get_height()\n",
        "#             ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "#                     f'{count}', ha='center', va='bottom')\n",
        "\n",
        "#         # Pie chart\n",
        "#         ax2.pie(counts, labels=class_names, autopct='%1.1f%%', startangle=90)\n",
        "#         ax2.set_title('Class Distribution (%)', fontweight='bold')\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(f'{self.output_dir}/figures/class_distribution.png', bbox_inches='tight')\n",
        "#         plt.show()\n",
        "\n",
        "#     def plot_sample_images(self, samples_per_class=5, figsize=(20, 12)):\n",
        "#         \"\"\"Display sample images from each class\"\"\"\n",
        "#         n_classes = len(self.unique_labels)\n",
        "\n",
        "#         fig, axes = plt.subplots(n_classes, samples_per_class, figsize=figsize)\n",
        "#         if n_classes == 1:\n",
        "#             axes = axes.reshape(1, -1)\n",
        "#         elif samples_per_class == 1:\n",
        "#             axes = axes.reshape(-1, 1)\n",
        "\n",
        "#         fig.suptitle('Sample Images by Class', fontsize=16, fontweight='bold')\n",
        "\n",
        "#         for i, label in enumerate(self.unique_labels):\n",
        "#             # Get indices for this class\n",
        "#             class_indices = np.where(self.Y_labels == label)[0]\n",
        "\n",
        "#             # Sample random images from this class\n",
        "#             if len(class_indices) >= samples_per_class:\n",
        "#                 sample_indices = np.random.choice(class_indices, samples_per_class, replace=False)\n",
        "#             else:\n",
        "#                 sample_indices = class_indices\n",
        "\n",
        "#             for j in range(samples_per_class):\n",
        "#                 if j < len(sample_indices):\n",
        "#                     img = self.X_data[sample_indices[j]].copy()\n",
        "\n",
        "#                     # Prepare image for display\n",
        "#                     display_img, cmap = self._prepare_image_for_display(img)\n",
        "\n",
        "#                     # Normalize if needed\n",
        "#                     if display_img.max() > 1:\n",
        "#                         display_img = display_img.astype(float) / 255.0\n",
        "\n",
        "#                     axes[i, j].imshow(display_img, cmap=cmap)\n",
        "#                     axes[i, j].axis('off')\n",
        "\n",
        "#                     if j == 0:  # Label the first column with class names\n",
        "#                         axes[i, j].set_ylabel(self.label_to_name[label],\n",
        "#                                             rotation=90, fontsize=12, va='center')\n",
        "#                 else:\n",
        "#                     axes[i, j].axis('off')\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(f'{self.output_dir}/figures/sample_images.png', bbox_inches='tight')\n",
        "#         plt.show()\n",
        "\n",
        "#     def plot_pixel_intensity_analysis(self, figsize=(20, 12)):\n",
        "#         \"\"\"Analyze pixel intensity distributions\"\"\"\n",
        "#         fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
        "#         fig.suptitle('Pixel Intensity Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "#         # Overall intensity distribution\n",
        "#         axes[0, 0].hist(self.X_data.flatten(), bins=100, alpha=0.7, color='blue', density=True)\n",
        "#         axes[0, 0].set_title('Overall Pixel Intensity Distribution')\n",
        "#         axes[0, 0].set_xlabel('Pixel Intensity')\n",
        "#         axes[0, 0].set_ylabel('Density')\n",
        "\n",
        "#         # Mean intensity per image\n",
        "#         mean_intensities = np.mean(self.X_data.reshape(self.n_samples, -1), axis=1)\n",
        "#         axes[0, 1].hist(mean_intensities, bins=50, alpha=0.7, color='green', density=True)\n",
        "#         axes[0, 1].set_title('Mean Intensity per Image')\n",
        "#         axes[0, 1].set_xlabel('Mean Intensity')\n",
        "#         axes[0, 1].set_ylabel('Density')\n",
        "\n",
        "#         # Standard deviation per image\n",
        "#         std_intensities = np.std(self.X_data.reshape(self.n_samples, -1), axis=1)\n",
        "#         axes[0, 2].hist(std_intensities, bins=50, alpha=0.7, color='red', density=True)\n",
        "#         axes[0, 2].set_title('Intensity Standard Deviation per Image')\n",
        "#         axes[0, 2].set_xlabel('Std Intensity')\n",
        "#         axes[0, 2].set_ylabel('Density')\n",
        "\n",
        "#         # Class-wise intensity comparison\n",
        "#         class_intensities = []\n",
        "#         class_labels = []\n",
        "#         for label in self.unique_labels:\n",
        "#             mask = self.Y_labels == label\n",
        "#             class_data = self.X_data[mask]\n",
        "#             class_mean_intensities = np.mean(class_data.reshape(np.sum(mask), -1), axis=1)\n",
        "#             class_intensities.extend(class_mean_intensities)\n",
        "#             class_labels.extend([self.label_to_name[label]] * len(class_mean_intensities))\n",
        "\n",
        "#         intensity_df = pd.DataFrame({\n",
        "#             'intensity': class_intensities,\n",
        "#             'class': class_labels\n",
        "#         })\n",
        "\n",
        "#         # Create boxplot data\n",
        "#         box_data = [intensity_df[intensity_df['class'] == name]['intensity'].values\n",
        "#                    for name in self.label_names]\n",
        "\n",
        "#         axes[1, 0].boxplot(box_data, labels=self.label_names)\n",
        "#         axes[1, 0].set_title('Mean Intensity by Class')\n",
        "#         axes[1, 0].set_ylabel('Mean Intensity')\n",
        "#         axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "#         # Average image intensity heatmap by class\n",
        "#         avg_images = np.zeros((len(self.unique_labels), *self.image_shape))\n",
        "#         for i, label in enumerate(self.unique_labels):\n",
        "#             mask = self.Y_labels == label\n",
        "#             avg_images[i] = np.mean(self.X_data[mask], axis=0)\n",
        "\n",
        "#         # Calculate average intensity across spatial dimensions\n",
        "#         if len(self.image_shape) == 3:\n",
        "#             if self.channels_first:\n",
        "#                 # Average across height and width for each channel\n",
        "#                 avg_intensities = np.mean(avg_images, axis=(2, 3))  # Shape: (n_classes, n_channels)\n",
        "#             else:\n",
        "#                 # Average across height and width for each channel\n",
        "#                 avg_intensities = np.mean(avg_images, axis=(1, 2))  # Shape: (n_classes, n_channels)\n",
        "#         else:\n",
        "#             # Grayscale images - average across spatial dimensions\n",
        "#             avg_intensities = np.mean(avg_images, axis=(1, 2))  # Shape: (n_classes,)\n",
        "#             avg_intensities = avg_intensities.reshape(-1, 1)  # Make it 2D for heatmap\n",
        "\n",
        "#         im = axes[1, 1].imshow(avg_intensities, cmap='viridis', aspect='auto')\n",
        "#         axes[1, 1].set_title('Average Intensity by Class')\n",
        "#         axes[1, 1].set_ylabel('Class Index')\n",
        "#         axes[1, 1].set_yticks(range(len(self.unique_labels)))\n",
        "#         axes[1, 1].set_yticklabels([self.label_to_name[label] for label in self.unique_labels])\n",
        "\n",
        "#         if len(self.image_shape) == 3:\n",
        "#             if self.channels_first:\n",
        "#                 n_channels = self.image_shape[0]\n",
        "#             else:\n",
        "#                 n_channels = self.image_shape[2]\n",
        "\n",
        "#             if n_channels > 1:\n",
        "#                 axes[1, 1].set_xlabel('Channel')\n",
        "#                 axes[1, 1].set_xticks(range(n_channels))\n",
        "#                 if n_channels == 3:\n",
        "#                     axes[1, 1].set_xticklabels(['R', 'G', 'B'])\n",
        "#                 else:\n",
        "#                     axes[1, 1].set_xticklabels([f'Ch{i}' for i in range(n_channels)])\n",
        "#         else:\n",
        "#             axes[1, 1].set_xlabel('Intensity')\n",
        "\n",
        "#         plt.colorbar(im, ax=axes[1, 1])\n",
        "\n",
        "#         # Channel analysis for color images\n",
        "#         if len(self.image_shape) == 3:\n",
        "#             if self.channels_first:\n",
        "#                 n_channels = self.image_shape[0]\n",
        "#                 channel_means = np.mean(self.X_data, axis=(0, 2, 3))  # Average over batch, height, width\n",
        "#             else:\n",
        "#                 n_channels = self.image_shape[2]\n",
        "#                 channel_means = np.mean(self.X_data, axis=(0, 1, 2))  # Average over batch, height, width\n",
        "\n",
        "#             if n_channels > 1:\n",
        "#                 colors = ['red', 'green', 'blue'] if n_channels == 3 else ['gray'] * n_channels\n",
        "#                 axes[1, 2].bar(range(n_channels), channel_means, color=colors)\n",
        "#                 axes[1, 2].set_title('Mean Intensity by Channel')\n",
        "#                 axes[1, 2].set_xlabel('Channel')\n",
        "#                 axes[1, 2].set_ylabel('Mean Intensity')\n",
        "#                 if n_channels == 3:\n",
        "#                     axes[1, 2].set_xticks(range(3))\n",
        "#                     axes[1, 2].set_xticklabels(['Red', 'Green', 'Blue'])\n",
        "#                 else:\n",
        "#                     axes[1, 2].set_xticks(range(n_channels))\n",
        "#                     axes[1, 2].set_xticklabels([f'Ch{i}' for i in range(n_channels)])\n",
        "#             else:\n",
        "#                 axes[1, 2].text(0.5, 0.5, 'Single Channel\\n(Grayscale)',\n",
        "#                                ha='center', va='center', transform=axes[1, 2].transAxes)\n",
        "#                 axes[1, 2].set_title('Channel Information')\n",
        "#         else:\n",
        "#             axes[1, 2].text(0.5, 0.5, 'Single Channel\\n(Grayscale)',\n",
        "#                            ha='center', va='center', transform=axes[1, 2].transAxes)\n",
        "#             axes[1, 2].set_title('Channel Information')\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(f'{self.output_dir}/figures/pixel_intensity_analysis.png', bbox_inches='tight')\n",
        "#         plt.show()\n",
        "\n",
        "#     def perform_dimensionality_reduction(self, n_components=2, sample_size=5000):\n",
        "#         \"\"\"Perform PCA and t-SNE for visualization\"\"\"\n",
        "#         print(\"Performing dimensionality reduction...\")\n",
        "\n",
        "#         # Sample data if too large\n",
        "#         if self.n_samples > sample_size:\n",
        "#             indices = np.random.choice(self.n_samples, sample_size, replace=False)\n",
        "#             X_sample = self.X_data[indices]\n",
        "#             Y_sample = self.Y_labels[indices]\n",
        "#         else:\n",
        "#             X_sample = self.X_data\n",
        "#             Y_sample = self.Y_labels\n",
        "\n",
        "#         # Flatten images\n",
        "#         X_flat = X_sample.reshape(len(X_sample), -1)\n",
        "\n",
        "#         # Normalize data\n",
        "#         X_normalized = (X_flat - X_flat.mean()) / (X_flat.std() + 1e-8)\n",
        "\n",
        "#         # PCA\n",
        "#         print(\"Computing PCA...\")\n",
        "#         pca = PCA(n_components=n_components)\n",
        "#         X_pca = pca.fit_transform(X_normalized)\n",
        "\n",
        "#         # t-SNE\n",
        "#         print(\"Computing t-SNE...\")\n",
        "#         tsne = TSNE(n_components=n_components, random_state=42, perplexity=30)\n",
        "#         X_tsne = tsne.fit_transform(X_normalized)\n",
        "\n",
        "#         # Plot results\n",
        "#         fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "#         # PCA plot\n",
        "#         scatter1 = ax1.scatter(X_pca[:, 0], X_pca[:, 1],\n",
        "#                               c=Y_sample, cmap='tab10', alpha=0.6)\n",
        "#         ax1.set_title(f'PCA Visualization\\nExplained Variance: {pca.explained_variance_ratio_.sum():.3f}')\n",
        "#         ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.3f})')\n",
        "#         ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.3f})')\n",
        "\n",
        "#         # Add colorbar for PCA\n",
        "#         cbar1 = plt.colorbar(scatter1, ax=ax1)\n",
        "#         cbar1.set_label('Class')\n",
        "\n",
        "#         # t-SNE plot\n",
        "#         scatter2 = ax2.scatter(X_tsne[:, 0], X_tsne[:, 1],\n",
        "#                               c=Y_sample, cmap='tab10', alpha=0.6)\n",
        "#         ax2.set_title('t-SNE Visualization')\n",
        "#         ax2.set_xlabel('t-SNE 1')\n",
        "#         ax2.set_ylabel('t-SNE 2')\n",
        "\n",
        "#         # Add colorbar for t-SNE\n",
        "#         cbar2 = plt.colorbar(scatter2, ax=ax2)\n",
        "#         cbar2.set_label('Class')\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(f'{self.output_dir}/figures/dimensionality_reduction.png', bbox_inches='tight')\n",
        "#         plt.show()\n",
        "\n",
        "#         return pca, X_pca, X_tsne\n",
        "\n",
        "#     def create_data_summary_report(self):\n",
        "#         \"\"\"Create comprehensive data summary\"\"\"\n",
        "#         if not hasattr(self, 'data_properties'):\n",
        "#             self.analyze_data_properties()\n",
        "\n",
        "#         summary = f\"\"\"\n",
        "# FISH SPECIES DATASET - DATA ANALYSIS REPORT\n",
        "# {'='*60}\n",
        "\n",
        "# Dataset Overview:\n",
        "# - Total samples: {self.data_properties['dataset_size']:,}\n",
        "# - Number of classes: {self.data_properties['n_classes']}\n",
        "# - Image dimensions: {self.data_properties['image_shape']}\n",
        "# - Channels first format: {self.data_properties['channels_first']}\n",
        "# - Data type: {self.data_properties['data_type']}\n",
        "# - Memory usage: {self.data_properties['memory_usage_mb']:.1f} MB\n",
        "\n",
        "# Data Range:\n",
        "# - Minimum value: {self.data_properties['data_range']['min']:.3f}\n",
        "# - Maximum value: {self.data_properties['data_range']['max']:.3f}\n",
        "# - Mean value: {self.data_properties['data_range']['mean']:.3f}\n",
        "# - Standard deviation: {self.data_properties['data_range']['std']:.3f}\n",
        "\n",
        "# Class Distribution:\n",
        "# \"\"\"\n",
        "\n",
        "#         for class_name, stats in self.data_properties['class_statistics'].items():\n",
        "#             summary += f\"\\n{class_name}:\\n\"\n",
        "#             summary += f\"  - Sample count: {stats['count']:,}\\n\"\n",
        "#             summary += f\"  - Mean intensity: {stats['mean_intensity']:.3f}\\n\"\n",
        "#             summary += f\"  - Std intensity: {stats['std_intensity']:.3f}\\n\"\n",
        "#             summary += f\"  - Intensity range: {stats['min_intensity']:.3f} - {stats['max_intensity']:.3f}\\n\"\n",
        "\n",
        "#         # Save report\n",
        "#         with open(f'{self.output_dir}/reports/data_summary.txt', 'w') as f:\n",
        "#             f.write(summary)\n",
        "\n",
        "#         print(summary)\n",
        "#         return summary\n",
        "\n",
        "#     def run_complete_analysis(self, sample_size_dr=5000):\n",
        "#         \"\"\"Run complete analysis pipeline\"\"\"\n",
        "#         print(\"Starting comprehensive NumPy dataset analysis...\")\n",
        "#         print(\"=\" * 60)\n",
        "\n",
        "#         # Step 1: Analyze data properties\n",
        "#         self.analyze_data_properties()\n",
        "\n",
        "#         # Step 2: Create visualizations\n",
        "#         print(\"\\nGenerating visualizations...\")\n",
        "#         self.plot_class_distribution()\n",
        "#         self.plot_sample_images()\n",
        "#         self.plot_pixel_intensity_analysis()\n",
        "\n",
        "#         # Step 3: Dimensionality reduction\n",
        "#         pca, X_pca, X_tsne = self.perform_dimensionality_reduction(sample_size=sample_size_dr)\n",
        "\n",
        "#         # Step 4: Generate report\n",
        "#         print(\"\\nGenerating comprehensive report...\")\n",
        "#         self.create_data_summary_report()\n",
        "\n",
        "#         print(f\"\\nAnalysis complete! Results saved to: {self.output_dir}\")\n",
        "#         print(\"\\nGenerated files:\")\n",
        "#         print(\"- Figures: class_distribution.png, sample_images.png, pixel_intensity_analysis.png, dimensionality_reduction.png\")\n",
        "#         print(\"- Reports: data_summary.txt\")\n",
        "\n",
        "#         return pca, X_pca, X_tsne\n",
        "\n",
        "\n",
        "# # Usage example:\n",
        "# analyzer = FishDatasetNumpyAnalyzer(X_Loaded, Y_Loaded, output_dir='./fish_classification_results')\n",
        "# pca_model, X_pca_result, X_tsne_result = analyzer.run_complete_analysis(sample_size_dr=3000)\n",
        "# print(\"\\nDataset analysis completed successfully!\")\n",
        "# print(\"All visualizations and reports have been generated.\")"
      ],
      "metadata": {
        "id": "3GW4mxs4UgSQ"
      },
      "id": "3GW4mxs4UgSQ",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 6: Model Architecture"
      ],
      "metadata": {
        "id": "EJcWrfAbXyhI"
      },
      "id": "EJcWrfAbXyhI"
    },
    {
      "cell_type": "code",
      "source": [
        "# class ModelFactory:\n",
        "#     @staticmethod\n",
        "#     def create_model(model_name, params=None, num_classes=Config.NUM_CLASSES):\n",
        "#         \"\"\"Create model with GPU optimizations\"\"\"\n",
        "#         if params is None:\n",
        "#             params = {}\n",
        "#         dropout_rate = params.get('dropout', 0.5)\n",
        "#         hidden_dim_multiplier = params.get('hidden_dim_multiplier', 0.5)\n",
        "\n",
        "#         # Create base model\n",
        "#         model = ModelFactory._create_base_model(model_name, params, num_classes, dropout_rate, hidden_dim_multiplier)\n",
        "\n",
        "#         # Apply GPU optimizations\n",
        "#         return ModelFactory._optimize_for_gpu(model)\n",
        "\n",
        "#     @staticmethod\n",
        "#     def _optimize_for_gpu(model):\n",
        "#         \"\"\"Apply GPU-specific optimizations\"\"\"\n",
        "#         if torch.cuda.is_available():\n",
        "#             # Convert to channels_last memory format for better GPU utilization\n",
        "#             model = model.to(memory_format=torch.channels_last)\n",
        "\n",
        "#             # Enable torch.compile for PyTorch 2.0+ (significant speedup)\n",
        "#             if hasattr(torch, 'compile') and torch.cuda.get_device_capability()[0] >= 7:\n",
        "#                 try:\n",
        "#                     model = torch.compile(model, mode='max-autotune', dynamic=True)\n",
        "#                 except Exception:\n",
        "#                     pass  # Fallback if compilation fails\n",
        "\n",
        "#             # Replace standard activations with more GPU-efficient ones\n",
        "#             ModelFactory._replace_activations(model)\n",
        "\n",
        "#         return model\n",
        "\n",
        "#     @staticmethod\n",
        "#     def _replace_activations(model):\n",
        "#         \"\"\"Replace ReLU with more GPU-efficient activations\"\"\"\n",
        "#         for name, module in model.named_children():\n",
        "#             if isinstance(module, nn.ReLU):\n",
        "#                 # Replace with SiLU for better GPU utilization\n",
        "#                 setattr(model, name, nn.SiLU(inplace=True))\n",
        "#             elif len(list(module.children())) > 0:\n",
        "#                 ModelFactory._replace_activations(module)\n",
        "\n",
        "#     @staticmethod\n",
        "#     def _create_gpu_optimized_classifier(in_features, hidden_dim, num_classes, dropout_rate):\n",
        "#         \"\"\"Create GPU-optimized classifier with grouped operations\"\"\"\n",
        "#         return nn.Sequential(\n",
        "#             # Group operations for better GPU memory access\n",
        "#             nn.Dropout(dropout_rate),\n",
        "#             nn.Linear(in_features, hidden_dim, bias=False),  # Remove bias (BatchNorm handles it)\n",
        "#             nn.BatchNorm1d(hidden_dim),\n",
        "#             nn.SiLU(inplace=True),  # More GPU-efficient than ReLU\n",
        "\n",
        "#             # Second layer with residual-like structure\n",
        "#             nn.Dropout(dropout_rate * 0.5),\n",
        "#             nn.Linear(hidden_dim, hidden_dim // 2, bias=False),\n",
        "#             nn.BatchNorm1d(hidden_dim // 2),\n",
        "#             nn.SiLU(inplace=True),\n",
        "\n",
        "#             # Final classification layer\n",
        "#             nn.Linear(hidden_dim // 2, num_classes)\n",
        "#         )\n",
        "\n",
        "#     @staticmethod\n",
        "#     def _create_base_model(model_name, params, num_classes, dropout_rate, hidden_dim_multiplier):\n",
        "#         \"\"\"Create the base model architecture\"\"\"\n",
        "\n",
        "#         if model_name == 'resnet50':\n",
        "#             model = models.resnet50(weights='IMAGENET1K_V2')\n",
        "#             # Unfreeze more layers for better GPU utilization\n",
        "#             for name, param in model.named_parameters():\n",
        "#                 param.requires_grad = False\n",
        "#                 if any(layer in name for layer in [\"layer2\", \"layer3\", \"layer4\", \"fc\"]):\n",
        "#                     param.requires_grad = True\n",
        "\n",
        "#             num_features = model.fc.in_features\n",
        "#             hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "#             model.fc = ModelFactory._create_gpu_optimized_classifier(\n",
        "#                 num_features, hidden_dim, num_classes, dropout_rate\n",
        "#             )\n",
        "\n",
        "#         elif model_name == 'efficientnet_b0':\n",
        "#             model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "#             # Unfreeze more layers for better GPU utilization\n",
        "#             for name, param in model.named_parameters():\n",
        "#                 param.requires_grad = False\n",
        "#                 if any(layer in name for layer in [\"_blocks.12\", \"_blocks.13\", \"_blocks.14\", \"_blocks.15\", \"_blocks.16\", \"classifier\"]):\n",
        "#                     param.requires_grad = True\n",
        "\n",
        "#             num_features = model.classifier[1].in_features\n",
        "#             hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "#             model.classifier = ModelFactory._create_gpu_optimized_classifier(\n",
        "#                 num_features, hidden_dim, num_classes, dropout_rate\n",
        "#             )\n",
        "\n",
        "#         elif model_name == 'mobilenet_v3_large':\n",
        "#             model = models.mobilenet_v3_large(weights='IMAGENET1K_V2')\n",
        "#             # Unfreeze more layers for better GPU utilization\n",
        "#             for name, param in model.named_parameters():\n",
        "#                 param.requires_grad = False\n",
        "#                 if any(layer in name for layer in [\"features.10\", \"features.11\", \"features.12\", \"features.13\", \"classifier\"]):\n",
        "#                     param.requires_grad = True\n",
        "\n",
        "#             num_features = 960\n",
        "#             hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "#             model.classifier = ModelFactory._create_gpu_optimized_classifier(\n",
        "#                 num_features, hidden_dim, num_classes, dropout_rate\n",
        "#             )\n",
        "\n",
        "#         elif model_name == 'vgg16':\n",
        "#             model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "#             # Unfreeze more layers for better GPU utilization\n",
        "#             for name, param in model.named_parameters():\n",
        "#                 param.requires_grad = False\n",
        "#                 if any(layer in name for layer in [\"features.24\", \"features.26\", \"features.28\", \"classifier\"]):\n",
        "#                     param.requires_grad = True\n",
        "\n",
        "#             hidden_dim = int(4096 * hidden_dim_multiplier)\n",
        "#             # Simplified classifier for better GPU utilization\n",
        "#             model.classifier = nn.Sequential(\n",
        "#                 nn.Dropout(dropout_rate),\n",
        "#                 nn.Linear(512 * 7 * 7, hidden_dim, bias=False),\n",
        "#                 nn.BatchNorm1d(hidden_dim),\n",
        "#                 nn.SiLU(inplace=True),\n",
        "#                 nn.Dropout(dropout_rate * 0.5),\n",
        "#                 nn.Linear(hidden_dim, hidden_dim // 2, bias=False),\n",
        "#                 nn.BatchNorm1d(hidden_dim // 2),\n",
        "#                 nn.SiLU(inplace=True),\n",
        "#                 nn.Linear(hidden_dim // 2, num_classes)\n",
        "#             )\n",
        "\n",
        "#         elif model_name == 'densenet121':\n",
        "#             model = models.densenet121(weights='IMAGENET1K_V1')\n",
        "#             # Unfreeze more layers for better GPU utilization\n",
        "#             for name, param in model.named_parameters():\n",
        "#                 param.requires_grad = False\n",
        "#                 if any(layer in name for layer in [\"denseblock3\", \"denseblock4\", \"classifier\"]):\n",
        "#                     param.requires_grad = True\n",
        "\n",
        "#             num_features = model.classifier.in_features\n",
        "#             hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "#             model.classifier = ModelFactory._create_gpu_optimized_classifier(\n",
        "#                 num_features, hidden_dim, num_classes, dropout_rate\n",
        "#             )\n",
        "\n",
        "#         elif model_name == 'inception_v3':\n",
        "#             model = models.inception_v3(weights='IMAGENET1K_V1')\n",
        "#             # Unfreeze more layers for better GPU utilization\n",
        "#             for name, param in model.named_parameters():\n",
        "#                 param.requires_grad = False\n",
        "#                 if any(layer in name for layer in [\"Mixed_6\", \"Mixed_7a\", \"Mixed_7b\", \"Mixed_7c\", \"fc\", \"AuxLogits\"]):\n",
        "#                     param.requires_grad = True\n",
        "\n",
        "#             num_features = model.fc.in_features\n",
        "#             hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "\n",
        "#             # Main classifier\n",
        "#             model.fc = ModelFactory._create_gpu_optimized_classifier(\n",
        "#                 num_features, hidden_dim, num_classes, dropout_rate\n",
        "#             )\n",
        "\n",
        "#             # Auxiliary classifier (if exists)\n",
        "#             if hasattr(model, 'AuxLogits') and model.AuxLogits is not None:\n",
        "#                 aux_features = model.AuxLogits.fc.in_features\n",
        "#                 aux_hidden = int(aux_features * hidden_dim_multiplier)\n",
        "#                 model.AuxLogits.fc = ModelFactory._create_gpu_optimized_classifier(\n",
        "#                     aux_features, aux_hidden, num_classes, dropout_rate\n",
        "#                 )\n",
        "\n",
        "#         elif model_name == 'vit_b_16':\n",
        "#             model = models.vit_b_16(weights='IMAGENET1K_V1')\n",
        "#             # Unfreeze more layers for better GPU utilization\n",
        "#             for name, param in model.named_parameters():\n",
        "#                 param.requires_grad = False\n",
        "#                 if any(layer in name for layer in [\"encoder.layers.8\", \"encoder.layers.9\", \"encoder.layers.10\", \"encoder.layers.11\", \"heads\"]):\n",
        "#                     param.requires_grad = True\n",
        "\n",
        "#             num_features = model.heads.head.in_features\n",
        "#             hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "#             model.heads.head = ModelFactory._create_gpu_optimized_classifier(\n",
        "#                 num_features, hidden_dim, num_classes, dropout_rate\n",
        "#             )\n",
        "\n",
        "#         elif model_name == 'convnext_base':\n",
        "#             model = models.convnext_base(weights='IMAGENET1K_V1')\n",
        "#             # Unfreeze more layers for better GPU utilization\n",
        "#             for name, param in model.named_parameters():\n",
        "#                 param.requires_grad = False\n",
        "#                 if any(layer in name for layer in [\"features.6\", \"features.7\", \"classifier\"]):\n",
        "#                     param.requires_grad = True\n",
        "\n",
        "#             num_features = model.classifier[2].in_features\n",
        "#             hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "#             model.classifier = nn.Sequential(\n",
        "#                 model.classifier[0],  # Keep the LayerNorm\n",
        "#                 model.classifier[1],  # Keep the Flatten\n",
        "#                 nn.Dropout(dropout_rate),\n",
        "#                 nn.Linear(num_features, hidden_dim, bias=False),\n",
        "#                 nn.BatchNorm1d(hidden_dim),\n",
        "#                 nn.SiLU(inplace=True),\n",
        "#                 nn.Dropout(dropout_rate * 0.5),\n",
        "#                 nn.Linear(hidden_dim, hidden_dim // 2, bias=False),\n",
        "#                 nn.BatchNorm1d(hidden_dim // 2),\n",
        "#                 nn.SiLU(inplace=True),\n",
        "#                 nn.Linear(hidden_dim // 2, num_classes)\n",
        "#             )\n",
        "\n",
        "#         elif model_name == 'regnet_y_32gf':\n",
        "#             model = models.regnet_y_32gf(weights='IMAGENET1K_V2')\n",
        "#             # Unfreeze more layers for better GPU utilization\n",
        "#             for name, param in model.named_parameters():\n",
        "#                 param.requires_grad = False\n",
        "#                 if any(layer in name for layer in [\"trunk_output.block3\", \"trunk_output.block4\", \"fc\"]):\n",
        "#                     param.requires_grad = True\n",
        "\n",
        "#             num_features = model.fc.in_features\n",
        "#             hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "#             model.fc = ModelFactory._create_gpu_optimized_classifier(\n",
        "#                 num_features, hidden_dim, num_classes, dropout_rate\n",
        "#             )\n",
        "\n",
        "#         elif model_name == 'cnn':\n",
        "#             class GPUOptimizedCNN(nn.Module):\n",
        "#                 def __init__(self, num_classes=5, dropout_rate=0.3, hidden_dim_multiplier=0.3):\n",
        "#                     super(GPUOptimizedCNN, self).__init__()\n",
        "\n",
        "#                     # GPU-optimized feature extractor with depthwise separable convolutions\n",
        "#                     self.features = nn.Sequential(\n",
        "#                         # Block 1 - Initial feature extraction\n",
        "#                         nn.Conv2d(3, 32, kernel_size=3, stride=2, padding=1, bias=False),\n",
        "#                         nn.BatchNorm2d(32),\n",
        "#                         nn.SiLU(inplace=True),\n",
        "\n",
        "#                         # Block 2 - Depthwise separable conv\n",
        "#                         nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1, groups=32, bias=False),  # Depthwise\n",
        "#                         nn.Conv2d(32, 64, kernel_size=1, bias=False),  # Pointwise\n",
        "#                         nn.BatchNorm2d(64),\n",
        "#                         nn.SiLU(inplace=True),\n",
        "#                         nn.MaxPool2d(2, 2),\n",
        "\n",
        "#                         # Block 3 - More efficient computation\n",
        "#                         nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1, groups=64, bias=False),  # Depthwise\n",
        "#                         nn.Conv2d(64, 128, kernel_size=1, bias=False),  # Pointwise\n",
        "#                         nn.BatchNorm2d(128),\n",
        "#                         nn.SiLU(inplace=True),\n",
        "#                         nn.MaxPool2d(2, 2),\n",
        "\n",
        "#                         # Block 4 - Final feature extraction\n",
        "#                         nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1, groups=128, bias=False),  # Depthwise\n",
        "#                         nn.Conv2d(128, 256, kernel_size=1, bias=False),  # Pointwise\n",
        "#                         nn.BatchNorm2d(256),\n",
        "#                         nn.SiLU(inplace=True),\n",
        "\n",
        "#                         # Global average pooling for efficiency\n",
        "#                         nn.AdaptiveAvgPool2d((1, 1))\n",
        "#                     )\n",
        "\n",
        "#                     # Efficient classifier\n",
        "#                     hidden_dim = max(128, int(256 * hidden_dim_multiplier))\n",
        "#                     self.classifier = nn.Sequential(\n",
        "#                         nn.Flatten(),\n",
        "#                         nn.Dropout(dropout_rate),\n",
        "#                         nn.Linear(256, hidden_dim, bias=False),\n",
        "#                         nn.BatchNorm1d(hidden_dim),\n",
        "#                         nn.SiLU(inplace=True),\n",
        "#                         nn.Dropout(dropout_rate * 0.5),\n",
        "#                         nn.Linear(hidden_dim, num_classes)\n",
        "#                     )\n",
        "\n",
        "#                     # Initialize weights properly\n",
        "#                     self._initialize_weights()\n",
        "\n",
        "#                 def _initialize_weights(self):\n",
        "#                     for m in self.modules():\n",
        "#                         if isinstance(m, nn.Conv2d):\n",
        "#                             nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "#                         elif isinstance(m, nn.Linear):\n",
        "#                             nn.init.xavier_uniform_(m.weight, gain=1.0)\n",
        "#                             if m.bias is not None:\n",
        "#                                 nn.init.zeros_(m.bias)\n",
        "#                         elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
        "#                             if m.weight is not None:\n",
        "#                                 nn.init.ones_(m.weight)\n",
        "#                             if m.bias is not None:\n",
        "#                                 nn.init.zeros_(m.bias)\n",
        "\n",
        "#                 def forward(self, x):\n",
        "#                     # Ensure channels_last format for GPU optimization\n",
        "#                     if x.device.type == 'cuda':\n",
        "#                         x = x.to(memory_format=torch.channels_last)\n",
        "\n",
        "#                     # Feature extraction\n",
        "#                     x = self.features(x)\n",
        "\n",
        "#                     # Classification\n",
        "#                     x = self.classifier(x)\n",
        "\n",
        "#                     return x\n",
        "\n",
        "#             model = GPUOptimizedCNN(num_classes=num_classes, dropout_rate=dropout_rate,\n",
        "#                                   hidden_dim_multiplier=hidden_dim_multiplier)\n",
        "\n",
        "#         else:\n",
        "#             raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "#         return model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ModelFactory:\n",
        "    @staticmethod\n",
        "    # def create_model(model_name, num_classes=Config.NUM_CLASSES, dropout_rate=0.5, hidden_dim_multiplier=0.5):\n",
        "    def create_model(model_name, params=None, num_classes=Config.NUM_CLASSES, dropout_rate=0.5, hidden_dim_multiplier=0.5):\n",
        "        #Create model with configurable architecture\n",
        "        if params is None:\n",
        "            params = {}\n",
        "        dropout_rate = params.get('dropout', 0.5)\n",
        "        hidden_dim_multiplier = params.get('hidden_dim_multiplier', 0.5)\n",
        "\n",
        "        if model_name == 'resnet50':\n",
        "            model = models.resnet50(weights='IMAGENET1K_V2')\n",
        "            # Partial unfreeze for better accuracy: unfreeze layer4 and fc\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                # if \"layer4\" in name or \"fc\" in name:\n",
        "                if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'efficientnet_b0':\n",
        "            model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: last blocks\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"_blocks.15\" in name or \"_blocks.16\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = model.classifier[1].in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'mobilenet_v3_large':\n",
        "            model = models.mobilenet_v3_large(weights='IMAGENET1K_V2')\n",
        "            # Partial unfreeze: last features\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"features.12\" in name or \"features.13\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = 960\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'vgg16':\n",
        "            model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: classifier and last features\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"classifier\" in name or \"features.28\" in name:\n",
        "                    param.requires_grad = True\n",
        "            hidden_dim = int(4096 * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Linear(512 * 7 * 7, 4096),\n",
        "                nn.ReLU(True),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(4096, hidden_dim),\n",
        "                nn.ReLU(True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'densenet121':\n",
        "            model = models.densenet121(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: denseblock4 and classifier\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"denseblock4\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = model.classifier.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'inception_v3':\n",
        "            model = models.inception_v3(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: Mixed_7a, Mixed_7b, Mixed_7c and classifiers\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if any(layer in name for layer in [\"Mixed_7a\", \"Mixed_7b\", \"Mixed_7c\", \"fc\", \"AuxLogits\"]):\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "\n",
        "            # Main classifier\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "            # Auxiliary classifier (if exists)\n",
        "            if hasattr(model, 'AuxLogits') and model.AuxLogits is not None:\n",
        "                aux_features = model.AuxLogits.fc.in_features\n",
        "                aux_hidden = int(aux_features * hidden_dim_multiplier)\n",
        "                model.AuxLogits.fc = nn.Sequential(\n",
        "                    nn.Dropout(dropout_rate),\n",
        "                    nn.Linear(aux_features, aux_hidden),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.BatchNorm1d(aux_hidden),\n",
        "                    nn.Dropout(dropout_rate / 2),\n",
        "                    nn.Linear(aux_hidden, num_classes)\n",
        "                )\n",
        "\n",
        "        elif model_name == 'vit_b_16':\n",
        "            model = models.vit_b_16(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: last encoder layers and head\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if any(layer in name for layer in [\"encoder.layers.10\", \"encoder.layers.11\", \"heads\"]):\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.heads.head.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.heads.head = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'convnext_base':\n",
        "            model = models.convnext_base(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: last stages and classifier\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if any(layer in name for layer in [\"features.7\", \"classifier\"]):\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.classifier[2].in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                model.classifier[0],  # Keep the LayerNorm\n",
        "                model.classifier[1],  # Keep the Flatten\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'regnet_y_32gf':\n",
        "            model = models.regnet_y_32gf(weights='IMAGENET1K_V2')\n",
        "            # Partial unfreeze: last trunk stage and fc\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"trunk_output\" in name or \"fc\" in name:\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'cnn':\n",
        "            # class SimpleCNN(nn.Module):\n",
        "\n",
        "            class SimpleCNN(nn.Module):\n",
        "                def __init__(self, num_classes=5, dropout_rate=0.3, hidden_dim_multiplier=0.3):\n",
        "                    super(SimpleCNN, self).__init__()\n",
        "\n",
        "                    # More conservative feature extractor to prevent overfitting\n",
        "                    self.features = nn.Sequential(\n",
        "                        # Block 1 - Start small\n",
        "                        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.1),  # Spatial dropout in conv layers\n",
        "                        nn.MaxPool2d(2, 2),  # 224 -> 112\n",
        "\n",
        "                        # Block 2\n",
        "                        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.15),\n",
        "                        nn.MaxPool2d(2, 2),  # 112 -> 56\n",
        "\n",
        "                        # Block 3\n",
        "                        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.2),\n",
        "                        nn.MaxPool2d(2, 2),  # 56 -> 28\n",
        "\n",
        "                        # Block 4 - Add one more conv before pooling\n",
        "                        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.25),\n",
        "                        nn.MaxPool2d(2, 2),  # 28 -> 14\n",
        "\n",
        "                        # Block 5 - Final feature extraction\n",
        "                        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(256),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.3),\n",
        "                        nn.AdaptiveAvgPool2d((7, 7))  # Fixed spatial size\n",
        "                    )\n",
        "\n",
        "                    # Calculate features after adaptive pooling\n",
        "                    conv_output_size = 256 * 7 * 7  # 12544\n",
        "\n",
        "                    # Much smaller hidden dimension to prevent overfitting\n",
        "                    hidden_dim = int(conv_output_size * hidden_dim_multiplier)\n",
        "                    hidden_dim = max(64, min(hidden_dim, 512))  # Smaller range\n",
        "\n",
        "                    # Simple but effective classifier\n",
        "                    self.classifier = nn.Sequential(\n",
        "                        nn.Dropout(dropout_rate),\n",
        "                        nn.Linear(conv_output_size, hidden_dim),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.BatchNorm1d(hidden_dim),\n",
        "                        nn.Dropout(dropout_rate * 0.5),\n",
        "                        nn.Linear(hidden_dim, num_classes)\n",
        "                    )\n",
        "\n",
        "                    # Initialize weights properly\n",
        "                    self._initialize_weights()\n",
        "\n",
        "                def _initialize_weights(self):\n",
        "                    for m in self.modules():\n",
        "                        if isinstance(m, nn.Conv2d):\n",
        "                            # Use smaller initialization for better gradient flow\n",
        "                            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "                        elif isinstance(m, nn.Linear):\n",
        "                            # Smaller initialization for linear layers\n",
        "                            nn.init.xavier_uniform_(m.weight, gain=0.5)\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "                        elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
        "                            if m.weight is not None:\n",
        "                                nn.init.ones_(m.weight)\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "\n",
        "                def forward(self, x):\n",
        "                    # Feature extraction\n",
        "                    x = self.features(x)\n",
        "\n",
        "                    # Flatten\n",
        "                    x = torch.flatten(x, 1)\n",
        "\n",
        "                    # Classification with gradient clipping\n",
        "                    x = self.classifier(x)\n",
        "\n",
        "                    # Clip outputs to prevent extreme values\n",
        "                    x = torch.clamp(x, min=-10, max=10)\n",
        "\n",
        "                    return x\n",
        "\n",
        "            # # Example usage\n",
        "            # model = SimpleCNN(num_classes=num_classes, dropout_rate=dropout_rate, hidden_dim_multiplier=hidden_dim_multiplier)\n",
        "            # model = model.to(Config.DEVICE)  # Move to device right after creation\n",
        "            model = SimpleCNN(num_classes=num_classes, dropout_rate=dropout_rate, hidden_dim_multiplier=hidden_dim_multiplier)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "        return model"
      ],
      "metadata": {
        "id": "Pxu1Cn5CXx-B"
      },
      "id": "Pxu1Cn5CXx-B",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 7: Ensamble Model Architecture"
      ],
      "metadata": {
        "id": "HMjRUeNFW-m_"
      },
      "id": "HMjRUeNFW-m_"
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# 6. ENSEMBLE METHODS\n",
        "# ================================================================================================================================\n",
        "# Purpose: Implement ensemble methods (simple, weighted, confidence-based, learnable).\n",
        "\n",
        "class EnsembleManager:\n",
        "    def __init__(self, models_dict, val_data):\n",
        "        self.models = models_dict\n",
        "        self.X_val, self.y_val = val_data\n",
        "        self.model_predictions = self._get_predictions()\n",
        "        self.histories = {}\n",
        "\n",
        "    def _get_predictions(self):\n",
        "        print(\"Getting model predictions for ensemble...\")\n",
        "        predictions = {}\n",
        "\n",
        "        val_dataset = FishDataset(self.X_val, self.y_val, DataManager.get_transforms(False))\n",
        "        val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            model.eval()\n",
        "            all_preds = []\n",
        "            all_probs = []\n",
        "            all_losses = []\n",
        "            all_labels = []\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    outputs = model(images)\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    loss = criterion(outputs, labels).item()\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    all_preds.extend(predicted.cpu().numpy())\n",
        "                    all_probs.extend(probabilities.cpu().numpy())\n",
        "                    all_losses.append(loss)\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = correct / total\n",
        "            f1 = f1_score(self.y_val, all_preds, average='macro')\n",
        "            avg_loss = np.mean(all_losses)\n",
        "\n",
        "            predictions[name] = {\n",
        "                'predictions': np.array(all_preds),\n",
        "                'probabilities': np.array(all_probs),\n",
        "                'loss': avg_loss,\n",
        "                'accuracy': accuracy,\n",
        "                'f1': f1,\n",
        "                'true_labels': np.array(all_labels)\n",
        "            }\n",
        "\n",
        "            print(f\"  {name}: F1 = {f1:.4f}, Acc = {accuracy:.4f}, Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def simple_average_ensemble(self, model_combo):\n",
        "        selected_probs = [self.model_predictions[name]['probabilities'] for name in model_combo]\n",
        "        avg_probs = np.mean(selected_probs, axis=0)\n",
        "        predictions = np.argmax(avg_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        avg_probs = np.mean(selected_probs, axis=0) if selected_probs else np.zeros((len(self.y_val), Config.NUM_CLASSES))\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            # 'probabilities': avg_probs,\n",
        "            'probabilities': avg_probs if avg_probs.ndim == 2 else np.zeros((0, Config.NUM_CLASSES)),\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def weighted_average_ensemble(self, model_combo):\n",
        "        weights = []\n",
        "        selected_probs = []\n",
        "\n",
        "        for name in model_combo:\n",
        "            f1 = self.model_predictions[name]['f1']\n",
        "            weights.append(f1)\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        weights = np.array(weights) / np.sum(weights)\n",
        "        weighted_probs = np.average(selected_probs, axis=0, weights=weights)\n",
        "        predictions = np.argmax(weighted_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.average([self.model_predictions[name]['loss'] for name in model_combo], weights=weights)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'weights': weights,\n",
        "            'models': model_combo,\n",
        "            'probabilities': weighted_probs,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def confidence_based_ensemble(self, model_combo):\n",
        "        final_predictions = []\n",
        "        all_probs = []\n",
        "\n",
        "        for i in range(len(self.y_val)):\n",
        "            confidences = []\n",
        "            probs = []\n",
        "\n",
        "            for name in model_combo:\n",
        "                prob = self.model_predictions[name]['probabilities'][i]\n",
        "                confidence = np.max(prob)\n",
        "                confidences.append(confidence)\n",
        "                probs.append(prob)\n",
        "\n",
        "            confidences = np.array(confidences)\n",
        "            weights = confidences / np.sum(confidences) if np.sum(confidences) > 0 else np.ones(len(confidences)) / len(confidences)\n",
        "\n",
        "            final_prob = np.average(probs, axis=0, weights=weights)\n",
        "            final_predictions.append(np.argmax(final_prob))\n",
        "            all_probs.append(final_prob)\n",
        "\n",
        "        predictions = np.array(final_predictions)\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'probabilities': np.array(all_probs),\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def learnable_weighted_ensemble(self, model_combo, epochs=30):\n",
        "        print(f\"Training learnable weighted ensemble with {len(model_combo)} models...\")\n",
        "\n",
        "        selected_probs = []\n",
        "        for name in model_combo:\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        ensemble_input = np.stack(selected_probs, axis=1)\n",
        "\n",
        "        X_ensemble = torch.FloatTensor(ensemble_input).to(Config.DEVICE)\n",
        "        y_ensemble = torch.LongTensor(self.y_val).to(Config.DEVICE)\n",
        "\n",
        "        ensemble_model = LearnableWeightedEnsemble(\n",
        "            num_models=len(model_combo),\n",
        "            num_classes=Config.NUM_CLASSES\n",
        "        ).to(Config.DEVICE)\n",
        "\n",
        "        optimizer = optim.AdamW(ensemble_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "        history = {'train_loss': [], 'train_acc': [], 'val_f1': []}\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            ensemble_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions, weights = ensemble_model(X_ensemble)\n",
        "            loss = criterion(predictions, y_ensemble)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            accuracy = accuracy_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy())\n",
        "            f1 = f1_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy(), average='macro')\n",
        "\n",
        "            history['train_loss'].append(loss.item())\n",
        "            history['train_acc'].append(accuracy)\n",
        "            history['val_f1'].append(f1)\n",
        "\n",
        "            print(f\"Ensemble Epoch {epoch+1}/{epochs}: Loss = {loss.item():.4f}, \"\n",
        "                  f\"Acc = {accuracy:.4f}, F1 = {f1:.4f}\")\n",
        "\n",
        "            if loss.item() < best_loss:\n",
        "                best_loss = loss.item()\n",
        "                torch.save(ensemble_model.state_dict(), f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\")\n",
        "\n",
        "        ensemble_model.load_state_dict(torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\"))\n",
        "        ensemble_model.eval()\n",
        "        with torch.no_grad():\n",
        "            final_predictions, learned_weights = ensemble_model(X_ensemble)\n",
        "            predictions = final_predictions.argmax(dim=1).cpu().numpy()\n",
        "            probabilities = torch.softmax(final_predictions, dim=1).cpu().numpy()\n",
        "            avg_weights = learned_weights.mean(dim=0).cpu().numpy()\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        self.histories[f\"learnable_weighted_{'+'.join(model_combo)}\"] = history\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'learned_weights': avg_weights,\n",
        "            'probabilities': probabilities,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def test_ensemble_combinations(self):\n",
        "        print(\"Testing ensemble combinations...\")\n",
        "\n",
        "        model_names = list(self.models.keys())\n",
        "        all_results = {}\n",
        "        best_result = None\n",
        "        best_score = 0\n",
        "\n",
        "        for size in range(2, min(len(model_names) + 1, 5)):\n",
        "            print(f\"Testing {size}-model combinations...\")\n",
        "\n",
        "            for combo in list(combinations(model_names, size))[:5]:\n",
        "                combo_name = f\"combo_{size}_{'+'.join(combo)}\"\n",
        "\n",
        "                for method_name in Config.ENSEMBLE_METHODS:\n",
        "                    full_name = f\"{combo_name}_{method_name}\"\n",
        "\n",
        "                    try:\n",
        "                        if method_name == 'simple_average':\n",
        "                            result = self.simple_average_ensemble(combo)\n",
        "                        elif method_name == 'weighted_average':\n",
        "                            result = self.weighted_average_ensemble(combo)\n",
        "                        elif method_name == 'confidence_based':\n",
        "                            result = self.confidence_based_ensemble(combo)\n",
        "                        elif method_name == 'learnable_weighted':\n",
        "                            result = self.learnable_weighted_ensemble(combo)\n",
        "\n",
        "                        # Verify result contains required keys\n",
        "                        required_keys = ['accuracy', 'f1', 'loss', 'predictions', 'models', 'probabilities', 'true_labels']\n",
        "                        if not all(key in result for key in required_keys):\n",
        "                            missing = [key for key in required_keys if key not in result]\n",
        "                            print(f\"  {full_name}: Missing keys {missing}\")\n",
        "                            continue\n",
        "                        # Ensure probabilities is 2D\n",
        "                        if 'probabilities' in result and (result['probabilities'].ndim != 2 or result['probabilities'].shape[1] != Config.NUM_CLASSES):\n",
        "                            result['probabilities'] = np.zeros((len(result['true_labels']), Config.NUM_CLASSES))\n",
        "\n",
        "                        all_results[full_name] = result\n",
        "                        print(f\"  {full_name}: F1 = {result['f1']:.4f}, Acc = {result['accuracy']:.4f}, \"\n",
        "                              f\"Loss = {result['loss']:.4f}, True Labels Shape = {result['true_labels'].shape}\")\n",
        "\n",
        "                        if result['f1'] > best_score:\n",
        "                            best_score = result['f1']\n",
        "                            best_result = (full_name, result)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"  {full_name}: FAILED - {str(e)}\")\n",
        "\n",
        "        if best_result:\n",
        "            print(f\"\\n‚úì Best ensemble: {best_result[0]} (F1: {best_result[1]['f1']:.4f})\")\n",
        "        else:\n",
        "            print(\"\\nNo valid ensemble results generated.\")\n",
        "\n",
        "        return all_results, best_result\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# LEARNABLE WEIGHTED ENSEMBLE MODEL\n",
        "# ===============================================================================================================================\n",
        "# Purpose: Define a neural network for learning optimal ensemble weights.\n",
        "\n",
        "class LearnableWeightedEnsemble(nn.Module):\n",
        "    \"\"\"Ensemble model with per-class adaptive weights and attention\"\"\"\n",
        "    def __init__(self, num_models, num_classes, hidden_dim=128, num_heads=4):\n",
        "        super(LearnableWeightedEnsemble, self).__init__()\n",
        "        self.num_models = num_models\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Attention mechanism to learn relations between model predictions\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=num_classes, num_heads=num_heads, batch_first=True)\n",
        "\n",
        "        # Weight network outputs per-class weights for each model\n",
        "        self.weight_network = nn.Sequential(\n",
        "            nn.Linear(num_classes, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes),\n",
        "            nn.Sigmoid()  # Per-class weight scaling\n",
        "        )\n",
        "\n",
        "        # Prediction head: combines weighted predictions + raw predictions\n",
        "        self.prediction_head = nn.Sequential(\n",
        "            nn.Linear(num_classes * (num_models + 1), hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(num_classes * 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, model_predictions):\n",
        "        \"\"\"\n",
        "        model_predictions: (batch, num_models, num_classes)\n",
        "        Returns:\n",
        "            final_predictions: logits for classification\n",
        "            weights: learned per-class weights for each model\n",
        "        \"\"\"\n",
        "        batch_size = model_predictions.size(0)\n",
        "\n",
        "        # --- Step 1: Attention over model predictions --- #The model looks at how predictions of different models relate to each other.\n",
        "        attn_output, _ = self.attention(model_predictions, model_predictions, model_predictions)\n",
        "        # shape: (batch, num_models, num_classes)\n",
        "\n",
        "\n",
        "        # --- Step 2: Per-class weights for each model ---\n",
        "        #Learns a weight for each model for each class.\n",
        "        #softmax ensures weights across models sum to 1 for each class.\n",
        "        #Basically: ‚ÄúFor class 0, I trust model 2 more; for class 1, I trust model 0 more.‚Äù\n",
        "        weights = self.weight_network(attn_output)  # (batch, num_models, num_classes)\n",
        "        weights = F.softmax(weights, dim=1)  # normalize over models\n",
        "\n",
        "\n",
        "        # --- Step 3: Weighted average across models ---\n",
        "        #Combines the models‚Äô predictions using the learned weights ‚Üí smarter than a plain average.\n",
        "        weighted_avg = torch.sum(model_predictions * weights, dim=1)  # (batch, num_classes)\n",
        "\n",
        "\n",
        "        # --- Step 4: Residual connection with raw predictions ---\n",
        "        #Combines the weighted average and all raw predictions.Gives the network more info to refine the final prediction.\n",
        "        flat_preds = model_predictions.view(batch_size, -1)  # (batch, num_models * num_classes)\n",
        "        final_input = torch.cat([weighted_avg, flat_preds], dim=1)  # (batch, num_classes + num_models*num_classes)\n",
        "\n",
        "\n",
        "        # --- Step 5: Final refined prediction ---\n",
        "        #A small feed-forward network refines the predictions.Output: (batch_size, num_classes) ‚Üí logits for each class.\n",
        "        final_predictions = self.prediction_head(final_input)  # (batch, num_classes)\n",
        "\n",
        "        return final_predictions, weights\n",
        "        #It learns which model is best for each class, combines their predictions smartly using attention, and produces a refined final prediction.\n",
        "\n",
        "    # def entropy_regularization(self, weights):\n",
        "    #     \"\"\"Encourage diverse weight usage (optional loss term).\"\"\"\n",
        "    #     # weights: (batch, num_models, num_classes)\n",
        "    #     entropy = -torch.sum(weights * torch.log(weights + 1e-8), dim=1)  # (batch, num_classes)\n",
        "    #     return torch.mean(entropy)\n"
      ],
      "metadata": {
        "id": "pWZlr59kXHue"
      },
      "id": "pWZlr59kXHue",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 8: üìä Optuna Trials [Hyper-parameter Tuning]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DgnPYu28n6Db"
      },
      "id": "DgnPYu28n6Db"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Optimized for maximum GPU utilization and enhanced user experience\n",
        "# from threading import Lock\n",
        "# from termcolor import colored, cprint\n",
        "\n",
        "# import warnings\n",
        "# from optuna.exceptions import ExperimentalWarning\n",
        "# # Suppress only ExperimentalWarning\n",
        "# warnings.filterwarnings(\"ignore\", category=ExperimentalWarning)\n",
        "# import optuna\n",
        "# optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# # # Configure logging\n",
        "# # logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "# # logger = logging.getLogger(__name__)\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torch.utils.data import DataLoader, WeightedRandomSampler\n",
        "# import numpy as np\n",
        "# import os\n",
        "# import gc\n",
        "# import psutil\n",
        "# import time\n",
        "# import json\n",
        "# import traceback\n",
        "# from tqdm import tqdm\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# from sklearn.utils.class_weight import compute_class_weight\n",
        "# from sklearn.metrics import f1_score\n",
        "# from typing import Dict, Any, Tuple\n",
        "\n",
        "\n",
        "# def worker_init_fn(worker_id):\n",
        "#     #Initialize worker with different random seed\n",
        "#     np.random.seed(torch.initial_seed() % 2**32 + worker_id)\n",
        "\n",
        "# class Optuna_DataManager:\n",
        "\n",
        "#     @staticmethod\n",
        "#     def create_data_loaders(X, Y, train_batch_size=64, val_batch_size=128,\n",
        "#                                     test_size=0.2, augmentation_strength='medium',\n",
        "#                                     num_workers=8, pin_memory=True, persistent_workers=True):\n",
        "\n",
        "#         # Split data strategically\n",
        "#         X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "#             X, Y, test_size=test_size, random_state=42, stratify=Y\n",
        "#         )\n",
        "#         X_train, X_val, y_train, y_val = train_test_split(\n",
        "#             X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
        "#         )\n",
        "\n",
        "#         # OPTIMIZATION: Delete intermediate variables immediately to save CPU RAM\n",
        "#         del X_temp, y_temp\n",
        "#         gc.collect()\n",
        "\n",
        "#         cprint(f\"üìä Data Distribution:\", 'cyan', attrs=['bold'])\n",
        "#         print(f\"   Train: {len(X_train):,} samples\")\n",
        "#         print(f\"   Val:   {len(X_val):,} samples\")\n",
        "#         print(f\"   Test:  {len(X_test):,} samples\")\n",
        "#         print(f\"   Batch: Train={train_batch_size}, Val={val_batch_size}\")\n",
        "\n",
        "#         # Create datasets with transforms (assuming these classes exist)\n",
        "#         # You need to define these or import them\n",
        "#         try:\n",
        "#             # from your_data_module import FishDataset, DataManager  # Replace with actual imports\n",
        "#             train_dataset = FishDataset(X_train, y_train, DataManager.get_transforms(True, augmentation_strength))\n",
        "#             val_dataset = FishDataset(X_val, y_val, DataManager.get_transforms(False))\n",
        "#             test_dataset = FishDataset(X_test, y_test, DataManager.get_transforms(False))\n",
        "#         except ImportError:\n",
        "#             raise ImportError(\"FishDataset and DataManager classes not found. Please ensure they are imported.\")\n",
        "#         except Exception as e:\n",
        "#             raise Exception(f\"Error creating datasets: {e}\")\n",
        "\n",
        "#         # OPTIMIZATION: More efficient class weight calculation to save memory\n",
        "#         unique_classes, class_counts = np.unique(y_train, return_counts=True)\n",
        "#         class_weights = len(y_train) / (len(unique_classes) * class_counts)\n",
        "#         class_weight_dict = dict(zip(unique_classes, class_weights))\n",
        "#         sample_weights = [class_weight_dict[y] for y in y_train]\n",
        "#         sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "\n",
        "#         # Clean up intermediate weight calculations\n",
        "#         del class_weights, class_weight_dict, sample_weights\n",
        "\n",
        "#         # OPTIMIZATION: Reduce CPU workers to save RAM, prioritize GPU feeding\n",
        "#         if num_workers is None:\n",
        "#             if torch.cuda.is_available():\n",
        "#                 # More conservative worker count to save CPU RAM\n",
        "#                 num_workers = min(os.cpu_count() // 2, 8)  # Reduced from 16\n",
        "#             else:\n",
        "#                 num_workers = 2  # Minimal for CPU-only\n",
        "#         else:\n",
        "#             # Cap the provided num_workers to save CPU RAM\n",
        "#             num_workers = min(num_workers, os.cpu_count() // 2, 8)\n",
        "\n",
        "#         # OPTIMIZATION: Reduce prefetch factor to save CPU memory\n",
        "#         prefetch_factor = 2 if torch.cuda.is_available() else 1  # Reduced from 4\n",
        "\n",
        "#         # Create GPU-optimized data loaders\n",
        "#         train_loader = DataLoader(\n",
        "#             train_dataset,\n",
        "#             batch_size=train_batch_size,\n",
        "#             sampler=sampler,\n",
        "#             num_workers=num_workers,\n",
        "#             pin_memory=pin_memory and torch.cuda.is_available(),\n",
        "#             prefetch_factor=prefetch_factor,\n",
        "#             persistent_workers=persistent_workers and num_workers > 0,\n",
        "#             worker_init_fn=worker_init_fn,\n",
        "#             drop_last=True\n",
        "#         )\n",
        "\n",
        "#         val_loader = DataLoader(\n",
        "#             val_dataset,\n",
        "#             batch_size=val_batch_size,\n",
        "#             shuffle=False,\n",
        "#             num_workers=num_workers,\n",
        "#             pin_memory=pin_memory and torch.cuda.is_available(),\n",
        "#             prefetch_factor=prefetch_factor,\n",
        "#             persistent_workers=persistent_workers and num_workers > 0,\n",
        "#             worker_init_fn=worker_init_fn\n",
        "#         )\n",
        "\n",
        "#         test_loader = DataLoader(\n",
        "#             test_dataset,\n",
        "#             batch_size=val_batch_size,\n",
        "#             shuffle=False,\n",
        "#             num_workers=num_workers,\n",
        "#             pin_memory=pin_memory and torch.cuda.is_available(),\n",
        "#             prefetch_factor=prefetch_factor,\n",
        "#             persistent_workers=persistent_workers and num_workers > 0,\n",
        "#             worker_init_fn=worker_init_fn\n",
        "#         )\n",
        "\n",
        "#         return train_loader, val_loader, test_loader, (X_val, y_val), (X_test, y_test)\n",
        "\n",
        "\n",
        "# def setup_maximum_gpu_utilization() -> Tuple[int, float, float]:\n",
        "#     \"\"\"Setup GPU optimizations with proper error handling\"\"\"\n",
        "#     print(\"\\n\" + \"=\"*40)\n",
        "#     cprint(\"üöÄ SETTING UP MAXIMUM GPU UTILIZATION\", 'red', attrs=['bold'])\n",
        "#     print(\"=\"*40)\n",
        "\n",
        "#     gpu_memory_gb = 0.0\n",
        "#     if torch.cuda.is_available():\n",
        "#         # Aggressive GPU optimizations\n",
        "#         torch.cuda.empty_cache()\n",
        "#         torch.backends.cudnn.benchmark = True\n",
        "#         torch.backends.cudnn.deterministic = False\n",
        "#         torch.backends.cudnn.enabled = True\n",
        "\n",
        "#         # Maximum performance settings\n",
        "#         if hasattr(torch.backends.cuda.matmul, 'allow_tf32'):\n",
        "#             torch.backends.cuda.matmul.allow_tf32 = True\n",
        "#         if hasattr(torch.backends.cudnn, 'allow_tf32'):\n",
        "#             torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "#         # Fixed: Proper Flash Attention setup\n",
        "#         if hasattr(torch.backends.cuda, 'enable_flash_sdp'):\n",
        "#             torch.backends.cuda.enable_flash_sdp(True)\n",
        "\n",
        "#         # OPTIMIZATION: Use more aggressive GPU memory (increased to 95%)\n",
        "#         torch.cuda.set_per_process_memory_fraction(0.95)\n",
        "\n",
        "#         # Get GPU specifications\n",
        "#         for i in range(torch.cuda.device_count()):\n",
        "#             gpu_props = torch.cuda.get_device_properties(i)\n",
        "#             gpu_memory_gb = max(gpu_memory_gb, gpu_props.total_memory / 1e9)\n",
        "\n",
        "#             cprint(f\"üéÆ GPU {i}: {gpu_props.name}\", 'green', attrs=['bold'])\n",
        "#             print(f\"   Memory: {gpu_memory_gb:.1f}GB\")\n",
        "#             print(f\"   Compute: {gpu_props.major}.{gpu_props.minor}\")\n",
        "#             print(f\"   Cores: {gpu_props.multi_processor_count}\")\n",
        "\n",
        "#         # Set multi-GPU if available\n",
        "#         if torch.cuda.device_count() > 1:\n",
        "#             cprint(f\"üî• Using {torch.cuda.device_count()} GPUs!\", 'red', attrs=['bold'])\n",
        "#     else:\n",
        "#         cprint(\"‚ö†Ô∏è  No GPU available - using CPU only\", 'yellow', attrs=['bold'])\n",
        "\n",
        "#     # OPTIMIZATION: Conservative CPU optimizations to save RAM\n",
        "#     cpu_count = os.cpu_count()\n",
        "#     optimal_threads = min(cpu_count // 2, 8)  # More conservative to save CPU RAM\n",
        "\n",
        "#     torch.set_num_threads(optimal_threads)\n",
        "#     os.environ['OMP_NUM_THREADS'] = str(optimal_threads)\n",
        "#     os.environ['MKL_NUM_THREADS'] = str(optimal_threads)\n",
        "#     os.environ['NUMEXPR_NUM_THREADS'] = str(optimal_threads)\n",
        "\n",
        "#     # Memory information\n",
        "#     memory_info = psutil.virtual_memory()\n",
        "#     available_ram = memory_info.available / (1024**3)\n",
        "#     total_ram = memory_info.total / (1024**3)\n",
        "\n",
        "#     cprint(f\"üíª CPU: {cpu_count} cores (using {optimal_threads})\", 'blue', attrs=['bold'])\n",
        "#     cprint(f\"üß† RAM: {total_ram:.1f}GB total, {available_ram:.1f}GB available\", 'blue', attrs=['bold'])\n",
        "\n",
        "#     return optimal_threads, available_ram, gpu_memory_gb\n",
        "\n",
        "\n",
        "# def get_maximum_batch_sizes(model_name: str, available_ram_gb: float, gpu_memory_gb: float) -> Tuple[int, int]:\n",
        "#     \"\"\"Calculate maximum batch sizes for full GPU utilization - ENHANCED for better GPU usage\"\"\"\n",
        "\n",
        "#     # OPTIMIZATION: More aggressive base batch sizes for better GPU utilization\n",
        "#     base_batch_sizes = {\n",
        "#         'resnet50': {'train': 96, 'val': 192},           # Increased from 64/128\n",
        "#         'efficientnet_b0': {'train': 128, 'val': 256},   # Increased from 96/192\n",
        "#         'mobilenet_v3_large': {'train': 160, 'val': 320}, # Increased from 128/256\n",
        "#         'vgg16': {'train': 48, 'val': 96},               # Increased from 32/64\n",
        "#         'densenet121': {'train': 64, 'val': 128},        # Increased from 48/96\n",
        "#         'inception_v3': {'train': 56, 'val': 112},       # Increased from 40/80\n",
        "#         'vit_b_16': {'train': 48, 'val': 96},            # Increased from 32/64\n",
        "#         'convnext_base': {'train': 48, 'val': 96},       # Increased from 36/72\n",
        "#         'regnet_y_32gf': {'train': 32, 'val': 64}       # Increased from 24/48\n",
        "#     }\n",
        "\n",
        "#     # OPTIMIZATION: More aggressive GPU memory scaling\n",
        "#     if gpu_memory_gb >= 24:  # High-end GPU (RTX 4090, A100)\n",
        "#         gpu_multiplier = 2.5  # Increased from 1.8\n",
        "#     elif gpu_memory_gb >= 16:  # Mid-range GPU (RTX 4080, 3090)\n",
        "#         gpu_multiplier = 2.0  # Increased from 1.5\n",
        "#     elif gpu_memory_gb >= 12:  # RTX 4070Ti, 3080Ti\n",
        "#         gpu_multiplier = 1.7  # New tier\n",
        "#     elif gpu_memory_gb >= 8:   # Entry-level GPU (RTX 3070, 4060Ti)\n",
        "#         gpu_multiplier = 1.3  # Increased from 1.2\n",
        "#     else:\n",
        "#         gpu_multiplier = 1.0\n",
        "\n",
        "#     # RAM scaling - less conservative since we're prioritizing GPU\n",
        "#     ram_multiplier = min(1.5, available_ram_gb / 16)  # Reduced impact\n",
        "#     total_multiplier = gpu_multiplier * 0.8 + ram_multiplier * 0.2  # 80% GPU focus, 20% RAM\n",
        "\n",
        "#     model_key = model_name.lower()\n",
        "#     if model_key not in base_batch_sizes:\n",
        "#         model_key = 'resnet50'\n",
        "\n",
        "#     base_train = base_batch_sizes[model_key]['train']\n",
        "#     base_val = base_batch_sizes[model_key]['val']\n",
        "\n",
        "#     train_batch = int(base_train * total_multiplier)\n",
        "#     val_batch = int(base_val * total_multiplier)\n",
        "\n",
        "#     # OPTIMIZATION: Higher minimum viable sizes for better GPU utilization\n",
        "#     train_batch = max(32, train_batch)  # Increased from 16\n",
        "#     val_batch = max(64, val_batch)      # Increased from 32\n",
        "\n",
        "#     return train_batch, val_batch\n",
        "\n",
        "\n",
        "# class HyperparameterOptimizer:\n",
        "#     \"\"\"Enhanced hyperparameter optimizer with proper error handling\"\"\"\n",
        "\n",
        "#     def __init__(self, model_name: str, train_loader, val_loader, n_trials: int = 100,\n",
        "#                   train_batch_size: int = 64, val_batch_size: int = 128, X = None , Y = None ):\n",
        "#         self.model_name = model_name\n",
        "#         self.train_loader = train_loader\n",
        "#         self.val_loader = val_loader\n",
        "#         self.n_trials = n_trials\n",
        "#         self.train_batch_size = train_batch_size  # ADD THIS\n",
        "#         self.val_batch_size = val_batch_size      # ADD THIS\n",
        "#         self.X = X  # ADD THIS\n",
        "#         self.Y = Y  # ADD THIS\n",
        "\n",
        "#         # Set Google Drive path\n",
        "#         self.drive_path = '/content/drive/MyDrive/Hilsha'\n",
        "#         os.makedirs(self.drive_path, exist_ok=True)\n",
        "\n",
        "#         # Use all available GPUs\n",
        "#         if torch.cuda.is_available():\n",
        "#             self.device = torch.device('cuda:0')\n",
        "#             self.use_multi_gpu = torch.cuda.device_count() > 1\n",
        "#         else:\n",
        "#             self.device = torch.device('cpu')\n",
        "#             self.use_multi_gpu = False\n",
        "\n",
        "#         self.lock = Lock()\n",
        "#         self.best_accuracy = 0.0\n",
        "#         self.current_trial = 0\n",
        "\n",
        "#         # Track best trial information\n",
        "#         self.best_trial_info = {\n",
        "#             'trial_number': 0,\n",
        "#             'accuracy': 0.0,\n",
        "#             'train_loss': 0.0,\n",
        "#             'val_loss': 0.0,\n",
        "#             'train_acc': 0.0,\n",
        "#             'val_acc': 0.0,\n",
        "#             'train_f1': 0.0,\n",
        "#             'val_f1': 0.0,\n",
        "#             'hyperparameters': {}\n",
        "#         }\n",
        "\n",
        "#     def suggest_hyperparameters(self, trial) -> Dict[str, Any]:\n",
        "#         return {\n",
        "#             # More conservative learning rate range for better convergence\n",
        "#             'lr': trial.suggest_float('lr', 5e-6, 5e-3, log=True),\n",
        "\n",
        "#             # Wider weight decay range for better regularization\n",
        "#             'weight_decay': trial.suggest_float('weight_decay', 1e-7, 5e-2, log=True),\n",
        "\n",
        "#             # Add RMSprop which works well for many vision models\n",
        "#             'optimizer': trial.suggest_categorical('optimizer', ['adamw', 'adam', 'sgd', 'rmsprop']),\n",
        "\n",
        "#             # Add more scheduler options including warmup restart\n",
        "#             'scheduler': trial.suggest_categorical('scheduler', ['cosine', 'cosine_warm', 'step', 'plateau']),\n",
        "\n",
        "#             # Reduce label smoothing max for better accuracy\n",
        "#             'label_smoothing': trial.suggest_float('label_smoothing', 0.0, 0.15),\n",
        "\n",
        "#             # More conservative gradient clipping\n",
        "#             'gradient_clip': trial.suggest_float('gradient_clip', 0.5, 1.5),\n",
        "\n",
        "#             # Extended warmup range\n",
        "#             'warmup_epochs': trial.suggest_int('warmup_epochs', 0, 5),\n",
        "\n",
        "#             # Model-specific dropout based on architecture\n",
        "#             'dropout': self._get_model_specific_dropout(trial),\n",
        "\n",
        "#             # Flexible batch size multipliers\n",
        "#             # Get batch multipliers first\n",
        "#             'train_batch_multiplier': trial.suggest_categorical('train_batch_multiplier', [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]),\n",
        "#             'val_batch_multiplier': trial.suggest_categorical('val_batch_multiplier', [0.5, 0.75, 1.0, 1.25, 1.5, 2.0]),\n",
        "\n",
        "#             # Calculate and round to nearest power of 2 for GPU efficiency\n",
        "#             'train_batch_size': max(8, 2 ** round(__import__('math').log2(max(8, int(self.train_batch_size * trial.params['train_batch_multiplier']))))),\n",
        "#             'val_batch_size': max(16, 2 ** round(__import__('math').log2(max(16, int(self.val_batch_size * trial.params['val_batch_multiplier'])))))\n",
        "#         }\n",
        "\n",
        "#     def _get_model_specific_dropout(self, trial):\n",
        "#         \"\"\"Get model-specific dropout ranges\"\"\"\n",
        "#         if 'vgg' in self.model_name.lower():\n",
        "#             # VGG needs higher dropout\n",
        "#             return trial.suggest_float('dropout', 0.3, 0.7)\n",
        "#         elif 'mobilenet' in self.model_name.lower():\n",
        "#             # MobileNet is already regularized\n",
        "#             return trial.suggest_float('dropout', 0.1, 0.4)\n",
        "#         elif 'efficientnet' in self.model_name.lower():\n",
        "#             # EfficientNet has built-in regularization\n",
        "#             return trial.suggest_float('dropout', 0.1, 0.4)\n",
        "#         elif 'inception' in self.model_name.lower():\n",
        "#             # Inception needs moderate dropout\n",
        "#             return trial.suggest_float('dropout', 0.2, 0.5)\n",
        "#         else:\n",
        "#             # ResNet, DenseNet - standard range\n",
        "#             return trial.suggest_float('dropout', 0.1, 0.5)\n",
        "\n",
        "#     def create_model_with_params(self, params: Dict[str, Any]):\n",
        "#         \"\"\"Create model with parameters - you need to implement this\"\"\"\n",
        "#         # This is a placeholder - implement your model creation logic\n",
        "#         try:\n",
        "#             # from your_model_module import ModelFactory  # Replace with actual import\n",
        "#             model = ModelFactory.create_model(self.model_name, params)\n",
        "#             if self.use_multi_gpu:\n",
        "#                 model = nn.DataParallel(model)\n",
        "#             return model.to(self.device)\n",
        "#         except ImportError:\n",
        "#             raise ImportError(\"ModelFactory not found. Please ensure it is imported.\")\n",
        "#         except Exception as e:\n",
        "#             raise Exception(f\"Error creating model: {e}\")\n",
        "\n",
        "#     def display_hyperparameters(self, trial_num: int, params: Dict[str, Any]):\n",
        "#         \"\"\"Display hyperparameters in a formatted way\"\"\"\n",
        "#         print(\"\\n\" + \"üîß\" * 40)\n",
        "#         cprint(f\"üìã TRIAL {trial_num} HYPERPARAMETERS - {self.model_name.upper()}\", 'cyan', attrs=['bold'])\n",
        "#         print(\"üîß\" * 40)\n",
        "\n",
        "#         # Display batch configuration with multipliers\n",
        "#         cprint(\"  üéØ BATCH CONFIGURATION:\", 'yellow', attrs=['bold'])\n",
        "#         print(f\"    üîπ {'base_train_batch':<20}: {self.train_batch_size}\")\n",
        "#         print(f\"    üîπ {'train_multiplier':<20}: {params.get('train_batch_multiplier', 1.0)}\")\n",
        "#         print(f\"    üîπ {'final_train_batch':<20}: {params['train_batch_size']}\")\n",
        "#         print(f\"    üîπ {'base_val_batch':<20}: {self.val_batch_size}\")\n",
        "#         print(f\"    üîπ {'val_multiplier':<20}: {params.get('val_batch_multiplier', 1.0)}\")\n",
        "#         print(f\"    üîπ {'final_val_batch':<20}: {params['val_batch_size']}\")\n",
        "\n",
        "#         # Display other hyperparameters\n",
        "#         cprint(\"  üéØ HYPERPARAMETERS:\", 'yellow', attrs=['bold'])\n",
        "#         skip_keys = ['train_batch_size', 'val_batch_size', 'train_batch_multiplier', 'val_batch_multiplier']\n",
        "#         for key, value in params.items():\n",
        "#             if key not in skip_keys:\n",
        "#                 if isinstance(value, float):\n",
        "#                     print(f\"    üîπ {key:<20}: {value:.8f}\")\n",
        "#                 else:\n",
        "#                     print(f\"    üîπ {key:<20}: {value}\")\n",
        "#         print(\"üîß\" * 40)\n",
        "\n",
        "#     def display_best_trial_status(self):\n",
        "#         \"\"\"Display current best trial information\"\"\"\n",
        "#         # print(\"\\n\" + \"üèÜ\" * 40)\n",
        "#         cprint(f\"üëë CURRENT BEST TRIAL STATUS - {self.model_name.upper()}\", 'red', attrs=['bold'])\n",
        "#         print(\"üèÜ\" * 40)\n",
        "\n",
        "#         if self.best_trial_info['trial_number'] > 0:\n",
        "#             cprint(f\"  ü•á Best Trial : #{self.best_trial_info['trial_number']}\", 'yellow', attrs=['bold'])\n",
        "#             cprint(f\"  üéØ Best Accuracy: {self.best_trial_info['accuracy']:.4f}%\", 'green', attrs=['bold'])\n",
        "\n",
        "#             # Display metrics\n",
        "#             print(f\"  üìä METRICS:\")\n",
        "#             print(f\"    üî∏ Train Loss:     {self.best_trial_info['train_loss']:.6f}\")\n",
        "#             print(f\"    üî∏ Val Loss:       {self.best_trial_info['val_loss']:.6f}\")\n",
        "#             print(f\"    üî∏ Train Accuracy: {self.best_trial_info['train_acc']:.4f}%\")\n",
        "#             print(f\"    üî∏ Val Accuracy:   {self.best_trial_info['val_acc']:.4f}%\")\n",
        "#             print(f\"    üî∏ Train F1:       {self.best_trial_info['train_f1']:.4f}%\")\n",
        "#             print(f\"    üî∏ Val F1:         {self.best_trial_info['val_f1']:.4f}%\")\n",
        "#         else:\n",
        "#             cprint(\"  üîÑ No trials completed yet\", 'yellow')\n",
        "\n",
        "#         # print(\"üèÜ\" * 80)\n",
        "\n",
        "#     def create_optimizer_and_scheduler(self, model, params: Dict[str, Any], steps_per_epoch: int):\n",
        "#         \"\"\"Create optimizer and scheduler with GPU optimizations\"\"\"\n",
        "\n",
        "#         # Create optimizer\n",
        "#         if params['optimizer'] == 'adamw':\n",
        "#             optimizer = torch.optim.AdamW(\n",
        "#                 model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'],\n",
        "#                 betas=(0.9, 0.999), eps=1e-8\n",
        "#             )\n",
        "#         elif params['optimizer'] == 'adam':\n",
        "#             optimizer = torch.optim.Adam(\n",
        "#                 model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'],\n",
        "#                 betas=(0.9, 0.999), eps=1e-8\n",
        "#             )\n",
        "#         elif params['optimizer'] == 'sgd':\n",
        "#             optimizer = torch.optim.SGD(\n",
        "#                 model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'],\n",
        "#                 momentum=0.9, nesterov=True\n",
        "#             )\n",
        "#         else:  # rmsprop\n",
        "#             optimizer = torch.optim.RMSprop(\n",
        "#                 model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'],\n",
        "#                 momentum=0.9, alpha=0.99\n",
        "#             )\n",
        "\n",
        "#         # Create scheduler\n",
        "#         if params['scheduler'] == 'cosine':\n",
        "#             scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=8)\n",
        "#         elif params['scheduler'] == 'cosine_warm':\n",
        "#             scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=2)\n",
        "#         elif params['scheduler'] == 'step':\n",
        "#             scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.7)\n",
        "#         else:  # plateau\n",
        "#             scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "#                 optimizer, mode='max', patience=2, factor=0.5\n",
        "#             )\n",
        "\n",
        "#         return optimizer, scheduler\n",
        "\n",
        "#     def train_and_validate(self, model, params: Dict[str, Any], train_loader, val_loader, epochs: int=None, trial=None) -> Tuple[float, Dict]:\n",
        "#         #Enhanced training with comprehensive metrics and GPU utilization\n",
        "#         if epochs is None:\n",
        "#             epochs = Config.OPTUNA_EPOCHS\n",
        "\n",
        "#         steps_per_epoch = len(train_loader)\n",
        "#         optimizer, scheduler = self.create_optimizer_and_scheduler(model, params, steps_per_epoch)\n",
        "#         criterion = nn.CrossEntropyLoss(label_smoothing=params.get('label_smoothing', 0.0))\n",
        "#         scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
        "\n",
        "#         # OPTIMIZATION: Enable aggressive GPU optimizations\n",
        "#         if torch.cuda.is_available():\n",
        "#             torch.backends.cudnn.benchmark = True\n",
        "#             torch.backends.cudnn.deterministic = False\n",
        "#             # Reset peak memory stats for accurate monitoring\n",
        "#             torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "#         # OPTIMIZATION: Use larger gradient accumulation for better GPU utilization\n",
        "#         gradient_accumulation_steps = max(1, 128 // params.get('train_batch_size', train_loader.batch_size))\n",
        "\n",
        "#         best_val_acc = 0.0\n",
        "#         metrics_history = []\n",
        "#         patience = 0  # ‡¶≤‡ßÅ‡¶™‡ßá‡¶∞ ‡¶¨‡¶æ‡¶á‡¶∞‡ßá initialize\n",
        "#         epoch_best_f1 = 0.0\n",
        "\n",
        "#         for epoch in range(epochs):\n",
        "#             # OPTIMIZATION: Aggressive memory cleanup each epoch\n",
        "#             if torch.cuda.is_available():\n",
        "#                 torch.cuda.empty_cache()\n",
        "\n",
        "#             # Training phase\n",
        "#             model.train()\n",
        "#             train_loss = 0.0\n",
        "#             train_correct = 0\n",
        "#             train_total = 0\n",
        "#             train_preds = []\n",
        "#             train_targets = []\n",
        "\n",
        "#             accumulated_loss = 0\n",
        "\n",
        "#             train_pbar = tqdm(\n",
        "#                 train_loader,\n",
        "#                 desc=f\"  üèÉ Epoch {epoch+1:2d} Train\",\n",
        "#                 leave=False,\n",
        "#                 ncols=100\n",
        "#             )\n",
        "\n",
        "#             for batch_idx, (data, targets) in enumerate(train_pbar):\n",
        "#                 data, targets = data.to(self.device, non_blocking=True), targets.to(self.device, non_blocking=True)\n",
        "\n",
        "#                 if scaler and torch.cuda.is_available():\n",
        "#                     # OPTIMIZATION: More aggressive mixed precision usage\n",
        "#                     with torch.cuda.amp.autocast(enabled=True):\n",
        "#                         outputs = model(data)\n",
        "#                         loss = criterion(outputs, targets) / gradient_accumulation_steps\n",
        "\n",
        "#                     scaler.scale(loss).backward()\n",
        "#                     accumulated_loss += loss.item()\n",
        "\n",
        "#                     # OPTIMIZATION: Better gradient accumulation for larger effective batch size\n",
        "#                     if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
        "#                         scaler.unscale_(optimizer)\n",
        "#                         torch.nn.utils.clip_grad_norm_(model.parameters(), params.get('gradient_clip', 1.0))\n",
        "#                         scaler.step(optimizer)\n",
        "#                         scaler.update()\n",
        "#                         optimizer.zero_grad()\n",
        "#                 else:\n",
        "#                     outputs = model(data)\n",
        "#                     loss = criterion(outputs, targets) / gradient_accumulation_steps\n",
        "#                     loss.backward()\n",
        "\n",
        "#                     if (batch_idx + 1) % gradient_accumulation_steps == 0:\n",
        "#                         torch.nn.utils.clip_grad_norm_(model.parameters(), params.get('gradient_clip', 1.0))\n",
        "#                         optimizer.step()\n",
        "#                         optimizer.zero_grad()\n",
        "\n",
        "#                 # Metrics calculation\n",
        "#                 train_loss += loss.item() * gradient_accumulation_steps * data.size(0)\n",
        "#                 _, predicted = torch.max(outputs, 1)\n",
        "#                 train_total += targets.size(0)\n",
        "#                 train_correct += (predicted == targets).sum().item()\n",
        "\n",
        "#                 train_preds.extend(predicted.cpu().numpy())\n",
        "#                 train_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "#                 # Update progress bar\n",
        "#                 current_acc = 100 * train_correct / train_total\n",
        "#                 train_pbar.set_postfix({\n",
        "#                     'Loss': f'{loss.item() * gradient_accumulation_steps:.4f}',\n",
        "#                     'Acc': f'{current_acc:.2f}%'\n",
        "#                 })\n",
        "\n",
        "#             # Validation phase\n",
        "#             model.eval()\n",
        "#             val_loss = 0.0\n",
        "#             val_correct = 0\n",
        "#             val_total = 0\n",
        "#             val_preds = []\n",
        "#             val_targets = []\n",
        "\n",
        "#             with torch.no_grad():\n",
        "#                 for data, targets in val_loader:\n",
        "#                     data, targets = data.to(self.device, non_blocking=True), targets.to(self.device, non_blocking=True)\n",
        "\n",
        "#                     if scaler and torch.cuda.is_available():\n",
        "#                         with torch.cuda.amp.autocast():\n",
        "#                             outputs = model(data)\n",
        "#                             loss = criterion(outputs, targets)\n",
        "#                     else:\n",
        "#                         outputs = model(data)\n",
        "#                         loss = criterion(outputs, targets)\n",
        "\n",
        "#                     val_loss += loss.item() * data.size(0)\n",
        "#                     _, predicted = torch.max(outputs, 1)\n",
        "#                     val_total += targets.size(0)\n",
        "#                     val_correct += (predicted == targets).sum().item()\n",
        "\n",
        "#                     val_preds.extend(predicted.cpu().numpy())\n",
        "#                     val_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "#             # Calculate metrics\n",
        "#             train_accuracy = 100 * train_correct / train_total\n",
        "#             val_accuracy = 100 * val_correct / val_total\n",
        "#             avg_train_loss = train_loss / train_total\n",
        "#             avg_val_loss = val_loss / val_total\n",
        "\n",
        "#             train_f1 = f1_score(train_targets, train_preds, average='weighted') * 100\n",
        "#             val_f1 = f1_score(val_targets, val_preds, average='weighted') * 100\n",
        "\n",
        "#             val_wrong = val_total - val_correct\n",
        "\n",
        "#             # Print epoch results\n",
        "#             print(f\"    üìä TL:{avg_train_loss:.4f} VL:{avg_val_loss:.4f} | \" +\n",
        "#                   f\"TA:{train_accuracy:.2f}% VA:{val_accuracy:.2f}% | \" +\n",
        "#                   f\"TF1:{train_f1:.2f}% VF1:{val_f1:.2f}% | \" +\n",
        "#                   f\"WP:{val_wrong}\")\n",
        "\n",
        "#             # Store metrics\n",
        "#             epoch_metrics = {\n",
        "#                 'epoch': epoch + 1,\n",
        "#                 'train_loss': avg_train_loss,\n",
        "#                 'val_loss': avg_val_loss,\n",
        "#                 'train_acc': train_accuracy,\n",
        "#                 'val_acc': val_accuracy,\n",
        "#                 'train_f1': train_f1,\n",
        "#                 'val_f1': val_f1,\n",
        "#                 'wrong_predictions': val_wrong\n",
        "#             }\n",
        "#             metrics_history.append(epoch_metrics)\n",
        "\n",
        "#             # Update best accuracy\n",
        "#             if val_accuracy > best_val_acc:\n",
        "#                 best_val_acc = val_accuracy\n",
        "\n",
        "#             # Update scheduler\n",
        "#             if params['scheduler'] == 'plateau':\n",
        "#                 scheduler.step(val_accuracy)\n",
        "#             else:\n",
        "#                 scheduler.step()\n",
        "\n",
        "#             # Early stopping for optimization speed\n",
        "#             if epoch+1 >= 5 and val_accuracy < 50.0:\n",
        "#                 print(f\"‚ö†Ô∏è Early stopping cause epoch {epoch+1} but still not satisfactory accuracy obtain.\")\n",
        "#                 break\n",
        "\n",
        "#             # Early stopping for not improvement\n",
        "#             if val_f1 > epoch_best_f1 * 1.001:  # improvement condition (0.1% increment)\n",
        "#                 epoch_best_f1 = val_f1\n",
        "#                 patience = 0  # reset patience, ‡¶ï‡¶æ‡¶∞‡¶£ improvement ‡¶π‡¶Ø‡¶º‡ßá‡¶õ‡ßá\n",
        "#             else:\n",
        "#                 patience += 1  # no improvement, patience ‡¶¨‡¶æ‡¶°‡¶º‡¶æ‡¶ì\n",
        "#             if patience > Config.PATIENCE:\n",
        "#                 print(f\"‚ö†Ô∏è Early stopping: No improvement for {Config.PATIENCE} consecutive epochs\")\n",
        "#                 break\n",
        "\n",
        "#             #Early stopping for trial level pruning\n",
        "#             # Report intermediate value for pruning\n",
        "#             if trial is not None:\n",
        "#                 trial.report(val_accuracy, epoch)\n",
        "#                 # Check if trial should be pruned\n",
        "#                 if trial.should_prune():\n",
        "#                     print(f\"    ‚ö†Ô∏è Early stopping at epoch {epoch+1}: Low accuracy probability detected\")\n",
        "#                     print(f\"    üîÑ Pruning trial - proceeding to next hyperparameter combination\")\n",
        "#                     raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "#         return best_val_acc, {'history': metrics_history, 'best_epoch_metrics': max(metrics_history, key=lambda x: x['val_acc'])}\n",
        "\n",
        "#     def objective(self, trial) -> float:\n",
        "#       \"\"\"Enhanced objective function with detailed progress tracking\"\"\"\n",
        "#       self.current_trial += 1\n",
        "\n",
        "#       print(\"\\n\" + \"‚ñà\" * 100)\n",
        "#       cprint(f\"üî• TRIAL {self.current_trial:3d}/{self.n_trials} STARTING - {self.model_name.upper()}\", 'red', attrs=['bold'])\n",
        "#       print(\"‚ñà\" * 100)\n",
        "\n",
        "#       try:\n",
        "#           with self.lock:\n",
        "#               if torch.cuda.is_available():\n",
        "#                   torch.cuda.empty_cache()\n",
        "#                   for i in range(torch.cuda.device_count()):\n",
        "#                       memory_used = torch.cuda.memory_allocated(i) / 1e9\n",
        "#                       memory_total = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
        "#                       print(f\"  üéÆ GPU {i}: {memory_used:.1f}/{memory_total:.1f}GB ({memory_used/memory_total*100:.1f}%)\")\n",
        "#               gc.collect()\n",
        "\n",
        "#           # Get hyperparameters\n",
        "#           params = self.suggest_hyperparameters(trial)\n",
        "#           self.display_hyperparameters(self.current_trial, params)\n",
        "\n",
        "#           # Recreate data loaders with new batch sizes if they differ significantly\n",
        "#           current_train_batch = params['train_batch_size']\n",
        "#           current_val_batch = params['val_batch_size']\n",
        "\n",
        "#           # Only recreate loaders if batch size changed significantly\n",
        "#           if (abs(current_train_batch - self.train_loader.batch_size) > 8 or\n",
        "#               abs(current_val_batch - self.val_loader.batch_size) > 16):\n",
        "\n",
        "#               train_loader, val_loader, _, _, _ = Optuna_DataManager.create_data_loaders(\n",
        "#                   self.X, self.Y,\n",
        "#                   train_batch_size=current_train_batch,\n",
        "#                   val_batch_size=current_val_batch,\n",
        "#                   num_workers=4,  # OPTIMIZATION: Reduced workers to save CPU RAM\n",
        "#                   pin_memory=True,\n",
        "#                   persistent_workers=True\n",
        "#               )\n",
        "#               using_new_loaders = True  # ADD THIS FLAG\n",
        "#           else:\n",
        "#               train_loader = self.train_loader\n",
        "#               val_loader = self.val_loader\n",
        "#               using_new_loaders = False  # ADD THIS FLAG\n",
        "\n",
        "#           # Create and train model\n",
        "#           model = self.create_model_with_params(params)\n",
        "#           best_acc, detailed_metrics = self.train_and_validate(\n",
        "#               model, params, train_loader, val_loader, trial=trial  # PASS THE LOADERS\n",
        "#           )\n",
        "\n",
        "#           # SUCCESS HANDLING - Move this BEFORE the except blocks\n",
        "#           best_epoch_metrics = detailed_metrics['best_epoch_metrics']\n",
        "\n",
        "#           # Trial completion summary\n",
        "#           print(\"  \" + \"‚îÄ\" * 80)\n",
        "#           cprint(f\"  ‚úÖ TRIAL {self.current_trial} COMPLETED\", 'green', attrs=['bold'])\n",
        "#           cprint(f\"  üéØ Highest Validation Accuracy for this Trial: {best_acc:.4f}%\", 'yellow', attrs=['bold'])\n",
        "\n",
        "#           # Update best trial info if this is better\n",
        "#           if best_acc > self.best_accuracy:\n",
        "#               self.best_accuracy = best_acc\n",
        "#               self.best_trial_info = {\n",
        "#                   'trial_number': self.current_trial,\n",
        "#                   'accuracy': best_acc,\n",
        "#                   'train_loss': best_epoch_metrics['train_loss'],\n",
        "#                   'val_loss': best_epoch_metrics['val_loss'],\n",
        "#                   'train_acc': best_epoch_metrics['train_acc'],\n",
        "#                   'val_acc': best_epoch_metrics['val_acc'],\n",
        "#                   'train_f1': best_epoch_metrics['train_f1'],\n",
        "#                   'val_f1': best_epoch_metrics['val_f1'],\n",
        "#                   'hyperparameters': params.copy()\n",
        "#               }\n",
        "#               cprint(f\"  üèÜ NEW BEST ACCURACY: {best_acc:.4f}%\", 'red', attrs=['bold'])\n",
        "#               # Save immediately to Google Drive only\n",
        "#               self.save_best_params_immediately()\n",
        "\n",
        "#           self.display_best_trial_status()\n",
        "\n",
        "#           # OPTIMIZATION: Cleanup - ADD LOADER CLEANUP\n",
        "#           del model\n",
        "#           if using_new_loaders:  # Clean up new loaders if created\n",
        "#               del train_loader, val_loader\n",
        "#           if torch.cuda.is_available():\n",
        "#               torch.cuda.empty_cache()\n",
        "#           gc.collect()\n",
        "\n",
        "#           return best_acc\n",
        "\n",
        "#       except optuna.exceptions.TrialPruned:\n",
        "#           cprint(f\"  ‚úÇÔ∏è TRIAL {self.current_trial} PRUNED: Low accuracy probability detected\", 'yellow', attrs=['bold'])\n",
        "#           cprint(f\"  üîÑ Skipping to next hyperparameter combination for efficiency\", 'cyan')\n",
        "#           # Cleanup\n",
        "#           if 'model' in locals():\n",
        "#               del model\n",
        "#           if 'using_new_loaders' in locals() and using_new_loaders:\n",
        "#               if 'train_loader' in locals():\n",
        "#                   del train_loader\n",
        "#               if 'val_loader' in locals():\n",
        "#                   del val_loader\n",
        "#           if torch.cuda.is_available():\n",
        "#               torch.cuda.empty_cache()\n",
        "#           gc.collect()\n",
        "#           raise  # Re-raise the TrialPruned exception\n",
        "\n",
        "#       except Exception as e:\n",
        "#           cprint(f\"  ‚ùå TRIAL {self.current_trial} FAILED: {e}\", 'red', attrs=['bold'])\n",
        "#           cprint(f\"  üìã Error Details: {traceback.format_exc()}\", 'yellow')\n",
        "#           # Cleanup\n",
        "#           if 'model' in locals():\n",
        "#               del model\n",
        "#           if 'using_new_loaders' in locals() and using_new_loaders:\n",
        "#               if 'train_loader' in locals():\n",
        "#                   del train_loader\n",
        "#               if 'val_loader' in locals():\n",
        "#                   del val_loader\n",
        "#           if torch.cuda.is_available():\n",
        "#               torch.cuda.empty_cache()\n",
        "#           gc.collect()\n",
        "#           return 0.0\n",
        "\n",
        "#     def optimize(self) -> Dict[str, Any]:\n",
        "#         \"\"\"Run optimization with enhanced progress tracking\"\"\"\n",
        "\n",
        "#         # print(\"\\n\" + \"üöÄ\" *20)\n",
        "#         cprint(f\"STARTING HYPERPARAMETER OPTIMIZATION FOR {self.model_name.upper()}\", 'red', attrs=['bold'])\n",
        "#         print(\"üöÄ\" * 20)\n",
        "\n",
        "#         # Create study\n",
        "#         study = optuna.create_study(\n",
        "#             direction='maximize',\n",
        "#             sampler=optuna.samplers.TPESampler(\n",
        "#                 # OPTIMIZATION: Reduced startup trials to save time and CPU\n",
        "#                 n_startup_trials = max(10, self.n_trials // 8),  # Reduced from n_trials // 6\n",
        "#                 # Example: If you set n_startup_trials=10, the first 10 trials will be random, then trial 11 onwards will use TPE-guided sampling.\n",
        "#                 n_ei_candidates=24,  # Reduced from 32 to save CPU\n",
        "#                 constant_liar=True,\n",
        "#                 multivariate=True\n",
        "#             ),\n",
        "#             # Sampler's n_startup_trials ‚Üí when TPE optimization begins.\n",
        "#             # Pruner's n_startup_trials ‚Üí how many full trials to finish before pruning starts.\n",
        "#             # Pruner's n_warmup_steps ‚Üí how many epochs per trial to protect before pruning checks.\n",
        "#             pruner=optuna.pruners.MedianPruner(\n",
        "#                 # OPTIMIZATION: More aggressive pruning to save resources\n",
        "#                 n_startup_trials = max(6, self.n_trials //12),  # More aggressive\n",
        "#                 n_warmup_steps=2,    # Reduced from 3\n",
        "#                 interval_steps=1\n",
        "#             )\n",
        "#         )\n",
        "\n",
        "#         # Run optimization with early stopping check\n",
        "#         cprint(f\"üéØ Target: {self.n_trials} trials\", 'cyan', attrs=['bold'])\n",
        "#         for trial_num in range(self.n_trials):\n",
        "#             try:\n",
        "#                 study.optimize(self.objective, timeout=None, n_jobs=1, n_trials=1)\n",
        "\n",
        "#                 # Check for early stopping after each trial\n",
        "#                 if self.best_accuracy >= 99.5:\n",
        "#                     cprint(f\"\\nüéØ TARGET ACCURACY ACHIEVED!\", 'red', attrs=['bold'])\n",
        "#                     cprint(f\"üèÜ Best Accuracy: {self.best_accuracy:.4f}% >= 99.5%\", 'green', attrs=['bold'])\n",
        "#                     cprint(f\"‚ö° Stopping optimization early after {self.current_trial} trials\", 'yellow', attrs=['bold'])\n",
        "#                     cprint(f\"üöÄ Moving to next model for maximum efficiency!\", 'cyan', attrs=['bold'])\n",
        "#                     break\n",
        "\n",
        "#             except KeyboardInterrupt:\n",
        "#                 cprint(f\"\\n‚ö†Ô∏è Optimization interrupted by user\", 'yellow', attrs=['bold'])\n",
        "#                 break\n",
        "#             except Exception as e:\n",
        "#                 cprint(f\"‚ö†Ô∏è Trial failed: {e}\", 'red')\n",
        "#                 continue\n",
        "\n",
        "#         # Final results\n",
        "#         print(\"\\n\" + \"üèÅ\" * 40)\n",
        "#         if self.best_accuracy >= 99.5:\n",
        "#             cprint(f\"üéØ OPTIMIZATION COMPLETED - TARGET ACHIEVED!\", 'green', attrs=['bold'])\n",
        "#             cprint(f\"‚ö° Completed in {self.current_trial} trials (saved {self.n_trials - self.current_trial} trials)\", 'yellow', attrs=['bold'])\n",
        "#         else:\n",
        "#             cprint(f\"OPTIMIZATION COMPLETED FOR {self.model_name.upper()}\", 'green', attrs=['bold'])\n",
        "\n",
        "#         cprint(f\"üèÜ OPTIMIZATION BEST ACCURACY: {self.best_accuracy:.4f}%\", 'red', attrs=['bold'])\n",
        "#         print(\"üèÅ\" * 40)\n",
        "\n",
        "#         return study.best_params if study.best_params else {}\n",
        "\n",
        "#     def save_best_params_immediately(self) -> None:\n",
        "#         \"\"\"Save best parameters immediately to Google Drive only\"\"\"\n",
        "#         if self.best_trial_info['trial_number'] == 0:\n",
        "#             return\n",
        "\n",
        "#         # Google Drive save only\n",
        "#         drive_file = f\"{self.drive_path}/{self.model_name}_best_params_trial_{self.best_trial_info['trial_number']}.json\"\n",
        "\n",
        "#         results_with_meta = {\n",
        "#             'model_name': self.model_name,\n",
        "#             'trial_number': self.best_trial_info['trial_number'],\n",
        "#             'accuracy': self.best_trial_info['accuracy'],\n",
        "#             'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "#             'metrics': {\n",
        "#                 'train_loss': self.best_trial_info['train_loss'],\n",
        "#                 'val_loss': self.best_trial_info['val_loss'],\n",
        "#                 'train_acc': self.best_trial_info['train_acc'],\n",
        "#                 'val_acc': self.best_trial_info['val_acc'],\n",
        "#                 'train_f1': self.best_trial_info['train_f1'],\n",
        "#                 'val_f1': self.best_trial_info['val_f1']\n",
        "#             },\n",
        "#             'hyperparameters': self.best_trial_info['hyperparameters']\n",
        "#         }\n",
        "\n",
        "#         # Save to Google Drive only\n",
        "#         with open(drive_file, 'w') as f:\n",
        "#             json.dump(results_with_meta, f, indent=4, sort_keys=True)\n",
        "\n",
        "#         cprint(f\"  ‚òÅÔ∏è Best params saved to Drive: {drive_file}\", 'green')\n",
        "\n",
        "# def optimize_single_model(model_name: str, config: Dict[str, Any]) -> Dict[str, Any]:\n",
        "#     \"\"\"Optimize single model with maximum GPU utilization\"\"\"\n",
        "\n",
        "#     print(\"\\n\" + \"‚ö°\" * 50)\n",
        "#     cprint(f\"OPTIMIZING {model_name.upper()}\", 'red', attrs=['bold'])\n",
        "#     print(\"‚ö°\" * 50)\n",
        "\n",
        "#     try:\n",
        "#         # Setup environment\n",
        "#         optimal_threads, available_ram, gpu_memory_gb = setup_maximum_gpu_utilization()\n",
        "\n",
        "#         # Get maximum batch sizes\n",
        "#         train_batch_size, val_batch_size = get_maximum_batch_sizes(\n",
        "#             model_name, available_ram, gpu_memory_gb\n",
        "#         )\n",
        "\n",
        "#         cprint(f\"üéØ Maximum Batch Sizes - Train: {train_batch_size}, Val: {val_batch_size}\", 'green', attrs=['bold'])\n",
        "\n",
        "#         # Create data loaders with reduced workers to save CPU RAM\n",
        "#         train_loader, val_loader, test_loader, val_data, test_data = Optuna_DataManager.create_data_loaders(\n",
        "#             config['X'], config['Y'],\n",
        "#             train_batch_size=train_batch_size,\n",
        "#             val_batch_size=val_batch_size,\n",
        "#             num_workers=optimal_threads//2,  # OPTIMIZATION: Reduced workers\n",
        "#             pin_memory=True,\n",
        "#             persistent_workers=True\n",
        "#         )\n",
        "\n",
        "#         # Run optimization\n",
        "#         optimizer = HyperparameterOptimizer(\n",
        "#             model_name, train_loader, val_loader,\n",
        "#             n_trials=Config.OPTUNA_TRIALS,\n",
        "#             train_batch_size=train_batch_size,\n",
        "#             val_batch_size=val_batch_size,\n",
        "#             X=config['X'],\n",
        "#             Y=config['Y']\n",
        "#         )\n",
        "\n",
        "#         best_params = optimizer.optimize()\n",
        "\n",
        "#         # OPTIMIZATION: Cleanup\n",
        "#         del optimizer, train_loader, val_loader, test_loader\n",
        "#         if torch.cuda.is_available():\n",
        "#             torch.cuda.empty_cache()\n",
        "#         gc.collect()\n",
        "\n",
        "#         return best_params\n",
        "\n",
        "#     except Exception as e:\n",
        "#         cprint(f\"‚ùå OPTIMIZATION FAILED FOR {model_name}: {e}\", 'red', attrs=['bold'])\n",
        "#         cprint(f\"üìã Error: {traceback.format_exc()}\", 'yellow')\n",
        "#         return {}\n",
        "\n",
        "# def parallel_hyperparameter_optimization(model_configs: Dict[str, Any], max_workers: int = 1) -> Dict[str, Any]:\n",
        "#     # Run optimization with sequential processing for maximum GPU utilization\n",
        "\n",
        "#     results = {}\n",
        "\n",
        "#     # print(\"\\n\" + \"üé™\" * 40)\n",
        "#     cprint(\"STARTING PARALLEL HYPERPARAMETER OPTIMIZATION\", 'red', attrs=['bold'])\n",
        "#     # print(\"üé™\" * 50)\n",
        "\n",
        "#     # Sequential processing for maximum GPU utilization per model\n",
        "#     for i, (model_name, config) in enumerate(model_configs.items(), 1):\n",
        "#         cprint(f\"\\nüìç MODEL {i}/{len(model_configs)}: {model_name.upper()}\", 'cyan', attrs=['bold'])\n",
        "\n",
        "#         try:\n",
        "#             best_params = optimize_single_model(model_name, config)\n",
        "#             results[model_name] = best_params\n",
        "\n",
        "#             if best_params:\n",
        "#                 cprint(f\"‚úÖ {model_name.upper()} OPTIMIZATION COMPLETED!\", 'green', attrs=['bold'])\n",
        "#             else:\n",
        "#                 cprint(f\"‚ùå {model_name.upper()} OPTIMIZATION FAILED!\", 'red', attrs=['bold'])\n",
        "\n",
        "#         except Exception as e:\n",
        "#             cprint(f\"‚ùå {model_name.upper()} CRASHED: {e}\", 'red', attrs=['bold'])\n",
        "#             results[model_name] = {}\n",
        "\n",
        "#         # OPTIMIZATION: Aggressive cleanup between models\n",
        "#         if torch.cuda.is_available():\n",
        "#             torch.cuda.empty_cache()\n",
        "#             torch.cuda.reset_peak_memory_stats()\n",
        "#         gc.collect()\n",
        "\n",
        "#     return results\n",
        "\n",
        "# def save_optimization_results(results: Dict[str, Any]) -> None:\n",
        "#     \"\"\"Save optimization results to Google Drive only\"\"\"\n",
        "\n",
        "#     # Set Google Drive path\n",
        "#     drive_path = '/content/drive/MyDrive/Hilsha/hyper-parameters'\n",
        "#     os.makedirs(f\"{drive_path}/hyperparameters\", exist_ok=True)\n",
        "\n",
        "#     print(\"\\n\" + \"üíæ\" * 50)\n",
        "#     cprint(\"SAVING OPTIMIZATION RESULTS TO GOOGLE DRIVE\", 'cyan', attrs=['bold'])\n",
        "#     print(\"üíæ\" * 50)\n",
        "\n",
        "#     # Save individual model results\n",
        "#     successful_models = 0\n",
        "#     for model_name, best_params in results.items():\n",
        "#         if best_params:\n",
        "#             # Google Drive save only\n",
        "#             drive_file = f\"{drive_path}/hyperparameters/{model_name}_best_params.json\"\n",
        "\n",
        "#             # Enhanced metadata\n",
        "#             results_with_meta = {\n",
        "#                 'model_name': model_name,\n",
        "#                 'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "#                 'gpu_optimized': True,\n",
        "#                 'hyperparameters': best_params,\n",
        "#                 'optimization_config': {\n",
        "#                     'framework': 'optuna',\n",
        "#                     'sampler': 'TPE_Multivariate',\n",
        "#                     'pruner': 'Median',\n",
        "#                     'trials': 40,\n",
        "#                     'gpu_acceleration': torch.cuda.is_available(),\n",
        "#                     'multi_gpu': torch.cuda.device_count() > 1 if torch.cuda.is_available() else False\n",
        "#                 }\n",
        "#             }\n",
        "\n",
        "#             with open(drive_file, 'w') as f:\n",
        "#                 json.dump(results_with_meta, f, indent=4, sort_keys=True)\n",
        "\n",
        "#             cprint(f\"‚úÖ {model_name.upper()} parameters saved to Google Drive!\", 'green')\n",
        "\n",
        "#             # Display best parameters\n",
        "#             print(f\"  üìã {model_name.upper()} BEST PARAMETERS:\")\n",
        "#             for key, value in best_params.items():\n",
        "#                 if isinstance(value, float):\n",
        "#                     print(f\"    üîπ {key:<20}: {value:.6f}\")\n",
        "#                 else:\n",
        "#                     print(f\"    üîπ {key:<20}: {value}\")\n",
        "#             print()\n",
        "\n",
        "#             successful_models += 1\n",
        "\n",
        "#     # Save master results file to Google Drive\n",
        "#     master_file = f\"{drive_path}/hyperparameters/all_best_params.json\"\n",
        "\n",
        "#     # GPU information\n",
        "#     gpu_info = {}\n",
        "#     if torch.cuda.is_available():\n",
        "#         gpu_info = {\n",
        "#             'gpu_count': torch.cuda.device_count(),\n",
        "#             'gpu_names': [torch.cuda.get_device_properties(i).name for i in range(torch.cuda.device_count())],\n",
        "#             'total_gpu_memory_gb': sum(torch.cuda.get_device_properties(i).total_memory / 1e9 for i in range(torch.cuda.device_count()))\n",
        "#         }\n",
        "\n",
        "#     master_results = {\n",
        "#         'optimization_summary': {\n",
        "#             'total_models': len(results),\n",
        "#             'successful_optimizations': successful_models,\n",
        "#             'failed_optimizations': len(results) - successful_models,\n",
        "#             'success_rate_percent': (successful_models / len(results)) * 100 if results else 0,\n",
        "#             'gpu_accelerated': torch.cuda.is_available(),\n",
        "#             'system_info': {\n",
        "#                 'cpu_cores': os.cpu_count(),\n",
        "#                 'ram_gb': psutil.virtual_memory().total / (1024**3),\n",
        "#                 **gpu_info\n",
        "#             }\n",
        "#         },\n",
        "#         'results': results\n",
        "#     }\n",
        "\n",
        "#     with open(master_file, 'w') as f:\n",
        "#         json.dump(master_results, f, indent=4, sort_keys=True)\n",
        "\n",
        "#     cprint(f\"üíæ Master results saved to Google Drive: {master_file}\", 'cyan', attrs=['bold'])\n",
        "\n",
        "#     # Final summary\n",
        "#     print(\"\\n\" + \"üìä\" * 50)\n",
        "#     cprint(\"OPTIMIZATION SUMMARY\", 'yellow', attrs=['bold'])\n",
        "#     print(\"üìä\" * 50)\n",
        "#     print(f\"  üéØ Total Models: {len(results)}\")\n",
        "#     print(f\"  ‚úÖ Successful: {successful_models}\")\n",
        "#     print(f\"  ‚ùå Failed: {len(results) - successful_models}\")\n",
        "#     print(f\"  üìà Success Rate: {(successful_models / len(results)) * 100:.1f}%\")\n",
        "#     if torch.cuda.is_available():\n",
        "#         print(f\"  üéÆ GPU Acceleration: Enabled ({torch.cuda.device_count()} GPUs)\")\n",
        "#     else:\n",
        "#         print(f\"  üíª GPU Acceleration: Disabled (CPU only)\")\n",
        "\n",
        "# def display_startup_banner():\n",
        "#     #Display an impressive startup banner\n",
        "#     banner = \"\"\"\n",
        "# ‚îå‚îÄ THE FISH OPTIMIZER ‚îÄ‚îê\n",
        "# ‚îÇ   üêü Optimizing üêü   ‚îÇ\n",
        "# ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "#     \"\"\"\n",
        "\n",
        "#     # print(\"\\n\" + \"=\"*120)\n",
        "#     cprint(banner, 'red', attrs=['bold'])\n",
        "#     # print(\"=\"*120)\n",
        "#     # cprint(\"üöÄ MAXIMUM GPU-ACCELERATED HYPERPARAMETER OPTIMIZATION üöÄ\", 'yellow', attrs=['bold'])\n",
        "#     # cprint(\"üî• DESIGNED FOR MAXIMUM PERFORMANCE AND USER EXPERIENCE üî•\", 'cyan', attrs=['bold'])\n",
        "#     # print(\"=\"*120)\n",
        "\n",
        "# def main():\n",
        "#     \"\"\"Enhanced main function with spectacular UI and maximum GPU utilization\"\"\"\n",
        "\n",
        "#     # Display startup banner\n",
        "#     display_startup_banner()\n",
        "\n",
        "#     # Environment setup with detailed reporting\n",
        "#     print(\"\\nüîß SYSTEM INITIALIZATION\")\n",
        "#     print(\"‚îÄ\" * 50)\n",
        "\n",
        "#     optimal_threads, available_ram, gpu_memory_gb = setup_maximum_gpu_utilization()\n",
        "\n",
        "#     # Data loading with progress\n",
        "#     print(\"\\nüìä DATA LOADING AND PREPROCESSING\")\n",
        "#     print(\"‚îÄ\" * 50)\n",
        "\n",
        "#     try:\n",
        "#         # You need to implement or import these classes\n",
        "#         # from your_data_module import DataManager  # Replace with actual import\n",
        "\n",
        "#         cprint(\"üîÑ Loading and balancing dataset...\", 'cyan', attrs=['bold'])\n",
        "#         X, Y = DataManager.load_and_balance_data()\n",
        "\n",
        "#         cprint(f\"‚úÖ Dataset loaded successfully!\", 'green', attrs=['bold'])\n",
        "#         print(f\"   üìà Total samples: {len(X):,}\")\n",
        "#         print(f\"   üè∑Ô∏è  Total labels: {len(Y):,}\")\n",
        "#         print(f\"   üìä Classes: {len(np.unique(Y))}\")\n",
        "\n",
        "#         if len(X) != len(Y) or len(X) == 0:\n",
        "#             raise ValueError(\"Invalid dataset: inconsistent or empty data\")\n",
        "\n",
        "#     except ImportError:\n",
        "#         cprint(\"‚ùå DataManager not found. Please ensure it is imported.\", 'red', attrs=['bold'])\n",
        "#         return\n",
        "#     except Exception as e:\n",
        "#         cprint(f\"‚ùå Data loading failed: {e}\", 'red', attrs=['bold'])\n",
        "#         return\n",
        "\n",
        "#     # Prepare model configurations\n",
        "#     print(\"\\nü§ñ MODEL CONFIGURATION\")\n",
        "#     print(\"‚îÄ\" * 50)\n",
        "\n",
        "#     # Default models if Config.MODELS is not available\n",
        "#     try:\n",
        "#         # from your_config_module import Config  # Replace with actual import\n",
        "#         models = Config.MODELS\n",
        "#     except ImportError:\n",
        "#         cprint(\"‚ö†Ô∏è  Config not found. Using default models.\", 'yellow', attrs=['bold'])\n",
        "#         models = ['resnet50', 'efficientnet_b0', 'mobilenet_v3_large']\n",
        "\n",
        "#     model_configs = {}\n",
        "#     for i, model_name in enumerate(models, 1):\n",
        "#         model_configs[model_name] = {'X': X, 'Y': Y}\n",
        "#         print(f\"  {i:2d}. {model_name}\")\n",
        "\n",
        "#     cprint(f\"üéØ Configured {len(models)} models for optimization\", 'green', attrs=['bold'])\n",
        "\n",
        "#     # Run optimization\n",
        "#     print(\"\\nüöÄ STARTING HYPERPARAMETER OPTIMIZATION\")\n",
        "#     print(\"‚îÄ\" * 50)\n",
        "\n",
        "#     start_time = time.time()\n",
        "\n",
        "#     all_best_params = parallel_hyperparameter_optimization(\n",
        "#         model_configs,\n",
        "#         max_workers=1\n",
        "#     )\n",
        "\n",
        "#     end_time = time.time()\n",
        "#     total_time = end_time - start_time\n",
        "\n",
        "#     # Save results to Google Drive only\n",
        "#     save_optimization_results(all_best_params)\n",
        "\n",
        "#     # Final summary\n",
        "#     print(\"\\n\" + \"üéâ\" * 45)\n",
        "#     cprint(\"üèÜ HYPERPARAMETER OPTIMIZATION COMPLETED! üèÜ\", 'red', attrs=['bold'])\n",
        "#     print(\"üéâ\" * 45)\n",
        "\n",
        "#     successful = sum(1 for params in all_best_params.values() if params)\n",
        "#     total = len(all_best_params)\n",
        "\n",
        "#     print(f\"‚è±Ô∏è  Total Time: {total_time//3600:.0f}h {(total_time%3600)//60:.0f}m {total_time%60:.0f}s\")\n",
        "#     print(f\"üìä Models Processed: {total}\")\n",
        "#     print(f\"‚úÖ Successful Optimizations: {successful}\")\n",
        "#     print(f\"‚ùå Failed Optimizations: {total - successful}\")\n",
        "#     print(f\"üìà Success Rate: {100*successful/total:.1f}%\")\n",
        "#     print(f\"üíæ Results Location: /content/drive/MyDrive/Hilsha/hyperparameters/\")\n",
        "\n",
        "#     if torch.cuda.is_available():\n",
        "#         print(f\"üéÆ GPU Utilization: Maximum\")\n",
        "#         print(f\"üî• Multi-GPU: {'Yes' if torch.cuda.device_count() > 1 else 'No'}\")\n",
        "\n",
        "#     print(\"\\n\" + \"üéâ\" * 45)\n",
        "#     cprint(\"üöÄ READY FOR TRAINING WITH OPTIMIZED HYPERPARAMETERS! üöÄ\", 'green', attrs=['bold'])\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "metadata": {
        "id": "CmSTaip_n5bV"
      },
      "id": "CmSTaip_n5bV",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 9: Training - Pipeline"
      ],
      "metadata": {
        "id": "UaFBF8Jucyz3"
      },
      "id": "UaFBF8Jucyz3"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # ============================================================================\n",
        "# # Resource Management\n",
        "# # ============================================================================\n",
        "# class ResourceManager:\n",
        "#     \"\"\"Smart resource management for optimal GPU/CPU utilization\"\"\"\n",
        "\n",
        "#     def __init__(self):\n",
        "#         self.gpu_memory_gb = 20\n",
        "#         self.cpu_memory_gb = 50\n",
        "#         self.max_gpu_usage = 0.85\n",
        "#         self.max_cpu_usage = 0.90\n",
        "\n",
        "#     def get_memory_stats(self):\n",
        "#         \"\"\"Get current memory usage statistics\"\"\"\n",
        "#         stats = {'cpu_percent': psutil.virtual_memory().percent}\n",
        "\n",
        "#         if torch.cuda.is_available():\n",
        "#             stats['gpu_allocated_gb'] = torch.cuda.memory_allocated() / (1024**3)\n",
        "#             stats['gpu_reserved_gb'] = torch.cuda.memory_reserved() / (1024**3)\n",
        "#             stats['gpu_percent'] = (stats['gpu_reserved_gb'] / self.gpu_memory_gb) * 100\n",
        "#         else:\n",
        "#             stats.update({'gpu_allocated_gb': 0, 'gpu_reserved_gb': 0, 'gpu_percent': 0})\n",
        "\n",
        "#         return stats\n",
        "\n",
        "#     def should_cleanup_aggressive(self):\n",
        "#         \"\"\"Check if aggressive cleanup is needed\"\"\"\n",
        "#         stats = self.get_memory_stats()\n",
        "#         return (stats['gpu_percent'] > 90 or stats['cpu_percent'] > 90)\n",
        "\n",
        "#     def aggressive_cleanup(self):\n",
        "#         \"\"\"Perform comprehensive memory cleanup\"\"\"\n",
        "#         if torch.cuda.is_available():\n",
        "#             torch.cuda.empty_cache()\n",
        "#             torch.cuda.synchronize()\n",
        "#         gc.collect()\n",
        "#         time.sleep(0.1)\n",
        "\n",
        "#     def optimize_batch_size(self, base_size, model_complexity=1.0):\n",
        "#         \"\"\"Calculate optimal batch size based on current memory state\"\"\"\n",
        "#         stats = self.get_memory_stats()\n",
        "#         memory_factor = max(0.4, 1.0 - (stats['gpu_percent'] / 100))\n",
        "#         optimal_size = int(base_size * memory_factor / model_complexity)\n",
        "#         return max(32, min(256, optimal_size))\n",
        "\n",
        "# # ============================================================================\n",
        "# # Training Progress Tracker (Console Only)\n",
        "# # ============================================================================\n",
        "# class TrainingProgressTracker:\n",
        "#     \"\"\"Track training progress without plotting dependencies\"\"\"\n",
        "\n",
        "#     def __init__(self, model_name, total_epochs, batches_per_epoch):\n",
        "#         self.model_name = model_name\n",
        "#         self.total_epochs = total_epochs\n",
        "#         self.batches_per_epoch = batches_per_epoch\n",
        "#         self.current_epoch = 0\n",
        "#         self.start_time = time.time()\n",
        "\n",
        "#     def start_epoch(self, epoch):\n",
        "#         \"\"\"Start tracking an epoch\"\"\"\n",
        "#         self.current_epoch = epoch\n",
        "#         self.epoch_start_time = time.time()\n",
        "\n",
        "#     def update_batch(self, batch_idx, loss, acc, is_training=True, total_batches=None):\n",
        "#         \"\"\"Update batch progress - simplified for console only\"\"\"\n",
        "#         if batch_idx % 50 == 0 and batch_idx > 0:\n",
        "#             phase = \"Train\" if is_training else \"Val\"\n",
        "#             elapsed = time.time() - self.epoch_start_time\n",
        "#             tqdm.write(f\"  [{phase}] Batch {batch_idx:4d} - Loss: {loss:.4f}, Acc: {acc:.4f}, Time: {elapsed:.1f}s\")\n",
        "\n",
        "#     def finish_epoch(self, train_loss, train_acc, val_loss, val_acc, val_f1, is_best=False, lr=None):\n",
        "#         \"\"\"Finish epoch tracking\"\"\"\n",
        "#         epoch_time = time.time() - self.epoch_start_time\n",
        "#         total_time = time.time() - self.start_time\n",
        "\n",
        "#         status = \"üåü NEW BEST!\" if is_best else \"\"\n",
        "\n",
        "#         tqdm.write(f\"\\nEpoch {self.current_epoch + 1}/{self.total_epochs} Complete {status}\")\n",
        "#         tqdm.write(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
        "#         tqdm.write(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
        "#         if lr:\n",
        "#             tqdm.write(f\"  LR: {lr:.6f}\")\n",
        "#         tqdm.write(f\"  Epoch Time: {epoch_time:.1f}s, Total: {total_time:.1f}s\")\n",
        "\n",
        "\n",
        "# # ============================================================================\n",
        "# # Model Evaluator (Training-focused)\n",
        "# # ============================================================================\n",
        "# class ModelEvaluator:\n",
        "#     \"\"\"Model evaluation for training purposes (no plotting)\"\"\"\n",
        "\n",
        "#     def evaluate_model(self, model, data_loader, model_name):\n",
        "#         \"\"\"Evaluate model and return metrics for saving\"\"\"\n",
        "#         model.eval()\n",
        "\n",
        "#         all_predictions = []\n",
        "#         all_labels = []\n",
        "#         all_probabilities = []\n",
        "#         misclassified_samples = []\n",
        "#         total_samples = 0\n",
        "#         correct_predictions = 0\n",
        "\n",
        "#         print(f\"\\nEvaluating {model_name}...\")\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             for batch_idx, (images, labels) in enumerate(data_loader):\n",
        "#                 images = images.to(Config.DEVICE, memory_format=torch.channels_last)\n",
        "#                 labels = labels.to(Config.DEVICE)\n",
        "\n",
        "#                 outputs = model(images)\n",
        "#                 probabilities = F.softmax(outputs, dim=1)\n",
        "#                 _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "#                 # Store results\n",
        "#                 all_predictions.extend(predicted.cpu().numpy())\n",
        "#                 all_labels.extend(labels.cpu().numpy())\n",
        "#                 all_probabilities.extend(probabilities.cpu().numpy())\n",
        "\n",
        "#                 # Track misclassified samples\n",
        "#                 mask = predicted != labels\n",
        "#                 if mask.any():\n",
        "#                     misclassified_indices = torch.where(mask)[0]\n",
        "#                     for idx in misclassified_indices:\n",
        "#                         misclassified_samples.append({\n",
        "#                             'batch_idx': batch_idx,\n",
        "#                             'sample_idx': idx.item(),\n",
        "#                             'true_label': labels[idx].item(),\n",
        "#                             'predicted_label': predicted[idx].item(),\n",
        "#                             'confidence': probabilities[idx].max().item(),\n",
        "#                             'image_tensor': images[idx].cpu()  # Store for later visualization\n",
        "#                         })\n",
        "\n",
        "#                 # Update counters\n",
        "#                 batch_size = labels.size(0)\n",
        "#                 total_samples += batch_size\n",
        "#                 correct_predictions += (predicted == labels).sum().item()\n",
        "\n",
        "#         # Calculate metrics\n",
        "#         accuracy = accuracy_score(all_labels, all_predictions)\n",
        "#         f1_macro = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
        "#         f1_weighted = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
        "#         conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "#         # Classification report\n",
        "#         class_report = classification_report(\n",
        "#             all_labels, all_predictions,\n",
        "#             target_names=Config.CLASS_NAMES,\n",
        "#             output_dict=True,\n",
        "#             zero_division=0\n",
        "#         )\n",
        "\n",
        "#         print(f\"Evaluation Results for {model_name}:\")\n",
        "#         print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "#         print(f\"  F1-Macro: {f1_macro:.4f}\")\n",
        "#         print(f\"  F1-Weighted: {f1_weighted:.4f}\")\n",
        "#         print(f\"  Misclassified: {len(misclassified_samples)}/{total_samples}\")\n",
        "\n",
        "#         return {\n",
        "#             'accuracy': accuracy,\n",
        "#             'f1_macro': f1_macro,\n",
        "#             'f1_weighted': f1_weighted,\n",
        "#             'confusion_matrix': conf_matrix.tolist(),  # Convert to list for JSON serialization\n",
        "#             'classification_report': class_report,\n",
        "#             'predictions': all_predictions,\n",
        "#             'true_labels': all_labels,\n",
        "#             'probabilities': np.array(all_probabilities).tolist(),  # Convert for JSON\n",
        "#             'misclassified_count': len(misclassified_samples),\n",
        "#             'total_samples': total_samples,\n",
        "#             'misclassified_details': misclassified_samples[:50]  # Limit to first 50 for storage\n",
        "#         }\n",
        "\n",
        "# # ============================================================================\n",
        "# # Enhanced Model Trainer\n",
        "# # ============================================================================\n",
        "# class EnhancedModelTrainer:\n",
        "#     def __init__(self, model, model_name, hyperparameters):\n",
        "#         self.model = model.to(Config.DEVICE)\n",
        "#         self.model_name = model_name\n",
        "#         self.hyperparameters = hyperparameters\n",
        "#         self.best_val_acc = 0.0\n",
        "#         self.best_val_f1 = 0.0\n",
        "#         self.patience_counter = 0\n",
        "\n",
        "#         # Resource management\n",
        "#         self.resource_manager = ResourceManager()\n",
        "#         self.memory_check_interval = 15\n",
        "\n",
        "#         # Setup training components\n",
        "#         self._setup_training_components()\n",
        "\n",
        "#         # Initialize history for saving\n",
        "#         self.history = {\n",
        "#             'train_loss': [],\n",
        "#             'train_acc': [],\n",
        "#             'val_loss': [],\n",
        "#             'val_acc': [],\n",
        "#             'val_f1': [],\n",
        "#             'learning_rates': [],\n",
        "#             'epoch_times': [],\n",
        "#             'memory_usage': []\n",
        "#         }\n",
        "\n",
        "#     def _setup_training_components(self):\n",
        "#         \"\"\"Setup optimizer, criterion, and scheduler\"\"\"\n",
        "#         # Filter hyperparameters\n",
        "#         allowed_keys = ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier',\n",
        "#                        'augmentation_strength', 'batch_size', 'optimizer_type',\n",
        "#                        'scheduler_type', 'label_smoothing']\n",
        "#         self.hyperparameters = {k: v for k, v in self.hyperparameters.items() if k in allowed_keys}\n",
        "\n",
        "#         # Optimizer setup\n",
        "#         lr = self.hyperparameters.get('lr', Config.LEARNING_RATE)\n",
        "#         weight_decay = self.hyperparameters.get('weight_decay', Config.WEIGHT_DECAY)\n",
        "#         optimizer_type = self.hyperparameters.get('optimizer_type', 'adamw')\n",
        "\n",
        "#         if optimizer_type == 'adamw':\n",
        "#             self.optimizer = optim.AdamW(\n",
        "#                 self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "#                 fused=torch.cuda.is_available()\n",
        "#             )\n",
        "#         elif optimizer_type == 'adam':\n",
        "#             self.optimizer = optim.Adam(\n",
        "#                 self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "#                 fused=torch.cuda.is_available()\n",
        "#             )\n",
        "#         else:\n",
        "#             self.optimizer = optim.SGD(\n",
        "#                 self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "#                 momentum=0.9, nesterov=True\n",
        "#             )\n",
        "\n",
        "#         # Criterion\n",
        "#         label_smoothing = self.hyperparameters.get('label_smoothing', 0.1)\n",
        "#         self.criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "#         # Scheduler\n",
        "#         scheduler_type = self.hyperparameters.get('scheduler_type', 'cosine')\n",
        "#         if scheduler_type == 'cosine':\n",
        "#             self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "#                 self.optimizer, T_max=Config.EPOCHS, eta_min=1e-6\n",
        "#             )\n",
        "#         elif scheduler_type == 'plateau':\n",
        "#             self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "#                 self.optimizer, mode='min', factor=0.5, patience=5\n",
        "#             )\n",
        "#         else:\n",
        "#             self.scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.95)\n",
        "\n",
        "#         # Mixed precision scaler\n",
        "#         self.scaler = torch.cuda.amp.GradScaler(enabled=Config.USE_MIXED_PRECISION)\n",
        "\n",
        "#     def train_epoch(self, train_loader, progress_tracker):\n",
        "#         \"\"\"Enhanced training epoch with smart memory management\"\"\"\n",
        "#         self.model.train()\n",
        "#         total_loss = 0\n",
        "#         correct = 0\n",
        "#         total = 0\n",
        "#         batch_count = len(train_loader)\n",
        "\n",
        "#         tqdm.write(f\"Training: {len(train_loader.dataset):,} samples, \"\n",
        "#                    f\"{batch_count:,} batches, batch_size: {train_loader.batch_size}\")\n",
        "\n",
        "#         try:\n",
        "#             for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "#                 try:\n",
        "#                     # Smart memory management\n",
        "#                     if batch_idx % self.memory_check_interval == 0:\n",
        "#                         if self.resource_manager.should_cleanup_aggressive():\n",
        "#                             self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "#                     # Move data to device\n",
        "#                     images = images.to(Config.DEVICE, non_blocking=True, memory_format=torch.channels_last)\n",
        "#                     labels = labels.to(Config.DEVICE, non_blocking=True)\n",
        "\n",
        "#                     # Forward pass\n",
        "#                     self.optimizer.zero_grad(set_to_none=True)\n",
        "#                     with torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "#                         outputs = self.model(images)\n",
        "#                         loss = self.criterion(outputs, labels)\n",
        "\n",
        "#                     # Backward pass\n",
        "#                     self.scaler.scale(loss).backward()\n",
        "#                     self.scaler.unscale_(self.optimizer)\n",
        "#                     torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "#                     self.scaler.step(self.optimizer)\n",
        "#                     self.scaler.update()\n",
        "\n",
        "#                     # Calculate metrics\n",
        "#                     _, predicted = torch.max(outputs, 1)\n",
        "#                     batch_acc = (predicted == labels).float().mean().item()\n",
        "#                     batch_loss = loss.item()\n",
        "\n",
        "#                     # Update totals\n",
        "#                     total_loss += batch_loss * images.size(0)\n",
        "#                     total += images.size(0)\n",
        "#                     correct += (predicted == labels).sum().item()\n",
        "\n",
        "#                     # Update progress\n",
        "#                     progress_tracker.update_batch(batch_idx, batch_loss, batch_acc, is_training=True, total_batches=batch_count)\n",
        "\n",
        "#                     # Memory cleanup\n",
        "#                     del outputs, loss, predicted, images, labels\n",
        "\n",
        "#                 except Exception as e:\n",
        "#                     tqdm.write(f\"Error in batch {batch_idx}: {str(e)}\")\n",
        "#                     self.resource_manager.aggressive_cleanup()\n",
        "#                     continue\n",
        "\n",
        "#             # Final cleanup\n",
        "#             self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "#             return total_loss / max(1, total), correct / max(1, total)\n",
        "\n",
        "#         except Exception as e:\n",
        "#             tqdm.write(f\"Training epoch failed: {str(e)}\")\n",
        "#             self.resource_manager.aggressive_cleanup()\n",
        "#             return float('inf'), 0.0\n",
        "\n",
        "#     def validate_epoch(self, val_loader, progress_tracker):\n",
        "#         \"\"\"Enhanced validation epoch with memory optimization\"\"\"\n",
        "#         self.model.eval()\n",
        "#         total_loss = 0\n",
        "#         total_samples = 0\n",
        "#         all_predictions = []\n",
        "#         all_labels = []\n",
        "#         batch_count = len(val_loader)\n",
        "\n",
        "#         tqdm.write(f\"Validation: {len(val_loader.dataset):,} samples, \"\n",
        "#                    f\"{batch_count:,} batches, batch_size: {val_loader.batch_size}\")\n",
        "\n",
        "#         try:\n",
        "#             with torch.no_grad():\n",
        "#                 for batch_idx, (images, labels) in enumerate(val_loader):\n",
        "#                     try:\n",
        "#                         images = images.to(Config.DEVICE, non_blocking=True, memory_format=torch.channels_last)\n",
        "#                         labels = labels.to(Config.DEVICE, non_blocking=True)\n",
        "\n",
        "#                         with torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "#                             outputs = self.model(images)\n",
        "#                             loss = self.criterion(outputs, labels)\n",
        "\n",
        "#                         _, predicted = torch.max(outputs, 1)\n",
        "#                         batch_acc = (predicted == labels).float().mean().item()\n",
        "#                         batch_loss = loss.item()\n",
        "\n",
        "#                         # Store results\n",
        "#                         total_loss += batch_loss * images.size(0)\n",
        "#                         total_samples += images.size(0)\n",
        "#                         all_predictions.extend(predicted.cpu().numpy())\n",
        "#                         all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "#                         # Update progress\n",
        "#                         progress_tracker.update_batch(batch_idx, batch_loss, batch_acc,\n",
        "#                                                     is_training=False, total_batches=batch_count)\n",
        "\n",
        "#                         # Memory cleanup\n",
        "#                         del outputs, loss, predicted, images, labels\n",
        "\n",
        "#                     except Exception as e:\n",
        "#                         tqdm.write(f\"Error in validation batch {batch_idx}: {str(e)}\")\n",
        "#                         continue\n",
        "\n",
        "#             # Calculate final metrics\n",
        "#             val_acc = accuracy_score(all_labels, all_predictions)\n",
        "#             val_f1 = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
        "\n",
        "#             return total_loss / max(1, total_samples), val_acc, val_f1\n",
        "\n",
        "#         except Exception as e:\n",
        "#             tqdm.write(f\"Validation epoch failed: {str(e)}\")\n",
        "#             self.resource_manager.aggressive_cleanup()\n",
        "#             return float('inf'), 0.0, 0.0\n",
        "\n",
        "#     def train_main_model(self, train_loader, val_loader, test_loader=None):\n",
        "#         \"\"\"Main model training with comprehensive data saving\"\"\"\n",
        "#         if not train_loader or len(train_loader.dataset) == 0:\n",
        "#             tqdm.write(f\"Skipping {self.model_name}: No training data\")\n",
        "#             return False\n",
        "\n",
        "#         if not val_loader or len(val_loader.dataset) == 0:\n",
        "#             tqdm.write(f\"Skipping {self.model_name}: No validation data\")\n",
        "#             return False\n",
        "\n",
        "#         tqdm.write(f\"\\nTraining {self.model_name}\")\n",
        "#         tqdm.write(f\"Training samples: {len(train_loader.dataset):,}\")\n",
        "#         tqdm.write(f\"Validation samples: {len(val_loader.dataset):,}\")\n",
        "#         tqdm.write(f\"Total epochs: {Config.EPOCHS}\")\n",
        "#         tqdm.write(f\"Batch size: {train_loader.batch_size}\")\n",
        "\n",
        "#         # Setup model for training\n",
        "#         self.model = self.model.to(Config.DEVICE, memory_format=torch.channels_last)\n",
        "\n",
        "#         # Progress tracker\n",
        "#         progress_tracker = TrainingProgressTracker(self.model_name, Config.EPOCHS, len(train_loader))\n",
        "\n",
        "#         # Training loop\n",
        "#         training_start_time = time.time()\n",
        "\n",
        "#         for epoch in range(Config.EPOCHS):\n",
        "#             epoch_start_time = time.time()\n",
        "#             tqdm.write(f\"\\nEpoch {epoch + 1}/{Config.EPOCHS}\")\n",
        "\n",
        "#             progress_tracker.start_epoch(epoch)\n",
        "\n",
        "#             # Training phase\n",
        "#             train_loss, train_acc = self.train_epoch(train_loader, progress_tracker)\n",
        "\n",
        "#             # Validation phase\n",
        "#             val_loss, val_acc, val_f1 = self.validate_epoch(val_loader, progress_tracker)\n",
        "\n",
        "#             # Learning rate scheduling\n",
        "#             if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "#                 self.scheduler.step(val_loss)\n",
        "#             else:\n",
        "#                 self.scheduler.step()\n",
        "\n",
        "#             # Track metrics\n",
        "#             is_best = val_f1 > self.best_val_f1 * 1.001\n",
        "#             current_lr = self.optimizer.param_groups[0]['lr']\n",
        "#             epoch_time = time.time() - epoch_start_time\n",
        "#             memory_stats = self.resource_manager.get_memory_stats()\n",
        "\n",
        "#             # Update progress tracker\n",
        "#             progress_tracker.finish_epoch(train_loss, train_acc, val_loss, val_acc, val_f1, is_best=is_best, lr=current_lr)\n",
        "\n",
        "#             # Store history\n",
        "#             self.history['train_loss'].append(float(train_loss))\n",
        "#             self.history['train_acc'].append(float(train_acc))\n",
        "#             self.history['val_loss'].append(float(val_loss))\n",
        "#             self.history['val_acc'].append(float(val_acc))\n",
        "#             self.history['val_f1'].append(float(val_f1))\n",
        "#             self.history['learning_rates'].append(float(current_lr))\n",
        "#             self.history['epoch_times'].append(float(epoch_time))\n",
        "#             self.history['memory_usage'].append(memory_stats)\n",
        "\n",
        "#             # Save best model\n",
        "#             if is_best:\n",
        "#                 self.best_val_f1 = val_f1\n",
        "#                 self.best_val_acc = val_acc\n",
        "#                 self.patience_counter = 0\n",
        "#                 self._save_best_model(epoch + 1, val_f1, val_acc)\n",
        "#             else:\n",
        "#                 self.patience_counter += 1\n",
        "\n",
        "#             # Early stopping check\n",
        "#             if self.patience_counter >= Config.PATIENCE:\n",
        "#                 total_time = time.time() - training_start_time\n",
        "#                 tqdm.write(f\"Early stopping at epoch {epoch + 1}\")\n",
        "#                 tqdm.write(f\"Total training time: {total_time:.1f}s\")\n",
        "#                 break\n",
        "\n",
        "#         # Final evaluation and save results\n",
        "#         eval_loader = test_loader if test_loader else val_loader\n",
        "#         self._final_evaluation_and_save(eval_loader, training_start_time)\n",
        "\n",
        "#         # Cleanup\n",
        "#         self.resource_manager.aggressive_cleanup()\n",
        "#         return True\n",
        "\n",
        "#     def _save_best_model(self, epoch, val_f1, val_acc):\n",
        "#         \"\"\"Save best model checkpoint\"\"\"\n",
        "#         checkpoint = {\n",
        "#             'model_state_dict': self.model.state_dict(),\n",
        "#             'model_name': self.model_name,\n",
        "#             'hyperparameters': self.hyperparameters,\n",
        "#             'epoch': epoch,\n",
        "#             'best_val_f1': val_f1,\n",
        "#             'best_val_acc': val_acc,\n",
        "#             'optimizer_state': self.optimizer.state_dict(),\n",
        "#             'scheduler_state': self.scheduler.state_dict() if self.scheduler else None,\n",
        "#             'num_classes': Config.NUM_CLASSES,\n",
        "#             'class_names': Config.CLASS_NAMES,\n",
        "#             'save_format_version': '1.0'\n",
        "#         }\n",
        "\n",
        "#         # Save paths\n",
        "#         best_model_dir = f\"{Config.OUTPUT_DIR}/best_model\"\n",
        "#         os.makedirs(best_model_dir, exist_ok=True)\n",
        "\n",
        "#         save_path = f\"{best_model_dir}/{self.model_name}_best.pt\"\n",
        "\n",
        "#         try:\n",
        "#             torch.save(checkpoint, save_path)\n",
        "#             tqdm.write(f\"‚úÖ Best model saved: F1={val_f1:.4f}, Acc={val_acc:.4f}\")\n",
        "#         except Exception as e:\n",
        "#             tqdm.write(f\"‚ùå Error saving model {self.model_name}: {e}\")\n",
        "\n",
        "#     def _final_evaluation_and_save(self, eval_loader, training_start_time):\n",
        "#         \"\"\"Final evaluation and comprehensive data saving\"\"\"\n",
        "#         # Load best model for evaluation\n",
        "#         best_model_path = f\"{Config.OUTPUT_DIR}/best_model/{self.model_name}_best.pt\"\n",
        "#         if os.path.exists(best_model_path):\n",
        "#             try:\n",
        "#                 checkpoint = torch.load(best_model_path, map_location=Config.DEVICE, weights_only=False)\n",
        "#                 if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:\n",
        "#                     self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "#                     tqdm.write(f\"‚úÖ Loaded best model for evaluation\")\n",
        "#                 else:\n",
        "#                     self.model.load_state_dict(checkpoint)\n",
        "#             except Exception as e:\n",
        "#                 tqdm.write(f\"‚ö†Ô∏è Could not load best model: {e}\")\n",
        "\n",
        "#         # Evaluate model\n",
        "#         evaluator = ModelEvaluator()\n",
        "#         evaluation_results = evaluator.evaluate_model(self.model, eval_loader, self.model_name)\n",
        "\n",
        "#         # Create comprehensive training data package\n",
        "#         training_data = {\n",
        "#             'model_info': {\n",
        "#                 'model_name': self.model_name,\n",
        "#                 'num_classes': Config.NUM_CLASSES,\n",
        "#                 'class_names': Config.CLASS_NAMES,\n",
        "#                 'total_parameters': sum(p.numel() for p in self.model.parameters()),\n",
        "#                 'trainable_parameters': sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
        "#             },\n",
        "#             'hyperparameters': self.hyperparameters,\n",
        "#             'training_history': self.history,\n",
        "#             'final_results': evaluation_results,\n",
        "#             'training_metadata': {\n",
        "#                 'total_training_time': time.time() - training_start_time,\n",
        "#                 'best_epoch': len(self.history['val_f1']) - self.patience_counter if self.patience_counter < Config.PATIENCE else len(self.history['val_f1']),\n",
        "#                 'best_val_f1': self.best_val_f1,\n",
        "#                 'best_val_acc': self.best_val_acc,\n",
        "#                 'early_stopped': self.patience_counter >= Config.PATIENCE,\n",
        "#                 'final_epoch': len(self.history['train_loss']),\n",
        "#                 'device_used': str(Config.DEVICE),\n",
        "#                 'mixed_precision': Config.USE_MIXED_PRECISION\n",
        "#             },\n",
        "#             'save_timestamp': time.time(),\n",
        "#             'config': {\n",
        "#                 'batch_size': Config.BATCH_SIZE,\n",
        "#                 'epochs': Config.EPOCHS,\n",
        "#                 'patience': Config.PATIENCE,\n",
        "#                 'learning_rate': Config.LEARNING_RATE,\n",
        "#                 'weight_decay': Config.WEIGHT_DECAY\n",
        "#             }\n",
        "#         }\n",
        "\n",
        "#         # Save training data\n",
        "#         results_dir = f\"{Config.OUTPUT_DIR}/training_results\"\n",
        "#         os.makedirs(results_dir, exist_ok=True)\n",
        "\n",
        "#         # Save as JSON (for easy reading by visualization script)\n",
        "#         json_path = f\"{results_dir}/{self.model_name}_training_data.json\"\n",
        "#         try:\n",
        "#             with open(json_path, 'w') as f:\n",
        "#                 json.dump(training_data, f, indent=2, default=str)\n",
        "#             tqdm.write(f\"‚úÖ Training data saved to {json_path}\")\n",
        "#         except Exception as e:\n",
        "#             tqdm.write(f\"‚ùå Error saving training data: {e}\")\n",
        "\n",
        "#         # Also save as pickle for complex objects\n",
        "#         import pickle\n",
        "#         pickle_path = f\"{results_dir}/{self.model_name}_training_data.pkl\"\n",
        "#         try:\n",
        "#             with open(pickle_path, 'wb') as f:\n",
        "#                 pickle.dump(training_data, f)\n",
        "#             tqdm.write(f\"‚úÖ Training data saved to {pickle_path}\")\n",
        "#         except Exception as e:\n",
        "#             tqdm.write(f\"‚ùå Error saving pickle data: {e}\")\n",
        "\n",
        "#         # Training summary\n",
        "#         total_training_time = time.time() - training_start_time\n",
        "#         tqdm.write(f\"\\nTraining Summary for {self.model_name}:\")\n",
        "#         tqdm.write(f\"  Final Accuracy: {evaluation_results.get('accuracy', 0.0):.4f}\")\n",
        "#         tqdm.write(f\"  Final F1 Score: {evaluation_results.get('f1_macro', 0.0):.4f}\")\n",
        "#         tqdm.write(f\"  Best Validation F1: {self.best_val_f1:.4f}\")\n",
        "#         tqdm.write(f\"  Total Training Time: {total_training_time:.1f}s\")\n",
        "#         tqdm.write(f\"  Final Epoch: {len(self.history['train_loss'])}/{Config.EPOCHS}\")\n",
        "\n",
        "#     def train_kfold(self, train_loader, val_loader, test_loader, n_folds=3):\n",
        "#         \"\"\"K-fold cross-validation with data saving\"\"\"\n",
        "#         if n_folds <= 0:\n",
        "#             tqdm.write(f\"Skipping k-fold for {self.model_name}: n_folds <= 0\")\n",
        "#             return False\n",
        "\n",
        "#         from torch.utils.data import ConcatDataset\n",
        "#         combined_dataset = ConcatDataset([train_loader.dataset, val_loader.dataset])\n",
        "#         total_samples = len(combined_dataset)\n",
        "#         min_samples_per_fold = 500\n",
        "\n",
        "#         # Adjust folds based on data availability\n",
        "#         if total_samples < n_folds * min_samples_per_fold:\n",
        "#             n_folds = max(1, total_samples // min_samples_per_fold)\n",
        "\n",
        "#         if n_folds < 2:\n",
        "#             tqdm.write(f\"Skipping k-fold: need at least {min_samples_per_fold*2} samples\")\n",
        "#             return False\n",
        "\n",
        "#         tqdm.write(f\"\\nK-fold Cross-Validation for {self.model_name} ({n_folds} folds)\")\n",
        "\n",
        "#         # Calculate fold indices\n",
        "#         samples_per_fold = total_samples // n_folds\n",
        "#         fold_results = []\n",
        "\n",
        "#         # Create model complexity map for batch size optimization\n",
        "#         model_complexity_map = {\n",
        "#             'efficientnet': 1.5, 'resnet': 1.0, 'vgg': 0.8,\n",
        "#             'mobilenet': 0.6, 'densenet': 1.3, 'convnext': 1.4\n",
        "#         }\n",
        "#         model_complexity = model_complexity_map.get(self.model_name.split('_')[0].lower(), 1.0)\n",
        "#         base_batch_size = self.hyperparameters.get('batch_size', Config.BATCH_SIZE)\n",
        "#         fold_batch_size = self.resource_manager.optimize_batch_size(base_batch_size, model_complexity)\n",
        "\n",
        "#         total_kfold_start = time.time()\n",
        "\n",
        "#         for fold in range(n_folds):\n",
        "#             fold_start_time = time.time()\n",
        "#             tqdm.write(f\"\\nTraining Fold {fold + 1}/{n_folds}\")\n",
        "\n",
        "#             try:\n",
        "#                 # Create fold indices\n",
        "#                 val_start = fold * samples_per_fold\n",
        "#                 val_end = min(val_start + samples_per_fold, total_samples)\n",
        "#                 val_idx = list(range(val_start, val_end))\n",
        "#                 train_idx = list(range(0, val_start)) + list(range(val_end, total_samples))\n",
        "\n",
        "#                 # Create fold data loaders\n",
        "#                 train_subsampler = SubsetRandomSampler(train_idx)\n",
        "#                 val_subsampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "#                 train_loader_fold = DataLoader(\n",
        "#                     combined_dataset, batch_size=fold_batch_size,\n",
        "#                     sampler=train_subsampler, num_workers=min(8, mp.cpu_count() // 2),\n",
        "#                     pin_memory=torch.cuda.is_available(), prefetch_factor=2\n",
        "#                 )\n",
        "\n",
        "#                 val_loader_fold = DataLoader(\n",
        "#                     combined_dataset, batch_size=fold_batch_size,\n",
        "#                     sampler=val_subsampler, num_workers=min(8, mp.cpu_count() // 2),\n",
        "#                     pin_memory=torch.cuda.is_available(), prefetch_factor=2\n",
        "#                 )\n",
        "\n",
        "#                 # Create fold model\n",
        "#                 fold_model = ModelFactory.create_model(\n",
        "#                     self.model_name, num_classes=Config.NUM_CLASSES,\n",
        "#                     dropout_rate=self.hyperparameters.get('dropout', 0.5),\n",
        "#                     hidden_dim_multiplier=self.hyperparameters.get('hidden_dim_multiplier', 0.5)\n",
        "#                 ).to(Config.DEVICE, memory_format=torch.channels_last)\n",
        "\n",
        "#                 # Create fold trainer\n",
        "#                 fold_trainer = EnhancedModelTrainer(\n",
        "#                     fold_model, f\"{self.model_name}_fold_{fold + 1}\", self.hyperparameters\n",
        "#                 )\n",
        "\n",
        "#                 # Train fold\n",
        "#                 fold_success = fold_trainer.train_main_model(train_loader_fold, val_loader_fold)\n",
        "#                 fold_time = time.time() - fold_start_time\n",
        "\n",
        "#                 if fold_success:\n",
        "#                     # Evaluate fold on test data\n",
        "#                     evaluator = ModelEvaluator()\n",
        "#                     eval_loader = test_loader if test_loader else val_loader_fold\n",
        "#                     fold_results_data = evaluator.evaluate_model(fold_model, eval_loader, f\"{self.model_name}_fold_{fold + 1}\")\n",
        "\n",
        "#                     # Store fold results\n",
        "#                     fold_result = {\n",
        "#                         'fold_number': fold + 1,\n",
        "#                         'training_time': fold_time,\n",
        "#                         'training_history': fold_trainer.history,\n",
        "#                         'evaluation_results': fold_results_data,\n",
        "#                         'hyperparameters': self.hyperparameters,\n",
        "#                         'fold_indices': {'train': train_idx, 'val': val_idx},\n",
        "#                         'model_info': {\n",
        "#                             'model_name': f\"{self.model_name}_fold_{fold + 1}\",\n",
        "#                             'total_parameters': sum(p.numel() for p in fold_model.parameters()),\n",
        "#                             'trainable_parameters': sum(p.numel() for p in fold_model.parameters() if p.requires_grad)\n",
        "#                         }\n",
        "#                     }\n",
        "\n",
        "#                     fold_results.append(fold_result)\n",
        "\n",
        "#                     # Save fold model\n",
        "#                     fold_model_dir = f\"{Config.OUTPUT_DIR}/kfold_models\"\n",
        "#                     os.makedirs(fold_model_dir, exist_ok=True)\n",
        "#                     torch.save(fold_model.state_dict(), f\"{fold_model_dir}/{self.model_name}_fold_{fold + 1}.pt\")\n",
        "\n",
        "#                     tqdm.write(f\"Fold {fold + 1} completed - Acc: {fold_results_data['accuracy']:.4f}, \"\n",
        "#                               f\"F1: {fold_results_data['f1_macro']:.4f}, Time: {fold_time:.1f}s\")\n",
        "#                 else:\n",
        "#                     tqdm.write(f\"Fold {fold + 1} training failed\")\n",
        "\n",
        "#                 # Cleanup\n",
        "#                 del fold_trainer, fold_model, train_loader_fold, val_loader_fold\n",
        "#                 self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "#             except Exception as e:\n",
        "#                 tqdm.write(f\"Error in fold {fold + 1}: {str(e)}\")\n",
        "#                 continue\n",
        "\n",
        "#         # Save comprehensive k-fold results\n",
        "#         if fold_results:\n",
        "#             total_kfold_time = time.time() - total_kfold_start\n",
        "\n",
        "#             # Calculate k-fold statistics\n",
        "#             fold_accuracies = [fr['evaluation_results']['accuracy'] for fr in fold_results]\n",
        "#             fold_f1_scores = [fr['evaluation_results']['f1_macro'] for fr in fold_results]\n",
        "\n",
        "#             kfold_summary = {\n",
        "#                 'model_name': self.model_name,\n",
        "#                 'n_folds': n_folds,\n",
        "#                 'successful_folds': len(fold_results),\n",
        "#                 'total_kfold_time': total_kfold_time,\n",
        "#                 'fold_results': fold_results,\n",
        "#                 'summary_statistics': {\n",
        "#                     'mean_accuracy': np.mean(fold_accuracies),\n",
        "#                     'std_accuracy': np.std(fold_accuracies),\n",
        "#                     'mean_f1_macro': np.mean(fold_f1_scores),\n",
        "#                     'std_f1_macro': np.std(fold_f1_scores),\n",
        "#                     'best_fold': {\n",
        "#                         'fold_number': fold_results[np.argmax(fold_f1_scores)]['fold_number'],\n",
        "#                         'accuracy': max(fold_accuracies),\n",
        "#                         'f1_macro': max(fold_f1_scores)\n",
        "#                     },\n",
        "#                     'worst_fold': {\n",
        "#                         'fold_number': fold_results[np.argmin(fold_f1_scores)]['fold_number'],\n",
        "#                         'accuracy': min(fold_accuracies),\n",
        "#                         'f1_macro': min(fold_f1_scores)\n",
        "#                     }\n",
        "#                 },\n",
        "#                 'hyperparameters': self.hyperparameters,\n",
        "#                 'save_timestamp': time.time()\n",
        "#             }\n",
        "\n",
        "#             # Save k-fold results\n",
        "#             kfold_dir = f\"{Config.OUTPUT_DIR}/kfold_results\"\n",
        "#             os.makedirs(kfold_dir, exist_ok=True)\n",
        "\n",
        "#             # Save as JSON\n",
        "#             json_path = f\"{kfold_dir}/{self.model_name}_kfold_results.json\"\n",
        "#             with open(json_path, 'w') as f:\n",
        "#                 json.dump(kfold_summary, f, indent=2, default=str)\n",
        "\n",
        "#             # Save as pickle\n",
        "#             import pickle\n",
        "#             pickle_path = f\"{kfold_dir}/{self.model_name}_kfold_results.pkl\"\n",
        "#             with open(pickle_path, 'wb') as f:\n",
        "#                 pickle.dump(kfold_summary, f)\n",
        "\n",
        "#             tqdm.write(f\"\\nK-fold Summary for {self.model_name}:\")\n",
        "#             tqdm.write(f\"  Successful folds: {len(fold_results)}/{n_folds}\")\n",
        "#             tqdm.write(f\"  Mean Accuracy: {np.mean(fold_accuracies):.4f} ¬± {np.std(fold_accuracies):.4f}\")\n",
        "#             tqdm.write(f\"  Mean F1-Score: {np.mean(fold_f1_scores):.4f} ¬± {np.std(fold_f1_scores):.4f}\")\n",
        "#             tqdm.write(f\"  Total time: {total_kfold_time:.1f}s\")\n",
        "#             tqdm.write(f\"  Results saved to {json_path}\")\n",
        "\n",
        "#         return len(fold_results) > 0\n",
        "\n",
        "#     def cleanup_trainer(self):\n",
        "#         \"\"\"Complete cleanup of trainer resources\"\"\"\n",
        "#         try:\n",
        "#             if hasattr(self, 'model'):\n",
        "#                 del self.model\n",
        "#             if hasattr(self, 'optimizer'):\n",
        "#                 del self.optimizer\n",
        "#             if hasattr(self, 'scheduler'):\n",
        "#                 del self.scheduler\n",
        "#             if hasattr(self, 'criterion'):\n",
        "#                 del self.criterion\n",
        "#             if hasattr(self, 'scaler'):\n",
        "#                 del self.scaler\n",
        "\n",
        "#             self.history.clear()\n",
        "#             self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "#         except Exception as e:\n",
        "#             tqdm.write(f\"Cleanup error: {e}\")\n",
        "\n",
        "# # ============================================================================\n",
        "# # Environment Setup\n",
        "# # ============================================================================\n",
        "# def setup_environment():\n",
        "#     \"\"\"Setup training environment for optimal performance\"\"\"\n",
        "#     # Set optimal thread count for CPU utilization\n",
        "#     torch.set_num_threads(min(16, os.cpu_count()))\n",
        "#     os.environ['OMP_NUM_THREADS'] = str(min(16, os.cpu_count()))\n",
        "\n",
        "#     # GPU optimizations\n",
        "#     if torch.cuda.is_available():\n",
        "#         torch.backends.cudnn.benchmark = True\n",
        "#         torch.backends.cudnn.deterministic = False\n",
        "#         torch.backends.cuda.matmul.allow_tf32 = True\n",
        "#         torch.backends.cudnn.allow_tf32 = True\n",
        "#         torch.backends.cuda.enable_flash_sdp(True)\n",
        "\n",
        "#         gpu_props = torch.cuda.get_device_properties(0)\n",
        "#         print(f\"GPU: {gpu_props.name}, Memory: {gpu_props.total_memory / 1024**3:.1f}GB\")\n",
        "\n",
        "#     print(f\"CPU Cores: {os.cpu_count()}, Using threads: {torch.get_num_threads()}\")\n",
        "\n",
        "# # ============================================================================\n",
        "# # Main Training Function\n",
        "# # ============================================================================\n",
        "# def main():\n",
        "#     \"\"\"Main training function\"\"\"\n",
        "#     print(\"\\nStarting Fish Species Model Training...\")\n",
        "#     print(\"=\"*70)\n",
        "\n",
        "#     # Environment setup\n",
        "#     setup_environment()\n",
        "\n",
        "#     # Create output directories\n",
        "#     directories = [\n",
        "#         f\"{Config.OUTPUT_DIR}/models\",\n",
        "#         f\"{Config.OUTPUT_DIR}/best_model\",\n",
        "#         f\"{Config.OUTPUT_DIR}/training_results\",\n",
        "#         f\"{Config.OUTPUT_DIR}/kfold_results\",\n",
        "#         f\"{Config.OUTPUT_DIR}/kfold_models\"\n",
        "#     ]\n",
        "\n",
        "#     for directory in directories:\n",
        "#         os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "#     # Initialize resource manager\n",
        "#     resource_manager = ResourceManager()\n",
        "\n",
        "#     # Load and balance data (REPLACE WITH YOUR IMPLEMENTATION)\n",
        "#     try:\n",
        "#         print(\"\\nLoading and balancing data...\")\n",
        "#         X, Y = DataManager.load_and_balance_data()\n",
        "#         print(f\"Total samples after balancing: {len(X):,}, Labels: {len(Y):,}\")\n",
        "\n",
        "#         # Validate data consistency\n",
        "#         if len(X) != len(Y):\n",
        "#             raise ValueError(f\"Inconsistent data: X has {len(X)} samples, Y has {len(Y)} labels\")\n",
        "#         if len(X) == 0:\n",
        "#             raise ValueError(\"No data available after loading and balancing\")\n",
        "\n",
        "#     except NotImplementedError:\n",
        "#         print(\"ERROR: Please implement DataManager.load_and_balance_data() with your actual data loading logic\")\n",
        "#         return\n",
        "#     except Exception as e:\n",
        "#         print(f\"ERROR loading data: {e}\")\n",
        "#         return\n",
        "\n",
        "#     # Load hyperparameters\n",
        "#     hyperparams_file = f\"{Config.OUTPUT_DIR}/hyperparameters/all_best_params.json\"\n",
        "#     if os.path.exists(hyperparams_file):\n",
        "#         with open(hyperparams_file, 'r') as f:\n",
        "#             all_best_params = json.load(f)\n",
        "#         print(f\"Loaded best parameters for {len(all_best_params)} models\")\n",
        "#     else:\n",
        "#         print(\"No hyperparameters found, using default parameters\")\n",
        "#         all_best_params = {}\n",
        "\n",
        "#     # Process each model individually\n",
        "#     for model_name in Config.MODELS:\n",
        "#         print(f\"\\n{'='*70}\")\n",
        "#         print(f\"TRAINING MODEL: {model_name}\")\n",
        "#         print(f\"{'='*70}\")\n",
        "\n",
        "#         try:\n",
        "#             # Get parameters for this model\n",
        "#             if model_name in all_best_params:\n",
        "#                 best_params = all_best_params[model_name]\n",
        "#                 print(f\"Using optimized parameters for {model_name}\")\n",
        "#             else:\n",
        "#                 # Default parameters\n",
        "#                 best_params = {\n",
        "#                     \"dropout\": 0.10289132195027265,\n",
        "#                     \"label_smoothing\": 0.03714841610239749,\n",
        "#                     \"lr\": 0.004155652374869997,\n",
        "#                     \"optimizer_type\": \"adamw\",\n",
        "#                     \"scheduler_type\": \"cosine\",\n",
        "#                     \"batch_size\": 64,\n",
        "#                     \"weight_decay\": 2.156989662164921e-06\n",
        "#                 }\n",
        "#                 print(f\"Using default parameters for {model_name}\")\n",
        "\n",
        "#             # Display parameters\n",
        "#             print(f\"\\n{model_name.upper()} TRAINING PARAMETERS:\")\n",
        "#             for key, value in best_params.items():\n",
        "#                 if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "#                     print(f\"  {key}: {value:.6f}\")\n",
        "#                 else:\n",
        "#                     print(f\"  {key}: {value}\")\n",
        "\n",
        "#             # Create data loaders\n",
        "#             print(f\"\\nCreating data loaders for {model_name}...\")\n",
        "#             try:\n",
        "#                 train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(\n",
        "#                     X, Y, test_size=0.2,\n",
        "#                     batch_size=best_params.get('batch_size', Config.BATCH_SIZE),\n",
        "#                     augmentation_strength=best_params.get('augmentation_strength', 'medium')\n",
        "#                 )\n",
        "\n",
        "#                 print(f\"Data loaders created successfully\")\n",
        "#                 print(f\"Train: {len(train_loader.dataset)}, Val: {len(val_loader.dataset)}, Test: {len(test_loader.dataset)}\")\n",
        "\n",
        "#             except NotImplementedError:\n",
        "#                 print(\"ERROR: Please implement DataManager.create_data_loaders() with your actual data loader creation\")\n",
        "#                 continue\n",
        "#             except Exception as e:\n",
        "#                 print(f\"ERROR creating data loaders: {e}\")\n",
        "#                 continue\n",
        "\n",
        "#             # Validate data loaders\n",
        "#             if not train_loader or len(train_loader.dataset) == 0:\n",
        "#                 print(f\"Skipping {model_name}: No training data available\")\n",
        "#                 continue\n",
        "#             if not val_loader or len(val_loader.dataset) == 0:\n",
        "#                 print(f\"Skipping {model_name}: No validation data available\")\n",
        "#                 continue\n",
        "\n",
        "#             # Create model\n",
        "#             print(f\"\\nCreating model: {model_name}\")\n",
        "#             try:\n",
        "#                 model = ModelFactory.create_model(\n",
        "#                     model_name, num_classes=Config.NUM_CLASSES,\n",
        "#                     dropout_rate=best_params.get('dropout', 0.5),\n",
        "#                     hidden_dim_multiplier=best_params.get('hidden_dim_multiplier', 0.5)\n",
        "#                 ).to(Config.DEVICE, memory_format=torch.channels_last)\n",
        "\n",
        "#                 total_params = sum(p.numel() for p in model.parameters())\n",
        "#                 trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "#                 print(f\"Model created: {total_params:,} total params, {trainable_params:,} trainable\")\n",
        "\n",
        "#             except NotImplementedError:\n",
        "#                 print(\"ERROR: Please implement ModelFactory.create_model() with your actual model creation\")\n",
        "#                 continue\n",
        "#             except Exception as e:\n",
        "#                 print(f\"ERROR creating model: {e}\")\n",
        "#                 continue\n",
        "\n",
        "#             # Train main model\n",
        "#             print(f\"\\nStarting main model training for {model_name}\")\n",
        "#             trainer = EnhancedModelTrainer(model, model_name, best_params)\n",
        "#             training_success = trainer.train_main_model(train_loader, val_loader, test_loader)\n",
        "\n",
        "#             if not training_success:\n",
        "#                 print(f\"Main training failed for {model_name}, skipping...\")\n",
        "#                 continue\n",
        "\n",
        "#             print(f\"Main model training completed for {model_name}\")\n",
        "\n",
        "#             # K-fold cross-validation\n",
        "#             print(f\"\\nStarting K-fold cross-validation for {model_name}\")\n",
        "#             total_samples = len(train_loader.dataset)\n",
        "#             min_samples_per_fold = 500\n",
        "#             max_folds = total_samples // min_samples_per_fold\n",
        "#             n_folds = min(3, max_folds) if max_folds > 1 else 0\n",
        "\n",
        "#             if n_folds > 1:\n",
        "#                 kfold_success = trainer.train_kfold(train_loader, val_loader, test_loader, n_folds=n_folds)\n",
        "#                 if kfold_success:\n",
        "#                     print(f\"K-fold validation completed for {model_name}\")\n",
        "#                 else:\n",
        "#                     print(f\"K-fold validation failed for {model_name}\")\n",
        "#             else:\n",
        "#                 print(f\"Skipping k-fold validation for {model_name}: insufficient data\")\n",
        "\n",
        "#             # Save model for ensemble\n",
        "#             model_ensemble_path = f\"{Config.OUTPUT_DIR}/models/{model_name}_for_ensemble.pt\"\n",
        "#             torch.save(model.state_dict(), model_ensemble_path)\n",
        "#             print(f\"Model saved for ensemble: {model_name}\")\n",
        "\n",
        "#             # Cleanup\n",
        "#             trainer.cleanup_trainer()\n",
        "#             del trainer, model, train_loader, val_loader, test_loader\n",
        "#             resource_manager.aggressive_cleanup()\n",
        "\n",
        "#             print(f\"‚úÖ {model_name} TRAINING COMPLETED!\")\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(f\"Error processing {model_name}: {e}\")\n",
        "#             import traceback\n",
        "#             traceback.print_exc()\n",
        "\n",
        "#             # Emergency cleanup\n",
        "#             try:\n",
        "#                 if 'trainer' in locals():\n",
        "#                     trainer.cleanup_trainer()\n",
        "#                     del trainer\n",
        "#                 if 'model' in locals():\n",
        "#                     del model\n",
        "#                 resource_manager.aggressive_cleanup()\n",
        "#             except:\n",
        "#                 pass\n",
        "#             continue\n",
        "\n",
        "#     # Final cleanup and summary\n",
        "#     print(\"\\nFinal cleanup and summary...\")\n",
        "#     try:\n",
        "#         if 'X' in locals():\n",
        "#             del X\n",
        "#         if 'Y' in locals():\n",
        "#             del Y\n",
        "#         if 'all_best_params' in locals():\n",
        "#             del all_best_params\n",
        "\n",
        "#         resource_manager.aggressive_cleanup()\n",
        "#         final_stats = resource_manager.get_memory_stats()\n",
        "#         print(f\"Final GPU memory: {final_stats['gpu_allocated_gb']:.2f}GB ({final_stats['gpu_percent']:.1f}%)\")\n",
        "#         print(f\"Final CPU usage: {final_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error in final cleanup: {e}\")\n",
        "\n",
        "#     print(\"\\n\" + \"=\"*70)\n",
        "#     print(\"MODEL TRAINING COMPLETED!\")\n",
        "#     print(\"=\"*70)\n",
        "#     print(\"\\nGenerated Files:\")\n",
        "#     print(f\"- Model checkpoints: {Config.OUTPUT_DIR}/models/\")\n",
        "#     print(f\"- Best models: {Config.OUTPUT_DIR}/best_model/\")\n",
        "#     print(f\"- Training results: {Config.OUTPUT_DIR}/training_results/\")\n",
        "#     print(f\"- K-fold results: {Config.OUTPUT_DIR}/kfold_results/\")\n",
        "#     print(f\"- K-fold models: {Config.OUTPUT_DIR}/kfold_models/\")\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ],
      "metadata": {
        "id": "V57jiUT2c3BV"
      },
      "id": "V57jiUT2c3BV",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 10: Evaluation and Plot's"
      ],
      "metadata": {
        "id": "rQ_reeX1cZz4"
      },
      "id": "rQ_reeX1cZz4"
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "Standalone Model Visualization and Evaluation Script\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision import models\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, f1_score, precision_score, recall_score,\n",
        "    roc_curve, auc, precision_recall_curve, average_precision_score,\n",
        "    confusion_matrix, classification_report\n",
        ")\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from datetime import datetime\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from dataclasses import dataclass, field\n",
        "from tqdm import tqdm\n",
        "\n",
        "# For TensorFlow/Keras support\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "except ImportError:\n",
        "    pass  # Optional, only if .keras models are used\n",
        "\n",
        "# For XAI\n",
        "from captum.attr import LayerGradCam\n",
        "\n",
        "# ============================================================================\n",
        "# Configuration\n",
        "# ============================================================================\n",
        "@dataclass\n",
        "class VisualizationConfig:\n",
        "    \"\"\"Configuration for visualization script\"\"\"\n",
        "    OUTPUT_DIR: str = \"/content/drive/MyDrive/Hilsha\"\n",
        "    MODELS_DIR: str = \"/content/drive/MyDrive/Hilsha\"\n",
        "    TRAINING_RESULTS_DIR: str = \"/content/drive/MyDrive/Hilsha/training_results\"\n",
        "    KFOLD_MODELS_DIR: str = \"/content/drive/MyDrive/Hilsha/kfold_models\"\n",
        "\n",
        "    # Output directories\n",
        "    RESULTS_DIR: str = \"/content/drive/MyDrive/Hilsha/results\"\n",
        "    SINGLE_MODELS_DIR: str = \"/content/drive/MyDrive/Hilsha/results/single_models\"\n",
        "    ENSEMBLES_DIR: str = \"/content/drive/MyDrive/Hilsha/results/ensembles\"\n",
        "    COMPARISONS_DIR: str = \"/content/drive/MyDrive/Hilsha/results/comparisons\"\n",
        "\n",
        "    # Model configuration\n",
        "    MODELS: Optional[List[str]] = None\n",
        "    NUM_CLASSES: int = 23\n",
        "    CLASS_NAMES: List[str] = None  # Update if known, e.g., ['Ilish', 'Chandana', 'Sardin', 'Sardinella', 'Punctatus', ...]\n",
        "\n",
        "    # Visualization settings\n",
        "    FIGURE_DPI: int = 300\n",
        "    FIGURE_SIZE: Tuple[int, int] = (12, 8)\n",
        "    COLOR_PALETTE: str = \"Set2\"\n",
        "\n",
        "    # Device\n",
        "    DEVICE: torch.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # XAI settings\n",
        "    XAI_IMAGE_SIZE: Tuple[int, int] = (224, 224)\n",
        "    XAI_METHODS: List[str] = field(default_factory=lambda: [\"gradcam\", \"gradient\", \"lrp\"])\n",
        "\n",
        "    def __post_init__(self):\n",
        "        \"\"\"Create output directories\"\"\"\n",
        "        for directory in [self.RESULTS_DIR, self.SINGLE_MODELS_DIR,\n",
        "                         self.ENSEMBLES_DIR, self.COMPARISONS_DIR]:\n",
        "            Path(directory).mkdir(parents=True, exist_ok=True)\n",
        "            print(f\"Created/Verified directory: {directory}\")\n",
        "\n",
        "# Initialize config\n",
        "Config = VisualizationConfig()\n",
        "\n",
        "# ============================================================================\n",
        "# Model Factory\n",
        "# ============================================================================\n",
        "class ModelFactory:\n",
        "    \"\"\"Factory for creating model architectures for loading weights\"\"\"\n",
        "\n",
        "    @staticmethod\n",
        "    def create_model(model_name, params=None, num_classes=Config.NUM_CLASSES, dropout_rate=0.5, hidden_dim_multiplier=0.5):\n",
        "        \"\"\"Create model with configurable architecture\"\"\"\n",
        "        if params is None:\n",
        "            params = {}\n",
        "        dropout_rate = params.get('dropout', dropout_rate)\n",
        "        hidden_dim_multiplier = params.get('hidden_dim_multiplier', hidden_dim_multiplier)\n",
        "\n",
        "        model_name = model_name.lower()\n",
        "        # Map fold and ensemble models to base architectures\n",
        "        if 'resnet50' in model_name:  # Covers resnet50, resnet50_fold_X, resnet50_for_ensemble\n",
        "            model_name = 'resnet50'\n",
        "        elif 'efficientnet_b0' in model_name:  # Covers efficientnet_b0, efficientnet_b0_fold_X, efficientnet_b0_for_ensemble\n",
        "            model_name = 'efficientnet_b0'\n",
        "\n",
        "        if model_name == 'resnet50':\n",
        "            model = models.resnet50(weights='IMAGENET1K_V2')\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'efficientnet_b0':\n",
        "            model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"_blocks.15\" in name or \"_blocks.16\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = model.classifier[1].in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'mobilenet_v3_large':\n",
        "            model = models.mobilenet_v3_large(weights='IMAGENET1K_V2')\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"features.12\" in name or \"features.13\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = 960\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'vgg16':\n",
        "            model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"classifier\" in name or \"features.28\" in name:\n",
        "                    param.requires_grad = True\n",
        "            hidden_dim = int(4096 * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Linear(512 * 7 * 7, 4096),\n",
        "                nn.ReLU(True),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(4096, hidden_dim),\n",
        "                nn.ReLU(True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'densenet121':\n",
        "            model = models.densenet121(weights='IMAGENET1K_V1')\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"denseblock4\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = model.classifier.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'inception_v3':\n",
        "            model = models.inception_v3(weights='IMAGENET1K_V1')\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if any(layer in name for layer in [\"Mixed_7a\", \"Mixed_7b\", \"Mixed_7c\", \"fc\", \"AuxLogits\"]):\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "            if hasattr(model, 'AuxLogits') and model.AuxLogits is not None:\n",
        "                aux_features = model.AuxLogits.fc.in_features\n",
        "                aux_hidden = int(aux_features * hidden_dim_multiplier)\n",
        "                model.AuxLogits.fc = nn.Sequential(\n",
        "                    nn.Dropout(dropout_rate),\n",
        "                    nn.Linear(aux_features, aux_hidden),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.BatchNorm1d(aux_hidden),\n",
        "                    nn.Dropout(dropout_rate / 2),\n",
        "                    nn.Linear(aux_hidden, num_classes)\n",
        "                )\n",
        "\n",
        "        elif model_name == 'vit_b_16':\n",
        "            model = models.vit_b_16(weights='IMAGENET1K_V1')\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if any(layer in name for layer in [\"encoder.layers.10\", \"encoder.layers.11\", \"heads\"]):\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.heads.head.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.heads.head = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'convnext_base':\n",
        "            model = models.convnext_base(weights='IMAGENET1K_V1')\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if any(layer in name for layer in [\"features.7\", \"classifier\"]):\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.classifier[2].in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                model.classifier[0],\n",
        "                model.classifier[1],\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'regnet_y_32gf':\n",
        "            model = models.regnet_y_32gf(weights='IMAGENET1K_V2')\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"trunk_output\" in name or \"fc\" in name:\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'cnn':\n",
        "            class SimpleCNN(nn.Module):\n",
        "                def __init__(self, num_classes=Config.NUM_CLASSES, dropout_rate=0.3, hidden_dim_multiplier=0.3):\n",
        "                    super(SimpleCNN, self).__init__()\n",
        "                    self.features = nn.Sequential(\n",
        "                        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.1),\n",
        "                        nn.MaxPool2d(2, 2),\n",
        "                        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.15),\n",
        "                        nn.MaxPool2d(2, 2),\n",
        "                        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.2),\n",
        "                        nn.MaxPool2d(2, 2),\n",
        "                        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.25),\n",
        "                        nn.MaxPool2d(2, 2),\n",
        "                        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(256),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.3),\n",
        "                        nn.AdaptiveAvgPool2d((7, 7))\n",
        "                    )\n",
        "                    conv_output_size = 256 * 7 * 7\n",
        "                    hidden_dim = int(conv_output_size * hidden_dim_multiplier)\n",
        "                    hidden_dim = max(64, min(hidden_dim, 512))\n",
        "                    self.classifier = nn.Sequential(\n",
        "                        nn.Dropout(dropout_rate),\n",
        "                        nn.Linear(conv_output_size, hidden_dim),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.BatchNorm1d(hidden_dim),\n",
        "                        nn.Dropout(dropout_rate * 0.5),\n",
        "                        nn.Linear(hidden_dim, num_classes)\n",
        "                    )\n",
        "                    self._initialize_weights()\n",
        "\n",
        "                def _initialize_weights(self):\n",
        "                    for m in self.modules():\n",
        "                        if isinstance(m, nn.Conv2d):\n",
        "                            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "                        elif isinstance(m, nn.Linear):\n",
        "                            nn.init.xavier_uniform_(m.weight, gain=0.5)\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "                        elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
        "                            if m.weight is not None:\n",
        "                                nn.init.ones_(m.weight)\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "\n",
        "                def forward(self, x):\n",
        "                    x = self.features(x)\n",
        "                    x = torch.flatten(x, 1)\n",
        "                    x = self.classifier(x)\n",
        "                    x = torch.clamp(x, min=-10, max=10)\n",
        "                    return x\n",
        "\n",
        "            model = SimpleCNN(num_classes=num_classes, dropout_rate=dropout_rate, hidden_dim_multiplier=hidden_dim_multiplier)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "        return model.to(Config.DEVICE)\n",
        "\n",
        "# ============================================================================\n",
        "# Dataset\n",
        "# ============================================================================\n",
        "class NumpyDataset(Dataset):\n",
        "    \"\"\"Dataset for loading NumPy arrays\"\"\"\n",
        "    def __init__(self, images: np.ndarray, labels: np.ndarray, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform or transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((224, 224)),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "        ])\n",
        "\n",
        "        # Ensure images are in (N, H, W, C) format\n",
        "        if self.images.shape[-1] not in [3, 4]:  # Check if last dimension is channels\n",
        "            if self.images.shape[1] in [3, 4]:  # Check if second dimension is channels\n",
        "                self.images = np.transpose(self.images, (0, 2, 3, 1))  # Convert (N, C, H, W) to (N, H, W, C)\n",
        "            else:\n",
        "                raise ValueError(f\"Unexpected image shape: {self.images.shape}\")\n",
        "\n",
        "        # Check label range\n",
        "        if np.max(self.labels) >= Config.NUM_CLASSES or np.min(self.labels) < 0:\n",
        "            raise ValueError(f\"Labels out of range [0, {Config.NUM_CLASSES-1}]: min={np.min(self.labels)}, max={np.max(self.labels)}\")\n",
        "\n",
        "        print(f\"Loaded {len(self.images)} samples\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, label\n",
        "\n",
        "# Add data loaders here (create_train_loader, create_val_loader, create_test_loader as previously provided)\n",
        "\n",
        "# ============================================================================\n",
        "# Model Manager\n",
        "# ============================================================================\n",
        "class ModelManager:\n",
        "    def __init__(self):\n",
        "        self.models = {}\n",
        "        self.model_configs = {}\n",
        "        self.training_histories = {}\n",
        "\n",
        "    def discover_models(self) -> List[str]:\n",
        "        \"\"\"Discover available trained models across multiple directories\"\"\"\n",
        "        models = []\n",
        "        patterns = [\"*_best.pt\", \"*_best.pth\", \"*.pt\", \"*.pth\", \"*.keras\"]\n",
        "        search_dirs = [\n",
        "            Path(Config.MODELS_DIR),\n",
        "            Path(Config.MODELS_DIR) / \"models\",\n",
        "            Path(Config.MODELS_DIR) / \"best_model\",\n",
        "            Path(Config.TRAINING_RESULTS_DIR),\n",
        "            Path(Config.KFOLD_MODELS_DIR)\n",
        "        ]\n",
        "\n",
        "        if Config.MODELS is None or not Config.MODELS:\n",
        "            for directory in search_dirs:\n",
        "                if not directory.exists():\n",
        "                    print(f\"Directory not found: {directory}\")\n",
        "                    continue\n",
        "                for pattern in patterns:\n",
        "                    model_files = list(directory.glob(pattern))\n",
        "                    for model_file in model_files:\n",
        "                        model_name = model_file.stem.replace(\"_best\", \"\")\n",
        "                        if model_name not in models:\n",
        "                            models.append(model_name)\n",
        "        else:\n",
        "            models = list(Config.MODELS)\n",
        "\n",
        "        return models\n",
        "\n",
        "    def load_model(self, model_name: str) -> Optional[nn.Module]:\n",
        "        \"\"\"Load a trained model from multiple possible directories\"\"\"\n",
        "        # Map fold and ensemble models to base names for history lookup\n",
        "        base_model_name = model_name\n",
        "        if 'resnet50' in model_name:\n",
        "            base_model_name = 'resnet50'\n",
        "        elif 'efficientnet_b0' in model_name:\n",
        "            base_model_name = 'efficientnet_b0'\n",
        "\n",
        "        possible_paths = [\n",
        "            Path(Config.MODELS_DIR) / \"best_model\" / f\"{model_name}_best.pt\",\n",
        "            Path(Config.MODELS_DIR) / \"models\" / f\"{model_name}_for_ensemble.pt\",\n",
        "            Path(Config.KFOLD_MODELS_DIR) / f\"{model_name}.pt\",\n",
        "            Path(Config.MODELS_DIR) / f\"{model_name}.pt\",\n",
        "            Path(Config.MODELS_DIR) / f\"{model_name}.pth\",\n",
        "            Path(Config.MODELS_DIR) / f\"{model_name}.keras\"\n",
        "        ]\n",
        "\n",
        "        model_path = None\n",
        "        for path in possible_paths:\n",
        "            if path.exists():\n",
        "                model_path = path\n",
        "                break\n",
        "\n",
        "        if model_path is None:\n",
        "            print(f\"Model file not found for: {model_name}\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            if str(model_path).endswith('.keras'):\n",
        "                model = keras.models.load_model(model_path)\n",
        "                self.model_configs[model_name] = {\n",
        "                    'hyperparameters': {},\n",
        "                    'num_classes': Config.NUM_CLASSES\n",
        "                }\n",
        "                print(f\"‚úÖ Loaded TensorFlow/Keras model: {model_name}\")\n",
        "                return model\n",
        "            else:\n",
        "                checkpoint = torch.load(model_path, map_location=Config.DEVICE, weights_only=False)\n",
        "                if isinstance(checkpoint, dict):\n",
        "                    model_state = checkpoint.get('model_state_dict', checkpoint.get('state_dict', checkpoint))\n",
        "                    hyperparams = checkpoint.get('hyperparameters', {})\n",
        "                    num_classes = checkpoint.get('num_classes', Config.NUM_CLASSES)\n",
        "                    if Config.CLASS_NAMES is None and 'class_names' in checkpoint:\n",
        "                        Config.CLASS_NAMES = checkpoint['class_names']\n",
        "                        Config.NUM_CLASSES = len(Config.CLASS_NAMES)\n",
        "                else:\n",
        "                    model_state = checkpoint\n",
        "                    hyperparams = {}\n",
        "                    num_classes = Config.NUM_CLASSES\n",
        "\n",
        "                model = ModelFactory.create_model(\n",
        "                    model_name,\n",
        "                    params=hyperparams,\n",
        "                    num_classes=num_classes,\n",
        "                    dropout_rate=hyperparams.get('dropout', 0.5),\n",
        "                    hidden_dim_multiplier=hyperparams.get('hidden_dim_multiplier', 0.5)\n",
        "                )\n",
        "\n",
        "                model.load_state_dict(model_state, strict=False)\n",
        "                model = model.to(Config.DEVICE)\n",
        "                model.eval()\n",
        "\n",
        "                self.model_configs[model_name] = {\n",
        "                    'hyperparameters': hyperparams,\n",
        "                    'num_classes': num_classes\n",
        "                }\n",
        "\n",
        "                print(f\"‚úÖ Loaded PyTorch model: {model_name}\")\n",
        "                return model\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading model {model_name}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def load_training_history(self, model_name: str) -> Optional[Dict]:\n",
        "        \"\"\"Load training history for a model\"\"\"\n",
        "        # Map fold and ensemble models to base names\n",
        "        base_model_name = model_name\n",
        "        if 'resnet50' in model_name:\n",
        "            base_model_name = 'resnet50'\n",
        "        elif 'efficientnet_b0' in model_name:\n",
        "            base_model_name = 'efficientnet_b0'\n",
        "\n",
        "        possible_paths = [\n",
        "            Path(Config.TRAINING_RESULTS_DIR) / f\"{base_model_name}_training_data.json\",\n",
        "            Path(Config.TRAINING_RESULTS_DIR) / f\"{base_model_name}_history.json\",\n",
        "            Path(Config.TRAINING_RESULTS_DIR) / f\"{base_model_name}.json\",\n",
        "            Path(Config.KFOLD_MODELS_DIR) / f\"{model_name}_kfold_results.json\"\n",
        "        ]\n",
        "\n",
        "        history_path = None\n",
        "        for path in possible_paths:\n",
        "            if path.exists():\n",
        "                history_path = path\n",
        "                break\n",
        "\n",
        "        if history_path is None:\n",
        "            print(f\"Training history not found for: {model_name}\")\n",
        "            return None\n",
        "\n",
        "        try:\n",
        "            with open(history_path, 'r') as f:\n",
        "                history = json.load(f)\n",
        "\n",
        "            print(f\"‚úÖ Loaded training history: {model_name}\")\n",
        "            return history\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ùå Error loading training history for {model_name}: {e}\")\n",
        "            return None\n",
        "\n",
        "    def load_all_models(self):\n",
        "        \"\"\"Load all available models and their histories\"\"\"\n",
        "        model_names = self.discover_models()\n",
        "\n",
        "        if not model_names:\n",
        "            print(\"No trained models found!\")\n",
        "            return\n",
        "\n",
        "        print(f\"Found {len(model_names)} models: {model_names}\")\n",
        "\n",
        "        for model_name in model_names:\n",
        "            model = self.load_model(model_name)\n",
        "            if model is not None:\n",
        "                self.models[model_name] = model\n",
        "\n",
        "            history = self.load_training_history(model_name)\n",
        "            if history is not None:\n",
        "                self.training_histories[model_name] = history\n",
        "\n",
        "        print(f\"Successfully loaded {len(self.models)} models and {len(self.training_histories)} histories\")\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# XAI Implementation\n",
        "# ============================================================================\n",
        "class XAIAnalyzer:\n",
        "    \"\"\"Explainable AI analyzer with multiple methods\"\"\"\n",
        "\n",
        "    def __init__(self, model: nn.Module, device: torch.device):\n",
        "        self.model = model.eval()\n",
        "        self.device = device\n",
        "        self.gradients = None\n",
        "        self.activations = None\n",
        "\n",
        "    def register_hooks(self, target_layer: nn.Module):\n",
        "        \"\"\"Register forward and backward hooks\"\"\"\n",
        "        def forward_hook(module, input, output):\n",
        "            self.activations = output.detach()\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            self.gradients = grad_output[0].detach()\n",
        "\n",
        "        target_layer.register_forward_hook(forward_hook)\n",
        "        target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "    def get_target_layer(self) -> nn.Module:\n",
        "        \"\"\"Get the target layer for gradient-based methods\"\"\"\n",
        "        target_layer = None\n",
        "        for name, module in self.model.named_modules():\n",
        "            if isinstance(module, (nn.Conv2d, nn.AdaptiveAvgPool2d)):\n",
        "                target_layer = module\n",
        "        return target_layer\n",
        "\n",
        "    def gradcam_plus_plus(self, input_tensor: torch.Tensor, class_idx: int) -> np.ndarray:\n",
        "        \"\"\"Generate Grad-CAM++ visualization\"\"\"\n",
        "        target_layer = self.get_target_layer()\n",
        "        if target_layer is None:\n",
        "            return np.zeros((224, 224))\n",
        "\n",
        "        self.register_hooks(target_layer)\n",
        "\n",
        "        # Forward pass\n",
        "        output = self.model(input_tensor)\n",
        "\n",
        "        # Backward pass\n",
        "        self.model.zero_grad()\n",
        "        class_score = output[:, class_idx].sum()\n",
        "        class_score.backward(retain_graph=True)\n",
        "\n",
        "        if self.gradients is None or self.activations is None:\n",
        "            return np.zeros((224, 224))\n",
        "\n",
        "        # Grad-CAM++ computation\n",
        "        gradients = self.gradients[0]  # (C, H, W)\n",
        "        activations = self.activations[0]  # (C, H, W)\n",
        "\n",
        "        # Calculate alpha weights\n",
        "        alpha_num = gradients.pow(2)\n",
        "        alpha_denom = 2.0 * gradients.pow(2) + \\\n",
        "                     (activations * gradients.pow(3)).sum(dim=(1, 2), keepdim=True)\n",
        "        alpha_denom = torch.where(alpha_denom != 0.0, alpha_denom, torch.ones_like(alpha_denom))\n",
        "        alpha = alpha_num / alpha_denom\n",
        "\n",
        "        # Calculate weights\n",
        "        weights = (alpha * F.relu(gradients)).sum(dim=(1, 2))\n",
        "\n",
        "        # Generate CAM\n",
        "        cam = (weights.unsqueeze(-1).unsqueeze(-1) * activations).sum(dim=0)\n",
        "        cam = F.relu(cam)\n",
        "\n",
        "        # Resize to input size\n",
        "        cam = F.interpolate(cam.unsqueeze(0).unsqueeze(0), size=(224, 224), mode='bilinear')\n",
        "        cam = cam.squeeze().cpu().numpy()\n",
        "\n",
        "        # Normalize\n",
        "        if cam.max() > cam.min():\n",
        "            cam = (cam - cam.min()) / (cam.max() - cam.min())\n",
        "\n",
        "        return cam\n",
        "\n",
        "    def gradient_saliency(self, input_tensor: torch.Tensor, class_idx: int) -> np.ndarray:\n",
        "        \"\"\"Generate gradient-based saliency map\"\"\"\n",
        "        input_tensor.requires_grad_(True)\n",
        "\n",
        "        # Forward pass\n",
        "        output = self.model(input_tensor)\n",
        "\n",
        "        # Backward pass\n",
        "        self.model.zero_grad()\n",
        "        class_score = output[:, class_idx]\n",
        "        class_score.backward()\n",
        "\n",
        "        # Get gradients\n",
        "        gradients = input_tensor.grad.data.abs()\n",
        "\n",
        "        # Take maximum across channels\n",
        "        saliency = gradients.max(dim=1)[0].squeeze().cpu().numpy()\n",
        "\n",
        "        # Normalize\n",
        "        if saliency.max() > saliency.min():\n",
        "            saliency = (saliency - saliency.min()) / (saliency.max() - saliency.min())\n",
        "\n",
        "        return saliency\n",
        "\n",
        "    def lrp_simple(self, input_tensor: torch.Tensor, class_idx: int) -> np.ndarray:\n",
        "        \"\"\"Simple LRP implementation (Layer-wise Relevance Propagation)\"\"\"\n",
        "        input_tensor.requires_grad_(True)\n",
        "\n",
        "        output = self.model(input_tensor)\n",
        "\n",
        "        # Backward pass\n",
        "        self.model.zero_grad()\n",
        "        class_score = output[:, class_idx]\n",
        "        class_score.backward()\n",
        "\n",
        "        # LRP approximation using input * gradient\n",
        "        relevance = (input_tensor * input_tensor.grad).sum(dim=1).abs()\n",
        "        relevance = relevance.squeeze().cpu().numpy()\n",
        "\n",
        "        # Normalize\n",
        "        if relevance.max() > relevance.min():\n",
        "            relevance = (relevance - relevance.min()) / (relevance.max() - relevance.min())\n",
        "\n",
        "        return relevance\n",
        "\n",
        "    def generate_all_explanations(self, input_tensor: torch.Tensor, class_idx: int) -> Dict[str, np.ndarray]:\n",
        "        \"\"\"Generate all XAI explanations\"\"\"\n",
        "        explanations = {}\n",
        "\n",
        "        try:\n",
        "            explanations['gradcam'] = self.gradcam_plus_plus(input_tensor, class_idx)\n",
        "        except Exception as e:\n",
        "            print(f\"Grad-CAM++ failed: {e}\")\n",
        "            explanations['gradcam'] = np.zeros((224, 224))\n",
        "\n",
        "        try:\n",
        "            explanations['gradient'] = self.gradient_saliency(input_tensor, class_idx)\n",
        "        except Exception as e:\n",
        "            print(f\"Gradient saliency failed: {e}\")\n",
        "            explanations['gradient'] = np.zeros((224, 224))\n",
        "\n",
        "        try:\n",
        "            explanations['lrp'] = self.lrp_simple(input_tensor, class_idx)\n",
        "        except Exception as e:\n",
        "            print(f\"LRP failed: {e}\")\n",
        "            explanations['lrp'] = np.zeros((224, 224))\n",
        "\n",
        "        return explanations\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Single Model Analyzer\n",
        "# ============================================================================\n",
        "class SingleModelAnalyzer:\n",
        "    \"\"\"Analyzes individual models\"\"\"\n",
        "\n",
        "    def __init__(self, model_manager: ModelManager):\n",
        "        self.model_manager = model_manager\n",
        "\n",
        "    def plot_training_dynamics(self, model_name: str, history: Dict):\n",
        "        \"\"\"Plot training dynamics for a single model\"\"\"\n",
        "        if 'training_history' not in history:\n",
        "            print(f\"No training history found for {model_name}\")\n",
        "            return\n",
        "\n",
        "        train_history = history['training_history']\n",
        "\n",
        "        # Create subplots\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        fig.suptitle(f'{model_name} - Training Dynamics', fontsize=16, fontweight='bold')\n",
        "\n",
        "        epochs = range(1, len(train_history.get('train_loss', [])) + 1)\n",
        "\n",
        "        # Training and Validation Loss\n",
        "        if 'train_loss' in train_history and 'val_loss' in train_history:\n",
        "            axes[0, 0].plot(epochs, train_history['train_loss'], 'b-', label='Training Loss', linewidth=2)\n",
        "            axes[0, 0].plot(epochs, train_history['val_loss'], 'r-', label='Validation Loss', linewidth=2)\n",
        "            axes[0, 0].set_title('Loss vs Epoch', fontweight='bold')\n",
        "            axes[0, 0].set_xlabel('Epoch')\n",
        "            axes[0, 0].set_ylabel('Loss')\n",
        "            axes[0, 0].legend()\n",
        "            axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Training and Validation Accuracy\n",
        "        if 'train_acc' in train_history and 'val_acc' in train_history:\n",
        "            axes[0, 1].plot(epochs, train_history['train_acc'], 'b-', label='Training Accuracy', linewidth=2)\n",
        "            axes[0, 1].plot(epochs, train_history['val_acc'], 'r-', label='Validation Accuracy', linewidth=2)\n",
        "            axes[0, 1].set_title('Accuracy vs Epoch', fontweight='bold')\n",
        "            axes[0, 1].set_xlabel('Epoch')\n",
        "            axes[0, 1].set_ylabel('Accuracy')\n",
        "            axes[0, 1].legend()\n",
        "            axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # F1 Score\n",
        "        if 'val_f1' in train_history:\n",
        "            axes[0, 2].plot(epochs, train_history['val_f1'], 'g-', label='Validation F1', linewidth=2)\n",
        "            axes[0, 2].set_title('F1-Score vs Epoch', fontweight='bold')\n",
        "            axes[0, 2].set_xlabel('Epoch')\n",
        "            axes[0, 2].set_ylabel('F1-Score')\n",
        "            axes[0, 2].legend()\n",
        "            axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "        # Learning Rate\n",
        "        if 'learning_rates' in train_history:\n",
        "            axes[1, 0].plot(epochs, train_history['learning_rates'], 'purple', linewidth=2)\n",
        "            axes[1, 0].set_title('Learning Rate vs Epoch', fontweight='bold')\n",
        "            axes[1, 0].set_xlabel('Epoch')\n",
        "            axes[1, 0].set_ylabel('Learning Rate')\n",
        "            axes[1, 0].set_yscale('log')\n",
        "            axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Training Time per Epoch\n",
        "        if 'epoch_times' in train_history:\n",
        "            axes[1, 1].plot(epochs, train_history['epoch_times'], 'orange', linewidth=2)\n",
        "            axes[1, 1].set_title('Training Time vs Epoch', fontweight='bold')\n",
        "            axes[1, 1].set_xlabel('Epoch')\n",
        "            axes[1, 1].set_ylabel('Time (seconds)')\n",
        "            axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Memory Usage (if available)\n",
        "        if 'memory_usage' in train_history and train_history['memory_usage']:\n",
        "            gpu_memory = [mem.get('gpu_percent', 0) for mem in train_history['memory_usage'] if isinstance(mem, dict)]\n",
        "            if gpu_memory:\n",
        "                axes[1, 2].plot(epochs[:len(gpu_memory)], gpu_memory, 'red', linewidth=2)\n",
        "                axes[1, 2].set_title('GPU Memory Usage vs Epoch', fontweight='bold')\n",
        "                axes[1, 2].set_xlabel('Epoch')\n",
        "                axes[1, 2].set_ylabel('GPU Memory (%)')\n",
        "                axes[1, 2].grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save plot\n",
        "        output_path = Path(Config.SINGLE_MODELS_DIR) / f\"{model_name}_training_dynamics.png\"\n",
        "        plt.savefig(output_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "\n",
        "        # Save PDF version\n",
        "        output_path_pdf = output_path.with_suffix('.pdf')\n",
        "        plt.savefig(output_path_pdf, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"‚úÖ Training dynamics saved: {output_path}\")\n",
        "\n",
        "\n",
        "    def evaluate_model_comprehensive(self, model_name: str, model: nn.Module, test_loader: DataLoader) -> Dict:\n",
        "        \"\"\"Comprehensive model evaluation\"\"\"\n",
        "        model.eval()\n",
        "        all_predictions = []\n",
        "        all_probabilities = []\n",
        "        all_labels = []\n",
        "        all_images = []\n",
        "\n",
        "        print(f\"Evaluating {model_name}...\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in tqdm(test_loader, desc=\"Evaluation\"):\n",
        "                images_device = images.to(Config.DEVICE)\n",
        "                labels = labels.to(Config.DEVICE)\n",
        "\n",
        "                outputs = model(images_device)\n",
        "                probabilities = F.softmax(outputs, dim=1)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "                all_probabilities.extend(probabilities.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_images.extend(images.cpu().numpy())\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        all_predictions = np.array(all_predictions)\n",
        "        all_probabilities = np.array(all_probabilities)\n",
        "        all_labels = np.array(all_labels)\n",
        "        all_images = np.array(all_images)\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(all_labels, all_predictions)\n",
        "        f1_macro = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
        "        f1_weighted = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
        "        precision_macro = precision_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
        "        recall_macro = recall_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
        "\n",
        "        # Confusion matrix\n",
        "        conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "        # Classification report\n",
        "        unique_labels = np.unique(all_labels)\n",
        "        if Config.CLASS_NAMES and len(Config.CLASS_NAMES) >= len(unique_labels):\n",
        "            class_names = [Config.CLASS_NAMES[i] for i in unique_labels]\n",
        "        else:\n",
        "            class_names = [f\"Class_{i}\" for i in unique_labels]\n",
        "\n",
        "        try:\n",
        "            class_report = classification_report(\n",
        "                all_labels, all_predictions,\n",
        "                labels=unique_labels,  # Explicitly specify labels\n",
        "                target_names=class_names,\n",
        "                output_dict=True,\n",
        "                zero_division=0\n",
        "            )\n",
        "        except ValueError as e:\n",
        "            print(f\"Error in classification_report: {e}\")\n",
        "            class_report = {str(i): {'precision': 0, 'recall': 0, 'f1-score': 0, 'support': 0} for i in unique_labels}\n",
        "            class_report.update({\n",
        "                'accuracy': {'precision': accuracy, 'recall': accuracy, 'f1-score': accuracy, 'support': len(all_labels)},\n",
        "                'macro avg': {'precision': precision_macro, 'recall': recall_macro, 'f1-score': f1_macro, 'support': len(all_labels)},\n",
        "                'weighted avg': {'precision': precision_macro, 'recall': recall_macro, 'f1-score': f1_weighted, 'support': len(all_labels)}\n",
        "            })\n",
        "\n",
        "        # Save classification report as CSV\n",
        "        report_df = pd.DataFrame(class_report).transpose()\n",
        "        report_path = Path(Config.SINGLE_MODELS_DIR) / f\"{model_name}_classification_report.csv\"\n",
        "        report_df.to_csv(report_path)\n",
        "\n",
        "        return {\n",
        "            'predictions': all_predictions,\n",
        "            'probabilities': all_probabilities,\n",
        "            'labels': all_labels,\n",
        "            'images': all_images,\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_weighted': f1_weighted,\n",
        "            'precision_macro': precision_macro,\n",
        "            'recall_macro': recall_macro,\n",
        "            'confusion_matrix': conf_matrix,\n",
        "            'classification_report': class_report\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_evaluation_metrics(self, model_name: str, eval_results: Dict):\n",
        "        \"\"\"Plot comprehensive evaluation metrics\"\"\"\n",
        "        fig = plt.figure(figsize=(20, 16))\n",
        "        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "        # ROC Curve\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        self._plot_roc_curve(ax1, eval_results)\n",
        "\n",
        "        # Precision-Recall Curve\n",
        "        ax2 = fig.add_subplot(gs[0, 1])\n",
        "        self._plot_precision_recall_curve(ax2, eval_results)\n",
        "\n",
        "        # Confusion Matrix (Normalized)\n",
        "        ax3 = fig.add_subplot(gs[0, 2])\n",
        "        self._plot_confusion_matrix(ax3, eval_results, normalize=True)\n",
        "\n",
        "        # Confusion Matrix (Raw Counts)\n",
        "        ax4 = fig.add_subplot(gs[1, 0])\n",
        "        self._plot_confusion_matrix(ax4, eval_results, normalize=False)\n",
        "\n",
        "        # Class-wise Metrics\n",
        "        ax5 = fig.add_subplot(gs[1, 1])\n",
        "        self._plot_class_metrics(ax5, eval_results)\n",
        "\n",
        "        # Per-class F1 Scores\n",
        "        ax6 = fig.add_subplot(gs[1, 2])\n",
        "        self._plot_per_class_f1(ax6, eval_results)\n",
        "\n",
        "        plt.suptitle(f'{model_name} - Evaluation Metrics', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Save plot\n",
        "        output_path = Path(Config.SINGLE_MODELS_DIR) / f\"{model_name}_evaluation_metrics.png\"\n",
        "        plt.savefig(output_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "\n",
        "        # Save PDF version\n",
        "        output_path_pdf = output_path.with_suffix('.pdf')\n",
        "        plt.savefig(output_path_pdf, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"‚úÖ Evaluation metrics saved: {output_path}\")\n",
        "\n",
        "    def _plot_roc_curve(self, ax, eval_results):\n",
        "        \"\"\"Plot ROC curve\"\"\"\n",
        "        labels_bin = label_binarize(eval_results['labels'], classes=list(range(Config.NUM_CLASSES)))\n",
        "\n",
        "        # Calculate micro-average ROC curve\n",
        "        fpr_micro, tpr_micro, _ = roc_curve(labels_bin.ravel(), eval_results['probabilities'].ravel())\n",
        "        roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
        "\n",
        "        ax.plot(fpr_micro, tpr_micro, 'b-', linewidth=2,\n",
        "                label=f'Micro-average ROC (AUC = {roc_auc_micro:.3f})')\n",
        "        ax.plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
        "        ax.set_xlabel('False Positive Rate')\n",
        "        ax.set_ylabel('True Positive Rate')\n",
        "        ax.set_title('ROC Curve', fontweight='bold')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "    def _plot_precision_recall_curve(self, ax, eval_results):\n",
        "        \"\"\"Plot Precision-Recall curve\"\"\"\n",
        "        labels_bin = label_binarize(eval_results['labels'], classes=list(range(Config.NUM_CLASSES)))\n",
        "\n",
        "        # Calculate precision-recall for micro-average\n",
        "        precision_micro, recall_micro, _ = precision_recall_curve(\n",
        "            labels_bin.ravel(), eval_results['probabilities'].ravel()\n",
        "        )\n",
        "        ap_micro = average_precision_score(labels_bin, eval_results['probabilities'], average='micro')\n",
        "\n",
        "        ax.plot(recall_micro, precision_micro, 'b-', linewidth=2,\n",
        "                label=f'Micro-average PR (AP = {ap_micro:.3f})')\n",
        "        ax.set_xlabel('Recall')\n",
        "        ax.set_ylabel('Precision')\n",
        "        ax.set_title('Precision-Recall Curve', fontweight='bold')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "\n",
        "    def _plot_confusion_matrix(self, ax, eval_results, normalize=False):\n",
        "        \"\"\"Plot confusion matrix\"\"\"\n",
        "        cm = eval_results['confusion_matrix']\n",
        "        unique_labels = np.unique(eval_results['labels'])\n",
        "        if Config.CLASS_NAMES:\n",
        "            class_names = [Config.CLASS_NAMES[i] for i in unique_labels if i < len(Config.CLASS_NAMES)]\n",
        "        else:\n",
        "            class_names = [f\"Class_{i}\" for i in unique_labels]\n",
        "\n",
        "        if normalize:\n",
        "            cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "            title = 'Normalized Confusion Matrix'\n",
        "            fmt = '.2f'\n",
        "        else:\n",
        "            title = 'Confusion Matrix (Counts)'\n",
        "            fmt = 'd'\n",
        "\n",
        "        sns.heatmap(cm, annot=True, fmt=fmt, cmap='Blues', ax=ax, cbar=False)\n",
        "        ax.set_title(title, fontweight='bold')\n",
        "        ax.set_xlabel('Predicted')\n",
        "        ax.set_ylabel('True')\n",
        "        ax.set_xticks(np.arange(len(class_names)))\n",
        "        ax.set_yticks(np.arange(len(class_names)))\n",
        "        ax.set_xticklabels(class_names, rotation=45, ha='right')\n",
        "        ax.set_yticklabels(class_names, rotation=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _plot_class_metrics(self, ax, eval_results):\n",
        "        \"\"\"Plot class-wise metrics\"\"\"\n",
        "        class_report = eval_results['classification_report']\n",
        "        unique_labels = np.unique(eval_results['labels'])\n",
        "\n",
        "        if Config.CLASS_NAMES:\n",
        "            classes = [Config.CLASS_NAMES[i] for i in unique_labels if i < len(Config.CLASS_NAMES)]\n",
        "        else:\n",
        "            classes = [f\"Class_{i}\" for i in unique_labels]\n",
        "\n",
        "        # Initialize metrics lists\n",
        "        precision = []\n",
        "        recall = []\n",
        "        f1 = []\n",
        "\n",
        "        # Populate metrics, checking for existence\n",
        "        for i in unique_labels:\n",
        "            if str(i) in class_report:\n",
        "                precision.append(class_report[str(i)]['precision'])\n",
        "                recall.append(class_report[str(i)]['recall'])\n",
        "                f1.append(class_report[str(i)]['f1-score'])\n",
        "            else:\n",
        "                precision.append(0)\n",
        "                recall.append(0)\n",
        "                f1.append(0)\n",
        "\n",
        "        # Check if metrics are empty or inconsistent\n",
        "        if not precision or not recall or not f1 or len(precision) != len(classes):\n",
        "            ax.text(0.5, 0.5, 'No valid metrics\\nfor plotting', ha='center', va='center', transform=ax.transAxes)\n",
        "            ax.axis('off')\n",
        "            print(\"Warning: Skipping class-wise metrics plot due to empty or inconsistent metrics\")\n",
        "            return\n",
        "\n",
        "        x = np.arange(len(classes))\n",
        "        width = 0.25\n",
        "\n",
        "        ax.bar(x - width, precision, width, label='Precision')\n",
        "        ax.bar(x, recall, width, label='Recall')\n",
        "        ax.bar(x + width, f1, width, label='F1')\n",
        "\n",
        "        ax.set_title('Class-wise Metrics', fontweight='bold')\n",
        "        ax.set_xlabel('Classes')\n",
        "        ax.set_ylabel('Score')\n",
        "        ax.set_xticks(x)\n",
        "        ax.set_xticklabels(classes, rotation=45, ha='right')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "\n",
        "\n",
        "    def _plot_per_class_f1(self, ax, eval_results):\n",
        "        \"\"\"Plot per-class F1 scores\"\"\"\n",
        "        class_report = eval_results['classification_report']\n",
        "        unique_labels = np.unique(eval_results['labels'])\n",
        "\n",
        "        if Config.CLASS_NAMES:\n",
        "            classes = [Config.CLASS_NAMES[i] for i in unique_labels if i < len(Config.CLASS_NAMES)]\n",
        "        else:\n",
        "            classes = [f\"Class_{i}\" for i in unique_labels]\n",
        "\n",
        "        f1 = []\n",
        "        for i in unique_labels:\n",
        "            if str(i) in class_report:\n",
        "                f1.append(class_report[str(i)]['f1-score'])\n",
        "            else:\n",
        "                f1.append(0)\n",
        "\n",
        "        if not f1 or len(f1) != len(classes):\n",
        "            ax.text(0.5, 0.5, 'No valid F1 scores\\nfor plotting', ha='center', va='center', transform=ax.transAxes)\n",
        "            ax.axis('off')\n",
        "            print(\"Warning: Skipping per-class F1 scores plot due to empty or inconsistent metrics\")\n",
        "            return\n",
        "\n",
        "        sorted_idx = np.argsort(f1)[::-1]\n",
        "        sorted_classes = [classes[i] for i in sorted_idx]\n",
        "        sorted_f1 = [f1[i] for i in sorted_idx]\n",
        "\n",
        "        ax.bar(sorted_classes, sorted_f1, color='green', alpha=0.8)\n",
        "        ax.set_title('Per-Class F1 Scores (Sorted)', fontweight='bold')\n",
        "        ax.set_ylabel('F1 Score')\n",
        "        ax.set_xticks(np.arange(len(sorted_classes)))\n",
        "        ax.set_xticklabels(sorted_classes, rotation=90)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "\n",
        "\n",
        "    def plot_xai_examples(self, model_name: str, model: nn.Module, eval_results: Dict):\n",
        "        \"\"\"Plot XAI examples for correct and incorrect predictions\"\"\"\n",
        "        from captum.attr import LayerGradCam\n",
        "        import torch\n",
        "\n",
        "        images = eval_results['images']\n",
        "        labels = eval_results['labels']\n",
        "        predictions = eval_results['predictions']\n",
        "        probabilities = eval_results['probabilities']\n",
        "\n",
        "        correct_idx = [i for i in range(len(labels)) if labels[i] == predictions[i]]\n",
        "        incorrect_idx = [i for i in range(len(labels)) if labels[i] != predictions[i]]\n",
        "\n",
        "        correct_idx = correct_idx[:4] if len(correct_idx) >= 4 else correct_idx\n",
        "        incorrect_idx = incorrect_idx[:4] if len(incorrect_idx) >= 4 else incorrect_idx\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Normalize images to [0, 1] for display\n",
        "        def normalize_image(img):\n",
        "            img = img.copy()\n",
        "            img = (img - img.min()) / (img.max() - img.min() + 1e-8)  # Normalize to [0, 1]\n",
        "            return img\n",
        "\n",
        "        # Determine target layer based on model type\n",
        "        def get_target_layer(model, model_name):\n",
        "            if 'resnet' in model_name.lower():\n",
        "                return model.layer4[-1]  # Last conv layer for ResNet\n",
        "            elif 'efficientnet' in model_name.lower():\n",
        "                return model.features[-1]  # Last conv layer for EfficientNet\n",
        "            else:\n",
        "                raise ValueError(f\"Unsupported model type: {model_name}\")\n",
        "\n",
        "        # Plot correct predictions\n",
        "        if correct_idx:\n",
        "            fig, axes = plt.subplots(2, len(correct_idx), figsize=(4 * len(correct_idx), 8))\n",
        "            axes = np.array(axes).reshape(2, -1) if len(correct_idx) > 1 else np.array([axes])\n",
        "\n",
        "            for i, idx in enumerate(correct_idx):\n",
        "                img = normalize_image(images[idx])\n",
        "                label = int(labels[idx])  # Convert to Python int\n",
        "                prob = probabilities[idx]\n",
        "\n",
        "                img_tensor = torch.from_numpy(images[idx]).float().to(Config.DEVICE)\n",
        "                img_tensor = img_tensor.unsqueeze(0)\n",
        "                img_tensor.requires_grad_(True)  # Enable gradients for Grad-CAM\n",
        "\n",
        "                try:\n",
        "                    target_layer = get_target_layer(model, model_name)\n",
        "                    grad_cam = LayerGradCam(model, target_layer)\n",
        "                    relevance = grad_cam.attribute(img_tensor, target=label)\n",
        "                    relevance = relevance.detach().cpu().numpy().squeeze()\n",
        "                    relevance = (relevance - relevance.min()) / (relevance.max() - relevance.min() + 1e-8)\n",
        "\n",
        "                    axes[0, i].imshow(np.transpose(img, (1, 2, 0)))\n",
        "                    axes[0, i].set_title(f\"True: {label}, Pred: {predictions[idx]}\\nProb: {prob[predictions[idx]]:.2f}\")\n",
        "                    axes[0, i].axis('off')\n",
        "\n",
        "                    axes[1, i].imshow(relevance, cmap='hot')\n",
        "                    axes[1, i].set_title('Grad-CAM Heatmap')\n",
        "                    axes[1, i].axis('off')\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Grad-CAM failed for idx {idx}: {e}\")\n",
        "                    axes[0, i].imshow(np.transpose(img, (1, 2, 0)))\n",
        "                    axes[0, i].set_title(f\"True: {label}, Pred: {predictions[idx]}\\nProb: {prob[predictions[idx]]:.2f}\")\n",
        "                    axes[0, i].axis('off')\n",
        "                    axes[1, i].text(0.5, 0.5, 'XAI Failed', ha='center', va='center')\n",
        "                    axes[1, i].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            output_path = Path(Config.SINGLE_MODELS_DIR) / f\"{model_name}_xai_correct.png\"\n",
        "            plt.savefig(output_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "            plt.savefig(output_path.with_suffix('.pdf'), dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "            print(f\"‚úÖ XAI for correct saved: {output_path}\")\n",
        "\n",
        "        # Plot incorrect predictions\n",
        "        if incorrect_idx:\n",
        "            fig, axes = plt.subplots(2, len(incorrect_idx), figsize=(4 * len(incorrect_idx), 8))\n",
        "            axes = np.array(axes).reshape(2, -1) if len(incorrect_idx) > 1 else np.array([axes])\n",
        "\n",
        "            for i, idx in enumerate(incorrect_idx):\n",
        "                img = normalize_image(images[idx])\n",
        "                label = int(labels[idx])  # Convert to Python int\n",
        "                prob = probabilities[idx]\n",
        "\n",
        "                img_tensor = torch.from_numpy(images[idx]).float().to(Config.DEVICE)\n",
        "                img_tensor = img_tensor.unsqueeze(0)\n",
        "                img_tensor.requires_grad_(True)  # Enable gradients for Grad-CAM\n",
        "\n",
        "                try:\n",
        "                    target_layer = get_target_layer(model, model_name)\n",
        "                    grad_cam = LayerGradCam(model, target_layer)\n",
        "                    relevance = grad_cam.attribute(img_tensor, target=label)\n",
        "                    relevance = relevance.detach().cpu().numpy().squeeze()\n",
        "                    relevance = (relevance - relevance.min()) / (relevance.max() - relevance.min() + 1e-8)\n",
        "\n",
        "                    axes[0, i].imshow(np.transpose(img, (1, 2, 0)))\n",
        "                    axes[0, i].set_title(f\"True: {label}, Pred: {predictions[idx]}\\nProb: {prob[predictions[idx]]:.2f}\")\n",
        "                    axes[0, i].axis('off')\n",
        "\n",
        "                    axes[1, i].imshow(relevance, cmap='hot')\n",
        "                    axes[1, i].set_title('Grad-CAM Heatmap')\n",
        "                    axes[1, i].axis('off')\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Grad-CAM failed for idx {idx}: {e}\")\n",
        "                    axes[0, i].imshow(np.transpose(img, (1, 2, 0)))\n",
        "                    axes[0, i].set_title(f\"True: {label}, Pred: {predictions[idx]}\\nProb: {prob[predictions[idx]]:.2f}\")\n",
        "                    axes[0, i].axis('off')\n",
        "                    axes[1, i].text(0.5, 0.5, 'XAI Failed', ha='center', va='center')\n",
        "                    axes[1, i].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            output_path = Path(Config.SINGLE_MODELS_DIR) / f\"{model_name}_xai_incorrect.png\"\n",
        "            plt.savefig(output_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "            plt.savefig(output_path.with_suffix('.pdf'), dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "            print(f\"‚úÖ XAI for incorrect saved: {output_path}\")\n",
        "\n",
        "\n",
        "    def plot_error_grid(self, model_name: str, eval_results: Dict):\n",
        "        \"\"\"Plot grid of incorrect predictions\"\"\"\n",
        "        images = eval_results['images']\n",
        "        labels = eval_results['labels']\n",
        "        predictions = eval_results['predictions']\n",
        "        probabilities = eval_results['probabilities']\n",
        "\n",
        "        incorrect_idx = [i for i in range(len(labels)) if labels[i] != predictions[i]]\n",
        "        incorrect_idx = incorrect_idx[:16] if len(incorrect_idx) >= 16 else incorrect_idx\n",
        "\n",
        "        if incorrect_idx:\n",
        "            rows = int(np.ceil(len(incorrect_idx) / 4))\n",
        "            fig, axes = plt.subplots(rows, 4, figsize=(16, 4 * rows))\n",
        "            axes = axes.flatten() if rows > 1 else np.array([axes])\n",
        "\n",
        "            def normalize_image(img):\n",
        "                img = img.copy()\n",
        "                img = (img - img.min()) / (img.max() - img.min() + 1e-8)  # Normalize to [0, 1]\n",
        "                return img\n",
        "\n",
        "            for i, idx in enumerate(incorrect_idx):\n",
        "                img = normalize_image(images[idx])\n",
        "                label = labels[idx]\n",
        "                pred = predictions[idx]\n",
        "                prob = probabilities[idx][pred]\n",
        "\n",
        "                axes[i].imshow(np.transpose(img, (1, 2, 0)))\n",
        "                axes[i].set_title(f\"True: {label}, Pred: {pred}\\nProb: {prob:.2f}\")\n",
        "                axes[i].axis('off')\n",
        "\n",
        "            for i in range(len(incorrect_idx), len(axes)):\n",
        "                axes[i].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            output_path = Path(Config.SINGLE_MODELS_DIR) / f\"{model_name}_error_grid.png\"\n",
        "            plt.savefig(output_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "            plt.savefig(output_path.with_suffix('.pdf'), dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "            print(f\"‚úÖ Error grid saved: {output_path}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Ensemble Classes\n",
        "# ============================================================================\n",
        "class BaseEnsemble(torch.nn.Module):\n",
        "    \"\"\"Base class for ensemble models\"\"\"\n",
        "    def __init__(self, models: List[nn.Module], model_names: List[str]):\n",
        "        super(BaseEnsemble, self).__init__()\n",
        "        self.models = torch.nn.ModuleList(models)\n",
        "        self.model_names = model_names\n",
        "        self.device = Config.DEVICE\n",
        "\n",
        "    def predict(self, data_loader: DataLoader) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    def get_name(self) -> str:\n",
        "        raise NotImplementedError\n",
        "\n",
        "# SimpleAverageEnsemble: Averages predictions from all models\n",
        "class SimpleAverageEnsemble(BaseEnsemble):\n",
        "    def __init__(self, models, model_names=None, num_classes=23):\n",
        "        \"\"\"\n",
        "        Initialize a simple averaging ensemble.\n",
        "\n",
        "        Args:\n",
        "            models (list): List of PyTorch models.\n",
        "            model_names (list): Names of the models (optional).\n",
        "            num_classes (int): Number of output classes (default: 23).\n",
        "        \"\"\"\n",
        "        super().__init__(models, model_names)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, x, training=False):\n",
        "        \"\"\"\n",
        "        Forward pass: Average predictions from all models.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor (batch_size, channels, height, width).\n",
        "            training (bool): Whether in training mode (unused here).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Averaged predictions.\n",
        "        \"\"\"\n",
        "        outputs = []\n",
        "        for model in self.models:\n",
        "            model.eval()  # Always in eval mode, as no training is needed\n",
        "            with torch.no_grad():\n",
        "                output = model(x)\n",
        "            outputs.append(output)\n",
        "        outputs = torch.stack(outputs, dim=0)\n",
        "        return outputs.mean(dim=0)\n",
        "\n",
        "    def get_name(self):\n",
        "        return \"Simple_Average_Ensemble\"\n",
        "\n",
        "# ConfidenceBasedEnsemble: Weights predictions by model confidence\n",
        "class ConfidenceBasedEnsemble(BaseEnsemble):\n",
        "    def __init__(self, models, model_names=None, num_classes=23):\n",
        "        \"\"\"\n",
        "        Initialize a confidence-based ensemble.\n",
        "\n",
        "        Args:\n",
        "            models (list): List of PyTorch models.\n",
        "            model_names (list): Names of the models (optional).\n",
        "            num_classes (int): Number of output classes (default: 23).\n",
        "        \"\"\"\n",
        "        super().__init__(models, model_names)\n",
        "        self.num_classes = num_classes\n",
        "        self.confidence_weights = None  # Will be set during training\n",
        "\n",
        "    def forward(self, x, training=False):\n",
        "        \"\"\"\n",
        "        Forward pass: Weight predictions by confidence.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor (batch_size, channels, height, width).\n",
        "            training (bool): Whether in training mode.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Weighted predictions.\n",
        "        \"\"\"\n",
        "        outputs = []\n",
        "        for model in self.models:\n",
        "            if training:\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            output = model(x)\n",
        "            outputs.append(output)\n",
        "        outputs = torch.stack(outputs, dim=0)\n",
        "        if self.confidence_weights is None:\n",
        "            return outputs.mean(dim=0)  # Fallback to simple average if not trained\n",
        "        weights = torch.tensor(self.confidence_weights, device=x.device, dtype=torch.float32)\n",
        "        weighted_outputs = outputs * weights.view(-1, 1, 1)\n",
        "        return weighted_outputs.sum(dim=0)\n",
        "\n",
        "    def train_weights(self, data_loader):\n",
        "        \"\"\"\n",
        "        Train confidence weights based on model accuracies.\n",
        "\n",
        "        Args:\n",
        "            data_loader (DataLoader): DataLoader for training/validation data.\n",
        "        \"\"\"\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        accuracies = []\n",
        "        for model in self.models:\n",
        "            model.eval()\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            with torch.no_grad():\n",
        "                for images, labels in data_loader:\n",
        "                    images, labels = images.to(device), labels.to(device)\n",
        "                    outputs = model(images)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    correct += (preds == labels).sum().item()\n",
        "                    total += labels.size(0)\n",
        "            accuracies.append(correct / total if total > 0 else 0)\n",
        "        total_acc = sum(accuracies)\n",
        "        self.confidence_weights = np.array(accuracies) / total_acc if total_acc > 0 else np.ones(len(accuracies)) / len(accuracies)\n",
        "        print(f\"Confidence weights: {self.confidence_weights}\")\n",
        "\n",
        "    def get_name(self):\n",
        "        return \"Confidence_Based_Ensemble\"\n",
        "\n",
        "# StackingEnsemble: Uses a meta-model (e.g., logistic regression) to combine predictions\n",
        "class StackingEnsemble(BaseEnsemble):\n",
        "    def __init__(self, models, model_names=None, num_classes=23):\n",
        "        \"\"\"\n",
        "        Initialize a stacking ensemble with a meta-model.\n",
        "\n",
        "        Args:\n",
        "            models (list): List of PyTorch models.\n",
        "            model_names (list): Names of the models (optional).\n",
        "            num_classes (int): Number of output classes (default: 23).\n",
        "        \"\"\"\n",
        "        super().__init__(models, model_names)\n",
        "        self.num_classes = num_classes\n",
        "        self.meta_model = None  # Will be set during training\n",
        "\n",
        "    def forward(self, x, training=False):\n",
        "        \"\"\"\n",
        "        Forward pass: Combine model predictions using the meta-model.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor (batch_size, channels, height, width).\n",
        "            training (bool): Whether in training mode.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Meta-model predictions.\n",
        "        \"\"\"\n",
        "        device = x.device\n",
        "        outputs = []\n",
        "        for model in self.models:\n",
        "            if training:\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            with torch.no_grad():\n",
        "                output = model(x)\n",
        "            outputs.append(output)\n",
        "        outputs = torch.stack(outputs, dim=0)  # (num_models, batch_size, num_classes)\n",
        "        outputs = outputs.permute(1, 0, 2).reshape(outputs.size(1), -1)  # (batch_size, num_models * num_classes)\n",
        "        if self.meta_model is None:\n",
        "            return outputs.mean(dim=1)  # Fallback if not trained\n",
        "        outputs = outputs.cpu().numpy()\n",
        "        meta_preds = torch.tensor(self.meta_model.predict_proba(outputs), dtype=torch.float32, device=device)\n",
        "        return meta_preds\n",
        "\n",
        "    def train_meta_model(self, data_loader):\n",
        "        \"\"\"\n",
        "        Train the meta-model (logistic regression) on model predictions.\n",
        "\n",
        "        Args:\n",
        "            data_loader (DataLoader): DataLoader for training data.\n",
        "        \"\"\"\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        X_meta, y_meta = [], []\n",
        "        for images, labels in data_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = []\n",
        "            for model in self.models:\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    output = model(images)\n",
        "                outputs.append(output)\n",
        "            outputs = torch.stack(outputs, dim=0)\n",
        "            outputs = outputs.permute(1, 0, 2).reshape(outputs.size(1), -1)  # (batch_size, num_models * num_classes)\n",
        "            X_meta.append(outputs.cpu().numpy())\n",
        "            y_meta.append(labels.cpu().numpy())\n",
        "        X_meta = np.concatenate(X_meta, axis=0)\n",
        "        y_meta = np.concatenate(y_meta, axis=0)\n",
        "        self.meta_model = LogisticRegression(multi_class='multinomial', max_iter=1000)\n",
        "        self.meta_model.fit(X_meta, y_meta)\n",
        "        print(\"Meta-model trained\")\n",
        "\n",
        "    def get_name(self):\n",
        "        return \"Stacking_Ensemble\"\n",
        "\n",
        "# SnapshotEnsemble: Averages snapshots (assuming models are snapshots)\n",
        "class SnapshotEnsemble(BaseEnsemble):\n",
        "    def __init__(self, models, model_names=None, num_classes=23):\n",
        "        \"\"\"\n",
        "        Initialize a snapshot ensemble.\n",
        "\n",
        "        Args:\n",
        "            models (list): List of PyTorch models (snapshots).\n",
        "            model_names (list): Names of the models (optional).\n",
        "            num_classes (int): Number of output classes (default: 23).\n",
        "        \"\"\"\n",
        "        super().__init__(models, model_names)\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, x, training=False):\n",
        "        \"\"\"\n",
        "        Forward pass: Average predictions from snapshots.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor (batch_size, channels, height, width).\n",
        "            training (bool): Whether in training mode.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Averaged predictions.\n",
        "        \"\"\"\n",
        "        outputs = []\n",
        "        for model in self.models:\n",
        "            if training:\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            with torch.no_grad():\n",
        "                output = model(x)\n",
        "            outputs.append(output)\n",
        "        outputs = torch.stack(outputs, dim=0)\n",
        "        return outputs.mean(dim=0)\n",
        "\n",
        "    def get_name(self):\n",
        "        return \"Snapshot_Ensemble\"\n",
        "\n",
        "# LearnableWeightedEnsemble (as previously fixed)\n",
        "class LearnableWeightedEnsemble(nn.Module):\n",
        "    def __init__(self, models, model_names=None, num_classes=23, weight_init=None, weight_regularization=0.01):\n",
        "        super(LearnableWeightedEnsemble, self).__init__()\n",
        "        self.models = nn.ModuleList(models)\n",
        "        self.model_names = model_names if model_names else [f\"Model_{i}\" for i in range(len(models))]\n",
        "        self.num_models = len(models)\n",
        "        if weight_init is None:\n",
        "            weight_init = torch.ones(self.num_models) / self.num_models\n",
        "        else:\n",
        "            weight_init = torch.tensor(weight_init, dtype=torch.float32)\n",
        "        self.weights = nn.Parameter(weight_init)\n",
        "        self.weight_regularization = weight_regularization\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def forward(self, x, training=False):\n",
        "        weights = F.softmax(self.weights, dim=0)\n",
        "        outputs = []\n",
        "        for model in self.models:\n",
        "            if training:\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "            output = model(x)\n",
        "            outputs.append(output)\n",
        "        outputs = torch.stack(outputs, dim=0)\n",
        "        weighted_outputs = outputs * weights.view(-1, 1, 1)\n",
        "        final_output = weighted_outputs.sum(dim=0)\n",
        "        return final_output\n",
        "\n",
        "    def get_regularization_loss(self):\n",
        "        return self.weight_regularization * torch.norm(self.weights, p=2)\n",
        "\n",
        "    def get_name(self):\n",
        "        return \"Learnable_Weighted_Ensemble\"\n",
        "\n",
        "    def train_weights(self, data_loader, num_epochs=10, learning_rate=0.001):\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.to(device)\n",
        "        optimizer = torch.optim.Adam([self.weights], lr=learning_rate, weight_decay=0.01)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            self.train()\n",
        "            train_loss = 0.0\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for images, labels in data_loader:\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self(images, training=True)\n",
        "                loss = criterion(outputs, labels) + self.get_regularization_loss()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                train_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "            train_acc = 100 * correct / total if total > 0 else 0\n",
        "            print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(data_loader):.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "\n",
        "# ============================================================================\n",
        "# Ensemble Analyzer\n",
        "# ============================================================================\n",
        "class EnsembleAnalyzer:\n",
        "    def evaluate_ensemble_comprehensive(self, ensemble, test_loader: DataLoader) -> Dict:\n",
        "        \"\"\"Comprehensive ensemble evaluation with robust sample handling\"\"\"\n",
        "        from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
        "        import numpy as np\n",
        "        import torch\n",
        "        from torch.utils.data import DataLoader\n",
        "        from pathlib import Path\n",
        "        import pandas as pd\n",
        "        from tqdm import tqdm\n",
        "        import torch.nn.functional as F\n",
        "\n",
        "        # Set ensemble to evaluation mode\n",
        "        if isinstance(ensemble, torch.nn.Module):\n",
        "            ensemble.eval()\n",
        "\n",
        "        all_predictions = []\n",
        "        all_probabilities = []\n",
        "        all_labels = []\n",
        "        all_images = []\n",
        "\n",
        "        ensemble_name = ensemble.get_name()\n",
        "        print(f\"Evaluating {ensemble_name}...\")\n",
        "\n",
        "        # Debug: Validate test_loader\n",
        "        total_samples = 0\n",
        "        for batch in test_loader:\n",
        "            images, labels = batch\n",
        "            total_samples += len(labels)\n",
        "            print(f\"Batch size: images={len(images)}, labels={len(labels)}\")\n",
        "        print(f\"Total expected samples from test_loader: {total_samples}\")\n",
        "\n",
        "        # Reset for prediction loop\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (images, labels) in enumerate(tqdm(test_loader, desc=f\"Evaluating {ensemble_name}\")):\n",
        "                images_device = images.to(Config.DEVICE)\n",
        "                labels = labels.to(Config.DEVICE)\n",
        "\n",
        "                try:\n",
        "                    # Use forward method for prediction\n",
        "                    outputs = ensemble(images_device)\n",
        "                    probabilities = F.softmax(outputs, dim=1)\n",
        "                    _, predicted = torch.max(probabilities, 1)\n",
        "\n",
        "                    # Check for NaN/Inf in outputs\n",
        "                    if torch.isnan(outputs).any() or torch.isinf(outputs).any():\n",
        "                        print(f\"Warning: NaN/Inf detected in outputs for batch {batch_idx} in {ensemble_name}\")\n",
        "                        probabilities = torch.where(torch.isnan(probabilities) | torch.isinf(probabilities),\n",
        "                                                 torch.zeros_like(probabilities), probabilities)\n",
        "                        predicted = torch.where(torch.isnan(predicted) | torch.isinf(predicted),\n",
        "                                              torch.zeros_like(predicted, dtype=torch.long), predicted)\n",
        "\n",
        "                    # Validate output shapes\n",
        "                    if predicted.size(0) != labels.size(0):\n",
        "                        print(f\"Shape mismatch in batch {batch_idx}: Predictions={predicted.size(0)}, Labels={labels.size(0)}\")\n",
        "                        continue\n",
        "\n",
        "                    # Append data\n",
        "                    all_predictions.extend(predicted.cpu().numpy())\n",
        "                    all_probabilities.extend(probabilities.cpu().numpy())\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "                    all_images.extend(images.cpu().numpy())\n",
        "\n",
        "                    # Debug: Log batch details\n",
        "                    print(f\"Batch {batch_idx}: Predictions={len(predicted)}, Probabilities={len(probabilities)}, Labels={len(labels)}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in batch {batch_idx} for {ensemble_name}: {e}\")\n",
        "                    continue\n",
        "\n",
        "        # Convert to numpy arrays\n",
        "        all_predictions = np.array(all_predictions)\n",
        "        all_probabilities = np.array(all_probabilities)\n",
        "        all_labels = np.array(all_labels)\n",
        "        all_images = np.array(all_images)\n",
        "\n",
        "        # Debug: Check final lengths\n",
        "        print(f\"Final counts for {ensemble_name}: Predictions={len(all_predictions)}, Labels={len(all_labels)}, Images={len(all_images)}\")\n",
        "\n",
        "        # Handle length mismatch\n",
        "        if len(all_predictions) != len(all_labels):\n",
        "            print(f\"Length mismatch in {ensemble_name}: Predictions={len(all_predictions)}, Labels={len(all_labels)}\")\n",
        "            min_len = min(len(all_predictions), len(all_labels))\n",
        "            print(f\"Truncating to {min_len} samples\")\n",
        "            all_predictions = all_predictions[:min_len]\n",
        "            all_probabilities = all_probabilities[:min_len]\n",
        "            all_labels = all_labels[:min_len]\n",
        "            all_images = all_images[:min_len]\n",
        "\n",
        "        # Validate labels\n",
        "        unique_labels = np.unique(all_labels)\n",
        "        print(f\"Unique labels in test data: {unique_labels}\")\n",
        "        if len(unique_labels) > Config.NUM_CLASSES:\n",
        "            print(f\"Warning: Found {len(unique_labels)} unique labels, but Config.NUM_CLASSES={Config.NUM_CLASSES}\")\n",
        "            # Map labels to valid range\n",
        "            label_mapping = {old_label: min(old_label, Config.NUM_CLASSES-1) for old_label in unique_labels}\n",
        "            all_labels = np.array([label_mapping.get(label, Config.NUM_CLASSES-1) for label in all_labels])\n",
        "            print(f\"Remapped labels to range [0, {Config.NUM_CLASSES-1}]\")\n",
        "\n",
        "        # Calculate metrics\n",
        "        accuracy = accuracy_score(all_labels, all_predictions)\n",
        "        f1_macro = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
        "        f1_weighted = f1_score(all_labels, all_predictions, average='weighted', zero_division=0)\n",
        "        precision_macro = precision_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
        "        recall_macro = recall_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
        "\n",
        "        # Confusion matrix\n",
        "        conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
        "\n",
        "        # Classification report\n",
        "        print(f\"Config.CLASS_NAMES: {Config.CLASS_NAMES}\")\n",
        "        if Config.CLASS_NAMES and len(Config.CLASS_NAMES) >= len(unique_labels):\n",
        "            class_names = [Config.CLASS_NAMES[i] for i in unique_labels if i < len(Config.CLASS_NAMES)]\n",
        "        else:\n",
        "            class_names = [f\"Class_{i}\" for i in unique_labels]\n",
        "        print(f\"Class names used: {class_names}\")\n",
        "\n",
        "        try:\n",
        "            class_report = classification_report(\n",
        "                all_labels, all_predictions,\n",
        "                labels=unique_labels,\n",
        "                target_names=class_names,\n",
        "                output_dict=True,\n",
        "                zero_division=0\n",
        "            )\n",
        "        except ValueError as e:\n",
        "            print(f\"Error in classification_report for {ensemble_name}: {e}\")\n",
        "            class_report = {str(i): {'precision': 0, 'recall': 0, 'f1-score': 0, 'support': 0} for i in unique_labels}\n",
        "            class_report.update({\n",
        "                'accuracy': {'precision': accuracy, 'recall': accuracy, 'f1-score': accuracy, 'support': len(all_labels)},\n",
        "                'macro avg': {'precision': precision_macro, 'recall': recall_macro, 'f1-score': f1_macro, 'support': len(all_labels)},\n",
        "                'weighted avg': {'precision': precision_macro, 'recall': recall_macro, 'f1-score': f1_weighted, 'support': len(all_labels)}\n",
        "            })\n",
        "\n",
        "        print(f\"Class report keys for {ensemble_name}: {list(class_report.keys())}\")\n",
        "\n",
        "        # Save classification report\n",
        "        report_df = pd.DataFrame(class_report).transpose()\n",
        "        report_path = Path(Config.ENSEMBLES_DIR) / f\"{ensemble_name}_classification_report.csv\"\n",
        "        report_df.to_csv(report_path)\n",
        "        print(f\"Saved classification report to {report_path}\")\n",
        "\n",
        "        return {\n",
        "            'ensemble_name': ensemble_name,\n",
        "            'predictions': all_predictions,\n",
        "            'probabilities': all_probabilities,\n",
        "            'labels': all_labels,\n",
        "            'images': all_images,\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_weighted': f1_weighted,\n",
        "            'precision_macro': precision_macro,\n",
        "            'recall_macro': recall_macro,\n",
        "            'confusion_matrix': conf_matrix,\n",
        "            'classification_report': class_report\n",
        "        }\n",
        "\n",
        "\n",
        "    def plot_evaluation_metrics(self, ensemble_name: str, eval_results: Dict):\n",
        "        \"\"\"Plot comprehensive evaluation metrics for ensemble\"\"\"\n",
        "        fig = plt.figure(figsize=(20, 16))\n",
        "        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
        "\n",
        "        # ROC Curve\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        SingleModelAnalyzer._plot_roc_curve(None, ax1, eval_results)  # Use static call\n",
        "\n",
        "        # Precision-Recall Curve\n",
        "        ax2 = fig.add_subplot(gs[0, 1])\n",
        "        SingleModelAnalyzer._plot_precision_recall_curve(None, ax2, eval_results)\n",
        "\n",
        "        # Confusion Matrix (Normalized)\n",
        "        ax3 = fig.add_subplot(gs[0, 2])\n",
        "        SingleModelAnalyzer._plot_confusion_matrix(None, ax3, eval_results, normalize=True)\n",
        "\n",
        "        # Confusion Matrix (Raw Counts)\n",
        "        ax4 = fig.add_subplot(gs[1, 0])\n",
        "        SingleModelAnalyzer._plot_confusion_matrix(None, ax4, eval_results, normalize=False)\n",
        "\n",
        "        # Class-wise Metrics\n",
        "        ax5 = fig.add_subplot(gs[1, 1])\n",
        "        SingleModelAnalyzer._plot_class_metrics(None, ax5, eval_results)\n",
        "\n",
        "        # Per-class F1 Scores\n",
        "        ax6 = fig.add_subplot(gs[1, 2])\n",
        "        SingleModelAnalyzer._plot_per_class_f1(None, ax6, eval_results)\n",
        "\n",
        "        plt.suptitle(f'{ensemble_name} - Evaluation Metrics', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Save plot\n",
        "        output_path = Path(Config.ENSEMBLES_DIR) / f\"{ensemble_name}_evaluation_metrics.png\"\n",
        "        plt.savefig(output_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "\n",
        "        # Save PDF version\n",
        "        output_path_pdf = output_path.with_suffix('.pdf')\n",
        "        plt.savefig(output_path_pdf, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"‚úÖ Evaluation metrics saved: {output_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_xai_examples(self, ensemble_name: str, ensemble, eval_results: Dict):\n",
        "        \"\"\"Plot XAI examples for correct and incorrect ensemble predictions\"\"\"\n",
        "        from captum.attr import LayerGradCam\n",
        "        import torch\n",
        "        import numpy as np\n",
        "        import matplotlib.pyplot as plt\n",
        "\n",
        "        images = eval_results['images']\n",
        "        labels = eval_results['labels']\n",
        "        predictions = eval_results['predictions']\n",
        "        probabilities = eval_results['probabilities']\n",
        "\n",
        "        correct_idx = [i for i in range(len(labels)) if labels[i] == predictions[i]]\n",
        "        incorrect_idx = [i for i in range(len(labels)) if labels[i] != predictions[i]]\n",
        "\n",
        "        correct_idx = correct_idx[:4] if len(correct_idx) >= 4 else correct_idx\n",
        "        incorrect_idx = incorrect_idx[:4] if len(incorrect_idx) >= 4 else incorrect_idx\n",
        "\n",
        "        # Normalize images to [0, 1] for display\n",
        "        def normalize_image(img):\n",
        "            img = img.copy()\n",
        "            img = (img - img.min()) / (img.max() - img.min() + 1e-8)  # Normalize to [0, 1]\n",
        "            return img\n",
        "\n",
        "        # Determine target layer for a model based on its architecture\n",
        "        def get_target_layer(model, model_name):\n",
        "            try:\n",
        "                model_name = model_name.lower()\n",
        "                if 'resnet50' in model_name:\n",
        "                    return model.layer4[-1]  # Last conv layer for ResNet\n",
        "                elif 'efficientnet_b0' in model_name:\n",
        "                    return model.features[-1]  # Last conv layer for EfficientNet\n",
        "                elif 'inception_v3' in model_name:\n",
        "                    return model.Mixed_7c  # Last inception module\n",
        "                else:\n",
        "                    # Fallback to last conv layer\n",
        "                    for name, module in model.named_modules():\n",
        "                        if isinstance(module, nn.Conv2d):\n",
        "                            target_layer = module\n",
        "                    return target_layer\n",
        "            except Exception as e:\n",
        "                print(f\"Error selecting target layer for {model_name}: {e}\")\n",
        "                return None\n",
        "\n",
        "        # Get the first model in the ensemble (assumes ensemble has a 'models' attribute)\n",
        "        try:\n",
        "            model = ensemble.models[0] if hasattr(ensemble, 'models') and len(ensemble.models) > 0 else None\n",
        "            model_name = ensemble.model_names[0] if hasattr(ensemble, 'model_names') and len(ensemble.model_names) > 0 else ensemble_name\n",
        "            if model is None:\n",
        "                raise ValueError(\"No models found in ensemble\")\n",
        "            if isinstance(model, torch.nn.Module):\n",
        "                model.eval()\n",
        "        except AttributeError:\n",
        "            print(f\"Cannot apply Grad-CAM: Ensemble {ensemble_name} does not support model access\")\n",
        "            model = None\n",
        "\n",
        "        # Plot correct predictions\n",
        "        if correct_idx:\n",
        "            fig, axes = plt.subplots(2, len(correct_idx), figsize=(4 * len(correct_idx), 8))\n",
        "            axes = np.array(axes).reshape(2, -1) if len(correct_idx) > 1 else np.array([axes])\n",
        "\n",
        "            for i, idx in enumerate(correct_idx):\n",
        "                img = normalize_image(images[idx])\n",
        "                label = int(labels[idx])  # Convert to Python int\n",
        "                prob = probabilities[idx]\n",
        "\n",
        "                axes[0, i].imshow(np.transpose(img, (1, 2, 0)))\n",
        "                axes[0, i].set_title(f\"True: {label}, Pred: {predictions[idx]}\\nProb: {prob[predictions[idx]]:.2f}\")\n",
        "                axes[0, i].axis('off')\n",
        "\n",
        "                if model:\n",
        "                    img_tensor = torch.from_numpy(images[idx]).float().to(Config.DEVICE)\n",
        "                    img_tensor = img_tensor.unsqueeze(0)\n",
        "                    img_tensor.requires_grad_(True)\n",
        "\n",
        "                    try:\n",
        "                        target_layer = get_target_layer(model, model_name)\n",
        "                        if target_layer is None:\n",
        "                            raise ValueError(\"No valid target layer found\")\n",
        "                        grad_cam = LayerGradCam(model, target_layer)\n",
        "                        relevance = grad_cam.attribute(img_tensor, target=label)\n",
        "                        relevance = relevance.detach().cpu().numpy().squeeze()\n",
        "                        relevance = (relevance - relevance.min()) / (relevance.max() - relevance.min() + 1e-8)\n",
        "\n",
        "                        axes[1, i].imshow(relevance, cmap='hot')\n",
        "                        axes[1, i].set_title('Grad-CAM Heatmap')\n",
        "                        axes[1, i].axis('off')\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Grad-CAM failed for idx {idx}: {e}\")\n",
        "                        axes[1, i].text(0.5, 0.5, 'XAI Failed', ha='center', va='center')\n",
        "                        axes[1, i].axis('off')\n",
        "                else:\n",
        "                    axes[1, i].text(0.5, 0.5, 'XAI Not Supported', ha='center', va='center')\n",
        "                    axes[1, i].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            output_path = Path(Config.ENSEMBLES_DIR) / f\"{ensemble_name}_xai_correct.png\"\n",
        "            plt.savefig(output_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "            plt.savefig(output_path.with_suffix('.pdf'), dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "            print(f\"‚úÖ Ensemble XAI for correct saved: {output_path}\")\n",
        "\n",
        "        # Plot incorrect predictions\n",
        "        if incorrect_idx:\n",
        "            fig, axes = plt.subplots(2, len(incorrect_idx), figsize=(4 * len(incorrect_idx), 8))\n",
        "            axes = np.array(axes).reshape(2, -1) if len(incorrect_idx) > 1 else np.array([axes])\n",
        "\n",
        "            for i, idx in enumerate(incorrect_idx):\n",
        "                img = normalize_image(images[idx])\n",
        "                label = int(labels[idx])  # Convert to Python int\n",
        "                prob = probabilities[idx]\n",
        "\n",
        "                axes[0, i].imshow(np.transpose(img, (1, 2, 0)))\n",
        "                axes[0, i].set_title(f\"True: {label}, Pred: {predictions[idx]}\\nProb: {prob[predictions[idx]]:.2f}\")\n",
        "                axes[0, i].axis('off')\n",
        "\n",
        "                if model:\n",
        "                    img_tensor = torch.from_numpy(images[idx]).float().to(Config.DEVICE)\n",
        "                    img_tensor = img_tensor.unsqueeze(0)\n",
        "                    img_tensor.requires_grad_(True)\n",
        "\n",
        "                    try:\n",
        "                        target_layer = get_target_layer(model, model_name)\n",
        "                        if target_layer is None:\n",
        "                            raise ValueError(\"No valid target layer found\")\n",
        "                        grad_cam = LayerGradCam(model, target_layer)\n",
        "                        relevance = grad_cam.attribute(img_tensor, target=label)\n",
        "                        relevance = relevance.detach().cpu().numpy().squeeze()\n",
        "                        relevance = (relevance - relevance.min()) / (relevance.max() - relevance.min() + 1e-8)\n",
        "\n",
        "                        axes[1, i].imshow(relevance, cmap='hot')\n",
        "                        axes[1, i].set_title('Grad-CAM Heatmap')\n",
        "                        axes[1, i].axis('off')\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Grad-CAM failed for idx {idx}: {e}\")\n",
        "                        axes[1, i].text(0.5, 0.5, 'XAI Failed', ha='center', va='center')\n",
        "                        axes[1, i].axis('off')\n",
        "                else:\n",
        "                    axes[1, i].text(0.5, 0.5, 'XAI Not Supported', ha='center', va='center')\n",
        "                    axes[1, i].axis('off')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            output_path = Path(Config.ENSEMBLES_DIR) / f\"{ensemble_name}_xai_incorrect.png\"\n",
        "            plt.savefig(output_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "            plt.savefig(output_path.with_suffix('.pdf'), dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "            print(f\"‚úÖ Ensemble XAI for incorrect saved: {output_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_error_grid(self, ensemble_name: str, eval_results: Dict):\n",
        "        \"\"\"Plot FP/FN/TP/TN grid for ensemble\"\"\"\n",
        "        labels = eval_results['labels']\n",
        "        predictions = eval_results['predictions']\n",
        "        images = eval_results['images']\n",
        "\n",
        "        class_id = 0  # Pick a class, modify as needed\n",
        "\n",
        "        tp_idx = np.where((predictions == class_id) & (labels == class_id))[0]\n",
        "        fn_idx = np.where((predictions != class_id) & (labels == class_id))[0]\n",
        "        fp_idx = np.where((predictions == class_id) & (labels != class_id))[0]\n",
        "        tn_idx = np.where((predictions != class_id) & (labels != class_id))[0]\n",
        "\n",
        "        types = ['TP', 'FN', 'FP', 'TN']\n",
        "        idx_lists = [tp_idx, fn_idx, fp_idx, tn_idx]\n",
        "\n",
        "        fig, axes = plt.subplots(4, 5, figsize=(15, 12))\n",
        "        fig.suptitle(f'{ensemble_name} - Error Analysis Grid for Class {class_id}', fontsize=16, fontweight='bold')\n",
        "\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "        for row, (type_, idx_list) in enumerate(zip(types, idx_lists)):\n",
        "            if len(idx_list) == 0:\n",
        "                for col in range(5):\n",
        "                    axes[row, col].text(0.5, 0.5, 'No example', ha='center', va='center')\n",
        "                    axes[row, col].axis('off')\n",
        "                continue\n",
        "\n",
        "            np.random.shuffle(idx_list)\n",
        "            examples = idx_list[:5]\n",
        "\n",
        "            for col, idx in enumerate(examples):\n",
        "                img = images[idx].transpose(1, 2, 0)\n",
        "                img = std * img + mean\n",
        "                img = np.clip(img, 0, 1)\n",
        "                axes[row, col].imshow(img)\n",
        "                pred = predictions[idx]\n",
        "                true = labels[idx]\n",
        "                axes[row, col].set_title(f'Pred: {pred}\\nTrue: {true}')\n",
        "                axes[row, col].axis('off')\n",
        "\n",
        "            for col in range(len(examples), 5):\n",
        "                axes[row, col].axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        output_path = Path(Config.ENSEMBLES_DIR) / f\"{ensemble_name}_error_grid.png\"\n",
        "        plt.savefig(output_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "        plt.savefig(output_path.with_suffix('.pdf'), dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        print(f\"‚úÖ Ensemble error grid saved: {output_path}\")\n",
        "\n",
        "# ============================================================================\n",
        "# Comparative Analysis\n",
        "# ============================================================================\n",
        "class ComparativeAnalyzer:\n",
        "    \"\"\"Performs comparative analysis between models and ensembles\"\"\"\n",
        "\n",
        "    def __init__(self, model_manager: ModelManager):\n",
        "        self.model_manager = model_manager\n",
        "\n",
        "    def compare_single_models(self, single_model_results: Dict[str, Dict]):\n",
        "        \"\"\"Compare all single models\"\"\"\n",
        "        print(\"\\nCreating single model comparison...\")\n",
        "\n",
        "        if not single_model_results:\n",
        "            print(\"No single model results to compare\")\n",
        "            return None\n",
        "\n",
        "        # Collect metrics\n",
        "        models = []\n",
        "        accuracies = []\n",
        "        f1_macros = []\n",
        "        f1_weighteds = []\n",
        "        precisions = []\n",
        "        recalls = []\n",
        "\n",
        "        for model_name, results in single_model_results.items():\n",
        "            models.append(model_name)\n",
        "            accuracies.append(results['accuracy'])\n",
        "            f1_macros.append(results['f1_macro'])\n",
        "            f1_weighteds.append(results['f1_weighted'])\n",
        "            precisions.append(results['precision_macro'])\n",
        "            recalls.append(results['recall_macro'])\n",
        "\n",
        "        # Create comparison plots\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        fig.suptitle('Single Models Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Accuracy comparison\n",
        "        axes[0, 0].bar(models, accuracies, color='skyblue', alpha=0.8)\n",
        "        axes[0, 0].set_title('Accuracy Comparison', fontweight='bold')\n",
        "        axes[0, 0].set_ylabel('Accuracy')\n",
        "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # F1 Macro comparison\n",
        "        axes[0, 1].bar(models, f1_macros, color='lightgreen', alpha=0.8)\n",
        "        axes[0, 1].set_title('F1-Macro Comparison', fontweight='bold')\n",
        "        axes[0, 1].set_ylabel('F1-Macro')\n",
        "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # F1 Weighted comparison\n",
        "        axes[0, 2].bar(models, f1_weighteds, color='lightcoral', alpha=0.8)\n",
        "        axes[0, 2].set_title('F1-Weighted Comparison', fontweight='bold')\n",
        "        axes[0, 2].set_ylabel('F1-Weighted')\n",
        "        axes[0, 2].tick_params(axis='x', rotation=45)\n",
        "        axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "        # Precision comparison\n",
        "        axes[1, 0].bar(models, precisions, color='orange', alpha=0.8)\n",
        "        axes[1, 0].set_title('Precision Comparison', fontweight='bold')\n",
        "        axes[1, 0].set_ylabel('Precision')\n",
        "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Recall comparison\n",
        "        axes[1, 1].bar(models, recalls, color='purple', alpha=0.8)\n",
        "        axes[1, 1].set_title('Recall Comparison', fontweight='bold')\n",
        "        axes[1, 1].set_ylabel('Recall')\n",
        "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Overall performance radar chart\n",
        "        ax_radar = axes[1, 2]\n",
        "        self._create_performance_summary(ax_radar, single_model_results)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save comparison\n",
        "        output_path = Path(Config.COMPARISONS_DIR) / \"single_models_comparison.png\"\n",
        "        plt.savefig(output_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "\n",
        "        # Save PDF version\n",
        "        output_path_pdf = output_path.with_suffix('.pdf')\n",
        "        plt.savefig(output_path_pdf, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        # Save comparison table\n",
        "        comparison_df = pd.DataFrame({\n",
        "            'Model': models,\n",
        "            'Accuracy': accuracies,\n",
        "            'F1_Macro': f1_macros,\n",
        "            'F1_Weighted': f1_weighteds,\n",
        "            'Precision_Macro': precisions,\n",
        "            'Recall_Macro': recalls\n",
        "        })\n",
        "\n",
        "        # Sort by F1_Macro (descending)\n",
        "        comparison_df = comparison_df.sort_values('F1_Macro', ascending=False)\n",
        "\n",
        "        csv_path = Path(Config.COMPARISONS_DIR) / \"single_models_comparison.csv\"\n",
        "        comparison_df.to_csv(csv_path, index=False)\n",
        "\n",
        "        print(f\"Single models comparison saved: {output_path}\")\n",
        "        print(f\"Best single model: {comparison_df.iloc[0]['Model']} (F1-Macro: {comparison_df.iloc[0]['F1_Macro']:.4f})\")\n",
        "\n",
        "        return comparison_df.iloc[0]['Model']  # Return best model name\n",
        "\n",
        "    def compare_ensemble_models(self, ensemble_results: Dict[str, Dict]):\n",
        "        \"\"\"Compare all ensemble models\"\"\"\n",
        "        print(\"\\nCreating ensemble comparison...\")\n",
        "\n",
        "        if not ensemble_results:\n",
        "            print(\"No ensemble results to compare\")\n",
        "            return None\n",
        "\n",
        "        # Collect metrics\n",
        "        ensembles = []\n",
        "        accuracies = []\n",
        "        f1_macros = []\n",
        "        f1_weighteds = []\n",
        "        precisions = []\n",
        "        recalls = []\n",
        "\n",
        "        for _, results in ensemble_results.items():\n",
        "            ensembles.append(results['ensemble_name'])\n",
        "            accuracies.append(results['accuracy'])\n",
        "            f1_macros.append(results['f1_macro'])\n",
        "            f1_weighteds.append(results['f1_weighted'])\n",
        "            precisions.append(results['precision_macro'])\n",
        "            recalls.append(results['recall_macro'])\n",
        "\n",
        "        # Create comparison plots\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        fig.suptitle('Ensemble Models Comparison', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Accuracy comparison\n",
        "        axes[0, 0].bar(ensembles, accuracies, color='skyblue', alpha=0.8)\n",
        "        axes[0, 0].set_title('Accuracy Comparison', fontweight='bold')\n",
        "        axes[0, 0].set_ylabel('Accuracy')\n",
        "        axes[0, 0].tick_params(axis='x', rotation=45)\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # F1 Macro comparison\n",
        "        axes[0, 1].bar(ensembles, f1_macros, color='lightgreen', alpha=0.8)\n",
        "        axes[0, 1].set_title('F1-Macro Comparison', fontweight='bold')\n",
        "        axes[0, 1].set_ylabel('F1-Macro')\n",
        "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # F1 Weighted comparison\n",
        "        axes[0, 2].bar(ensembles, f1_weighteds, color='lightcoral', alpha=0.8)\n",
        "        axes[0, 2].set_title('F1-Weighted Comparison', fontweight='bold')\n",
        "        axes[0, 2].set_ylabel('F1-Weighted')\n",
        "        axes[0, 2].tick_params(axis='x', rotation=45)\n",
        "        axes[0, 2].grid(True, alpha=0.3)\n",
        "\n",
        "        # Precision comparison\n",
        "        axes[1, 0].bar(ensembles, precisions, color='orange', alpha=0.8)\n",
        "        axes[1, 0].set_title('Precision Comparison', fontweight='bold')\n",
        "        axes[1, 0].set_ylabel('Precision')\n",
        "        axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "        axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Recall comparison\n",
        "        axes[1, 1].bar(ensembles, recalls, color='purple', alpha=0.8)\n",
        "        axes[1, 1].set_title('Recall Comparison', fontweight='bold')\n",
        "        axes[1, 1].set_ylabel('Recall')\n",
        "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
        "        axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "        # Performance improvement chart\n",
        "        ax_improvement = axes[1, 2]\n",
        "        ax_improvement.bar(ensembles, f1_macros, color='gold', alpha=0.8)\n",
        "        ax_improvement.set_title('F1-Macro Performance', fontweight='bold')\n",
        "        ax_improvement.set_ylabel('F1-Macro Score')\n",
        "        ax_improvement.tick_params(axis='x', rotation=45)\n",
        "        ax_improvement.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save comparison\n",
        "        output_path = Path(Config.COMPARISONS_DIR) / \"ensemble_models_comparison.png\"\n",
        "        plt.savefig(output_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "\n",
        "        # Save PDF version\n",
        "        output_path_pdf = output_path.with_suffix('.pdf')\n",
        "        plt.savefig(output_path_pdf, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        # Save comparison table\n",
        "        comparison_df = pd.DataFrame({\n",
        "            'Ensemble': ensembles,\n",
        "            'Accuracy': accuracies,\n",
        "            'F1_Macro': f1_macros,\n",
        "            'F1_Weighted': f1_weighteds,\n",
        "            'Precision_Macro': precisions,\n",
        "            'Recall_Macro': recalls\n",
        "        })\n",
        "\n",
        "        # Sort by F1_Macro (descending)\n",
        "        comparison_df = comparison_df.sort_values('F1_Macro', ascending=False)\n",
        "\n",
        "        csv_path = Path(Config.COMPARISONS_DIR) / \"ensemble_models_comparison.csv\"\n",
        "        comparison_df.to_csv(csv_path, index=False)\n",
        "\n",
        "        print(f\"Ensemble comparison saved: {output_path}\")\n",
        "        print(f\"Best ensemble: {comparison_df.iloc[0]['Ensemble']} (F1-Macro: {comparison_df.iloc[0]['F1_Macro']:.4f})\")\n",
        "\n",
        "        return comparison_df.iloc[0]['Ensemble']  # Return best ensemble name\n",
        "\n",
        "    def create_final_comparison(self, best_single_model: str, best_ensemble_name: str,\n",
        "                               single_model_results: Dict, ensemble_results: Dict, test_loader: DataLoader):\n",
        "        \"\"\"Create final comparison between best single model and best ensemble\"\"\"\n",
        "        print(f\"\\nCreating final comparison: {best_single_model} vs {best_ensemble_name}\")\n",
        "\n",
        "        # Get results\n",
        "        single_result = single_model_results[best_single_model]\n",
        "        ensemble_result = None\n",
        "\n",
        "        for _, results in ensemble_results.items():\n",
        "            if results['ensemble_name'] == best_ensemble_name:\n",
        "                ensemble_result = results\n",
        "                break\n",
        "\n",
        "        if ensemble_result is None:\n",
        "            print(\"Could not find ensemble result for final comparison\")\n",
        "            return\n",
        "\n",
        "        # Create comparison metrics\n",
        "        metrics = ['Accuracy', 'F1-Macro', 'F1-Weighted', 'Precision', 'Recall']\n",
        "        single_values = [\n",
        "            single_result['accuracy'],\n",
        "            single_result['f1_macro'],\n",
        "            single_result['f1_weighted'],\n",
        "            single_result['precision_macro'],\n",
        "            single_result['recall_macro']\n",
        "        ]\n",
        "        ensemble_values = [\n",
        "            ensemble_result['accuracy'],\n",
        "            ensemble_result['f1_macro'],\n",
        "            ensemble_result['f1_weighted'],\n",
        "            ensemble_result['precision_macro'],\n",
        "            ensemble_result['recall_macro']\n",
        "        ]\n",
        "\n",
        "        # Create final comparison plot\n",
        "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "        fig.suptitle(f'Final Comparison: {best_single_model} vs {best_ensemble_name}', fontsize=16, fontweight='bold')\n",
        "\n",
        "        # Side-by-side bar comparison\n",
        "        x = np.arange(len(metrics))\n",
        "        width = 0.35\n",
        "\n",
        "        axes[0, 0].bar(x - width/2, single_values, width, label=best_single_model, alpha=0.8, color='skyblue')\n",
        "        axes[0, 0].bar(x + width/2, ensemble_values, width, label=best_ensemble_name, alpha=0.8, color='lightcoral')\n",
        "        axes[0, 0].set_title('Metrics Comparison', fontweight='bold')\n",
        "        axes[0, 0].set_ylabel('Score')\n",
        "        axes[0, 0].set_xticks(x)\n",
        "        axes[0, 0].set_xticklabels(metrics, rotation=45, ha='right')\n",
        "        axes[0, 0].legend()\n",
        "        axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "        # Performance improvement\n",
        "        improvements = [(e - s) / s * 100 if s > 0 else 0 for s, e in zip(single_values, ensemble_values)]\n",
        "        colors = ['green' if imp > 0 else 'red' for imp in improvements]\n",
        "\n",
        "        axes[0, 1].bar(metrics, improvements, color=colors, alpha=0.7)\n",
        "        axes[0, 1].set_title('Performance Improvement (%)', fontweight='bold')\n",
        "        axes[0, 1].set_ylabel('Improvement (%)')\n",
        "        axes[0, 1].tick_params(axis='x', rotation=45)\n",
        "        axes[0, 1].grid(True, alpha=0.3)\n",
        "        axes[0, 1].axhline(y=0, color='black', linestyle='-', linewidth=0.8)\n",
        "\n",
        "        # Summary statistics\n",
        "        axes[0, 2].axis('off')\n",
        "        summary_text = f\"\"\"\n",
        "Final Comparison Summary\n",
        "\n",
        "Single Model: {best_single_model}\n",
        "Best Ensemble: {best_ensemble_name}\n",
        "\n",
        "Single Model Performance:\n",
        "‚Ä¢ Accuracy: {single_result['accuracy']:.4f}\n",
        "‚Ä¢ F1-Macro: {single_result['f1_macro']:.4f}\n",
        "‚Ä¢ F1-Weighted: {single_result['f1_weighted']:.4f}\n",
        "\n",
        "Ensemble Performance:\n",
        "‚Ä¢ Accuracy: {ensemble_result['accuracy']:.4f}\n",
        "‚Ä¢ F1-Macro: {ensemble_result['f1_macro']:.4f}\n",
        "‚Ä¢ F1-Weighted: {ensemble_result['f1_weighted']:.4f}\n",
        "\n",
        "Average Improvement: {np.mean([i for i in improvements if not np.isnan(i)]):.2f}%\n",
        "        \"\"\"\n",
        "        axes[0, 2].text(0.1, 0.9, summary_text, transform=axes[0, 2].transAxes,\n",
        "                       fontsize=10, verticalalignment='top',\n",
        "                       bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.7))\n",
        "\n",
        "        # XAI Comparison\n",
        "        self._create_final_xai_comparison(axes[1, :], best_single_model, best_ensemble_name,\n",
        "                                         single_model_results, ensemble_results, test_loader)\n",
        "\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save final comparison\n",
        "        output_path = Path(Config.COMPARISONS_DIR) / \"final_comparison_best_models.png\"\n",
        "        plt.savefig(output_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "\n",
        "        # Save PDF version\n",
        "        output_path_pdf = output_path.with_suffix('.pdf')\n",
        "        plt.savefig(output_path_pdf, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "\n",
        "        # Save final comparison metrics\n",
        "        final_comparison_df = pd.DataFrame({\n",
        "            'Metric': metrics,\n",
        "            f'{best_single_model}': single_values,\n",
        "            f'{best_ensemble_name}': ensemble_values,\n",
        "            'Improvement_%': improvements\n",
        "        })\n",
        "\n",
        "        csv_path = Path(Config.COMPARISONS_DIR) / \"final_comparison_metrics.csv\"\n",
        "        final_comparison_df.to_csv(csv_path, index=False)\n",
        "\n",
        "        print(f\"Final comparison saved: {output_path}\")\n",
        "\n",
        "        # Print summary\n",
        "        avg_improvement = np.mean([imp for imp in improvements if not np.isnan(imp)])\n",
        "        print(f\"Average performance improvement: {avg_improvement:.2f}%\")\n",
        "\n",
        "        if avg_improvement > 0:\n",
        "            print(f\"{best_ensemble_name} outperforms {best_single_model} by {avg_improvement:.2f}% on average\")\n",
        "        else:\n",
        "            print(f\"{best_single_model} performs better than {best_ensemble_name} by {abs(avg_improvement):.2f}% on average\")\n",
        "\n",
        "    def _create_performance_summary(self, ax, results: Dict):\n",
        "        \"\"\"Create performance summary chart\"\"\"\n",
        "        models = list(results.keys())[:5]  # Show top 5 models\n",
        "        f1_scores = [results[model]['f1_macro'] for model in models]\n",
        "\n",
        "        ax.bar(models, f1_scores, color='gold', alpha=0.8)\n",
        "        ax.set_title('Top Models F1-Macro', fontweight='bold')\n",
        "        ax.set_ylabel('F1-Macro Score')\n",
        "        ax.tick_params(axis='x', rotation=45)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _create_final_xai_comparison(self, axes, best_single_model, best_ensemble_name,\n",
        "                                single_model_results, ensemble_results, test_loader):\n",
        "        \"\"\"Create final XAI comparison between best single model and best ensemble\"\"\"\n",
        "        import torch\n",
        "        import numpy as np\n",
        "        import matplotlib.pyplot as plt\n",
        "        from captum.attr import LayerGradCam\n",
        "\n",
        "        # Load the best single model\n",
        "        best_model = self.model_manager.models[best_single_model]\n",
        "        best_model.eval()\n",
        "\n",
        "        # Find the best ensemble object\n",
        "        best_ensemble_obj = None\n",
        "        for _, results in ensemble_results.items():\n",
        "            if results['ensemble_name'] == best_ensemble_name:\n",
        "                best_ensemble_obj = results.get('ensemble_object', None)\n",
        "                break\n",
        "\n",
        "        if best_ensemble_obj is None:\n",
        "            for ax in axes.flatten():\n",
        "                ax.text(0.5, 0.5, 'XAI Comparison\\nNot Available',\n",
        "                        ha='center', va='center', transform=ax.transAxes)\n",
        "                ax.axis('off')\n",
        "            return\n",
        "\n",
        "        # Find examples for XAI comparison (one correct, one incorrect)\n",
        "        correct_example = None\n",
        "        incorrect_example = None\n",
        "        single_result = single_model_results[best_single_model]\n",
        "        ensemble_result = ensemble_results[best_ensemble_name]\n",
        "\n",
        "        # Get indices for correct and incorrect predictions where both single and ensemble agree\n",
        "        single_correct = np.where(single_result['labels'] == single_result['predictions'])[0]\n",
        "        single_incorrect = np.where(single_result['labels'] != single_result['predictions'])[0]\n",
        "        ensemble_correct = np.where(ensemble_result['labels'] == ensemble_result['predictions'])[0]\n",
        "        ensemble_incorrect = np.where(ensemble_result['labels'] != ensemble_result['predictions'])[0]\n",
        "\n",
        "        # Find common correct and incorrect examples\n",
        "        common_correct = np.intersect1d(single_correct, ensemble_correct)\n",
        "        common_incorrect = np.intersect1d(single_incorrect, ensemble_incorrect)\n",
        "\n",
        "        if len(common_correct) > 0:\n",
        "            idx = common_correct[0]\n",
        "            correct_example = {\n",
        "                'image': single_result['images'][idx],\n",
        "                'true_label': single_result['labels'][idx],\n",
        "                'single_pred': single_result['predictions'][idx],\n",
        "                'ensemble_pred': ensemble_result['predictions'][idx],\n",
        "                'single_prob': single_result['probabilities'][idx][single_result['predictions'][idx]],\n",
        "                'ensemble_prob': ensemble_result['probabilities'][idx][ensemble_result['predictions'][idx]]\n",
        "            }\n",
        "        if len(common_incorrect) > 0:\n",
        "            idx = common_incorrect[0]\n",
        "            incorrect_example = {\n",
        "                'image': single_result['images'][idx],\n",
        "                'true_label': single_result['labels'][idx],\n",
        "                'single_pred': single_result['predictions'][idx],\n",
        "                'ensemble_pred': ensemble_result['predictions'][idx],\n",
        "                'single_prob': single_result['probabilities'][idx][single_result['predictions'][idx]],\n",
        "                'ensemble_prob': ensemble_result['probabilities'][idx][ensemble_result['predictions'][idx]]\n",
        "            }\n",
        "\n",
        "        # Denormalization parameters\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "\n",
        "        # Plot setup: 2 rows (correct, incorrect), 7 columns (image + 3 methods x 2 models)\n",
        "        if len(axes.shape) == 1:\n",
        "            axes = axes.reshape(1, -1)\n",
        "        if axes.shape[0] < 2 or axes.shape[1] < 7:\n",
        "            print(\"Warning: Insufficient axes for XAI comparison. Creating new figure.\")\n",
        "            fig, axes = plt.subplots(2, 7, figsize=(28, 8))\n",
        "        else:\n",
        "            axes = axes[:2, :7]  # Ensure we use only the first 2 rows and 7 columns\n",
        "\n",
        "        # Process both correct and incorrect examples\n",
        "        examples = [correct_example, incorrect_example]\n",
        "        titles = ['Correct Prediction', 'Incorrect Prediction']\n",
        "\n",
        "        for row, (example, title) in enumerate(zip(examples, titles)):\n",
        "            if example is None:\n",
        "                for col in range(7):\n",
        "                    axes[row, col].text(0.5, 0.5, f'{title}\\nNot Found',\n",
        "                                        ha='center', va='center', transform=axes[row, col].transAxes)\n",
        "                    axes[row, col].axis('off')\n",
        "                continue\n",
        "\n",
        "            # Prepare input tensor\n",
        "            input_tensor = torch.from_numpy(example['image']).float().to(Config.DEVICE)\n",
        "            input_tensor = input_tensor.unsqueeze(0)\n",
        "            input_tensor.requires_grad_(True)\n",
        "\n",
        "            # Denormalize image for display\n",
        "            img = example['image'].transpose(1, 2, 0)\n",
        "            img = std * img + mean\n",
        "            img = np.clip(img, 0, 1)\n",
        "\n",
        "            # Single model XAI\n",
        "            single_analyzer = XAIAnalyzer(best_model, Config.DEVICE)\n",
        "            single_explanations = single_analyzer.generate_all_explanations(input_tensor, example['true_label'])\n",
        "\n",
        "            # Ensemble XAI (average across models)\n",
        "            ensemble_explanations = {method: [] for method in Config.XAI_METHODS}\n",
        "            for m in best_ensemble_obj.models:\n",
        "                analyzer = XAIAnalyzer(m, Config.DEVICE)\n",
        "                exp = analyzer.generate_all_explanations(input_tensor, example['true_label'])\n",
        "                for method in Config.XAI_METHODS:\n",
        "                    ensemble_explanations[method].append(exp[method])\n",
        "            ensemble_explanations = {method: np.mean(exps, axis=0) for method, exps in ensemble_explanations.items()}\n",
        "\n",
        "            # Plot original image\n",
        "            axes[row, 0].imshow(img)\n",
        "            axes[row, 0].set_title(\n",
        "                f'{title}\\nTrue: {example[\"true_label\"]}\\n'\n",
        "                f'Single Pred: {example[\"single_pred\"]} ({example[\"single_prob\"]:.2f})\\n'\n",
        "                f'Ensemble Pred: {example[\"ensemble_pred\"]} ({example[\"ensemble_prob\"]:.2f})',\n",
        "                fontsize=8\n",
        "            )\n",
        "            axes[row, 0].axis('off')\n",
        "\n",
        "            # Plot XAI methods\n",
        "            for col, method in enumerate(Config.XAI_METHODS, start=1):\n",
        "                # Single model heatmap\n",
        "                single_heatmap = single_explanations[method]\n",
        "                axes[row, col].imshow(single_heatmap, cmap='hot')\n",
        "                axes[row, col].set_title(f'Single {method.capitalize()}', fontsize=8)\n",
        "                axes[row, col].axis('off')\n",
        "\n",
        "                # Ensemble heatmap\n",
        "                ensemble_heatmap = ensemble_explanations[method]\n",
        "                axes[row, col + 3].imshow(ensemble_heatmap, cmap='hot')\n",
        "                axes[row, col + 3].set_title(f'Ensemble {method.capitalize()}', fontsize=8)\n",
        "                axes[row, col + 3].axis('off')\n",
        "\n",
        "        # Adjust layout\n",
        "        plt.tight_layout()\n",
        "\n",
        "        # Save XAI comparison\n",
        "        output_path = Path(Config.COMPARISONS_DIR) / \"final_xai_comparison.png\"\n",
        "        plt.savefig(output_path, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "        output_path_pdf = output_path.with_suffix('.pdf')\n",
        "        plt.savefig(output_path_pdf, dpi=Config.FIGURE_DPI, bbox_inches='tight')\n",
        "        print(f\"‚úÖ Final XAI comparison saved: {output_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================================\n",
        "# Main Execution\n",
        "# ============================================================================\n",
        "# Required imports (ensure these are at the top of your script)\n",
        "# DataLoader functions\n",
        "def create_train_loader(batch_size=32, data_dir=\"/content/drive/MyDrive/Hilsha\", train_split=0.6, random_seed=42):\n",
        "    images_path = Path(data_dir) / \"X_data.npy\"\n",
        "    labels_path = Path(data_dir) / \"Y_labels.npy\"\n",
        "    try:\n",
        "        images = np.load(images_path)\n",
        "        labels = np.load(labels_path)\n",
        "        print(f\"Loaded data: {images.shape} images, {labels.shape} labels\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: Data files not found at {images_path} or {labels_path}\")\n",
        "        raise e\n",
        "    labels = labels.astype(np.int64)\n",
        "    train_val_images, _, train_val_labels, _ = train_test_split(\n",
        "        images, labels, test_size=0.2, random_state=random_seed, stratify=labels\n",
        "    )\n",
        "    train_images, _, train_labels, _ = train_test_split(\n",
        "        train_val_images, train_val_labels, train_size=train_split/(1-0.2), random_state=random_seed, stratify=train_val_labels\n",
        "    )\n",
        "    print(f\"Created train set: {train_images.shape[0]} samples\")\n",
        "    train_dataset = NumpyDataset(train_images, train_labels)\n",
        "    train_loader = DataLoader(\n",
        "        train_dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "    print(f\"Created train DataLoader with {len(train_dataset)} samples\")\n",
        "    return train_loader\n",
        "\n",
        "def create_val_loader(batch_size=32, data_dir=\"/content/drive/MyDrive/Hilsha\", train_split=0.6, val_split=0.2, random_seed=42):\n",
        "    images_path = Path(data_dir) / \"X_data.npy\"\n",
        "    labels_path = Path(data_dir) / \"Y_labels.npy\"\n",
        "    try:\n",
        "        images = np.load(images_path)\n",
        "        labels = np.load(labels_path)\n",
        "        print(f\"Loaded data: {images.shape} images, {labels.shape} labels\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: Data files not found at {images_path} or {labels_path}\")\n",
        "        raise e\n",
        "    labels = labels.astype(np.int64)\n",
        "    train_val_images, _, train_val_labels, _ = train_test_split(\n",
        "        images, labels, test_size=0.2, random_state=random_seed, stratify=labels\n",
        "    )\n",
        "    _, val_images, _, val_labels = train_test_split(\n",
        "        train_val_images, train_val_labels, train_size=train_split/(1-0.2), random_state=random_seed, stratify=train_val_labels\n",
        "    )\n",
        "    print(f\"Created validation set: {val_images.shape[0]} samples\")\n",
        "    val_dataset = NumpyDataset(val_images, val_labels)\n",
        "    val_loader = DataLoader(\n",
        "        val_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "    print(f\"Created validation DataLoader with {len(val_dataset)} samples\")\n",
        "    return val_loader\n",
        "\n",
        "def create_test_loader(batch_size=32, data_dir=\"/content/drive/MyDrive/Hilsha\", test_split=0.2, random_seed=42):\n",
        "    images_path = Path(data_dir) / \"X_data.npy\"\n",
        "    labels_path = Path(data_dir) / \"Y_labels.npy\"\n",
        "    try:\n",
        "        images = np.load(images_path)\n",
        "        labels = np.load(labels_path)\n",
        "        print(f\"Loaded data: {images.shape} images, {labels.shape} labels\")\n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: Data files not found at {images_path} or {labels_path}\")\n",
        "        raise e\n",
        "    labels = labels.astype(np.int64)\n",
        "    _, test_images, _, test_labels = train_test_split(\n",
        "        images, labels, test_size=test_split, random_state=random_seed, stratify=labels\n",
        "    )\n",
        "    print(f\"Created test set: {test_images.shape[0]} samples\")\n",
        "    test_dataset = NumpyDataset(test_images, test_labels)\n",
        "    test_loader = DataLoader(\n",
        "        test_dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True if torch.cuda.is_available() else False\n",
        "    )\n",
        "    print(f\"Created test DataLoader with {len(test_dataset)} samples\")\n",
        "    return test_loader\n",
        "\n",
        "# Main execution block\n",
        "if __name__ == \"__main__\":\n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "    # Verify model directory\n",
        "    model_dir = Path(Config.MODELS_DIR)\n",
        "    if model_dir.exists():\n",
        "        print(f\"Model directory found: {model_dir}\")\n",
        "        print(f\"Files: {list(model_dir.glob('*'))}\")\n",
        "    else:\n",
        "        print(f\"Model directory not found: {model_dir}\")\n",
        "        print(\"Please verify the path or move model files to the correct location\")\n",
        "\n",
        "    # Initialize model manager\n",
        "    model_manager = ModelManager()\n",
        "    model_manager.load_all_models()\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = create_train_loader(batch_size=32, train_split=0.6)\n",
        "    val_loader = create_val_loader(batch_size=32, train_split=0.6, val_split=0.2)\n",
        "    test_loader = create_test_loader(batch_size=32, test_split=0.2)\n",
        "\n",
        "    # Evaluate single models\n",
        "    single_analyzer = SingleModelAnalyzer(model_manager)\n",
        "    single_model_results = {}\n",
        "\n",
        "    for model_name, model in model_manager.models.items():\n",
        "        history = model_manager.training_histories.get(model_name)\n",
        "        if history:\n",
        "            single_analyzer.plot_training_dynamics(model_name, history)\n",
        "\n",
        "        if 'fold' not in model_name:\n",
        "            eval_results = single_analyzer.evaluate_model_comprehensive(model_name, model, test_loader)\n",
        "            single_analyzer.plot_evaluation_metrics(model_name, eval_results)\n",
        "            single_analyzer.plot_xai_examples(model_name, model, eval_results)\n",
        "            single_analyzer.plot_error_grid(model_name, eval_results)\n",
        "            single_model_results[model_name] = eval_results\n",
        "\n",
        "    # Evaluate ensembles\n",
        "    ensemble_analyzer = EnsembleAnalyzer()\n",
        "    ensemble_results = {}\n",
        "\n",
        "    # Filter main models for ensemble\n",
        "    main_model_names = [name for name in model_manager.models if 'fold' not in name and name in ['resnet50', 'efficientnet_b0', 'inception_v3']]\n",
        "    main_models = [model_manager.models[name] for name in main_model_names]\n",
        "\n",
        "    if not main_models:\n",
        "        print(\"No main models found for ensembles. Skipping ensemble evaluation.\")\n",
        "    else:\n",
        "        ensemble_classes = [\n",
        "            SimpleAverageEnsemble,\n",
        "            ConfidenceBasedEnsemble,\n",
        "            StackingEnsemble,\n",
        "            LearnableWeightedEnsemble,\n",
        "            SnapshotEnsemble\n",
        "        ]\n",
        "\n",
        "        for ensemble_class in ensemble_classes:\n",
        "            try:\n",
        "                ensemble = ensemble_class(main_models, model_names=main_model_names, num_classes=Config.NUM_CLASSES)\n",
        "\n",
        "                if hasattr(ensemble, 'train_meta_model'):\n",
        "                    ensemble.train_meta_model(train_loader)\n",
        "                if hasattr(ensemble, 'train_weights'):\n",
        "                    ensemble.train_weights(val_loader)\n",
        "\n",
        "                eval_results = ensemble_analyzer.evaluate_ensemble_comprehensive(ensemble, test_loader)\n",
        "                ensemble_analyzer.plot_evaluation_metrics(eval_results['ensemble_name'], eval_results)\n",
        "                ensemble_analyzer.plot_xai_examples(eval_results['ensemble_name'], ensemble, eval_results)\n",
        "                ensemble_analyzer.plot_error_grid(eval_results['ensemble_name'], eval_results)\n",
        "\n",
        "                ensemble_results[ensemble.get_name()] = eval_results\n",
        "            except Exception as e:\n",
        "                print(f\"Error evaluating {ensemble_class.__name__}: {str(e)}\")\n",
        "                continue\n",
        "\n",
        "        comparative = ComparativeAnalyzer(model_manager)\n",
        "        best_single = comparative.compare_single_models(single_model_results)\n",
        "        best_ensemble = comparative.compare_ensemble_models(ensemble_results)\n",
        "        comparative.create_final_comparison(best_single, best_ensemble, single_model_results, ensemble_results, test_loader)"
      ],
      "metadata": {
        "id": "fB1kbRasWOXu",
        "outputId": "669507c0-aa22-446d-b30f-30bb33594fe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "fB1kbRasWOXu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created/Verified directory: /content/drive/MyDrive/Hilsha/results\n",
            "Created/Verified directory: /content/drive/MyDrive/Hilsha/results/single_models\n",
            "Created/Verified directory: /content/drive/MyDrive/Hilsha/results/ensembles\n",
            "Created/Verified directory: /content/drive/MyDrive/Hilsha/results/comparisons\n",
            "Mounted at /content/drive\n",
            "Model directory found: /content/drive/MyDrive/Hilsha\n",
            "Files: [PosixPath('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip'), PosixPath('/content/drive/MyDrive/Hilsha/X_data.npy'), PosixPath('/content/drive/MyDrive/Hilsha/Y_labels.npy'), PosixPath('/content/drive/MyDrive/Hilsha/models'), PosixPath('/content/drive/MyDrive/Hilsha/best_model'), PosixPath('/content/drive/MyDrive/Hilsha/training_results'), PosixPath('/content/drive/MyDrive/Hilsha/kfold_results'), PosixPath('/content/drive/MyDrive/Hilsha/kfold_models'), PosixPath('/content/drive/MyDrive/Hilsha/results')]\n",
            "Found 10 models: ['resnet50_for_ensemble', 'efficientnet_b0_for_ensemble', 'resnet50', 'resnet50_fold_1', 'resnet50_fold_2', 'resnet50_fold_3', 'efficientnet_b0', 'efficientnet_b0_fold_1', 'efficientnet_b0_fold_2', 'efficientnet_b0_fold_3']\n",
            "Model file not found for: resnet50_for_ensemble\n",
            "‚úÖ Loaded training history: resnet50_for_ensemble\n",
            "Model file not found for: efficientnet_b0_for_ensemble\n",
            "‚úÖ Loaded training history: efficientnet_b0_for_ensemble\n",
            "‚úÖ Loaded PyTorch model: resnet50\n",
            "‚úÖ Loaded training history: resnet50\n",
            "‚úÖ Loaded PyTorch model: resnet50_fold_1\n",
            "‚úÖ Loaded training history: resnet50_fold_1\n",
            "‚úÖ Loaded PyTorch model: resnet50_fold_2\n",
            "‚úÖ Loaded training history: resnet50_fold_2\n",
            "‚úÖ Loaded PyTorch model: resnet50_fold_3\n",
            "‚úÖ Loaded training history: resnet50_fold_3\n",
            "‚úÖ Loaded PyTorch model: efficientnet_b0\n",
            "‚úÖ Loaded training history: efficientnet_b0\n",
            "‚úÖ Loaded PyTorch model: efficientnet_b0_fold_1\n",
            "‚úÖ Loaded training history: efficientnet_b0_fold_1\n",
            "‚úÖ Loaded PyTorch model: efficientnet_b0_fold_2\n",
            "‚úÖ Loaded training history: efficientnet_b0_fold_2\n",
            "‚úÖ Loaded PyTorch model: efficientnet_b0_fold_3\n",
            "‚úÖ Loaded training history: efficientnet_b0_fold_3\n",
            "Successfully loaded 8 models and 10 histories\n",
            "Loaded data: (8407, 3, 224, 224) images, (8407,) labels\n",
            "Created train set: 5043 samples\n",
            "Loaded 5043 samples\n",
            "Created train DataLoader with 5043 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üåç Real-World Data Test üîéüìä\n"
      ],
      "metadata": {
        "id": "_X2tyIMkfV_q"
      },
      "id": "_X2tyIMkfV_q"
    },
    {
      "cell_type": "code",
      "source": [
        "# Add this import at the top\n",
        "# from your_model_module import ModelFactory  # Replace with your actual import\n",
        "\n",
        "# Simple Image Predictor for Google Colab\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from google.colab import files\n",
        "import os\n",
        "\n",
        "# Setup - Replace these with your values\n",
        "CLASS_NAMES = ['Class1', 'Class2', 'Class3', 'Class4', 'Class5']  # Replace with your 5 classes\n",
        "MODEL_PATH = \"/content/output/best_model/your_model_name_best.pt\"  # Replace with your model path\n",
        "\n",
        "# Image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Load model\n",
        "def load_model():\n",
        "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    # Load checkpoint\n",
        "    checkpoint = torch.load(MODEL_PATH, map_location=device, weights_only=False)\n",
        "\n",
        "    # Get model info from checkpoint\n",
        "    model_name = checkpoint['model_name']\n",
        "    hyperparameters = checkpoint.get('hyperparameters', {})\n",
        "\n",
        "    # Create model using your ModelFactory\n",
        "    model = ModelFactory.create_model(\n",
        "        model_name,\n",
        "        params=hyperparameters,\n",
        "        num_classes=len(CLASS_NAMES)\n",
        "    )\n",
        "\n",
        "    # Load the trained weights\n",
        "    model.load_state_dict(checkpoint['state_dict'])\n",
        "    model.to(device)\n",
        "\n",
        "    print(f\"Loaded model: {model_name}\")\n",
        "    return model, device\n",
        "\n",
        "# Predict function\n",
        "def predict_image(image_path_or_pil):\n",
        "    model, device = load_model()\n",
        "    if model is None:\n",
        "        return\n",
        "\n",
        "    # Load and preprocess image\n",
        "    if isinstance(image_path_or_pil, str):\n",
        "        image = Image.open(image_path_or_pil)\n",
        "    else:\n",
        "        image = image_path_or_pil\n",
        "\n",
        "    if image.mode != 'RGB':\n",
        "        image = image.convert('RGB')\n",
        "\n",
        "    input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    # Make prediction\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        probabilities = torch.softmax(outputs, dim=1)\n",
        "        confidence, predicted_idx = torch.max(probabilities, 1)\n",
        "\n",
        "    predicted_class = CLASS_NAMES[predicted_idx.item()]\n",
        "    confidence_score = confidence.item()\n",
        "\n",
        "    # Show results\n",
        "    plt.figure(figsize=(10, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.imshow(image)\n",
        "    plt.title('Input Image')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    probs = probabilities[0].cpu().numpy()\n",
        "    colors = ['green' if i == predicted_idx else 'skyblue' for i in range(len(CLASS_NAMES))]\n",
        "    plt.bar(CLASS_NAMES, probs, color=colors)\n",
        "    plt.title('Predictions')\n",
        "    plt.xticks(rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"üéØ Predicted: {predicted_class}\")\n",
        "    print(f\"üìä Confidence: {confidence_score:.2%}\")\n",
        "\n",
        "    return predicted_class, confidence_score\n",
        "\n",
        "# Predict from URL\n",
        "def predict_from_url(image_url):\n",
        "    try:\n",
        "        response = requests.get(image_url)\n",
        "        image = Image.open(BytesIO(response.content))\n",
        "        return predict_image(image)\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {e}\")\n",
        "\n",
        "# Predict from uploaded file\n",
        "def predict_uploaded():\n",
        "    print(\"Upload an image file:\")\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    if uploaded:\n",
        "        filename = list(uploaded.keys())[0]\n",
        "        result = predict_image(filename)\n",
        "        os.remove(filename)  # Clean up\n",
        "        return result\n",
        "    else:\n",
        "        print(\"No file uploaded\")\n",
        "\n",
        "# Example usage:\n",
        "print(\"üöÄ Simple Image Predictor Ready!\")\n",
        "print(\"\\nHow to use:\")\n",
        "print(\"1. First, replace MODEL_PATH and CLASS_NAMES above\")\n",
        "print(\"2. Fix the load_model() function with your actual model\")\n",
        "print(\"3. Then run:\")\n",
        "print(\"   predict_uploaded()  # To upload image\")\n",
        "print(\"   predict_from_url('http://example.com/image.jpg')  # To predict from URL\")\n",
        "\n",
        "\n",
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# from torchvision import transforms, models\n",
        "# from PIL import Image\n",
        "# import requests\n",
        "# from io import BytesIO\n",
        "\n",
        "# # ---------------------------\n",
        "# # CONFIG\n",
        "# # ---------------------------\n",
        "# MODEL_PATH = \"best_model.pth\"   # ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ trained model file\n",
        "# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# # ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ dataset ‡¶è‡¶∞ class ‡¶≤‡¶ø‡¶∏‡ßç‡¶ü (‡¶®‡¶ø‡¶ú‡ßá‡¶∞ dataset ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶¨‡¶¶‡¶≤‡¶æ‡¶¨‡ßá)\n",
        "# CLASS_NAMES = [\"ilish\", \"chandana\", \"sardin\", \"sardinella\", \"punctatus\"]\n",
        "\n",
        "# # ---------------------------\n",
        "# # Load Model\n",
        "# # ---------------------------\n",
        "# def load_model():\n",
        "#     model = models.resnet50(weights=None)   # ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶Ø‡ßá‡¶ü‡¶æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá‡¶õ‡ßã ‡¶∏‡ßá‡¶ü‡¶æ ‡¶¨‡¶∏‡¶æ‡¶ì\n",
        "#     num_features = model.fc.in_features\n",
        "#     model.fc = nn.Linear(num_features, len(CLASS_NAMES))\n",
        "\n",
        "#     checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
        "#     model.load_state_dict(checkpoint[\"model_state_dict\"])  # ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ save format ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ adjust ‡¶ï‡¶∞‡ßã\n",
        "#     model.to(DEVICE)\n",
        "#     model.eval()\n",
        "#     return model\n",
        "\n",
        "# # ---------------------------\n",
        "# # Preprocess\n",
        "# # ---------------------------\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)),    # training ‡¶∏‡¶Æ‡ßü ‡¶Ø‡¶æ ‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡ßã, ‡¶∏‡ßá‡¶ü‡¶æ ‡¶Æ‡ßá‡¶≤‡¶æ‡¶§‡ßá ‡¶π‡¶¨‡ßá\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize([0.485, 0.456, 0.406],\n",
        "#                          [0.229, 0.224, 0.225])\n",
        "# ])\n",
        "\n",
        "# def load_image(img_path=None, img_url=None):\n",
        "#     if img_path:\n",
        "#         image = Image.open(img_path).convert(\"RGB\")\n",
        "#     elif img_url:\n",
        "#         response = requests.get(img_url)\n",
        "#         image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "#     else:\n",
        "#         raise ValueError(\"Provide either img_path or img_url\")\n",
        "#     return image\n",
        "\n",
        "# # ---------------------------\n",
        "# # Prediction\n",
        "# # ---------------------------\n",
        "# def predict_image(model, image):\n",
        "#     img_tensor = transform(image).unsqueeze(0).to(DEVICE)\n",
        "#     with torch.no_grad():\n",
        "#         outputs = model(img_tensor)\n",
        "#         probs = torch.softmax(outputs, dim=1)\n",
        "#         conf, pred = torch.max(probs, 1)\n",
        "#     return CLASS_NAMES[pred.item()], conf.item()\n",
        "\n",
        "# # ---------------------------\n",
        "# # Main\n",
        "# # ---------------------------\n",
        "# if __name__ == \"__main__\":\n",
        "#     model = load_model()\n",
        "\n",
        "#     # Option 1: ‡¶≤‡ßã‡¶ï‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶•‡ßá‡¶ï‡ßá\n",
        "#     img_path = \"test_fish.jpg\"\n",
        "#     image = load_image(img_path=img_path)\n",
        "#     label, confidence = predict_image(model, image)\n",
        "#     print(f\"Prediction: {label} ({confidence:.2f})\")\n",
        "\n",
        "#     # Option 2: URL ‡¶•‡ßá‡¶ï‡ßá\n",
        "#     img_url = \"https://example.com/sample_fish.jpg\"\n",
        "#     image = load_image(img_url=img_url)\n",
        "#     label, confidence = predict_image(model, image)\n",
        "#     print(f\"Prediction: {label} ({confidence:.2f})\")\n"
      ],
      "metadata": {
        "id": "kcr-u7s4phe3"
      },
      "id": "kcr-u7s4phe3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cdd48bb6",
      "metadata": {
        "id": "cdd48bb6"
      },
      "source": [
        "#End"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}