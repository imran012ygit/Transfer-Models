{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran012x/Transfer-Models/blob/main/Hilsha_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01bea336",
      "metadata": {
        "id": "01bea336"
      },
      "source": [
        "#Colab-connect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "344965bc",
      "metadata": {
        "id": "344965bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55994296-c30a-42f1-ea76-3e7d3b8a9cfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# # Upload a file\n",
        "# uploaded = files.upload()\n",
        "# # Get the file name\n",
        "# file_name = list(uploaded.keys())[0]\n",
        "# print(f\"Uploaded file: {file_name}\")\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# # with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_224_11k.zip', 'r') as zip_ref:\n",
        "# #     zip_ref.extractall('')\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de009928",
      "metadata": {
        "id": "de009928"
      },
      "source": [
        "#Data Preprocess and Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6f95c03b",
      "metadata": {
        "id": "6f95c03b"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "# from tqdm import tqdm\n",
        "# import random\n",
        "# import gc\n",
        "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "# import threading\n",
        "# import zipfile\n",
        "\n",
        "# # Check GPU availability\n",
        "# print(\"GPU Available:\", torch.cuda.is_available())\n",
        "# print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "# # Define fish classes and dataset paths\n",
        "# fish_classes = ['ilish', 'chandana', 'sardin', 'sardinella', 'punctatus'] #0,1,2,3,4\n",
        "# zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip').extractall('/content/.hidden_fish')\n",
        "# data_dir = '/content/.hidden_fish'\n",
        "\n",
        "# image_limits = {\n",
        "#     'ilish': 3000,\n",
        "#     'chandana': 1185,\n",
        "#     'sardin': 2899,\n",
        "#     'sardinella': 370,\n",
        "#     'punctatus': 953\n",
        "# }\n",
        "\n",
        "# # Settings\n",
        "# total_images = sum(image_limits.values())\n",
        "# batch_size = 100\n",
        "# num_threads = 4\n",
        "\n",
        "\n",
        "# # Output paths\n",
        "# output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "# labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "# xdata_file = os.path.join(output_dir, 'X_data.npy')\n",
        "\n",
        "# save_lock = threading.Lock()  # for thread-safe writes -> Prevents race conditions when multiple threads write to the same list.\n",
        "\n",
        "# # Function to gather image paths\n",
        "# def get_image_paths(class_name, max_images):\n",
        "#     path = os.path.join(data_dir, class_name)\n",
        "#     files = sorted(os.listdir(path))\n",
        "#     random.shuffle(files)\n",
        "#     return [os.path.join(path, f) for f in files[:max_images]]\n",
        "\n",
        "# # Load and preprocess batch\n",
        "# def load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     end_idx = min(start_idx + batch_size, len(image_paths))\n",
        "#     batch_paths = image_paths[start_idx:end_idx]\n",
        "#     batch_images = []\n",
        "\n",
        "#     for img_path in batch_paths:\n",
        "#         img = Image.open(img_path).resize((224, 224)).convert('RGB')\n",
        "#         img_tensor = torch.tensor(np.array(img), dtype=torch.uint8).permute(2, 0, 1)  # C x H x W\n",
        "#         batch_images.append(img_tensor)\n",
        "\n",
        "#     batch_tensor = torch.stack(batch_images)  # B x C x H x W\n",
        "#     batch_labels = np.full((len(batch_images),), class_idx, dtype=np.int32)\n",
        "#     return batch_tensor, batch_labels\n",
        "\n",
        "# # Process one batch and return tensors & labels (no file saving)\n",
        "# def process_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     return load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx)\n",
        "\n",
        "# def preprocess_and_save_all(overwrite=True):\n",
        "#     if os.path.exists(labels_file) and os.path.exists(xdata_file) and not overwrite:\n",
        "#         print(\"Preprocessed data already exists. Set overwrite=True to reprocess.\")\n",
        "#         return\n",
        "\n",
        "#     all_images = []\n",
        "#     all_labels = []\n",
        "#     processed_count = 0\n",
        "\n",
        "#     for idx, class_name in enumerate(fish_classes):\n",
        "#         print(f\"\\nProcessing class: {class_name}\")\n",
        "#         image_paths = get_image_paths(class_name, image_limits[class_name])\n",
        "#         total_batches = (len(image_paths) + batch_size - 1) // batch_size\n",
        "#         #It ensures ceiling division ‚Äî rounding up, not down.\n",
        "#         # Normal division: 103 / 20 = 5.15 ‚Üí floor division // 20 = 5 (‚ùå missing last 3 images)\n",
        "#         # This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ‚úÖ\n",
        "\n",
        "#         with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "#             futures = []\n",
        "#             for start in range(0, len(image_paths), batch_size):\n",
        "#                 futures.append(executor.submit(process_batch, image_paths, start, batch_size, idx))\n",
        "\n",
        "#             for future in tqdm(as_completed(futures), total=total_batches, desc=class_name):#taqaddum (ÿ™ŸÇÿØŸëŸÖ) ‚Äì Arabic for \"progress\".\n",
        "#                 # futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\n",
        "#                 # as_completed(futures): Yields each future as it finishes (not in order).\n",
        "\n",
        "#                 batch_tensor, batch_labels = future.result()\n",
        "#                 with save_lock: #Locks this section so that only one thread can update the shared lists safely.\n",
        "#                     all_images.append(batch_tensor)\n",
        "#                     all_labels.append(batch_labels)\n",
        "#                     processed_count += batch_tensor.size(0)\n",
        "#                     print(f\"Processed batch with {batch_tensor.size(0)} images, total processed: {processed_count}/{total_images}\")\n",
        "#                 gc.collect()\n",
        "\n",
        "#     # Combine all tensors and labels\n",
        "#     X = torch.cat(all_images, dim=0).numpy()\n",
        "#     Y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "#     # Save final arrays\n",
        "#     np.save(xdata_file, X, allow_pickle=False)#Malicious .npy -> import os;os.system(\"rm -rf /\")  # ‚Üê Dangerous command\n",
        "#     np.save(labels_file, Y, allow_pickle=False)\n",
        "\n",
        "#     print(f\"\\n‚úÖ Done! Saved {processed_count} images in {xdata_file}\")\n",
        "#     print(f\"X_data shape: {X.shape}, Y_labels shape: {Y.shape}\")\n",
        "\n",
        "#     if processed_count != total_images:\n",
        "#         raise ValueError(f\"Expected {total_images} images, but processed {processed_count}\")\n",
        "\n",
        "# # Run preprocessing and save directly to X_data.npy and Y_labels.npy\n",
        "# preprocess_and_save_all(overwrite=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0fbbeb4",
      "metadata": {
        "id": "c0fbbeb4"
      },
      "source": [
        "####DATA LOADING...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "23d9c0c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23d9c0c0",
        "outputId": "6d6fe631-b973-4c44-c34a-d6c54c989f41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ X_data.npy: 1.18 GB\n",
            "üìÅ Y_labels.npy: 32.96 KB\n",
            "‚úÖ X shape: (8407, 3, 224, 224), dtype: uint8\n",
            "‚úÖ Y shape: (8407,), dtype: int32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614331559.py:42: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  X = torch.from_numpy(X)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Torch tensors ready on cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Your data path\n",
        "output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "data_file = os.path.join(output_dir, 'X_data.npy')\n",
        "labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "\n",
        "# Readable size format\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    for unit in ['', 'K', 'M', 'G', 'T']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return f\"{num:3.2f} {unit}{suffix}\"\n",
        "        num /= 1024.0\n",
        "    return f\"{num:.2f} T{suffix}\"\n",
        "\n",
        "# Main loader\n",
        "def load_preprocessed_data(as_torch=True, normalize=True, to_device=None):\n",
        "    # Check file existence #cpu,cuda (CUDA stands for Compute Unified Device Architecture.)\n",
        "    for path in [data_file, labels_file]:\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Missing: {path}\")\n",
        "\n",
        "    # Print file sizes\n",
        "    print(f\"üìÅ X_data.npy: {sizeof_fmt(os.path.getsize(data_file))}\")\n",
        "    print(f\"üìÅ Y_labels.npy: {sizeof_fmt(os.path.getsize(labels_file))}\")\n",
        "\n",
        "    # Load with mmap\n",
        "    X = np.load(data_file, mmap_mode='r')\n",
        "    Y = np.load(labels_file, mmap_mode='r')\n",
        "\n",
        "    print(f\"‚úÖ X shape: {X.shape}, dtype: {X.dtype}\")\n",
        "    print(f\"‚úÖ Y shape: {Y.shape}, dtype: {Y.dtype}\")\n",
        "\n",
        "    # Sanity check\n",
        "    if len(X) != len(Y):\n",
        "        raise ValueError(\"Mismatch between number of samples in X and Y\")\n",
        "\n",
        "    # Convert to torch\n",
        "    if as_torch:\n",
        "        X = torch.from_numpy(X)\n",
        "        Y = torch.from_numpy(Y)\n",
        "\n",
        "        if normalize and X.dtype == torch.uint8:\n",
        "            X = X.float() / 255.0\n",
        "\n",
        "        if to_device:\n",
        "            X = X.to(to_device)\n",
        "            Y = Y.to(to_device)\n",
        "\n",
        "        print(f\"üß† Torch tensors ready on {to_device or 'CPU'}\")\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# üîÅ Example call\n",
        "X, Y = load_preprocessed_data(\n",
        "    as_torch=True,\n",
        "    normalize=True,\n",
        "    to_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. IMPORTS AND INITIAL SETUP\n",
        "# =============================================================================\n",
        "# Purpose: Import all required libraries and set up warnings to suppress unnecessary messages.\n",
        "\n",
        "# !pip install pytorch-gradcam optuna captum  # Uncomment if running in a new environment\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from itertools import combinations\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, f1_score,\n",
        "                             accuracy_score, precision_score, recall_score)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Augmentation\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# Hyperparameter optimization\n",
        "try:\n",
        "    import optuna\n",
        "    OPTUNA_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPTUNA_AVAILABLE = False\n",
        "    print(\"Warning: Optuna not available. Using default hyperparameters.\")\n",
        "\n",
        "# XAI dependencies\n",
        "import torch.autograd as autograd\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# ---\n",
        "# 2. CONFIGURATION\n",
        "# =============================================================================\n",
        "# Purpose: Define configuration settings and initialize the environment.\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration settings\"\"\"\n",
        "    # Paths - UPDATE THESE TO YOUR ACTUAL PATHS\n",
        "    DATA_FILE = '/content/drive/MyDrive/Hilsha/X_data.npy'\n",
        "    LABELS_FILE = '/content/drive/MyDrive/Hilsha/Y_labels.npy'\n",
        "    OUTPUT_DIR = './fish_classification_results'\n",
        "\n",
        "    # Dataset parameters\n",
        "    NUM_CLASSES = 5\n",
        "    CLASS_LABELS = ['Ilish', 'Chandana', 'Sardin', 'Sardinella', 'Punctatus']\n",
        "    INPUT_SIZE = 224\n",
        "\n",
        "    # Training parameters\n",
        "    BATCH_SIZE = 64\n",
        "    EPOCHS = 1\n",
        "    DATALOADER_NUM_WORKERS = 4\n",
        "    PIN_MEMORY = True\n",
        "    USE_MIXED_PRECISION = True\n",
        "    COMPILE_MODEL = True\n",
        "    PATIENCE = 10\n",
        "    LEARNING_RATE = 1e-4\n",
        "    WEIGHT_DECAY = 1e-4\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    OPTUNA_TRIALS = 1\n",
        "    OPTUNA_EPOCHS = 1\n",
        "\n",
        "    # Models to train\n",
        "    MODELS = ['resnet50', 'efficientnet_b0',\n",
        "              'mobilenet_v3_large','vgg16', 'densenet121']\n",
        "\n",
        "    # Ensemble methods\n",
        "    ENSEMBLE_METHODS = ['simple_average', 'weighted_average', 'confidence_based', 'learnable_weighted']\n",
        "\n",
        "    # Device\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    SEED = 42\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"Setup random seeds and directories\"\"\"\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "\n",
        "    directories = [\n",
        "        Config.OUTPUT_DIR,\n",
        "        f\"{Config.OUTPUT_DIR}/models\",\n",
        "        f\"{Config.OUTPUT_DIR}/visualizations\",\n",
        "        f\"{Config.OUTPUT_DIR}/reports\",\n",
        "        f\"{Config.OUTPUT_DIR}/xai_visualizations\"\n",
        "    ]\n",
        "\n",
        "    for directory in directories:\n",
        "        Path(directory).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(f\"Using device: {Config.DEVICE}\")\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "# ---\n",
        "# 3. TRAINING PROGRESS TRACKER\n",
        "# =============================================================================\n",
        "# Purpose: Track and display training progress with progress bars and epoch summaries.\n",
        "\n",
        "class TrainingProgressTracker:\n",
        "    \"\"\"Track and display detailed training progress\"\"\"\n",
        "\n",
        "    def __init__(self, model_name, total_epochs, total_batches_per_epoch):\n",
        "        self.model_name = model_name\n",
        "        self.total_epochs = total_epochs\n",
        "        self.total_batches_per_epoch = total_batches_per_epoch\n",
        "        self.start_time = time.time()\n",
        "        self.epoch_start_time = None\n",
        "        self.batch_times = []\n",
        "\n",
        "    def start_epoch(self, epoch):\n",
        "        \"\"\"Start tracking an epoch\"\"\"\n",
        "        self.current_epoch = epoch\n",
        "        self.epoch_start_time = time.time()\n",
        "        self.batch_times = []\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Model: {self.model_name.upper()} | Epoch: {epoch+1}/{self.total_epochs}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "    def update_batch(self, batch_idx, batch_loss, batch_acc, is_training=True):\n",
        "        \"\"\"Update progress for current batch\"\"\"\n",
        "        batch_time = time.time()\n",
        "        self.batch_times.append(batch_time)\n",
        "\n",
        "        # Calculate timing estimates\n",
        "        if len(self.batch_times) > 1:\n",
        "            avg_batch_time = np.mean(np.diff(self.batch_times[-10:]))\n",
        "        else:\n",
        "            avg_batch_time = 1.0\n",
        "\n",
        "        remaining_batches = self.total_batches_per_epoch - (batch_idx + 1)\n",
        "        eta_epoch = remaining_batches * avg_batch_time\n",
        "\n",
        "        # Progress bar\n",
        "        progress_pct = (batch_idx + 1) / self.total_batches_per_epoch * 100\n",
        "        bar_length = 30\n",
        "        filled_length = int(bar_length * (batch_idx + 1) // self.total_batches_per_epoch)\n",
        "        bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "        # Format time\n",
        "        eta_str = str(timedelta(seconds=int(eta_epoch)))\n",
        "\n",
        "        # Display progress\n",
        "        mode = \"TRAIN\" if is_training else \"VAL  \"\n",
        "        print(f\"\\r{mode} |{bar}| {progress_pct:5.1f}% | \"\n",
        "              f\"Batch: {batch_idx+1:4d}/{self.total_batches_per_epoch} | \"\n",
        "              f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
        "              f\"ETA: {eta_str}\", end='', flush=True)\n",
        "\n",
        "    def finish_epoch(self, train_loss, train_acc, val_loss, val_acc, val_f1,\n",
        "                    is_best=False, lr=None):\n",
        "        \"\"\"Finish epoch and display summary\"\"\"\n",
        "        epoch_time = time.time() - self.epoch_start_time\n",
        "        total_time = time.time() - self.start_time\n",
        "\n",
        "        print(f\"\\n{'-'*60}\")\n",
        "        print(f\"EPOCH SUMMARY:\")\n",
        "        print(f\"  Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"  Val Loss:   {val_loss:.6f} | Val Acc:   {val_acc:.4f}\")\n",
        "        print(f\"  Val F1:     {val_f1:.4f} | Epoch Time: {epoch_time:.1f}s\")\n",
        "        if lr:\n",
        "            print(f\"  Learning Rate: {lr:.2e}\")\n",
        "\n",
        "        if is_best:\n",
        "            print(f\"  ‚òÖ NEW BEST MODEL! (F1: {val_f1:.4f})\")\n",
        "\n",
        "        print(f\"  Total Time: {str(timedelta(seconds=int(total_time)))}\")\n",
        "        print(f\"{'-'*60}\")\n",
        "\n",
        "# ---\n",
        "# 4. DATA LOADING AND PREPROCESSING\n",
        "# =============================================================================\n",
        "# Purpose: Handle dataset creation, data loading, balancing with SMOTE, and data augmentation.\n",
        "\n",
        "class FishDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = self._preprocess_images(images)\n",
        "        self.labels = labels.astype(np.int64)\n",
        "        self.transform = transform\n",
        "\n",
        "    def _preprocess_images(self, images):\n",
        "        if images.max() > 1.5:\n",
        "            images = images.astype(np.float32) / 255.0\n",
        "        if len(images.shape) == 4 and images.shape[1] == 3:\n",
        "            images = np.transpose(images, (0, 2, 3, 1))\n",
        "        return images.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "        else:\n",
        "            image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class DataManager:\n",
        "    @staticmethod\n",
        "    def get_transforms(is_training=True, augmentation_strength='medium'):\n",
        "        \"\"\"Get data transforms with configurable augmentation strength\"\"\"\n",
        "        if is_training:\n",
        "            if augmentation_strength == 'light':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.3),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            elif augmentation_strength == 'heavy':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.7),\n",
        "                    A.VerticalFlip(p=0.5),\n",
        "                    A.RandomRotate90(p=0.7),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, p=0.8),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.8),\n",
        "                    A.HueSaturationValue(hue_shift_limit=30, sat_shift_limit=40, val_shift_limit=30, p=0.7),\n",
        "                    A.GaussianBlur(blur_limit=(3, 9), p=0.5),\n",
        "                    A.GaussNoise(var_limit=(10.0, 80.0), p=0.4),\n",
        "                    A.CoarseDropout(max_holes=12, max_height=25, max_width=25, p=0.5),\n",
        "                    A.ElasticTransform(p=0.3),\n",
        "                    A.GridDistortion(p=0.3),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            else:  # medium\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.5),\n",
        "                    A.VerticalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.5),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.7),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
        "                    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.6),\n",
        "                    A.GaussianBlur(blur_limit=(3, 7), p=0.4),\n",
        "                    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "                    A.CoarseDropout(max_holes=8, max_height=20, max_width=20, p=0.4),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "        else:\n",
        "            return A.Compose([\n",
        "                A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "\n",
        "    @staticmethod\n",
        "    def load_and_balance_data():\n",
        "        \"\"\"Load data and apply SMOTE\"\"\"\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "\n",
        "        X = np.load(Config.DATA_FILE)\n",
        "        Y = np.load(Config.LABELS_FILE)\n",
        "\n",
        "        print(f\"Original data shape: {X.shape}\")\n",
        "        print(f\"Original class distribution: {np.bincount(Y)}\")\n",
        "\n",
        "        print(\"Applying SMOTE for class balancing...\")\n",
        "        X_flat = X.reshape(X.shape[0], -1)\n",
        "        smote = SMOTE(random_state=Config.SEED, k_neighbors=min(5, np.bincount(Y).min()-1))\n",
        "        X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y)\n",
        "        X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "\n",
        "        print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "\n",
        "        return X_balanced, Y_balanced\n",
        "\n",
        "    @staticmethod\n",
        "    def create_data_loaders(X, Y, test_size=0.2, batch_size=None, augmentation_strength='medium'):\n",
        "        if batch_size is None:\n",
        "            if torch.cuda.is_available():\n",
        "                gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "                if gpu_memory_gb >= 24:\n",
        "                    batch_size = 128\n",
        "                elif gpu_memory_gb >= 12:\n",
        "                    batch_size = 96\n",
        "                elif gpu_memory_gb >= 8:\n",
        "                    batch_size = 64\n",
        "                else:\n",
        "                    batch_size = 48\n",
        "            else:\n",
        "                batch_size = Config.BATCH_SIZE\n",
        "\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "            X, Y, test_size=test_size, random_state=Config.SEED, stratify=Y\n",
        "        )\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=0.25, random_state=Config.SEED, stratify=y_temp\n",
        "        )\n",
        "\n",
        "        print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "        print(f\"Using optimized batch size: {batch_size}\")\n",
        "\n",
        "        train_dataset = FishDataset(X_train, y_train,\n",
        "                                  DataManager.get_transforms(True, augmentation_strength))\n",
        "        val_dataset = FishDataset(X_val, y_val, DataManager.get_transforms(False))\n",
        "        test_dataset = FishDataset(X_test, y_test, DataManager.get_transforms(False))\n",
        "\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "        sample_weights = [class_weights[y] for y in y_train]\n",
        "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=sampler,\n",
        "            num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            prefetch_factor=2,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            prefetch_factor=2,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            prefetch_factor=2,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "        return train_loader, val_loader, test_loader, (X_val, y_val), (X_test, y_test)\n",
        "\n",
        "# ---\n",
        "# 5. MODEL FACTORY\n",
        "# =============================================================================\n",
        "# Purpose: Create different neural network models with customizable architectures.\n",
        "\n",
        "class ModelFactory:\n",
        "    @staticmethod\n",
        "    def create_model(model_name, num_classes=Config.NUM_CLASSES, dropout_rate=0.5,\n",
        "                    hidden_dim_multiplier=0.5):\n",
        "        \"\"\"Create model with configurable architecture\"\"\"\n",
        "\n",
        "        if model_name == 'resnet50':\n",
        "            model = models.resnet50(weights='IMAGENET1K_V2')\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'efficientnet_b0':\n",
        "            model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "            num_features = model.classifier[1].in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'mobilenet_v3_large':\n",
        "            model = models.mobilenet_v3_large(weights='IMAGENET1K_V2')\n",
        "            num_features = 960\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'vgg16':\n",
        "            model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "            hidden_dim = int(4096 * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Linear(512 * 7 * 7, 4096),\n",
        "                nn.ReLU(True),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(4096, hidden_dim),\n",
        "                nn.ReLU(True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'densenet121':\n",
        "            model = models.densenet121(weights='IMAGENET1K_V1')\n",
        "            num_features = model.classifier.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "        return model\n",
        "\n",
        "# ---\n",
        "# 6. LEARNABLE WEIGHTED ENSEMBLE MODEL\n",
        "# =============================================================================\n",
        "# Purpose: Define a neural network for learning optimal ensemble weights.\n",
        "\n",
        "class LearnableWeightedEnsemble(nn.Module):\n",
        "    \"\"\"Neural network for learning optimal ensemble weights\"\"\"\n",
        "    def __init__(self, num_models, num_classes, hidden_dim=64):\n",
        "        super(LearnableWeightedEnsemble, self).__init__()\n",
        "        self.num_models = num_models\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.weight_network = nn.Sequential(\n",
        "            nn.Linear(num_models * num_classes, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim // 2, num_models),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "        self.prediction_head = nn.Sequential(\n",
        "            nn.Linear(num_classes, num_classes * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(num_classes * 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, model_predictions):\n",
        "        batch_size = model_predictions.shape[0]\n",
        "\n",
        "        flattened_preds = model_predictions.view(batch_size, -1)\n",
        "\n",
        "        weights = self.weight_network(flattened_preds)\n",
        "\n",
        "        weighted_avg = torch.sum(model_predictions * weights.unsqueeze(-1), dim=1)\n",
        "\n",
        "        final_predictions = self.prediction_head(weighted_avg)\n",
        "\n",
        "        return final_predictions, weights\n",
        "\n",
        "# ---\n",
        "# 7. HYPERPARAMETER OPTIMIZATION\n",
        "# =============================================================================\n",
        "# Purpose: Tune model hyperparameters using Optuna.\n",
        "\n",
        "class ExpandedHyperparameterOptimizer:\n",
        "    def __init__(self, model_name, train_loader, val_loader):\n",
        "        self.model_name = model_name\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.total_batches_per_epoch = len(train_loader)\n",
        "        self.batch_times = []\n",
        "\n",
        "    def _update_progress(self, batch_idx, batch_loss, batch_acc, trial_params, is_training=True):\n",
        "        \"\"\"Display progress during hyperparameter tuning\"\"\"\n",
        "        batch_time = time.time()\n",
        "        self.batch_times.append(batch_time)\n",
        "\n",
        "        if len(self.batch_times) > 1:\n",
        "            avg_batch_time = np.mean(np.diff(self.batch_times[-10:]))\n",
        "        else:\n",
        "            avg_batch_time = 1.0\n",
        "\n",
        "        remaining_batches = self.total_batches_per_epoch - (batch_idx + 1)\n",
        "        eta_epoch = remaining_batches * avg_batch_time\n",
        "\n",
        "        progress_pct = (batch_idx + 1) / self.total_batches_per_epoch * 100\n",
        "        bar_length = 30\n",
        "        filled_length = int(bar_length * (batch_idx + 1) // self.total_batches_per_epoch)\n",
        "        bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "        eta_str = str(timedelta(seconds=int(eta_epoch)))\n",
        "\n",
        "        mode = \"TRAIN\" if is_training else \"VAL  \"\n",
        "        print(f\"\\r{mode} |{bar}| {progress_pct:5.1f}% | \"\n",
        "              f\"Batch: {batch_idx+1:4d}/{self.total_batches_per_epoch} | \"\n",
        "              f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
        "              f\"ETA: {eta_str} | Params: {self._format_params(trial_params)}\", end='', flush=True)\n",
        "\n",
        "    def _format_params(self, params):\n",
        "        \"\"\"Format hyperparameters for display\"\"\"\n",
        "        formatted = []\n",
        "        for key, value in params.items():\n",
        "            if key in ['lr', 'weight_decay']:\n",
        "                formatted.append(f\"{key}: {value:.4f}\")\n",
        "            elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                formatted.append(f\"{key}: {value:.1f}\")\n",
        "            else:\n",
        "                formatted.append(f\"{key}: {value}\")\n",
        "        return \", \".join(formatted)\n",
        "\n",
        "    def objective(self, trial):\n",
        "        \"\"\"Optuna objective function with hyperparameters\"\"\"\n",
        "        lr = trial.suggest_float('lr', 1e-5, 5e-3, log=True)\n",
        "        weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
        "        dropout = trial.suggest_float('dropout', 0.2, 0.8)\n",
        "        hidden_dim_multiplier = trial.suggest_float('hidden_dim_multiplier', 0.25, 1.0)\n",
        "        augmentation_strength = trial.suggest_categorical('augmentation_strength',\n",
        "                                                        ['light', 'medium', 'heavy'])\n",
        "        batch_size = trial.suggest_categorical('batch_size', [16, 24, 32, 48, 64])\n",
        "        optimizer_type = trial.suggest_categorical('optimizer_type', ['adam', 'adamw', 'sgd'])\n",
        "        scheduler_type = trial.suggest_categorical('scheduler_type',\n",
        "                                                 ['cosine', 'step', 'exponential'])\n",
        "        label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.2)\n",
        "\n",
        "        trial_params = {\n",
        "            'lr': lr, 'weight_decay': weight_decay, 'dropout': dropout,\n",
        "            'hidden_dim_multiplier': hidden_dim_multiplier, 'augmentation_strength': augmentation_strength,\n",
        "            'batch_size': batch_size, 'optimizer_type': optimizer_type, 'scheduler_type': scheduler_type,\n",
        "            'label_smoothing': label_smoothing\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            print(f\"\\nTrial {trial.number} parameters:\")\n",
        "            for key, value in trial_params.items():\n",
        "                if key in ['lr', 'weight_decay']:\n",
        "                    print(f\"  {key}: {value:.4f}\")\n",
        "                elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                    print(f\"  {key}: {value:.1f}\")\n",
        "                else:\n",
        "                    print(f\"  {key}: {value}\")\n",
        "\n",
        "            temp_train_loader = DataLoader(\n",
        "                self.train_loader.dataset,\n",
        "                batch_size=batch_size,\n",
        "                sampler=self.train_loader.sampler\n",
        "            )\n",
        "            temp_val_loader = DataLoader(\n",
        "                self.val_loader.dataset,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=False\n",
        "            )\n",
        "\n",
        "            model = ModelFactory.create_model(\n",
        "                self.model_name,\n",
        "                dropout_rate=dropout,\n",
        "                hidden_dim_multiplier=hidden_dim_multiplier\n",
        "            )\n",
        "            model = model.to(Config.DEVICE)\n",
        "\n",
        "            if optimizer_type == 'adam':\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "            elif optimizer_type == 'adamw':\n",
        "                optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "            else:\n",
        "                optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                                    momentum=0.9, nesterov=True)\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "            if scheduler_type == 'cosine':\n",
        "                scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.OPTUNA_EPOCHS)\n",
        "            elif scheduler_type == 'step':\n",
        "                scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.7)\n",
        "            else:\n",
        "                scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "            best_val_acc = 0\n",
        "            patience_counter = 0\n",
        "\n",
        "            for epoch in range(Config.OPTUNA_EPOCHS):\n",
        "                self.batch_times = []\n",
        "                model.train()\n",
        "                train_correct = 0\n",
        "                train_total = 0\n",
        "                train_loss = 0\n",
        "\n",
        "                for batch_idx, (images, labels) in enumerate(temp_train_loader):\n",
        "                    if batch_idx > 15:\n",
        "                        break\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "\n",
        "                    batch_loss = loss.item()\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    train_total += labels.size(0)\n",
        "                    train_correct += (predicted == labels).sum().item()\n",
        "                    train_loss += batch_loss\n",
        "\n",
        "                    batch_acc = train_correct / train_total\n",
        "                    self._update_progress(batch_idx, batch_loss, batch_acc, trial_params, is_training=True)\n",
        "\n",
        "                model.eval()\n",
        "                val_correct = 0\n",
        "                val_total = 0\n",
        "                val_loss = 0\n",
        "                val_predictions = []\n",
        "                val_labels = []\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for batch_idx, (images, labels) in enumerate(temp_val_loader):\n",
        "                        if batch_idx > 8:\n",
        "                            break\n",
        "                        images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                        outputs = model(images)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        batch_loss = loss.item()\n",
        "                        val_loss += batch_loss\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "                        val_total += labels.size(0)\n",
        "                        val_correct += (predicted == labels).sum().item()\n",
        "                        val_predictions.extend(predicted.cpu().numpy())\n",
        "                        val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                        batch_acc = val_correct / val_total\n",
        "                        self._update_progress(batch_idx, batch_loss, batch_acc, trial_params, is_training=False)\n",
        "\n",
        "                train_acc = train_correct / train_total\n",
        "                val_acc = val_correct / val_total\n",
        "                val_f1 = f1_score(val_labels, val_predictions, average='macro')\n",
        "                scheduler.step()\n",
        "\n",
        "                print(f\"\\nEpoch {epoch+1}/{Config.OPTUNA_EPOCHS} Summary: \"\n",
        "                      f\"Train Loss: {train_loss/len(temp_train_loader):.6f}, \"\n",
        "                      f\"Train Acc: {train_acc:.4f}, Val Loss: {val_loss/len(temp_val_loader):.6f}, \"\n",
        "                      f\"Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "                if val_acc > best_val_acc:\n",
        "                    best_val_acc = val_acc\n",
        "                    patience_counter = 0\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "\n",
        "                if patience_counter >= 4:\n",
        "                    print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "                trial.report(val_acc, epoch)\n",
        "                if trial.should_prune():\n",
        "                    raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "            return best_val_acc\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nTrial failed: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "    def optimize(self):\n",
        "        print(f\"Optimizing hyperparameters for {self.model_name}...\")\n",
        "\n",
        "        if not OPTUNA_AVAILABLE:\n",
        "            return {\n",
        "                'lr': Config.LEARNING_RATE,\n",
        "                'dropout': 0.5,\n",
        "                'weight_decay': Config.WEIGHT_DECAY,\n",
        "                'hidden_dim_multiplier': 0.5,\n",
        "                'augmentation_strength': 'medium',\n",
        "                'batch_size': Config.BATCH_SIZE,\n",
        "                'optimizer_type': 'adamw',\n",
        "                'scheduler_type': 'cosine',\n",
        "                'label_smoothing': 0.1\n",
        "            }\n",
        "\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(self.objective, n_trials=Config.OPTUNA_TRIALS, timeout=1200)\n",
        "\n",
        "        best_params = study.best_trial.params\n",
        "        print(f\"\\nBest params for {self.model_name}:\")\n",
        "        for key, value in best_params.items():\n",
        "            if key in ['lr', 'weight_decay']:\n",
        "                print(f\"  {key}: {value:.4f}\")\n",
        "            elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                print(f\"  {key}: {value:.1f}\")\n",
        "            else:\n",
        "                print(f\"  {key}: {value}\")\n",
        "        print(f\"Best validation accuracy: {study.best_trial.value:.4f}\")\n",
        "\n",
        "        return best_params\n",
        "\n",
        "# ---\n",
        "# 8. MODEL TRAINING\n",
        "# =============================================================================\n",
        "# Purpose: Train individual models with optimized hyperparameters.\n",
        "\n",
        "class EnhancedModelTrainer:\n",
        "    def __init__(self, model, model_name, hyperparameters):\n",
        "        self.model = model.to(Config.DEVICE)\n",
        "        self.model_name = model_name\n",
        "        self.hyperparameters = hyperparameters\n",
        "        self.best_val_acc = 0.0\n",
        "        self.best_val_f1 = 0.0\n",
        "        self.patience_counter = 0\n",
        "        self.history = {\n",
        "            'train_loss': [], 'train_acc': [],\n",
        "            'val_loss': [], 'val_acc': [], 'val_f1': [],\n",
        "            'learning_rates': []\n",
        "        }\n",
        "        # Create model directory\n",
        "        os.makedirs(f\"{Config.OUTPUT_DIR}/models\", exist_ok=True)\n",
        "        self._setup_training_components()\n",
        "\n",
        "    def _setup_training_components(self):\n",
        "        lr = self.hyperparameters.get('lr', Config.LEARNING_RATE)\n",
        "        weight_decay = self.hyperparameters.get('weight_decay', Config.WEIGHT_DECAY)\n",
        "        optimizer_type = self.hyperparameters.get('optimizer_type', 'adamw')\n",
        "\n",
        "        if optimizer_type == 'adam':\n",
        "            self.optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        elif optimizer_type == 'adamw':\n",
        "            self.optimizer = optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        else:\n",
        "            self.optimizer = optim.SGD(self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                                     momentum=0.9, nesterov=True)\n",
        "\n",
        "        label_smoothing = self.hyperparameters.get('label_smoothing', 0.1)\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "        scheduler_type = self.hyperparameters.get('scheduler_type', 'cosine')\n",
        "        if scheduler_type == 'cosine':\n",
        "            self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "                self.optimizer, T_0=10, T_mult=2\n",
        "            )\n",
        "        elif scheduler_type == 'step':\n",
        "            self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.5)\n",
        "        else:\n",
        "            self.scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.95)\n",
        "\n",
        "    def train_epoch(self, train_loader, progress_tracker):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        batch_losses = []\n",
        "        batch_accuracies = []\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(images)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            batch_loss = loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            batch_total = labels.size(0)\n",
        "            batch_correct = (predicted == labels).sum().item()\n",
        "            batch_acc = batch_correct / batch_total\n",
        "\n",
        "            total_loss += batch_loss\n",
        "            total += batch_total\n",
        "            correct += batch_correct\n",
        "            batch_losses.append(batch_loss)\n",
        "            batch_accuracies.append(batch_acc)\n",
        "\n",
        "            progress_tracker.update_batch(batch_idx, batch_loss, batch_acc, is_training=True)\n",
        "\n",
        "        return total_loss / len(train_loader), correct / total\n",
        "\n",
        "    def validate_epoch(self, val_loader, progress_tracker):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (images, labels) in enumerate(val_loader):\n",
        "                images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                batch_loss = loss.item()\n",
        "                total_loss += batch_loss\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                batch_acc = (predicted == labels).float().mean().item()\n",
        "\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                progress_tracker.update_batch(batch_idx, batch_loss, batch_acc, is_training=False)\n",
        "\n",
        "        if not all_labels:\n",
        "            print(f\"Warning: No validation data processed for {self.model_name}\")\n",
        "            return float('inf'), 0.0, 0.0\n",
        "\n",
        "        accuracy = accuracy_score(all_labels, all_predictions)\n",
        "        f1 = f1_score(all_labels, all_predictions, average='macro')\n",
        "        return total_loss / len(val_loader), accuracy, f1\n",
        "\n",
        "    def train(self, train_loader, val_loader):\n",
        "        print(f\"Training {self.model_name} with hyperparameters:\")\n",
        "        for key, value in self.hyperparameters.items():\n",
        "            if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                print(f\"  {key}: {value:.4f}\")\n",
        "            else:\n",
        "                print(f\"  {key}: {value}\")\n",
        "\n",
        "        progress_tracker = TrainingProgressTracker(\n",
        "            self.model_name, Config.EPOCHS, len(train_loader)\n",
        "        )\n",
        "\n",
        "        for epoch in range(Config.EPOCHS):\n",
        "            progress_tracker.start_epoch(epoch)\n",
        "            train_loss, train_acc = self.train_epoch(train_loader, progress_tracker)\n",
        "            val_loss, val_acc, val_f1 = self.validate_epoch(val_loader, progress_tracker)\n",
        "            self.scheduler.step()\n",
        "            current_lr = self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "            self.history['val_f1'].append(val_f1)\n",
        "            self.history['learning_rates'].append(current_lr)\n",
        "\n",
        "            is_best = False\n",
        "            if val_f1 > self.best_val_f1:\n",
        "                self.best_val_f1 = val_f1\n",
        "                self.best_val_acc = val_acc\n",
        "                self.patience_counter = 0\n",
        "                is_best = True\n",
        "                torch.save(self.model.state_dict(),\n",
        "                          f\"{Config.OUTPUT_DIR}/models/{self.model_name}_best.pt\")\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "\n",
        "            progress_tracker.finish_epoch(\n",
        "                train_loss, train_acc, val_loss, val_acc, val_f1,\n",
        "                is_best=is_best, lr=current_lr\n",
        "            )\n",
        "\n",
        "            if self.patience_counter >= Config.PATIENCE:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        print(f\"History for {self.model_name}:\")\n",
        "        print(f\"  train_loss: {len(self.history['train_loss'])} entries\")\n",
        "        print(f\"  train_acc: {len(self.history['train_acc'])} entries\")\n",
        "        print(f\"  val_loss: {len(self.history['val_loss'])} entries\")\n",
        "        print(f\"  val_acc: {len(self.history['val_acc'])} entries\")\n",
        "        print(f\"  val_f1: {len(self.history['val_f1'])} entries\")\n",
        "\n",
        "        self.model.load_state_dict(\n",
        "            torch.load(f\"{Config.OUTPUT_DIR}/models/{self.model_name}_best.pt\")\n",
        "        )\n",
        "\n",
        "        print(f\"\\n‚úì {self.model_name} training completed!\")\n",
        "        print(f\"  Best Validation F1: {self.best_val_f1:.4f}\")\n",
        "        print(f\"  Best Validation Accuracy: {self.best_val_acc:.4f}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return self.history\n",
        "\n",
        "# ---\n",
        "# 9. ENSEMBLE METHODS\n",
        "# =============================================================================\n",
        "# Purpose: Implement ensemble methods (simple, weighted, confidence-based, learnable).\n",
        "\n",
        "class EnsembleManager:\n",
        "    def __init__(self, models_dict, val_data):\n",
        "        self.models = models_dict\n",
        "        self.X_val, self.y_val = val_data\n",
        "        self.model_predictions = self._get_predictions()\n",
        "        self.histories = {}\n",
        "\n",
        "    def _get_predictions(self):\n",
        "        print(\"Getting model predictions for ensemble...\")\n",
        "        predictions = {}\n",
        "\n",
        "        val_dataset = FishDataset(self.X_val, self.y_val, DataManager.get_transforms(False))\n",
        "        val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            model.eval()\n",
        "            all_preds = []\n",
        "            all_probs = []\n",
        "            all_losses = []\n",
        "            all_labels = []\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    outputs = model(images)\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    loss = criterion(outputs, labels).item()\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    all_preds.extend(predicted.cpu().numpy())\n",
        "                    all_probs.extend(probabilities.cpu().numpy())\n",
        "                    all_losses.append(loss)\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = correct / total\n",
        "            f1 = f1_score(self.y_val, all_preds, average='macro')\n",
        "            avg_loss = np.mean(all_losses)\n",
        "\n",
        "            predictions[name] = {\n",
        "                'predictions': np.array(all_preds),\n",
        "                'probabilities': np.array(all_probs),\n",
        "                'loss': avg_loss,\n",
        "                'accuracy': accuracy,\n",
        "                'f1': f1,\n",
        "                'true_labels': np.array(all_labels)\n",
        "            }\n",
        "\n",
        "            print(f\"  {name}: F1 = {f1:.4f}, Acc = {accuracy:.4f}, Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def simple_average_ensemble(self, model_combo):\n",
        "        selected_probs = [self.model_predictions[name]['probabilities'] for name in model_combo]\n",
        "        avg_probs = np.mean(selected_probs, axis=0)\n",
        "        predictions = np.argmax(avg_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'probabilities': avg_probs,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def weighted_average_ensemble(self, model_combo):\n",
        "        weights = []\n",
        "        selected_probs = []\n",
        "\n",
        "        for name in model_combo:\n",
        "            f1 = self.model_predictions[name]['f1']\n",
        "            weights.append(f1)\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        weights = np.array(weights) / np.sum(weights)\n",
        "        weighted_probs = np.average(selected_probs, axis=0, weights=weights)\n",
        "        predictions = np.argmax(weighted_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.average([self.model_predictions[name]['loss'] for name in model_combo], weights=weights)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'weights': weights,\n",
        "            'models': model_combo,\n",
        "            'probabilities': weighted_probs,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def confidence_based_ensemble(self, model_combo):\n",
        "        final_predictions = []\n",
        "        all_probs = []\n",
        "\n",
        "        for i in range(len(self.y_val)):\n",
        "            confidences = []\n",
        "            probs = []\n",
        "\n",
        "            for name in model_combo:\n",
        "                prob = self.model_predictions[name]['probabilities'][i]\n",
        "                confidence = np.max(prob)\n",
        "                confidences.append(confidence)\n",
        "                probs.append(prob)\n",
        "\n",
        "            confidences = np.array(confidences)\n",
        "            weights = confidences / np.sum(confidences) if np.sum(confidences) > 0 else np.ones(len(confidences)) / len(confidences)\n",
        "\n",
        "            final_prob = np.average(probs, axis=0, weights=weights)\n",
        "            final_predictions.append(np.argmax(final_prob))\n",
        "            all_probs.append(final_prob)\n",
        "\n",
        "        predictions = np.array(final_predictions)\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'probabilities': np.array(all_probs),\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def learnable_weighted_ensemble(self, model_combo, epochs=30):\n",
        "        print(f\"Training learnable weighted ensemble with {len(model_combo)} models...\")\n",
        "\n",
        "        selected_probs = []\n",
        "        for name in model_combo:\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        ensemble_input = np.stack(selected_probs, axis=1)\n",
        "\n",
        "        X_ensemble = torch.FloatTensor(ensemble_input).to(Config.DEVICE)\n",
        "        y_ensemble = torch.LongTensor(self.y_val).to(Config.DEVICE)\n",
        "\n",
        "        ensemble_model = LearnableWeightedEnsemble(\n",
        "            num_models=len(model_combo),\n",
        "            num_classes=Config.NUM_CLASSES\n",
        "        ).to(Config.DEVICE)\n",
        "\n",
        "        optimizer = optim.AdamW(ensemble_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "        history = {'train_loss': [], 'train_acc': [], 'val_f1': []}\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            ensemble_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions, weights = ensemble_model(X_ensemble)\n",
        "            loss = criterion(predictions, y_ensemble)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            accuracy = accuracy_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy())\n",
        "            f1 = f1_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy(), average='macro')\n",
        "\n",
        "            history['train_loss'].append(loss.item())\n",
        "            history['train_acc'].append(accuracy)\n",
        "            history['val_f1'].append(f1)\n",
        "\n",
        "            print(f\"Ensemble Epoch {epoch+1}/{epochs}: Loss = {loss.item():.4f}, \"\n",
        "                  f\"Acc = {accuracy:.4f}, F1 = {f1:.4f}\")\n",
        "\n",
        "            if loss.item() < best_loss:\n",
        "                best_loss = loss.item()\n",
        "                torch.save(ensemble_model.state_dict(), f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\")\n",
        "\n",
        "        ensemble_model.load_state_dict(torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\"))\n",
        "        ensemble_model.eval()\n",
        "        with torch.no_grad():\n",
        "            final_predictions, learned_weights = ensemble_model(X_ensemble)\n",
        "            predictions = final_predictions.argmax(dim=1).cpu().numpy()\n",
        "            probabilities = torch.softmax(final_predictions, dim=1).cpu().numpy()\n",
        "            avg_weights = learned_weights.mean(dim=0).cpu().numpy()\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        self.histories[f\"learnable_weighted_{'+'.join(model_combo)}\"] = history\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'learned_weights': avg_weights,\n",
        "            'probabilities': probabilities,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def test_ensemble_combinations(self):\n",
        "        print(\"Testing ensemble combinations...\")\n",
        "\n",
        "        model_names = list(self.models.keys())\n",
        "        all_results = {}\n",
        "        best_result = None\n",
        "        best_score = 0\n",
        "\n",
        "        for size in range(2, min(len(model_names) + 1, 5)):\n",
        "            print(f\"Testing {size}-model combinations...\")\n",
        "\n",
        "            for combo in list(combinations(model_names, size))[:5]:\n",
        "                combo_name = f\"combo_{size}_{'+'.join(combo)}\"\n",
        "\n",
        "                for method_name in Config.ENSEMBLE_METHODS:\n",
        "                    full_name = f\"{combo_name}_{method_name}\"\n",
        "\n",
        "                    try:\n",
        "                        if method_name == 'simple_average':\n",
        "                            result = self.simple_average_ensemble(combo)\n",
        "                        elif method_name == 'weighted_average':\n",
        "                            result = self.weighted_average_ensemble(combo)\n",
        "                        elif method_name == 'confidence_based':\n",
        "                            result = self.confidence_based_ensemble(combo)\n",
        "                        elif method_name == 'learnable_weighted':\n",
        "                            result = self.learnable_weighted_ensemble(combo)\n",
        "\n",
        "                        # Verify result contains required keys\n",
        "                        required_keys = ['accuracy', 'f1', 'loss', 'predictions', 'models', 'probabilities', 'true_labels']\n",
        "                        if not all(key in result for key in required_keys):\n",
        "                            missing = [key for key in required_keys if key not in result]\n",
        "                            print(f\"  {full_name}: Missing keys {missing}\")\n",
        "                            continue\n",
        "\n",
        "                        all_results[full_name] = result\n",
        "                        print(f\"  {full_name}: F1 = {result['f1']:.4f}, Acc = {result['accuracy']:.4f}, \"\n",
        "                              f\"Loss = {result['loss']:.4f}, True Labels Shape = {result['true_labels'].shape}\")\n",
        "\n",
        "                        if result['f1'] > best_score:\n",
        "                            best_score = result['f1']\n",
        "                            best_result = (full_name, result)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"  {full_name}: FAILED - {str(e)}\")\n",
        "\n",
        "        if best_result:\n",
        "            print(f\"\\n‚úì Best ensemble: {best_result[0]} (F1: {best_result[1]['f1']:.4f})\")\n",
        "        else:\n",
        "            print(\"\\nNo valid ensemble results generated.\")\n",
        "\n",
        "        return all_results, best_result\n",
        "\n",
        "# ---\n",
        "# 10. MODEL EVALUATION\n",
        "# =============================================================================\n",
        "# Purpose: Evaluate models on test data.\n",
        "\n",
        "class ModelEvaluator:\n",
        "    def evaluate_model(self, model, test_loader, model_name):\n",
        "        print(f\"Evaluating {model_name}...\")\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "        total_loss = 0\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels).item()\n",
        "                probabilities = torch.softmax(outputs, dim=1)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_probs.extend(probabilities.cpu().numpy())\n",
        "                total_loss += loss\n",
        "\n",
        "        if not all_labels:\n",
        "            print(f\"Warning: No test data processed for {model_name}\")\n",
        "            return {\n",
        "                'model_name': model_name,\n",
        "                'accuracy': 0.0,\n",
        "                'f1_macro': 0.0,\n",
        "                'f1_weighted': 0.0,\n",
        "                'precision_macro': 0.0,\n",
        "                'recall_macro': 0.0,\n",
        "                'f1_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "                'precision_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "                'recall_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "                'predictions': np.array([]),\n",
        "                'true_labels': np.array([]),\n",
        "                'probabilities': np.array([]),\n",
        "                'loss': float('inf')\n",
        "            }\n",
        "\n",
        "        accuracy = accuracy_score(all_labels, all_preds)\n",
        "        f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "        f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "        precision_macro = precision_score(all_labels, all_preds, average='macro')\n",
        "        recall_macro = recall_score(all_labels, all_preds, average='macro')\n",
        "        f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "        precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "        recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "        print(f\"{model_name} Evaluation: Acc = {accuracy:.4f}, F1 (Macro) = {f1_macro:.4f}, Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        return {\n",
        "            'model_name': model_name,\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_weighted': f1_weighted,\n",
        "            'precision_macro': precision_macro,\n",
        "            'recall_macro': recall_macro,\n",
        "            'f1_per_class': f1_per_class,\n",
        "            'precision_per_class': precision_per_class,\n",
        "            'recall_per_class': recall_per_class,\n",
        "            'predictions': np.array(all_preds),\n",
        "            'true_labels': np.array(all_labels),\n",
        "            'probabilities': np.array(all_probs),\n",
        "            'loss': avg_loss\n",
        "        }\n",
        "\n",
        "# ---\n",
        "# 11. ENHANCED VISUALIZATIONS\n",
        "# =============================================================================\n",
        "# Purpose: Generate visualizations for training history, ROC curves, confusion matrices, model comparisons, and XAI visualizations.\n",
        "\n",
        "class EnhancedVisualizations:\n",
        "    def __init__(self):\n",
        "        self.viz_dir = f\"{Config.OUTPUT_DIR}/visualizations\"\n",
        "        Path(self.viz_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def plot_training_history(self, histories, model_type='single'):\n",
        "        for model_name, history in histories.items():\n",
        "            print(f\"Plotting history for {model_name}:\")\n",
        "            print(f\"  train_loss: {len(history['train_loss'])} entries\")\n",
        "            print(f\"  train_acc: {len(history['train_acc'])} entries\")\n",
        "            print(f\"  val_loss: {len(history.get('val_loss', []))} entries\")\n",
        "            print(f\"  val_acc: {len(history.get('val_acc', []))} entries\")\n",
        "            print(f\"  val_f1: {len(history.get('val_f1', []))} entries\")\n",
        "\n",
        "            if not history['train_loss']:\n",
        "                print(f\"Skipping {model_name}: No training data available\")\n",
        "                continue\n",
        "\n",
        "            epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "            # Plot training loss\n",
        "            ax1.plot(epochs, history['train_loss'], label='Train Loss', color='blue')\n",
        "            if history.get('val_loss', []):\n",
        "                if len(history['val_loss']) == len(history['train_loss']):\n",
        "                    ax1.plot(epochs, history['val_loss'], label='Val Loss', color='orange')\n",
        "                else:\n",
        "                    print(f\"Warning: val_loss length ({len(history['val_loss'])}) does not match train_loss length ({len(history['train_loss'])}) for {model_name}\")\n",
        "            ax1.set_title(f'{model_name} - Loss vs Epoch')\n",
        "            ax1.set_xlabel('Epoch')\n",
        "            ax1.set_ylabel('Loss')\n",
        "            ax1.legend()\n",
        "            ax1.grid(True)\n",
        "\n",
        "            # Plot training accuracy\n",
        "            ax2.plot(epochs, history['train_acc'], label='Train Acc', color='green')\n",
        "            if history.get('val_acc', []):\n",
        "                if len(history['val_acc']) == len(history['train_acc']):\n",
        "                    ax2.plot(epochs, history['val_acc'], label='Val Acc', color='red')\n",
        "                else:\n",
        "                    print(f\"Warning: val_acc length ({len(history['val_acc'])}) does not match train_acc length ({len(history['train_acc'])}) for {model_name}\")\n",
        "            ax2.set_title(f'{model_name} - Accuracy vs Epoch')\n",
        "            ax2.set_xlabel('Epoch')\n",
        "            ax2.set_ylabel('Accuracy')\n",
        "            ax2.legend()\n",
        "            ax2.grid(True)\n",
        "\n",
        "            plt.suptitle(f'{model_type.capitalize()} Model: {model_name}', fontsize=16)\n",
        "            plt.tight_layout()\n",
        "            save_path = f\"{self.viz_dir}/{model_name}_training_history.png\"\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            print(f\"Training history plot saved: {save_path}\")\n",
        "\n",
        "    def plot_roc_curves(self, results, model_name):\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        if 'true_labels' not in results or 'probabilities' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'probabilities' in results for {model_name}\")\n",
        "            return\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            fpr, tpr, _ = roc_curve(np.array(results['true_labels']) == i, results['probabilities'][:, i])\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            ax.plot(fpr, tpr, label=f'Class {Config.CLASS_LABELS[i]} (AUC = {roc_auc:.2f})')\n",
        "        ax.plot([0, 1], [0, 1], 'k--')\n",
        "        ax.set_title(f'{model_name} - ROC Curve')\n",
        "        ax.set_xlabel('False Positive Rate')\n",
        "        ax.set_ylabel('True Positive Rate')\n",
        "        ax.legend()\n",
        "        ax.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def plot_confusion_matrix(self, results, model_name):\n",
        "        if 'true_labels' not in results or 'predictions' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'predictions' in results for {model_name}\")\n",
        "            return\n",
        "        cm = confusion_matrix(results['true_labels'], results['predictions'])\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "        sns.heatmap(cm_normalized, annot=cm, fmt='d', cmap='Blues',\n",
        "                    xticklabels=Config.CLASS_LABELS, yticklabels=Config.CLASS_LABELS,\n",
        "                    cbar_kws={'label': 'Normalized Count'})\n",
        "        ax.set_title(f'Confusion Matrix: {model_name}')\n",
        "        ax.set_xlabel('Predicted Label')\n",
        "        ax.set_ylabel('True Label')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.yticks(rotation=0)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_confusion_matrix.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(f\"Confusion matrix saved: {save_path}\")\n",
        "\n",
        "    def plot_model_comparison(self, single_results, ensemble_results):\n",
        "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        model_names = list(single_results.keys())\n",
        "        accuracies = [single_results[name]['accuracy'] for name in model_names]\n",
        "        f1_scores = [single_results[name]['f1_macro'] for name in model_names]\n",
        "        f1_weighted = [single_results[name]['f1_weighted'] for name in model_names]\n",
        "        losses = [single_results[name]['loss'] for name in model_names]\n",
        "\n",
        "        x = np.arange(len(model_names))\n",
        "        width = 0.2\n",
        "\n",
        "        ax1.bar(x - width*1.5, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "        ax1.bar(x - width/2, f1_scores, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "        ax1.bar(x + width/2, f1_weighted, width, label='F1 (Weighted)', alpha=0.8, color='lightgreen')\n",
        "        ax1.bar(x + width*1.5, losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "        ax1.set_xlabel('Models', fontweight='bold')\n",
        "        ax1.set_ylabel('Score', fontweight='bold')\n",
        "        ax1.set_title('Individual Model Performance', fontweight='bold', fontsize=14)\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, max(max(accuracies), max(f1_scores), max(f1_weighted), max(losses)) * 1.1)\n",
        "\n",
        "        if ensemble_results:\n",
        "            ensemble_items = list(ensemble_results.items())\n",
        "            ensemble_items.sort(key=lambda x: x[1]['f1'], reverse=True)\n",
        "            top_ensembles = ensemble_items[:10]\n",
        "\n",
        "            ensemble_names = [name.split('_')[-1] for name, _ in top_ensembles]\n",
        "            ensemble_f1s = [result['f1'] for _, result in top_ensembles]\n",
        "            ensemble_accs = [result['accuracy'] for _, result in top_ensembles]\n",
        "            ensemble_losses = [result['loss'] for _, result in top_ensembles]\n",
        "\n",
        "            x = np.arange(len(ensemble_names))\n",
        "            ax2.bar(x - width, ensemble_accs, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "            ax2.bar(x, ensemble_f1s, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "            ax2.bar(x + width, ensemble_losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "            ax2.set_xticks(x)\n",
        "            ax2.set_xticklabels([f\"{name}\" for name in ensemble_names], rotation=45, ha='right')\n",
        "            ax2.set_xlabel('Ensemble Methods', fontweight='bold')\n",
        "            ax2.set_ylabel('Score', fontweight='bold')\n",
        "            ax2.set_title('Top Ensemble Methods', fontweight='bold', fontsize=14)\n",
        "            ax2.legend()\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.set_ylim(0, max(max(ensemble_accs), max(ensemble_f1s), max(ensemble_losses)) * 1.1)\n",
        "\n",
        "        if single_results:\n",
        "            per_class_f1 = []\n",
        "            for model_name in model_names:\n",
        "                per_class_f1.append(single_results[model_name]['f1_per_class'])\n",
        "\n",
        "            per_class_f1 = np.array(per_class_f1)\n",
        "            im = ax3.imshow(per_class_f1, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "            ax3.set_xticks(range(len(Config.CLASS_LABELS)))\n",
        "            ax3.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right')\n",
        "            ax3.set_yticks(range(len(model_names)))\n",
        "            ax3.set_yticklabels(model_names)\n",
        "            ax3.set_title('Per-Class F1 Scores', fontweight='bold', fontsize=14)\n",
        "\n",
        "            cbar = plt.colorbar(im, ax=ax3)\n",
        "            cbar.set_label('F1 Score', rotation=270, labelpad=15)\n",
        "\n",
        "            for i in range(len(model_names)):\n",
        "                for j in range(len(Config.CLASS_LABELS)):\n",
        "                    ax3.text(j, i, f'{per_class_f1[i, j]:.2f}',\n",
        "                            ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
        "\n",
        "        if ensemble_results:\n",
        "            best_single_f1 = max(f1_scores)\n",
        "            best_single_name = model_names[f1_scores.index(best_single_f1)]\n",
        "            best_ensemble_f1 = max([result['f1'] for result in ensemble_results.values()])\n",
        "            best_ensemble_name = max(ensemble_results.items(), key=lambda x: x[1]['f1'])[0]\n",
        "\n",
        "            categories = ['Best Single\\nModel', 'Best Ensemble']\n",
        "            values = [best_single_f1, best_ensemble_f1]\n",
        "            colors = ['lightblue', 'gold']\n",
        "\n",
        "            bars = ax4.bar(categories, values, color=colors, alpha=0.8)\n",
        "            ax4.set_ylabel('F1 Score', fontweight='bold')\n",
        "            ax4.set_title('Single vs Ensemble Comparison', fontweight='bold', fontsize=14)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.set_ylim(0, 1)\n",
        "\n",
        "            for bar, value in zip(bars, values):\n",
        "                ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                        f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "            improvement = ((best_ensemble_f1 - best_single_f1) / best_single_f1) * 100\n",
        "            ax4.text(0.5, 0.5, f'Improvement:\\n{improvement:.2f}%',\n",
        "                    transform=ax4.transAxes, ha='center', va='center',\n",
        "                    fontsize=12, fontweight='bold',\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
        "\n",
        "            ax4.text(0, best_single_f1/2, best_single_name, ha='center', va='center',\n",
        "                    rotation=90, fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        save_path = f\"{self.viz_dir}/model_comparison.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(f\"Model comparison saved: {save_path}\")\n",
        "        return save_path\n",
        "\n",
        "    def plot_gradcam_lrp(self, models_dict, ensemble_results, test_loader, model_type='single'):\n",
        "        \"\"\"Generate and save Grad-CAM++ and LRP visualizations for single or ensemble models.\"\"\"\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "        save_dir = f\"{self.viz_dir}/{model_type}_xai\"\n",
        "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Get a small sample from test_loader\n",
        "        sample_images, sample_labels = next(iter(test_loader))\n",
        "        sample_images = sample_images[:5].to(Config.DEVICE)  # Limit to 5 images\n",
        "        sample_labels = sample_labels[:5].numpy()\n",
        "\n",
        "        if model_type == 'single':\n",
        "            for model_name, model in models_dict.items():\n",
        "                model.eval()\n",
        "                for idx, (image, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(image.unsqueeze(0))\n",
        "                        probabilities = torch.softmax(outputs, dim=1)\n",
        "                        predicted_class = outputs.argmax(dim=1).item()\n",
        "                        confidence = probabilities[0, predicted_class].item()\n",
        "                        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                    try:\n",
        "                        # Grad-CAM++\n",
        "                        gradcam_img, gradcam_heatmap = xai_visualizer.grad_cam_plus_plus(model, image, predicted_class)\n",
        "                        # LRP (using integrated gradients)\n",
        "                        lrp_img, lrp_heatmap = xai_visualizer.lrp(model, image, predicted_class)\n",
        "\n",
        "                        # Plot and save\n",
        "                        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "                        image_np = image.permute(1, 2, 0).cpu().numpy() * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                        image_np = np.clip(image_np, 0, 1)\n",
        "                        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                        ax1.imshow(image_np)\n",
        "                        ax1.set_title(f'Original Image\\nTrue: {Config.CLASS_LABELS[true_label]}\\nPredicted: {predicted_label} ({confidence:.2%})')\n",
        "                        ax1.axis('off')\n",
        "\n",
        "                        ax2.imshow(gradcam_img)\n",
        "                        ax2.set_title(f'{model_name} Grad-CAM++')\n",
        "                        ax2.axis('off')\n",
        "\n",
        "                        ax3.imshow(lrp_img)\n",
        "                        ax3.set_title(f'{model_name} Integrated Gradients')\n",
        "                        ax3.axis('off')\n",
        "\n",
        "                        plt.suptitle(f'{model_name} XAI Visualizations - Image {idx+1}', fontsize=16)\n",
        "                        save_path = f\"{save_dir}/{model_name}_image_{idx+1}_xai.png\"\n",
        "                        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "                        plt.close()\n",
        "                        print(f\"XAI visualization saved: {save_path}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error generating XAI for {model_name}, image {idx+1}: {e}\")\n",
        "                        continue\n",
        "\n",
        "        elif model_type == 'ensemble' and ensemble_results:\n",
        "            for ensemble_name, result in list(ensemble_results.items())[:5]:  # Limit to top 5 ensembles\n",
        "                model_combo = result['models']\n",
        "                for idx, (image, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
        "                    try:\n",
        "                        gradcam_heatmaps = []\n",
        "                        lrp_heatmaps = []\n",
        "                        model_predictions = []\n",
        "\n",
        "                        for model_name in model_combo:\n",
        "                            model = models_dict[model_name]\n",
        "                            model.eval()\n",
        "                            with torch.no_grad():\n",
        "                                outputs = model(image.unsqueeze(0))\n",
        "                                probabilities = torch.softmax(outputs, dim=1)\n",
        "                                model_predictions.append(probabilities.cpu().numpy()[0])\n",
        "\n",
        "                            predicted_class = np.argmax(probabilities.cpu().numpy()[0])\n",
        "                            gradcam_img, gradcam_heatmap = xai_visualizer.grad_cam_plus_plus(model, image, predicted_class)\n",
        "                            lrp_img, lrp_heatmap = xai_visualizer.lrp(model, image, predicted_class)\n",
        "\n",
        "                            # Extract heatmap values for averaging\n",
        "                            gradcam_heatmaps.append(cv2.cvtColor(gradcam_heatmap, cv2.COLOR_BGR2RGB))\n",
        "                            lrp_heatmaps.append(cv2.cvtColor(lrp_heatmap, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "                        # Average heatmaps for ensemble\n",
        "                        avg_gradcam = np.mean(gradcam_heatmaps, axis=0).astype(np.uint8)\n",
        "                        avg_lrp = np.mean(lrp_heatmaps, axis=0).astype(np.uint8)\n",
        "\n",
        "                        # Ensemble prediction\n",
        "                        final_probs = np.mean(model_predictions, axis=0)  # Simple average for visualization\n",
        "                        predicted_class = np.argmax(final_probs)\n",
        "                        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "                        confidence = final_probs[predicted_class]\n",
        "\n",
        "                        image_np = image.permute(1, 2, 0).cpu().numpy() * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                        image_np = np.clip(image_np, 0, 1)\n",
        "                        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                        superimposed_gradcam = cv2.addWeighted(image_np, 0.6, avg_gradcam, 0.4, 0)\n",
        "                        superimposed_lrp = cv2.addWeighted(image_np, 0.6, avg_lrp, 0.4, 0)\n",
        "\n",
        "                        # Plot and save\n",
        "                        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "                        ax1.imshow(image_np)\n",
        "                        ax1.set_title(f'Original Image\\nTrue: {Config.CLASS_LABELS[true_label]}\\nPredicted: {predicted_label} ({confidence:.2%})')\n",
        "                        ax1.axis('off')\n",
        "\n",
        "                        ax2.imshow(superimposed_gradcam)\n",
        "                        ax2.set_title(f'{ensemble_name} Grad-CAM++')\n",
        "                        ax2.axis('off')\n",
        "\n",
        "                        ax3.imshow(superimposed_lrp)\n",
        "                        ax3.set_title(f'{ensemble_name} Integrated Gradients')\n",
        "                        ax3.axis('off')\n",
        "\n",
        "                        plt.suptitle(f'Ensemble ({ensemble_name}) XAI Visualizations - Image {idx+1}', fontsize=16)\n",
        "                        save_path = f\"{save_dir}/{ensemble_name}_image_{idx+1}_xai.png\"\n",
        "                        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "                        plt.close()\n",
        "                        print(f\"Ensemble XAI visualization saved: {save_path}\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error generating ensemble XAI for {ensemble_name}, image {idx+1}: {e}\")\n",
        "                        continue\n",
        "\n",
        "    def plot_comparative_xai(self, models_dict, ensemble_results, test_loader, max_images=3):\n",
        "        \"\"\"Generate comparative XAI visualizations across all models for the same images.\"\"\"\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "        save_dir = f\"{self.viz_dir}/comparative_xai\"\n",
        "        Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "        # Get a small sample from test_loader\n",
        "        sample_images, sample_labels = next(iter(test_loader))\n",
        "        sample_images = sample_images[:max_images].to(Config.DEVICE)\n",
        "        sample_labels = sample_labels[:max_images].numpy()\n",
        "\n",
        "        for idx, (image, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
        "            try:\n",
        "                # Prepare figure for comparative visualization\n",
        "                num_models = len(models_dict)\n",
        "                fig, axes = plt.subplots(num_models, 3, figsize=(15, 5 * num_models), squeeze=False)\n",
        "\n",
        "                image_np = image.permute(1, 2, 0).cpu().numpy() * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                row_idx = 0\n",
        "                # Single models\n",
        "                for model_name, model in models_dict.items():\n",
        "                    try:\n",
        "                        model.eval()\n",
        "                        with torch.no_grad():\n",
        "                            outputs = model(image.unsqueeze(0))\n",
        "                            probabilities = torch.softmax(outputs, dim=1)\n",
        "                            predicted_class = outputs.argmax(dim=1).item()\n",
        "                            confidence = probabilities[0, predicted_class].item()\n",
        "                            predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                        gradcam_img, gradcam_heatmap = xai_visualizer.grad_cam_plus_plus(model, image, predicted_class)\n",
        "                        lrp_img, lrp_heatmap = xai_visualizer.lrp(model, image, predicted_class)\n",
        "\n",
        "                        # Plot original image, Grad-CAM++, and LRP\n",
        "                        axes[row_idx, 0].imshow(image_np)\n",
        "                        axes[row_idx, 0].set_title(f'Original Image\\nTrue: {Config.CLASS_LABELS[true_label]}\\n{model_name}: {predicted_label} ({confidence:.2%})')\n",
        "                        axes[row_idx, 0].axis('off')\n",
        "\n",
        "                        axes[row_idx, 1].imshow(gradcam_img)\n",
        "                        axes[row_idx, 1].set_title(f'{model_name} Grad-CAM++')\n",
        "                        axes[row_idx, 1].axis('off')\n",
        "\n",
        "                        axes[row_idx, 2].imshow(lrp_img)\n",
        "                        axes[row_idx, 2].set_title(f'{model_name} Integrated Gradients')\n",
        "                        axes[row_idx, 2].axis('off')\n",
        "\n",
        "                        row_idx += 1\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error in comparative XAI for {model_name}, image {idx+1}: {e}\")\n",
        "                        continue\n",
        "\n",
        "                plt.suptitle(f'Comparative XAI Visualizations - Image {idx+1}', fontsize=16)\n",
        "                plt.tight_layout()\n",
        "                save_path = f\"{save_dir}/comparative_xai_image_{idx+1}.png\"\n",
        "                plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "                plt.close()\n",
        "                print(f\"Comparative XAI visualization saved: {save_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in comparative XAI for image {idx+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "# ---\n",
        "# 12. FIXED XAI VISUALIZATIONS\n",
        "# =============================================================================\n",
        "# Purpose: Implement corrected Grad-CAM++ and LRP for visualizing important regions in images.\n",
        "\n",
        "class XAIVisualizer:\n",
        "    @staticmethod\n",
        "    def grad_cam_plus_plus(model, image, target_class):\n",
        "        \"\"\"Implement Grad-CAM++ for visualizing important image regions.\"\"\"\n",
        "        model.eval()\n",
        "\n",
        "        # Find the last convolutional layer\n",
        "        target_layer = None\n",
        "        for name, module in reversed(list(model.named_modules())):\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                target_layer = module\n",
        "                break\n",
        "\n",
        "        if target_layer is None:\n",
        "            raise ValueError(\"No convolutional layer found in the model\")\n",
        "\n",
        "        # Hook to capture gradients and activations\n",
        "        gradients = []\n",
        "        activations = []\n",
        "\n",
        "        def forward_hook(module, input, output):\n",
        "            activations.append(output)\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            gradients.append(grad_output[0])\n",
        "\n",
        "        # Register hooks\n",
        "        forward_handle = target_layer.register_forward_hook(forward_hook)\n",
        "        backward_handle = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "        try:\n",
        "            # Forward pass\n",
        "            image_tensor = image.unsqueeze(0).requires_grad_(True)\n",
        "            output = model(image_tensor)\n",
        "\n",
        "            # Backward pass\n",
        "            model.zero_grad()\n",
        "            score = output[0, target_class]\n",
        "            score.backward()\n",
        "\n",
        "            # Get gradients and activations\n",
        "            if not gradients or not activations:\n",
        "                raise ValueError(\"No gradients or activations captured\")\n",
        "\n",
        "            grad = gradients[0]  # Shape: (1, C, H, W)\n",
        "            act = activations[0]  # Shape: (1, C, H, W)\n",
        "\n",
        "            # Grad-CAM++ calculations\n",
        "            alpha_num = grad.pow(2)\n",
        "            alpha_denom = 2.0 * grad.pow(2) + (act * grad.pow(3)).sum(dim=(2, 3), keepdim=True)\n",
        "            alpha_denom = torch.where(alpha_denom != 0, alpha_denom, torch.ones_like(alpha_denom))\n",
        "            alpha = alpha_num / alpha_denom\n",
        "\n",
        "            weights = (alpha * F.relu(grad)).sum(dim=(2, 3))  # Shape: (1, C)\n",
        "            cam = (weights.unsqueeze(-1).unsqueeze(-1) * act).sum(dim=1, keepdim=True)  # Shape: (1, 1, H, W)\n",
        "            cam = F.relu(cam)\n",
        "\n",
        "            # Normalize\n",
        "            cam = cam - cam.min()\n",
        "            cam = cam / (cam.max() + 1e-8)\n",
        "\n",
        "            # Resize to input image size\n",
        "            cam = F.interpolate(cam, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "            cam = cam.squeeze().cpu().numpy()\n",
        "\n",
        "            # Apply colormap\n",
        "            cam = (cam * 255).astype(np.uint8)\n",
        "            heatmap = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
        "\n",
        "            # Convert original image for visualization\n",
        "            image_np = image.permute(1, 2, 0).cpu().numpy()\n",
        "            image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "            image_np = np.clip(image_np, 0, 1)\n",
        "            image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "            # Superimpose heatmap\n",
        "            superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "        finally:\n",
        "            # Remove hooks\n",
        "            forward_handle.remove()\n",
        "            backward_handle.remove()\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "    @staticmethod\n",
        "    def lrp(model, image, target_class):\n",
        "        \"\"\"Simplified LRP implementation using integrated gradients approach.\"\"\"\n",
        "        model.eval()\n",
        "\n",
        "        # Create baseline (black image)\n",
        "        baseline = torch.zeros_like(image)\n",
        "\n",
        "        # Generate path from baseline to image\n",
        "        num_steps = 50\n",
        "        alphas = torch.linspace(0, 1, num_steps).to(image.device)\n",
        "\n",
        "        gradients = []\n",
        "        for alpha in alphas:\n",
        "            interpolated = baseline + alpha * (image - baseline)\n",
        "            interpolated = interpolated.unsqueeze(0).requires_grad_(True)\n",
        "\n",
        "            output = model(interpolated)\n",
        "            score = output[0, target_class]\n",
        "\n",
        "            model.zero_grad()\n",
        "            score.backward()\n",
        "\n",
        "            gradients.append(interpolated.grad.clone())\n",
        "\n",
        "        # Average gradients\n",
        "        avg_gradients = torch.stack(gradients).mean(dim=0).squeeze(0)\n",
        "\n",
        "        # Compute integrated gradients\n",
        "        integrated_gradients = (image - baseline) * avg_gradients\n",
        "\n",
        "        # Sum across color channels\n",
        "        relevance = integrated_gradients.abs().sum(dim=0).cpu().numpy()\n",
        "\n",
        "        # Normalize\n",
        "        relevance = relevance / (relevance.max() + 1e-8)\n",
        "\n",
        "        # Apply colormap\n",
        "        relevance = (relevance * 255).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(relevance, cv2.COLORMAP_JET)\n",
        "\n",
        "        # Convert original image for visualization\n",
        "        image_np = image.permute(1, 2, 0).cpu().numpy()\n",
        "        image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "        # Superimpose heatmap\n",
        "        superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "\n",
        "# ---\n",
        "# 13. MAIN EXECUTION\n",
        "# =============================================================================\n",
        "# Purpose: Orchestrate the entire pipeline: data loading, model training, ensemble creation, evaluation, and visualization.\n",
        "\n",
        "def main():\n",
        "    print(\"Starting Fish Species Classification Pipeline...\")\n",
        "    print(\"=\"*70)\n",
        "    setup_environment()\n",
        "\n",
        "    # Load and balance data\n",
        "    X, Y = DataManager.load_and_balance_data()\n",
        "    train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(X, Y)\n",
        "\n",
        "    # Train individual models\n",
        "    single_models = {}\n",
        "    single_results = {}\n",
        "    histories = {}\n",
        "    evaluator = ModelEvaluator()\n",
        "    visualizer = EnhancedVisualizations()\n",
        "\n",
        "    for model_name in Config.MODELS:\n",
        "        print(f\"\\nTraining {model_name}...\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        # Optimize hyperparameters\n",
        "        optimizer = ExpandedHyperparameterOptimizer(model_name, train_loader, val_loader)\n",
        "        best_params = optimizer.optimize()\n",
        "\n",
        "        # Create and train model\n",
        "        model = ModelFactory.create_model(\n",
        "            model_name,\n",
        "            dropout_rate=best_params.get('dropout', 0.5),\n",
        "            hidden_dim_multiplier=best_params.get('hidden_dim_multiplier', 0.5)\n",
        "        )\n",
        "        trainer = EnhancedModelTrainer(model, model_name, best_params)\n",
        "        history = trainer.train(train_loader, val_loader)\n",
        "        histories[model_name] = history\n",
        "        single_models[model_name] = model\n",
        "\n",
        "        # Evaluate model\n",
        "        result = evaluator.evaluate_model(model, test_loader, model_name)\n",
        "        single_results[model_name] = result\n",
        "\n",
        "        # Plot ROC and confusion matrix\n",
        "        visualizer.plot_roc_curves(result, model_name)\n",
        "        visualizer.plot_confusion_matrix(result, model_name)\n",
        "\n",
        "    # Plot training history for single models\n",
        "    visualizer.plot_training_history(histories, model_type='single')\n",
        "\n",
        "    # Create and evaluate ensembles\n",
        "    ensemble_manager = EnsembleManager(single_models, val_data)\n",
        "    ensemble_results, best_ensemble = ensemble_manager.test_ensemble_combinations()\n",
        "\n",
        "    # Evaluate best ensemble on test set\n",
        "    if best_ensemble:\n",
        "        ensemble_name, ensemble_result = best_ensemble\n",
        "        ensemble_models = ensemble_result['models']\n",
        "        ensemble_method = ensemble_name.split('_')[-1]\n",
        "        print(f\"\\nEvaluating best ensemble ({ensemble_name}) on test set...\")\n",
        "\n",
        "        test_dataset = FishDataset(test_data[0], test_data[1], DataManager.get_transforms(False))\n",
        "        test_loader = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        if ensemble_method == 'learnable_weighted':\n",
        "            ensemble_model = LearnableWeightedEnsemble(\n",
        "                num_models=len(ensemble_models),\n",
        "                num_classes=Config.NUM_CLASSES\n",
        "            ).to(Config.DEVICE)\n",
        "            ensemble_model.load_state_dict(\n",
        "                torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(ensemble_models)}.pt\")\n",
        "            )\n",
        "            ensemble_model.eval()\n",
        "\n",
        "            all_preds = []\n",
        "            all_probs = []\n",
        "            all_labels = []\n",
        "            total_loss = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in test_loader:\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    model_probs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        model = single_models[model_name]\n",
        "                        outputs = model(images)\n",
        "                        probs = torch.softmax(outputs, dim=1)\n",
        "                        model_probs.append(probs)\n",
        "                    model_probs = torch.stack(model_probs, dim=1)\n",
        "                    outputs, _ = ensemble_model(model_probs)\n",
        "                    loss = criterion(outputs, labels).item()\n",
        "                    total_loss += loss\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    all_preds.extend(predicted.cpu().numpy())\n",
        "                    all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = accuracy_score(all_labels, all_preds)\n",
        "            f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "            avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "            ensemble_results[ensemble_name]['test_accuracy'] = accuracy\n",
        "            ensemble_results[ensemble_name]['test_f1'] = f1\n",
        "            ensemble_results[ensemble_name]['test_loss'] = avg_loss\n",
        "            ensemble_results[ensemble_name]['test_predictions'] = np.array(all_preds)\n",
        "            ensemble_results[ensemble_name]['test_probabilities'] = np.array(all_probs)\n",
        "            ensemble_results[ensemble_name]['test_true_labels'] = np.array(all_labels)\n",
        "\n",
        "            print(f\"Best Ensemble ({ensemble_name}) Test Results:\")\n",
        "            print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "            print(f\"  F1 Score (Macro): {f1:.4f}\")\n",
        "            print(f\"  Loss: {avg_loss:.4f}\")\n",
        "\n",
        "            visualizer.plot_roc_curves(ensemble_results[ensemble_name], ensemble_name)\n",
        "            visualizer.plot_confusion_matrix(ensemble_results[ensemble_name], ensemble_name)\n",
        "\n",
        "    # Plot model comparison\n",
        "    visualizer.plot_model_comparison(single_results, ensemble_results)\n",
        "\n",
        "    # Generate XAI visualizations\n",
        "    visualizer.plot_gradcam_lrp(single_models, ensemble_results, test_loader, model_type='single')\n",
        "    visualizer.plot_gradcam_lrp(single_models, ensemble_results, test_loader, model_type='ensemble')\n",
        "    visualizer.plot_comparative_xai(single_models, ensemble_results, test_loader)\n",
        "\n",
        "    # Save results\n",
        "    results = {\n",
        "        'single_results': {k: {kk: vv.tolist() if isinstance(vv, np.ndarray) else vv\n",
        "                              for kk, vv in v.items()} for k, v in single_results.items()},\n",
        "        'ensemble_results': {k: {kk: vv.tolist() if isinstance(vv, np.ndarray) else vv\n",
        "                                for kk, vv in v.items()} for k, v in ensemble_results.items()},\n",
        "        'best_ensemble': best_ensemble[0] if best_ensemble else None,\n",
        "        'best_ensemble_f1': best_ensemble[1]['f1'] if best_ensemble else None\n",
        "    }\n",
        "    with open(f\"{Config.OUTPUT_DIR}/results.json\", 'w') as f:\n",
        "        json.dump(results, f, indent=4)\n",
        "    print(f\"Results saved to {Config.OUTPUT_DIR}/results.json\")\n",
        "\n",
        "    # # REAL-WORLD TESTING (Commented out as requested)\n",
        "    # # =============================================================================\n",
        "    # # Purpose: Test the model on new, unseen images from a real-world dataset.\n",
        "    # print(\"\\nReal-World Testing (Commented Out)\")\n",
        "    # print(\"-\"*50)\n",
        "    # # real_world_images = load_real_world_data()  # Placeholder for loading real-world data\n",
        "    # # real_world_predictions = []\n",
        "    # # for image in real_world_images:\n",
        "    # #     processed_image = preprocess_real_world_image(image)\n",
        "    # #     with torch.no_grad():\n",
        "    # #         output = best_model(processed_image.to(Config.DEVICE))\n",
        "    # #         prediction = torch.argmax(output, dim=1).cpu().numpy()\n",
        "    # #         real_world_predictions.append(prediction)\n",
        "    # # save_real_world_results(real_world_predictions)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "tTKJCbvOdVsX",
        "outputId": "a4d26dba-7c7e-406f-9b43-747d046dd18a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "tTKJCbvOdVsX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Fish Species Classification Pipeline...\n",
            "======================================================================\n",
            "Using device: cuda\n",
            "PyTorch version: 2.8.0+cu126\n",
            "----------------------------------------------------------------------\n",
            "Loading and preprocessing data...\n",
            "Original data shape: (8407, 3, 224, 224)\n",
            "Original class distribution: [3000 1185 2899  370  953]\n",
            "Applying SMOTE for class balancing...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd48bb6",
      "metadata": {
        "id": "cdd48bb6"
      },
      "source": [
        "#End"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}