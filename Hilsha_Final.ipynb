{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran012x/Transfer-Models/blob/main/Hilsha_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training.."
      ],
      "metadata": {
        "id": "k1SaijPsU_az"
      },
      "id": "k1SaijPsU_az"
    },
    {
      "cell_type": "code",
      "source": [
        "#1. IMPORTS AND INITIAL SETUP\n",
        "# ================================================================================================================================\n",
        "# Purpose: Import all required libraries and set up warnings to suppress unnecessary messages.\n",
        "\n",
        "# # 1️⃣ Uninstall all broken/conflicting packages\n",
        "# !pip uninstall -y numpy pandas matplotlib seaborn opencv-python-headless opencv-contrib-python -q\n",
        "\n",
        "# # 2️⃣ Remove corrupted pandas folder\n",
        "# !rm -rf /usr/local/lib/python3.12/dist-packages/~andas* -q\n",
        "\n",
        "# # 3️⃣ Install compatible versions\n",
        "# !pip install numpy==1.26.4 pandas==2.2.2 matplotlib seaborn opencv-python-headless opencv-contrib-python -q\n",
        "\n",
        "# # 4️⃣ Restart runtime after this!\n",
        "\n",
        "\n",
        "# # 2. Install latest compatible versions for Python 3.12\n",
        "# !pip install --upgrade pip -q\n",
        "\n",
        "\n",
        "import warnings\n",
        "#For DeprecationWarning / FutureWarning specifically:\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
        "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
        "# Hide all pip warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "\n",
        "\n",
        "!pip install pytorch-gradcam optuna captum -q  # Uncomment if running in a new environment\n",
        "!pip install torchmetrics==0.11.4 -q # or whatever version you need\n",
        "# # !!pip install --upgrade --force-reinstall numpy seaborn matplotlib -q\n",
        "\n",
        "\n",
        "import sys\n",
        "import numpy\n",
        "import pandas\n",
        "import seaborn as sns\n",
        "\n",
        "print(f\"python_version: {sys.version.split()[0]}\")\n",
        "print(f\"numpy_version: {numpy.__version__}\")\n",
        "print(f\"pandas_version: {pandas.__version__}\")\n",
        "print(f\"seaborn_version: {sns.__version__}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "# !pip list | grep -E \"numpy|seaborn|matplotlib|pandas\"\n",
        "# !pip uninstall -y numpy seaborn matplotlib\n",
        "# !pip install numpy seaborn matplotlib\n",
        "\n",
        "\n",
        "\n",
        "# !pip install captum  -q  #> /dev/null 2>&1\n",
        "# !pip install --upgrade captum optuna\n",
        "# Install missing libraries in Colab\n",
        "# !pip install optuna torchmetrics captum -q\n",
        "# !pip install --upgrade --force-reinstall numpy pandas\n",
        "# !pip install --upgrade --force-reinstall numpy pandas scipy scikit-learn\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive_path = '/content/drive'\n",
        "\n",
        "if os.path.exists(drive_path) and os.path.ismount(drive_path):\n",
        "    print(\"Google Drive is already connected ✅\")\n",
        "else:\n",
        "    drive.mount(drive_path)\n",
        "    print(\"Google Drive connection done ✅\")\n",
        "\n",
        "\n",
        "\n",
        "# # Upload a file\n",
        "# uploaded = files.upload()\n",
        "# # Get the file name\n",
        "# file_name = list(uploaded.keys())[0]\n",
        "# print(f\"Uploaded file: {file_name}\")\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# # with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_224_11k.zip', 'r') as zip_ref:\n",
        "# #     zip_ref.extractall('')\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Standard Library\n",
        "# ============================================================\n",
        "import os\n",
        "import sys\n",
        "import gc\n",
        "import time\n",
        "import json\n",
        "import logging\n",
        "import random\n",
        "import warnings\n",
        "import subprocess\n",
        "import threading\n",
        "import traceback\n",
        "from pathlib import Path\n",
        "from itertools import combinations\n",
        "from datetime import datetime, timedelta\n",
        "import zipfile\n",
        "import threading\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# ============================================================\n",
        "# Data Handling & Utilities\n",
        "# ============================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================\n",
        "# Visualization\n",
        "# ============================================================\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# ============================================================\n",
        "# System & Resource Monitoring\n",
        "# ============================================================\n",
        "import psutil\n",
        "import pynvml\n",
        "\n",
        "# ============================================================\n",
        "# Machine Learning\n",
        "# ============================================================\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, f1_score, accuracy_score,\n",
        "    precision_score, recall_score, roc_curve, auc\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Imbalanced data handling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ============================================================\n",
        "# Deep Learning - PyTorch\n",
        "# ============================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, SubsetRandomSampler\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# ============================================================\n",
        "# Augmentation\n",
        "# ============================================================\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Explainable AI (XAI)\n",
        "# ============================================================\n",
        "\n",
        "import torch.autograd as autograd\n",
        "from captum.attr import LRP\n",
        "\n",
        "# Optuna\n",
        "import optuna\n",
        "import optuna.logging\n",
        "\n",
        "\n",
        "# Compute metrics on GPU\n",
        "# import torchmetrics.functional as tmf\n",
        "\n",
        "# ============================================================\n",
        "# Hyperparameter Optimization\n",
        "# ============================================================\n",
        "try:\n",
        "    OPTUNA_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPTUNA_AVAILABLE = False\n",
        "    print(\"Warning: Optuna not available. Using default hyperparameters.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 2. CONFIGURATION\n",
        "# ================================================================================================================================\n",
        "# Purpose: Define configuration settings and initialize the environment.\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration settings\"\"\"\n",
        "    # Paths - UPDATE THESE TO YOUR ACTUAL PATHS\n",
        "    DATA_FILE = '/content/drive/MyDrive/Hilsha/X_data.npy'\n",
        "    LABELS_FILE = '/content/drive/MyDrive/Hilsha/Y_labels.npy'\n",
        "    OUTPUT_DIR = './fish_classification_results'\n",
        "\n",
        "    # Dataset parameters\n",
        "    NUM_CLASSES = 5\n",
        "    CLASS_LABELS = ['Ilish', 'Chandana', 'Sardin', 'Sardinella', 'Punctatus']\n",
        "    INPUT_SIZE = 224\n",
        "\n",
        "    # Training parameters\n",
        "    BATCH_SIZE = 32 #Will Change Dynamically\n",
        "    DATALOADER_NUM_WORKERS = 1 #Will Change Dynamically\n",
        "    # Dynamically adjust batch size and workers\n",
        "    EPOCHS = 15\n",
        "    PIN_MEMORY = True\n",
        "    USE_MIXED_PRECISION = True #True\n",
        "    COMPILE_MODEL = True\n",
        "    PATIENCE = 4\n",
        "    LEARNING_RATE = 1e-5\n",
        "    WEIGHT_DECAY = 1e-4\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    OPTUNA_TRIALS = 12\n",
        "    OPTUNA_EPOCHS = 7\n",
        "\n",
        "    # Models to train\n",
        "    MODELS = ['resnet50','efficientnet_b0','mobilenet_v3_large','vgg16', 'densenet121']\n",
        "\n",
        "    # Ensemble methods\n",
        "    ENSEMBLE_METHODS = ['simple_average', 'weighted_average', 'confidence_based', 'learnable_weighted']\n",
        "\n",
        "    # Device\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    SEED = 42\n",
        "\n",
        "\n",
        "\n",
        "# def get_available_cpu_memory():\n",
        "#     \"\"\"Get available CPU memory in GB.\"\"\"\n",
        "#     mem = psutil.virtual_memory()\n",
        "#     return mem.available / 1024**3  # Convert bytes to GB\n",
        "\n",
        "# def get_available_gpu_memory():\n",
        "#     \"\"\"Get available GPU memory in GB.\"\"\"\n",
        "#     pynvml.nvmlInit()\n",
        "#     handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "#     mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
        "#     return mem_info.free / 1024**3  # Convert bytes to GB\n",
        "\n",
        "# def adjust_batch_size_and_workers(base_batch_size, base_num_workers):\n",
        "#     gpu_memory = get_available_gpu_memory()\n",
        "#     print(f\"GPU memory available: {gpu_memory:.2f} GB\")\n",
        "\n",
        "#     # Prioritize GPU memory for batch size\n",
        "#     if gpu_memory > 24:  # High-end GPU\n",
        "#         batch_size = base_batch_size * 4\n",
        "#         num_workers = min(8, psutil.cpu_count())  # Use more workers for high GPU memory\n",
        "#     elif gpu_memory > 12:  # Mid-range GPU\n",
        "#         batch_size = base_batch_size * 2\n",
        "#         num_workers = min(4, psutil.cpu_count())  # Moderate workers\n",
        "#     elif gpu_memory > 6:  # Lower-end GPU\n",
        "#         batch_size = base_batch_size\n",
        "#         num_workers = min(2, psutil.cpu_count())  # Minimal workers\n",
        "#     else:  # Very low GPU memory\n",
        "#         batch_size = max(8, base_batch_size // 2)\n",
        "#         num_workers = 0  # Disable workers to minimize CPU load\n",
        "\n",
        "    # if batch_size is None:\n",
        "    # if torch.cuda.is_available():\n",
        "    #     gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "    #     if gpu_memory_gb >= 24:\n",
        "    #         batch_size = 128\n",
        "    #     elif gpu_memory_gb >= 12:\n",
        "    #         batch_size = 96\n",
        "    #     elif gpu_memory_gb >= 8:\n",
        "    #         batch_size = 64\n",
        "    #     else:\n",
        "    #         batch_size = 48\n",
        "    # else:\n",
        "    #     batch_size = Config.BATCH_SIZE\n",
        "\n",
        "\n",
        "    # print(f\"Adjusted batch_size: {batch_size}, num_workers: {num_workers} And GPU memory: {gpu_memory:.2f} GB)\")\n",
        "    # return batch_size, num_workers\n",
        "\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"Setup random seeds, directories, and dynamically adjust batch size and workers\"\"\"\n",
        "\n",
        "    os.environ['PYTHONHASHSEED'] = str(Config.SEED)  # For hash seed reproducibility\n",
        "    random.seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    torch.cuda.manual_seed_all(Config.SEED)  # For multi-GPU if applicable\n",
        "    #Guard for GPU determinism (optional, but helpful if you want exact reproducibility across runs):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "\n",
        "    directories = [\n",
        "        Config.OUTPUT_DIR,\n",
        "        f\"{Config.OUTPUT_DIR}/models\",\n",
        "        f\"{Config.OUTPUT_DIR}/visualizations\",\n",
        "        f\"{Config.OUTPUT_DIR}/reports\",\n",
        "        f\"{Config.OUTPUT_DIR}/xai_visualizations\"\n",
        "    ]\n",
        "\n",
        "    for directory in directories:\n",
        "        Path(directory).mkdir(parents=True, exist_ok=True)#With exist_ok=True:Python will not raise an error if already exists.Or else raise a FileExistsError\n",
        "        #& parents=True → creates all missing parent directories in the path.\n",
        "\n",
        "    # Ensure all output directories exist\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/best_model\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/model_results\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/kfold_results\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/visualizations\", exist_ok=True)\n",
        "\n",
        "    print(f\"Using device: {Config.DEVICE}\")\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"Dynamic BATCH_SIZE: {Config.BATCH_SIZE}, DATALOADER_NUM_WORKERS: {Config.DATALOADER_NUM_WORKERS}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    seed = Config.SEED + worker_id\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "# class NpEncoder(json.JSONEncoder):\n",
        "#     def default(self, obj):\n",
        "#         if isinstance(obj, torch.Tensor):\n",
        "#             return obj.cpu().detach().numpy().tolist()  # Convert tensor to NumPy array, then to list\n",
        "#         if isinstance(obj, np.integer):\n",
        "#             return int(obj)\n",
        "#         if isinstance(obj, np.floating):\n",
        "#             return float(obj)\n",
        "#         if isinstance(obj, np.ndarray):\n",
        "#             return obj.tolist()\n",
        "#         return super(NpEncoder, self).default(obj)\n",
        "\n",
        "# Config.BATCH_SIZE, Config.DATALOADER_NUM_WORKERS = adjust_batch_size_and_workers(Config.BATCH_SIZE, Config.DATALOADER_NUM_WORKERS)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 3. TRAINING PROGRESS TRACKER\n",
        "# ================================================================================================================================\n",
        "# Purpose: Track and display training progress with progress bars and epoch summaries.\n",
        "\n",
        "class TrainingProgressTracker:\n",
        "    \"\"\"Track and display detailed training progress\"\"\"\n",
        "\n",
        "    def __init__(self, model_name, total_epochs, total_batches_per_epoch):\n",
        "        self.model_name = model_name\n",
        "        self.total_epochs = total_epochs\n",
        "        self.total_batches_per_epoch = total_batches_per_epoch\n",
        "\n",
        "        self.current_epoch = 0\n",
        "        self.start_time = time.time()\n",
        "        self.epoch_start_time = None\n",
        "        self.batch_times = []\n",
        "\n",
        "\n",
        "\n",
        "    def start_epoch(self, epoch):\n",
        "        \"\"\"Start tracking an epoch\"\"\"\n",
        "        self.current_epoch = epoch\n",
        "        self.epoch_start_time = time.time()\n",
        "        self.batch_times = []\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Model: {self.model_name.upper()} | Epoch: {epoch+1}/{self.total_epochs}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "\n",
        "\n",
        "    def update_batch(self, batch_idx, batch_loss, batch_acc, is_training=True,total_batches=None):\n",
        "        \"\"\"Update progress for current batch\"\"\"\n",
        "        batch_time = time.time()\n",
        "        self.batch_times.append(batch_time)\n",
        "\n",
        "\n",
        "        # Calculate timing estimates\n",
        "        if len(self.batch_times) > 1:\n",
        "            avg_batch_time = np.mean(np.diff(self.batch_times[-10:]))\n",
        "        else:\n",
        "            avg_batch_time = 1.0\n",
        "\n",
        "        total_batches = total_batches if total_batches is not None else self.total_batches_per_epoch\n",
        "        remaining_batches = total_batches - (batch_idx + 1)\n",
        "\n",
        "\n",
        "        # remaining_batches = self.total_batches_per_epoch - (batch_idx + 1)\n",
        "        eta_epoch = remaining_batches * avg_batch_time\n",
        "\n",
        "        # Progress bar\n",
        "        # progress_pct = (batch_idx + 1) / self.total_batches_per_epoch * 100\n",
        "        progress_pct = (batch_idx + 1) / total_batches * 100\n",
        "        bar_length = 30\n",
        "\n",
        "        # filled_length = int(bar_length * (batch_idx + 1) // self.total_batches_per_epoch)\n",
        "        filled_length = int(bar_length * (batch_idx + 1) // total_batches)\n",
        "        bar = '█' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "        # Format time\n",
        "        eta_str = str(timedelta(seconds=int(eta_epoch)))\n",
        "\n",
        "        # Display progress\n",
        "        mode = \"TRAIN\" if is_training else \"VAL  \"\n",
        "\n",
        "        print(f\"\\r{mode} |{bar}| {progress_pct:5.1f}% | \"\n",
        "              f\"Batch: {batch_idx+1:4d}/{total_batches} | \"\n",
        "              f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
        "              f\"ETA: {eta_str}\", end='', flush=True)\n",
        "\n",
        "\n",
        "    def finish_epoch(self, train_loss, train_acc, val_loss, val_acc, val_f1, is_best=False, lr=None):\n",
        "        \"\"\"Finish epoch and display summary\"\"\"\n",
        "        epoch_time = time.time() - self.epoch_start_time\n",
        "        total_time = time.time() - self.start_time\n",
        "\n",
        "        print(f\"\\n{'-'*60}\")\n",
        "        print(f\"EPOCH SUMMARY:\")\n",
        "        print(f\"  Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"  Val Loss:   {val_loss:.6f} | Val Acc:   {val_acc:.4f}\")\n",
        "        print(f\"  Val F1:     {val_f1:.4f} | Epoch Time: {epoch_time:.1f}s\")\n",
        "        if lr:\n",
        "            print(f\"  Learning Rate: {lr:.2e}\")\n",
        "\n",
        "        if is_best:\n",
        "            print(f\"  ★ NEW BEST MODEL! (F1: {val_f1:.4f})\")\n",
        "\n",
        "        print(f\"  Total Time: {str(timedelta(seconds=int(total_time)))}\")\n",
        "        print(f\"{'-'*60}\")\n",
        "\n",
        "\n",
        "# ---\n",
        "# 4. MODEL FACTORY\n",
        "# ================================================================================================================================\n",
        "# Purpose: Create different neural network models with customizable architectures.\n",
        "\n",
        "class ModelFactory:\n",
        "    @staticmethod\n",
        "    def create_model(model_name, num_classes=Config.NUM_CLASSES, dropout_rate=0.5,hidden_dim_multiplier=0.5):\n",
        "        \"\"\"Create model with configurable architecture\"\"\"\n",
        "\n",
        "        if model_name == 'resnet50':\n",
        "            model = models.resnet50(weights='IMAGENET1K_V2')\n",
        "            # Partial unfreeze for better accuracy: unfreeze layer4 and fc\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                # if \"layer4\" in name or \"fc\" in name:\n",
        "                if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'efficientnet_b0':\n",
        "            model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: last blocks\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"_blocks.15\" in name or \"_blocks.16\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = model.classifier[1].in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'mobilenet_v3_large':\n",
        "            model = models.mobilenet_v3_large(weights='IMAGENET1K_V2')\n",
        "            # Partial unfreeze: last features\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"features.12\" in name or \"features.13\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = 960\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'vgg16':\n",
        "            model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: classifier and last features\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"classifier\" in name or \"features.28\" in name:\n",
        "                    param.requires_grad = True\n",
        "            hidden_dim = int(4096 * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Linear(512 * 7 * 7, 4096),\n",
        "                nn.ReLU(True),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(4096, hidden_dim),\n",
        "                nn.ReLU(True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'densenet121':\n",
        "            model = models.densenet121(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: denseblock4 and classifier\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"denseblock4\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = model.classifier.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "\n",
        "        elif model_name == 'cnn':\n",
        "            # class SimpleCNN(nn.Module):\n",
        "\n",
        "            class SimpleCNN(nn.Module):\n",
        "                def __init__(self, num_classes=5, dropout_rate=0.3, hidden_dim_multiplier=0.3):\n",
        "                    super(SimpleCNN, self).__init__()\n",
        "\n",
        "                    # More conservative feature extractor to prevent overfitting\n",
        "                    self.features = nn.Sequential(\n",
        "                        # Block 1 - Start small\n",
        "                        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.1),  # Spatial dropout in conv layers\n",
        "                        nn.MaxPool2d(2, 2),  # 224 -> 112\n",
        "\n",
        "                        # Block 2\n",
        "                        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.15),\n",
        "                        nn.MaxPool2d(2, 2),  # 112 -> 56\n",
        "\n",
        "                        # Block 3\n",
        "                        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.2),\n",
        "                        nn.MaxPool2d(2, 2),  # 56 -> 28\n",
        "\n",
        "                        # Block 4 - Add one more conv before pooling\n",
        "                        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.25),\n",
        "                        nn.MaxPool2d(2, 2),  # 28 -> 14\n",
        "\n",
        "                        # Block 5 - Final feature extraction\n",
        "                        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(256),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.3),\n",
        "                        nn.AdaptiveAvgPool2d((7, 7))  # Fixed spatial size\n",
        "                    )\n",
        "\n",
        "                    # Calculate features after adaptive pooling\n",
        "                    conv_output_size = 256 * 7 * 7  # 12544\n",
        "\n",
        "                    # Much smaller hidden dimension to prevent overfitting\n",
        "                    hidden_dim = int(conv_output_size * hidden_dim_multiplier)\n",
        "                    hidden_dim = max(64, min(hidden_dim, 512))  # Smaller range\n",
        "\n",
        "                    # Simple but effective classifier\n",
        "                    self.classifier = nn.Sequential(\n",
        "                        nn.Dropout(dropout_rate),\n",
        "                        nn.Linear(conv_output_size, hidden_dim),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.BatchNorm1d(hidden_dim),\n",
        "                        nn.Dropout(dropout_rate * 0.5),\n",
        "                        nn.Linear(hidden_dim, num_classes)\n",
        "                    )\n",
        "\n",
        "                    # Initialize weights properly\n",
        "                    self._initialize_weights()\n",
        "\n",
        "                def _initialize_weights(self):\n",
        "                    for m in self.modules():\n",
        "                        if isinstance(m, nn.Conv2d):\n",
        "                            # Use smaller initialization for better gradient flow\n",
        "                            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "                        elif isinstance(m, nn.Linear):\n",
        "                            # Smaller initialization for linear layers\n",
        "                            nn.init.xavier_uniform_(m.weight, gain=0.5)\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "                        elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
        "                            if m.weight is not None:\n",
        "                                nn.init.ones_(m.weight)\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "\n",
        "                def forward(self, x):\n",
        "                    # Feature extraction\n",
        "                    x = self.features(x)\n",
        "\n",
        "                    # Flatten\n",
        "                    x = torch.flatten(x, 1)\n",
        "\n",
        "                    # Classification with gradient clipping\n",
        "                    x = self.classifier(x)\n",
        "\n",
        "                    # Clip outputs to prevent extreme values\n",
        "                    x = torch.clamp(x, min=-10, max=10)\n",
        "\n",
        "                    return x\n",
        "\n",
        "\n",
        "            # Example usage\n",
        "            model = SimpleCNN(num_classes=num_classes, dropout_rate=dropout_rate, hidden_dim_multiplier=hidden_dim_multiplier)\n",
        "            model = model.to(Config.DEVICE)  # Move to device right after creation\n",
        "\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 5. LEARNABLE WEIGHTED ENSEMBLE MODEL\n",
        "# ===============================================================================================================================\n",
        "# Purpose: Define a neural network for learning optimal ensemble weights.\n",
        "\n",
        "class LearnableWeightedEnsemble(nn.Module):\n",
        "    \"\"\"Ensemble model with per-class adaptive weights and attention\"\"\"\n",
        "    def __init__(self, num_models, num_classes, hidden_dim=128, num_heads=4):\n",
        "        super(LearnableWeightedEnsemble, self).__init__()\n",
        "        self.num_models = num_models\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Attention mechanism to learn relations between model predictions\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=num_classes, num_heads=num_heads, batch_first=True)\n",
        "\n",
        "        # Weight network outputs per-class weights for each model\n",
        "        self.weight_network = nn.Sequential(\n",
        "            nn.Linear(num_classes, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes),\n",
        "            nn.Sigmoid()  # Per-class weight scaling\n",
        "        )\n",
        "\n",
        "        # Prediction head: combines weighted predictions + raw predictions\n",
        "        self.prediction_head = nn.Sequential(\n",
        "            nn.Linear(num_classes * (num_models + 1), hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(num_classes * 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, model_predictions):\n",
        "        \"\"\"\n",
        "        model_predictions: (batch, num_models, num_classes)\n",
        "        Returns:\n",
        "            final_predictions: logits for classification\n",
        "            weights: learned per-class weights for each model\n",
        "        \"\"\"\n",
        "        batch_size = model_predictions.size(0)\n",
        "\n",
        "        # --- Step 1: Attention over model predictions --- #The model looks at how predictions of different models relate to each other.\n",
        "        attn_output, _ = self.attention(model_predictions, model_predictions, model_predictions)\n",
        "        # shape: (batch, num_models, num_classes)\n",
        "\n",
        "\n",
        "        # --- Step 2: Per-class weights for each model ---\n",
        "        #Learns a weight for each model for each class.\n",
        "        #softmax ensures weights across models sum to 1 for each class.\n",
        "        #Basically: “For class 0, I trust model 2 more; for class 1, I trust model 0 more.”\n",
        "        weights = self.weight_network(attn_output)  # (batch, num_models, num_classes)\n",
        "        weights = F.softmax(weights, dim=1)  # normalize over models\n",
        "\n",
        "\n",
        "        # --- Step 3: Weighted average across models ---\n",
        "        #Combines the models’ predictions using the learned weights → smarter than a plain average.\n",
        "        weighted_avg = torch.sum(model_predictions * weights, dim=1)  # (batch, num_classes)\n",
        "\n",
        "\n",
        "        # --- Step 4: Residual connection with raw predictions ---\n",
        "        #Combines the weighted average and all raw predictions.Gives the network more info to refine the final prediction.\n",
        "        flat_preds = model_predictions.view(batch_size, -1)  # (batch, num_models * num_classes)\n",
        "        final_input = torch.cat([weighted_avg, flat_preds], dim=1)  # (batch, num_classes + num_models*num_classes)\n",
        "\n",
        "\n",
        "        # --- Step 5: Final refined prediction ---\n",
        "        #A small feed-forward network refines the predictions.Output: (batch_size, num_classes) → logits for each class.\n",
        "        final_predictions = self.prediction_head(final_input)  # (batch, num_classes)\n",
        "\n",
        "        return final_predictions, weights\n",
        "        #It learns which model is best for each class, combines their predictions smartly using attention, and produces a refined final prediction.\n",
        "\n",
        "    # def entropy_regularization(self, weights):\n",
        "    #     \"\"\"Encourage diverse weight usage (optional loss term).\"\"\"\n",
        "    #     # weights: (batch, num_models, num_classes)\n",
        "    #     entropy = -torch.sum(weights * torch.log(weights + 1e-8), dim=1)  # (batch, num_classes)\n",
        "    #     return torch.mean(entropy)\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 6. ENSEMBLE METHODS\n",
        "# ================================================================================================================================\n",
        "# Purpose: Implement ensemble methods (simple, weighted, confidence-based, learnable).\n",
        "\n",
        "class EnsembleManager:\n",
        "    def __init__(self, models_dict, val_data):\n",
        "        self.models = models_dict\n",
        "        self.X_val, self.y_val = val_data\n",
        "        self.model_predictions = self._get_predictions()\n",
        "        self.histories = {}\n",
        "\n",
        "    def _get_predictions(self):\n",
        "        print(\"Getting model predictions for ensemble...\")\n",
        "        predictions = {}\n",
        "\n",
        "        val_dataset = FishDataset(self.X_val, self.y_val, DataManager.get_transforms(False))\n",
        "        val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            model.eval()\n",
        "            all_preds = []\n",
        "            all_probs = []\n",
        "            all_losses = []\n",
        "            all_labels = []\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    outputs = model(images)\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    loss = criterion(outputs, labels).item()\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    all_preds.extend(predicted.cpu().numpy())\n",
        "                    all_probs.extend(probabilities.cpu().numpy())\n",
        "                    all_losses.append(loss)\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = correct / total\n",
        "            f1 = f1_score(self.y_val, all_preds, average='macro')\n",
        "            avg_loss = np.mean(all_losses)\n",
        "\n",
        "            predictions[name] = {\n",
        "                'predictions': np.array(all_preds),\n",
        "                'probabilities': np.array(all_probs),\n",
        "                'loss': avg_loss,\n",
        "                'accuracy': accuracy,\n",
        "                'f1': f1,\n",
        "                'true_labels': np.array(all_labels)\n",
        "            }\n",
        "\n",
        "            print(f\"  {name}: F1 = {f1:.4f}, Acc = {accuracy:.4f}, Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def simple_average_ensemble(self, model_combo):\n",
        "        selected_probs = [self.model_predictions[name]['probabilities'] for name in model_combo]\n",
        "        avg_probs = np.mean(selected_probs, axis=0)\n",
        "        predictions = np.argmax(avg_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        avg_probs = np.mean(selected_probs, axis=0) if selected_probs else np.zeros((len(self.y_val), Config.NUM_CLASSES))\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            # 'probabilities': avg_probs,\n",
        "            'probabilities': avg_probs if avg_probs.ndim == 2 else np.zeros((0, Config.NUM_CLASSES)),\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def weighted_average_ensemble(self, model_combo):\n",
        "        weights = []\n",
        "        selected_probs = []\n",
        "\n",
        "        for name in model_combo:\n",
        "            f1 = self.model_predictions[name]['f1']\n",
        "            weights.append(f1)\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        weights = np.array(weights) / np.sum(weights)\n",
        "        weighted_probs = np.average(selected_probs, axis=0, weights=weights)\n",
        "        predictions = np.argmax(weighted_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.average([self.model_predictions[name]['loss'] for name in model_combo], weights=weights)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'weights': weights,\n",
        "            'models': model_combo,\n",
        "            'probabilities': weighted_probs,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def confidence_based_ensemble(self, model_combo):\n",
        "        final_predictions = []\n",
        "        all_probs = []\n",
        "\n",
        "        for i in range(len(self.y_val)):\n",
        "            confidences = []\n",
        "            probs = []\n",
        "\n",
        "            for name in model_combo:\n",
        "                prob = self.model_predictions[name]['probabilities'][i]\n",
        "                confidence = np.max(prob)\n",
        "                confidences.append(confidence)\n",
        "                probs.append(prob)\n",
        "\n",
        "            confidences = np.array(confidences)\n",
        "            weights = confidences / np.sum(confidences) if np.sum(confidences) > 0 else np.ones(len(confidences)) / len(confidences)\n",
        "\n",
        "            final_prob = np.average(probs, axis=0, weights=weights)\n",
        "            final_predictions.append(np.argmax(final_prob))\n",
        "            all_probs.append(final_prob)\n",
        "\n",
        "        predictions = np.array(final_predictions)\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'probabilities': np.array(all_probs),\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def learnable_weighted_ensemble(self, model_combo, epochs=30):\n",
        "        print(f\"Training learnable weighted ensemble with {len(model_combo)} models...\")\n",
        "\n",
        "        selected_probs = []\n",
        "        for name in model_combo:\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        ensemble_input = np.stack(selected_probs, axis=1)\n",
        "\n",
        "        X_ensemble = torch.FloatTensor(ensemble_input).to(Config.DEVICE)\n",
        "        y_ensemble = torch.LongTensor(self.y_val).to(Config.DEVICE)\n",
        "\n",
        "        ensemble_model = LearnableWeightedEnsemble(\n",
        "            num_models=len(model_combo),\n",
        "            num_classes=Config.NUM_CLASSES\n",
        "        ).to(Config.DEVICE)\n",
        "\n",
        "        optimizer = optim.AdamW(ensemble_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "        history = {'train_loss': [], 'train_acc': [], 'val_f1': []}\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            ensemble_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions, weights = ensemble_model(X_ensemble)\n",
        "            loss = criterion(predictions, y_ensemble)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            accuracy = accuracy_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy())\n",
        "            f1 = f1_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy(), average='macro')\n",
        "\n",
        "            history['train_loss'].append(loss.item())\n",
        "            history['train_acc'].append(accuracy)\n",
        "            history['val_f1'].append(f1)\n",
        "\n",
        "            print(f\"Ensemble Epoch {epoch+1}/{epochs}: Loss = {loss.item():.4f}, \"\n",
        "                  f\"Acc = {accuracy:.4f}, F1 = {f1:.4f}\")\n",
        "\n",
        "            if loss.item() < best_loss:\n",
        "                best_loss = loss.item()\n",
        "                torch.save(ensemble_model.state_dict(), f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\")\n",
        "\n",
        "        ensemble_model.load_state_dict(torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\"))\n",
        "        ensemble_model.eval()\n",
        "        with torch.no_grad():\n",
        "            final_predictions, learned_weights = ensemble_model(X_ensemble)\n",
        "            predictions = final_predictions.argmax(dim=1).cpu().numpy()\n",
        "            probabilities = torch.softmax(final_predictions, dim=1).cpu().numpy()\n",
        "            avg_weights = learned_weights.mean(dim=0).cpu().numpy()\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        self.histories[f\"learnable_weighted_{'+'.join(model_combo)}\"] = history\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'learned_weights': avg_weights,\n",
        "            'probabilities': probabilities,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def test_ensemble_combinations(self):\n",
        "        print(\"Testing ensemble combinations...\")\n",
        "\n",
        "        model_names = list(self.models.keys())\n",
        "        all_results = {}\n",
        "        best_result = None\n",
        "        best_score = 0\n",
        "\n",
        "        for size in range(2, min(len(model_names) + 1, 5)):\n",
        "            print(f\"Testing {size}-model combinations...\")\n",
        "\n",
        "            for combo in list(combinations(model_names, size))[:5]:\n",
        "                combo_name = f\"combo_{size}_{'+'.join(combo)}\"\n",
        "\n",
        "                for method_name in Config.ENSEMBLE_METHODS:\n",
        "                    full_name = f\"{combo_name}_{method_name}\"\n",
        "\n",
        "                    try:\n",
        "                        if method_name == 'simple_average':\n",
        "                            result = self.simple_average_ensemble(combo)\n",
        "                        elif method_name == 'weighted_average':\n",
        "                            result = self.weighted_average_ensemble(combo)\n",
        "                        elif method_name == 'confidence_based':\n",
        "                            result = self.confidence_based_ensemble(combo)\n",
        "                        elif method_name == 'learnable_weighted':\n",
        "                            result = self.learnable_weighted_ensemble(combo)\n",
        "\n",
        "                        # Verify result contains required keys\n",
        "                        required_keys = ['accuracy', 'f1', 'loss', 'predictions', 'models', 'probabilities', 'true_labels']\n",
        "                        if not all(key in result for key in required_keys):\n",
        "                            missing = [key for key in required_keys if key not in result]\n",
        "                            print(f\"  {full_name}: Missing keys {missing}\")\n",
        "                            continue\n",
        "                        # Ensure probabilities is 2D\n",
        "                        if 'probabilities' in result and (result['probabilities'].ndim != 2 or result['probabilities'].shape[1] != Config.NUM_CLASSES):\n",
        "                            result['probabilities'] = np.zeros((len(result['true_labels']), Config.NUM_CLASSES))\n",
        "\n",
        "                        all_results[full_name] = result\n",
        "                        print(f\"  {full_name}: F1 = {result['f1']:.4f}, Acc = {result['accuracy']:.4f}, \"\n",
        "                              f\"Loss = {result['loss']:.4f}, True Labels Shape = {result['true_labels'].shape}\")\n",
        "\n",
        "                        if result['f1'] > best_score:\n",
        "                            best_score = result['f1']\n",
        "                            best_result = (full_name, result)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"  {full_name}: FAILED - {str(e)}\")\n",
        "\n",
        "        if best_result:\n",
        "            print(f\"\\n✓ Best ensemble: {best_result[0]} (F1: {best_result[1]['f1']:.4f})\")\n",
        "        else:\n",
        "            print(\"\\nNo valid ensemble results generated.\")\n",
        "\n",
        "        return all_results, best_result\n",
        "\n",
        "\n",
        "# ---\n",
        "# 7. ENHANCED VISUALIZATIONS\n",
        "# ================================================================================================================================\n",
        "# Purpose: Generate visualizations for training history, ROC curves, confusion matrices, model comparisons, and XAI visualizations.\n",
        "\n",
        "class EnhancedVisualizations:\n",
        "    def __init__(self):\n",
        "        self.viz_dir = f\"{Config.OUTPUT_DIR}/visualizations\"\n",
        "        Path(self.viz_dir).mkdir(parents=True, exist_ok=True)\n",
        "        # Set better matplotlib parameters for spacing\n",
        "        plt.rcParams.update({\n",
        "            'figure.autolayout': True,\n",
        "            'axes.titlepad': 20,\n",
        "            'axes.labelpad': 10,\n",
        "            'xtick.major.pad': 8,\n",
        "            'ytick.major.pad': 8\n",
        "        })\n",
        "\n",
        "\n",
        "    def plot_single_model_history(self, history, model_name, alpha=0.2):  # (range: 0.1–0.3; lower = smoother, higher = more responsive)\n",
        "        \"\"\"Plot training history for individual model with better spacing\"\"\"\n",
        "        if not history['train_loss']:\n",
        "            print(f\"Skipping {model_name}: No training data available\")\n",
        "            return\n",
        "\n",
        "        # def smooth_ema(values, alpha):\n",
        "        #     \"\"\"Apply exponential moving average (EMA) smoothing to a list of values.\"\"\"\n",
        "        #     if not values:\n",
        "        #         return values\n",
        "        #     smoothed = [values[0]]\n",
        "        #     for val in values[1:]:\n",
        "        #         smoothed.append(alpha * val + (1 - alpha) * smoothed[-1])\n",
        "        #     return smoothed\n",
        "        def smooth_ema(values, alpha=0.1):\n",
        "            \"\"\"\n",
        "            Apply exponential moving average smoothing to a list or tensor of values.\n",
        "\n",
        "            Args:\n",
        "                values: List, NumPy array, or PyTorch tensor of numerical values\n",
        "                alpha: Smoothing factor (default: 0.1)\n",
        "\n",
        "            Returns:\n",
        "                List of smoothed values\n",
        "            \"\"\"\n",
        "            # Convert tensor to list if necessary\n",
        "            if torch.is_tensor(values):\n",
        "                values = values.cpu().numpy().tolist()\n",
        "            elif isinstance(values, np.ndarray):\n",
        "                values = values.tolist()\n",
        "\n",
        "            if not values:  # Check if the list is empty\n",
        "                return []\n",
        "\n",
        "            smoothed = [values[0]]\n",
        "            for i in range(1, len(values)):\n",
        "                smoothed.append(alpha * values[i] + (1 - alpha) * smoothed[-1])\n",
        "\n",
        "            return smoothed\n",
        "\n",
        "\n",
        "\n",
        "        epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "        # Create subplot with more space\n",
        "        fig = plt.figure(figsize=(16, 10))\n",
        "        gs = fig.add_gridspec(2, 2, hspace=0.4, wspace=0.3)\n",
        "\n",
        "        # Loss plot\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        smoothed_train_loss = smooth_ema(history['train_loss'], alpha)\n",
        "        smoothed_val_loss = smooth_ema(history.get('val_loss', []), alpha)\n",
        "        ax1.plot(epochs, smoothed_train_loss, 'b-', linewidth=2, label='Train Loss', marker='o', markersize=4)\n",
        "        if smoothed_val_loss:\n",
        "            ax1.plot(epochs, smoothed_val_loss, 'r-', linewidth=2, label='Val Loss', marker='s', markersize=4)\n",
        "        ax1.set_title(f'{model_name} - Loss vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "        ax1.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
        "        ax1.legend(frameon=True, shadow=True, fontsize=11)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.tick_params(labelsize=10)\n",
        "\n",
        "        # Accuracy plot\n",
        "        ax2 = fig.add_subplot(gs[0, 1])\n",
        "        ax2.plot(epochs, history['train_acc'], 'g-', linewidth=2, label='Train Acc', marker='o', markersize=4)\n",
        "        if history.get('val_acc', []):\n",
        "            ax2.plot(epochs, history['val_acc'], 'm-', linewidth=2, label='Val Acc', marker='s', markersize=4)\n",
        "        ax2.set_title(f'{model_name} - Accuracy vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax2.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "        ax2.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "        ax2.legend(frameon=True, shadow=True, fontsize=11)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.tick_params(labelsize=10)\n",
        "\n",
        "        # F1 Score plot\n",
        "        ax3 = fig.add_subplot(gs[1, 0])\n",
        "        smoothed_val_f1 = smooth_ema(history.get('val_f1', []), alpha)\n",
        "        if smoothed_val_f1:\n",
        "            ax3.plot(epochs, smoothed_val_f1, 'orange', linewidth=2, label='Val F1', marker='d', markersize=4)\n",
        "            ax3.set_title(f'{model_name} - F1 Score vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "            ax3.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "            ax3.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
        "            ax3.legend(frameon=True, shadow=True, fontsize=11)\n",
        "            ax3.grid(True, alpha=0.3)\n",
        "            ax3.tick_params(labelsize=10)\n",
        "\n",
        "        # Learning Rate plot\n",
        "        ax4 = fig.add_subplot(gs[1, 1])\n",
        "        smoothed_lr = smooth_ema(history.get('learning_rates', []), alpha)\n",
        "        if smoothed_lr:\n",
        "            ax4.plot(epochs, smoothed_lr, 'purple', linewidth=2, label='Learning Rate', marker='x', markersize=6)\n",
        "            ax4.set_title(f'{model_name} - Learning Rate vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "            ax4.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "            ax4.set_ylabel('Learning Rate', fontsize=12, fontweight='bold')\n",
        "            ax4.legend(frameon=True, shadow=True, fontsize=11)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.tick_params(labelsize=10)\n",
        "            ax4.set_yscale('log')\n",
        "\n",
        "        plt.suptitle(f'{model_name} Training Progress', fontsize=18, fontweight='bold', y=0.98)\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_individual_training_history.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Individual training history saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "    def plot_single_model_xai(self, model, model_name, test_loader, max_images=5):\n",
        "        \"\"\"Generate XAI visualizations for a single model using Grad-CAM++, Integrated Gradients, and LRP\"\"\"\n",
        "        print(f\"Generating XAI visualizations for {model_name}...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # # Get sample images\n",
        "        # sample_images, sample_labels = next(iter(test_loader))\n",
        "        # sample_images = sample_images[:max_images].to(Config.DEVICE)\n",
        "        # sample_labels = sample_labels[:max_images].numpy()\n",
        "\n",
        "        # Get sample images\n",
        "        sample_images = []\n",
        "        sample_labels = []\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            class_mask = np.where(test_loader.dataset.labels == i)[0]\n",
        "            if len(class_mask) > 0:\n",
        "                idx = np.random.choice(class_mask)\n",
        "                image, label = test_loader.dataset[idx]\n",
        "                if image.dim() == 4:\n",
        "                    image = image.squeeze(0)\n",
        "                sample_images.append(image.to(Config.DEVICE))\n",
        "                sample_labels.append(label)\n",
        "\n",
        "\n",
        "        for idx, (image, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
        "            try:\n",
        "                # Create figure with larger size for clearer images\n",
        "                fig = plt.figure(figsize=(24, 8))  # Standard size for clear visualization\n",
        "                gs = fig.add_gridspec(1, 4, wspace=0.15, hspace=0.2)  # 4 columns: Original, Grad-CAM++, Integrated Gradients, LRP\n",
        "\n",
        "                # Prepare original image\n",
        "                image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                # Plot original image\n",
        "                ax_orig = fig.add_subplot(gs[0, 0])\n",
        "                ax_orig.imshow(image_np)\n",
        "                ax_orig.set_title(f'Original Image\\nTrue: {Config.CLASS_LABELS[true_label]}',\n",
        "                                 fontsize=14, fontweight='bold', pad=15)\n",
        "                ax_orig.axis('off')\n",
        "\n",
        "                # Forward pass for prediction\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(image.unsqueeze(0))\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    predicted_class = outputs.argmax(dim=1).item()\n",
        "                    confidence = probabilities[0, predicted_class].item()\n",
        "                    predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                # Generate Grad-CAM++ visualization\n",
        "                gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(model, image, predicted_class)\n",
        "                ax_gradcam = fig.add_subplot(gs[0, 1])\n",
        "                ax_gradcam.imshow(gradcam_img)\n",
        "                ax_gradcam.set_title(f'{model_name}\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                    fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_gradcam.axis('off')\n",
        "\n",
        "                # Generate Integrated Gradients visualization\n",
        "                ig_img, _ = xai_visualizer.integrated_gradients(model, image, predicted_class)\n",
        "                ax_ig = fig.add_subplot(gs[0, 2])\n",
        "                ax_ig.imshow(ig_img)\n",
        "                ax_ig.set_title(f'{model_name}\\nIntegrated Gradients', fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_ig.axis('off')\n",
        "\n",
        "                # Generate LRP visualization\n",
        "                lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, image, predicted_class)\n",
        "                ax_lrp = fig.add_subplot(gs[0, 3])\n",
        "                # ax_lrp.imshow(lrp_img)\n",
        "                ax_lrp.imshow(cv2.cvtColor(lrp_img, cv2.COLOR_BGR2RGB))\n",
        "                ax_lrp.set_title(f'{model_name}\\nLRP', fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_lrp.axis('off')\n",
        "\n",
        "                plt.suptitle(f'XAI Analysis for {model_name} - Image {idx+1}', fontsize=16, fontweight='bold', y=0.95)\n",
        "                save_path = f\"{self.viz_dir}/{model_name}_xai_image_{idx+1}.png\"\n",
        "                plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "                plt.show()\n",
        "                print(f\"XAI visualization saved: {save_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating XAI for {model_name}, image {idx+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "    def plot_confusion_matrix(self, results, model_name):\n",
        "        \"\"\"Enhanced confusion matrix with better spacing\"\"\"\n",
        "        if 'true_labels' not in results or 'predictions' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'predictions' in results for {model_name}\")\n",
        "            return\n",
        "\n",
        "        cm = confusion_matrix(results['true_labels'], results['predictions'])\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        # Create figure with better spacing\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "        # Use better color scheme and formatting\n",
        "        sns.heatmap(cm_normalized, annot=cm, fmt='d', cmap='Blues',\n",
        "                    xticklabels=Config.CLASS_LABELS, yticklabels=Config.CLASS_LABELS,\n",
        "                    cbar_kws={'label': 'Normalized Count', 'shrink': 0.8},\n",
        "                    square=True, linewidths=0.5, annot_kws={'size': 12})\n",
        "\n",
        "        # === Move colorbar label to the top ===\n",
        "        cbar = ax.collections[0].colorbar\n",
        "        cbar.ax.yaxis.set_label_position('left')   # keep label aligned left of bar\n",
        "        cbar.set_label(\"Normalized Count\", rotation=0, labelpad=15)\n",
        "        cbar.ax.yaxis.set_label_coords(-1.2, 1.02)  # fine-tune position (x, y)\n",
        "\n",
        "        ax.set_title(f'Confusion Matrix: {model_name}', fontsize=16, fontweight='bold', pad=25)\n",
        "        ax.set_xlabel('Predicted Label', fontsize=14, fontweight='bold', labelpad=15)\n",
        "        ax.set_ylabel('True Label', fontsize=14, fontweight='bold', labelpad=15)\n",
        "\n",
        "        # Rotate labels for better readability\n",
        "        plt.xticks(rotation=45, ha='right', fontsize=12)\n",
        "        plt.yticks(rotation=0, fontsize=12)\n",
        "\n",
        "        # Add performance metrics as text\n",
        "        accuracy = accuracy_score(results['true_labels'], results['predictions'])\n",
        "        f1_macro = f1_score(results['true_labels'], results['predictions'], average='macro')\n",
        "        f1_weighted = f1_score(results['true_labels'], results['predictions'], average='weighted')\n",
        "\n",
        "        metrics_text = f'Accuracy: {accuracy:.4f}\\nF1 (Macro): {f1_macro:.4f}\\nF1 (Weighted): {f1_weighted:.4f}'\n",
        "        ax.text(1.15, 0.5, metrics_text, transform=ax.transAxes, fontsize=12,\n",
        "                verticalalignment='center', bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_enhanced_confusion_matrix.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced confusion matrix saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_roc_curves(self, results, model_name):\n",
        "        \"\"\"Plot ROC curves for multi-class classification.\"\"\"\n",
        "        import numpy as np\n",
        "        \"\"\"Enhanced ROC curves with better spacing and styling for multiclass\"\"\"\n",
        "        if 'true_labels' not in results or 'probabilities' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'probabilities' in results for {model_name}\")\n",
        "            return\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, Config.NUM_CLASSES))\n",
        "        probabilities = np.array(results['probabilities'])\n",
        "        if len(results['true_labels']) == 0 or probabilities.size == 0 or probabilities.ndim != 2 or probabilities.shape[1] != Config.NUM_CLASSES:\n",
        "            print(f\"Warning: Invalid or empty probabilities shape {probabilities.shape} for {model_name}. Skipping ROC plot.\")\n",
        "            ax.text(0.5, 0.5, 'No data available for ROC', horizontalalignment='center', verticalalignment='center', fontsize=12)\n",
        "            return\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, Config.NUM_CLASSES))\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            y_true_bin = (np.array(results['true_labels']) == i).astype(int)\n",
        "            y_score = probabilities[:, i]\n",
        "\n",
        "            fpr, tpr, _ = roc_curve(y_true_bin, y_score)\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            ax.plot(fpr, tpr, color=colors[i], linewidth=2,\n",
        "                    label=f'{Config.CLASS_LABELS[i]} (AUC = {roc_auc:.4f})')\n",
        "\n",
        "        # Diagonal line\n",
        "        ax.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.6, label='Random Classifier')\n",
        "\n",
        "        ax.set_title(f'{model_name} - ROC Curves', fontsize=16, fontweight='bold', pad=20)\n",
        "        ax.set_xlabel('False Positive Rate', fontsize=14, fontweight='bold', labelpad=10)\n",
        "        ax.set_ylabel('True Positive Rate', fontsize=14, fontweight='bold', labelpad=10)\n",
        "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', frameon=True, shadow=True, fontsize=11)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_xlim([0.0, 1.0])\n",
        "        ax.set_ylim([0.0, 1.05])\n",
        "\n",
        "        # Compute micro-average ROC curve\n",
        "        y_true_bin = label_binarize(results['true_labels'], classes=range(Config.NUM_CLASSES))\n",
        "        fpr_micro, tpr_micro, _ = roc_curve(y_true_bin.ravel(), results['probabilities'].ravel())\n",
        "        roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
        "        ax.plot(fpr_micro, tpr_micro, 'deeppink', linestyle=':', linewidth=4,\n",
        "                label=f'Micro-average (AUC = {roc_auc_micro:.4f})')\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_enhanced_roc_curves.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced ROC curves saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_misclassified_images(self, misclassified, model_name):\n",
        "        \"\"\"Plot up to 4 misclassified images in a 2x2 grid with improved visibility.\"\"\"\n",
        "        import matplotlib.pyplot as plt\n",
        "        import numpy as np\n",
        "\n",
        "        if not misclassified:\n",
        "            print(f\"No misclassified images for {model_name}\")\n",
        "            return\n",
        "\n",
        "        # Select up to 4 misclassified images\n",
        "        misclassified = misclassified[:4]\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(10, 10))  # Slightly smaller size\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for idx, item in enumerate(misclassified):\n",
        "            # image = item['image'].permute(1, 2, 0).cpu().numpy()  # Convert CHW -> HWC\n",
        "            image = item['image']\n",
        "            if isinstance(image, torch.Tensor):\n",
        "                image = image.permute(1, 2, 0).cpu().numpy()  # CHW -> HWC\n",
        "            elif isinstance(image, np.ndarray):\n",
        "                if image.shape[0] in [1, 3]:  # If channel-first\n",
        "                    image = np.transpose(image, (1, 2, 0))  # CHW -> HWC\n",
        "\n",
        "\n",
        "            # Normalize for display\n",
        "            if image.max() > 1.0:\n",
        "                image = image / 255.0\n",
        "            else:\n",
        "                image = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
        "            image = np.clip(image, 0, 1)\n",
        "\n",
        "            # Grayscale vs RGB\n",
        "            if image.shape[2] == 1:\n",
        "                image = image.squeeze()\n",
        "                axes[idx].imshow(image, cmap='gray')\n",
        "            else:\n",
        "                axes[idx].imshow(image)\n",
        "\n",
        "            # Titles with color\n",
        "            true_label = Config.CLASS_LABELS[item['true_label']]\n",
        "            pred_label = Config.CLASS_LABELS[item['pred_label']]\n",
        "            axes[idx].set_title(\n",
        "                f\"True: {true_label}\\nPred: {pred_label}\",\n",
        "                fontsize=9,\n",
        "                fontweight=\"bold\",\n",
        "                pad=10,\n",
        "                color=\"black\" #if true_label != pred_label else \"darkgreen\"\n",
        "            )\n",
        "\n",
        "            axes[idx].axis(\"off\")\n",
        "            # Add white border around each image\n",
        "            for spine in axes[idx].spines.values():\n",
        "                spine.set_edgecolor(\"lightgray\")\n",
        "                spine.set_linewidth(3)\n",
        "\n",
        "        # Hide unused subplots (if <4 images)\n",
        "        for idx in range(len(misclassified), 4):\n",
        "            axes[idx].axis(\"off\")\n",
        "\n",
        "        plt.suptitle(\n",
        "            f\"Misclassified Images for {model_name}\",\n",
        "            fontsize=12,\n",
        "            fontweight=\"bold\",\n",
        "            y=0.99,\n",
        "            color=\"black\"\n",
        "        )\n",
        "        plt.subplots_adjust(wspace=0.3, hspace=0.4)  # Increase padding between plots\n",
        "        save_path = f\"{self.viz_dir}/misclassified_{model_name}.png\"\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\", dpi=300, facecolor=\"white\")\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "        print(f\"Saved misclassified images plot for {model_name} at {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_kfold_results(self, fold_results, model_name, test_loader):\n",
        "        \"\"\"Plot k-fold results: 2x2 grid per fold and 1x2 comparison across folds.\"\"\"\n",
        "        n_folds = len(fold_results)\n",
        "        plt.style.use('seaborn-v0_8')  # Use modern Seaborn style\n",
        "\n",
        "        # 2x2 Grid Plot for Each Fold\n",
        "        for fold in range(n_folds):\n",
        "            fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "            fig.suptitle(f'{model_name} - Fold {fold+1} Metrics', fontsize=16)\n",
        "            history = fold_results[fold]['history']\n",
        "\n",
        "            # Plot Validation Accuracy\n",
        "            axes[0, 0].plot(history['val_acc'], label='Validation Accuracy', marker='s')\n",
        "            axes[0, 0].set_title('Validation Accuracy')\n",
        "            axes[0, 0].set_xlabel('Epoch')\n",
        "            axes[0, 0].set_ylabel('Accuracy')\n",
        "            axes[0, 0].legend()\n",
        "            axes[0, 0].grid(True)\n",
        "\n",
        "            # Plot Validation Loss\n",
        "            axes[0, 1].plot(history['val_loss'], label='Validation Loss', marker='s')\n",
        "            axes[0, 1].set_title('Validation Loss')\n",
        "            axes[0, 1].set_xlabel('Epoch')\n",
        "            axes[0, 1].set_ylabel('Loss')\n",
        "            axes[0, 1].legend()\n",
        "            axes[0, 1].grid(True)\n",
        "\n",
        "            # Hide unused subplots\n",
        "            axes[1, 0].set_visible(False)\n",
        "            axes[1, 1].set_visible(False)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        # 1x2 Comparison Plot Across Folds\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        fig.suptitle(f'{model_name} - Cross-Fold Comparison', fontsize=16)\n",
        "\n",
        "        # Plot Validation Accuracy Across Folds\n",
        "        for fold in range(n_folds):\n",
        "            history = fold_results[fold]['history']\n",
        "            axes[0].plot(history['val_acc'], label=f'Fold {fold+1}', marker='s')\n",
        "        axes[0].set_title('Validation Accuracy Across Folds')\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Accuracy')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True)\n",
        "\n",
        "        # Plot Validation Loss Across Folds\n",
        "        for fold in range(n_folds):\n",
        "            history = fold_results[fold]['history']\n",
        "            axes[1].plot(history['val_loss'], label=f'Fold {fold+1}', marker='s')\n",
        "        axes[1].set_title('Validation Loss Across Folds')\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('Loss')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def plot_model_results(self, model_name, fold_results, test_loader):\n",
        "        \"\"\"Plot model results: ROC curves, confusion matrix, misclassified images, XAI, and k-fold results.\"\"\"\n",
        "        print(f\"Generating plots for {model_name}\")\n",
        "\n",
        "        # Plot single-model results using first fold's result\n",
        "        first_result = fold_results[0]['result']\n",
        "        self.plot_roc_curves(first_result, model_name)\n",
        "        self.plot_confusion_matrix(first_result, model_name)\n",
        "        self.plot_misclassified_images(first_result['misclassified'], model_name)\n",
        "\n",
        "        # Recreate model for XAI plotting\n",
        "        model = ModelFactory.create_model(\n",
        "            model_name,\n",
        "            num_classes=Config.NUM_CLASSES,\n",
        "            dropout_rate=0.5,  # Use default or pass from hyperparameters\n",
        "            hidden_dim_multiplier=0.5\n",
        "        ).to(Config.DEVICE)\n",
        "        self.plot_single_model_xai(model, model_name, test_loader)\n",
        "\n",
        "        # Plot k-fold results\n",
        "        self.plot_kfold_results(fold_results, model_name, test_loader)\n",
        "\n",
        "        print(\"Completed plotting k-fold results\")\n",
        "\n",
        "        # Clean up\n",
        "        del model, fold_results, first_result\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "        gc.collect()\n",
        "        # print(f\"Plotting memory cleared: {torch.cuda.memory_summary()}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def generate_comprehensive_report(self, single_results, ensemble_results, best_ensemble):\n",
        "        \"\"\"Generate a comprehensive visual report\"\"\"\n",
        "        # fig = plt.figure(figsize=(24, 16))\n",
        "        fig = plt.figure(figsize=(30, 20))\n",
        "        gs = fig.add_gridspec(3, 4, hspace=0.4, wspace=0.3, top=0.92, bottom=0.08, left=0.05, right=0.95)\n",
        "\n",
        "        # Title\n",
        "        fig.suptitle('Fish Species Classification - Comprehensive Analysis Report',\n",
        "                    fontsize=24, fontweight='bold', y=0.96)\n",
        "\n",
        "        # 1. Model Performance Comparison\n",
        "        ax1 = fig.add_subplot(gs[0, :2])\n",
        "        model_names = list(single_results.keys())\n",
        "        accuracies = [single_results[name]['accuracy'] for name in model_names]\n",
        "        f1_scores = [single_results[name]['f1_macro'] for name in model_names]\n",
        "\n",
        "        x = np.arange(len(model_names))\n",
        "        width = 0.35\n",
        "\n",
        "        bars1 = ax1.bar(x - width/2, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "        bars2 = ax1.bar(x + width/2, f1_scores, width, label='F1 Score', alpha=0.8, color='lightcoral')\n",
        "\n",
        "        ax1.set_xlabel('Models', fontweight='bold', fontsize=12)\n",
        "        ax1.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "        ax1.set_title('Individual Model Performance', fontweight='bold', fontsize=14, pad=15)\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "        ax1.legend(fontsize=11)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, 1.1)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar in bars1 + bars2:\n",
        "            height = bar.get_height()\n",
        "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                    f'{height:.4f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        # 2. Best vs Worst Model Comparison\n",
        "        ax2 = fig.add_subplot(gs[0, 2:])\n",
        "        if ensemble_results and best_ensemble:\n",
        "            best_single_f1 = max(f1_scores)\n",
        "            worst_single_f1 = min(f1_scores)\n",
        "            best_ensemble_f1 = best_ensemble[1]['f1']\n",
        "\n",
        "            categories = ['Worst Single', 'Best Single', 'Best Ensemble']\n",
        "            values = [worst_single_f1, best_single_f1, best_ensemble_f1]\n",
        "            colors = ['lightcoral', 'lightblue', 'gold']\n",
        "\n",
        "            bars = ax2.bar(categories, values, color=colors, alpha=0.8)\n",
        "            ax2.set_ylabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax2.set_title('Performance Comparison', fontweight='bold', fontsize=14, pad=15)\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.set_ylim(0, max(values) * 1.1)\n",
        "\n",
        "            for bar, value in zip(bars, values):\n",
        "                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                        f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "        # 3. Per-class Performance Heatmap\n",
        "        ax3 = fig.add_subplot(gs[1, :2])\n",
        "        per_class_f1 = []\n",
        "        for model_name in model_names:\n",
        "            per_class_f1.append(single_results[model_name]['f1_per_class'])\n",
        "\n",
        "        per_class_f1 = np.array(per_class_f1)\n",
        "        im = ax3.imshow(per_class_f1, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "        ax3.set_xticks(range(len(Config.CLASS_LABELS)))\n",
        "        ax3.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right')\n",
        "        ax3.set_yticks(range(len(model_names)))\n",
        "        ax3.set_yticklabels(model_names)\n",
        "        ax3.set_title('Per-Class F1 Scores Heatmap', fontweight='bold', fontsize=14, pad=15)\n",
        "\n",
        "        # Add colorbar\n",
        "        cbar = plt.colorbar(im, ax=ax3, shrink=0.8)\n",
        "        cbar.set_label('F1 Score', rotation=270, labelpad=15)\n",
        "\n",
        "        # Add text annotations\n",
        "        for i in range(len(model_names)):\n",
        "            for j in range(len(Config.CLASS_LABELS)):\n",
        "                text_color = 'white' if per_class_f1[i, j] < 0.5 else 'black'\n",
        "                ax3.text(j, i, f'{per_class_f1[i, j]:.2f}',\n",
        "                        ha=\"center\", va=\"center\", color=text_color, fontsize=8, fontweight='bold')\n",
        "\n",
        "        # 4. Ensemble Methods Performance\n",
        "        ax4 = fig.add_subplot(gs[1, 2:])\n",
        "        if ensemble_results:\n",
        "            ensemble_items = list(ensemble_results.items())\n",
        "            ensemble_items.sort(key=lambda x: x[1]['f1'], reverse=True)\n",
        "            top_ensembles = ensemble_items[:8]\n",
        "\n",
        "            ensemble_names = [name.split('_')[-1] for name, _ in top_ensembles]\n",
        "            ensemble_f1s = [result['f1'] for _, result in top_ensembles]\n",
        "\n",
        "            bars = ax4.barh(range(len(ensemble_names)), ensemble_f1s, alpha=0.8, color='lightgreen')\n",
        "            ax4.set_yticks(range(len(ensemble_names)))\n",
        "            ax4.set_yticklabels(ensemble_names)\n",
        "            ax4.set_xlabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax4.set_title('Top Ensemble Methods', fontweight='bold', fontsize=14, pad=15)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "\n",
        "            for bar, value in zip(bars, ensemble_f1s):\n",
        "                ax4.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,\n",
        "                        f'{value:.4f}', ha='left', va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "        # 5. Summary Statistics Table\n",
        "        ax5 = fig.add_subplot(gs[2, :])\n",
        "        ax5.axis('off')\n",
        "\n",
        "        # Create summary data\n",
        "        summary_data = []\n",
        "        for model_name in model_names:\n",
        "            result = single_results[model_name]\n",
        "            summary_data.append([\n",
        "                model_name,\n",
        "                f\"{result['accuracy']:.4f}\",\n",
        "                f\"{result['f1_macro']:.4f}\",\n",
        "                f\"{result['f1_weighted']:.4f}\",\n",
        "                f\"{result['precision_macro']:.4f}\",\n",
        "                f\"{result['recall_macro']:.4f}\"\n",
        "            ])\n",
        "\n",
        "        if ensemble_results and best_ensemble:\n",
        "            best_result = best_ensemble[1]\n",
        "            summary_data.append([\n",
        "                f\"Best Ensemble\\n({best_ensemble[0]})\",\n",
        "                f\"{best_result['accuracy']:.4f}\",\n",
        "                f\"{best_result['f1']:.4f}\",\n",
        "                \"N/A\",\n",
        "                \"N/A\",\n",
        "                \"N/A\"\n",
        "            ])\n",
        "\n",
        "        columns = ['Model', 'Accuracy', 'F1 (Macro)', 'F1 (Weighted)', 'Precision', 'Recall']\n",
        "\n",
        "        table = ax5.table(cellText=summary_data, colLabels=columns, loc='center', cellLoc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1.2, 2)\n",
        "\n",
        "        # Style the table\n",
        "        for i in range(len(columns)):\n",
        "            table[(0, i)].set_facecolor('#4CAF50')\n",
        "            table[(0, i)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "        for i in range(1, len(summary_data) + 1):\n",
        "            for j in range(len(columns)):\n",
        "                if i % 2 == 0:\n",
        "                    table[(i, j)].set_facecolor('#f0f0f0')\n",
        "                else:\n",
        "                    table[(i, j)].set_facecolor('white')\n",
        "\n",
        "        ax5.set_title('Model Performance Summary', fontweight='bold', fontsize=16, pad=20)\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/comprehensive_report.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Comprehensive report saved: {save_path}\")\n",
        "        return save_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_model_comparison(self, single_results, ensemble_results):\n",
        "        \"\"\"Enhanced model comparison with better spacing\"\"\"\n",
        "        # fig = plt.figure(figsize=(20, 16))\n",
        "        fig = plt.figure(figsize=(30, 20))\n",
        "        gs = fig.add_gridspec(2, 2, hspace=0.4, wspace=0.3, top=0.92, bottom=0.08)\n",
        "\n",
        "        model_names = list(single_results.keys())\n",
        "        accuracies = [single_results[name]['accuracy'] for name in model_names]\n",
        "        f1_scores = [single_results[name]['f1_macro'] for name in model_names]\n",
        "        f1_weighted = [single_results[name]['f1_weighted'] for name in model_names]\n",
        "        # losses = [single_results[name]['loss'] for name in model_names]\n",
        "        # Use f1_macro as substitute since loss is not available in single_results\n",
        "        losses = [1 - single_results[name]['f1_macro'] for name in model_names]  # Convert F1 to loss-like metric\n",
        "\n",
        "        x = np.arange(len(model_names))\n",
        "        width = 0.2\n",
        "\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        bars1 = ax1.bar(x - width*1.5, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "        bars2 = ax1.bar(x - width/2, f1_scores, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "        bars3 = ax1.bar(x + width/2, f1_weighted, width, label='F1 (Weighted)', alpha=0.8, color='lightgreen')\n",
        "        bars4 = ax1.bar(x + width*1.5, losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "        ax1.set_xlabel('Models', fontweight='bold', fontsize=12)\n",
        "        ax1.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "        ax1.set_title('Individual Model Performance', fontweight='bold', fontsize=14, pad=20)\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(model_names, rotation=45, ha='right', fontsize=10)\n",
        "        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, max(max(accuracies), max(f1_scores), max(f1_weighted), max(losses)) * 1.1)\n",
        "\n",
        "        if ensemble_results:\n",
        "            ensemble_items = list(ensemble_results.items())\n",
        "            ensemble_items.sort(key=lambda x: x[1]['f1'], reverse=True)\n",
        "            top_ensembles = ensemble_items[:10]\n",
        "\n",
        "            ensemble_names = [name.split('_')[-1] for name, _ in top_ensembles]\n",
        "            ensemble_f1s = [result['f1'] for _, result in top_ensembles]\n",
        "            ensemble_accs = [result['accuracy'] for _, result in top_ensembles]\n",
        "            ensemble_losses = [result['loss'] for _, result in top_ensembles]\n",
        "\n",
        "            x = np.arange(len(ensemble_names))\n",
        "            ax2 = fig.add_subplot(gs[0, 1])\n",
        "            ax2.bar(x - width, ensemble_accs, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "            ax2.bar(x, ensemble_f1s, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "            ax2.bar(x + width, ensemble_losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "            ax2.set_xticks(x)\n",
        "            ax2.set_xticklabels([f\"{name}\" for name in ensemble_names], rotation=45, ha='right', fontsize=10)\n",
        "            ax2.set_xlabel('Ensemble Methods', fontweight='bold', fontsize=12)\n",
        "            ax2.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "            ax2.set_title('Top Ensemble Methods', fontweight='bold', fontsize=14, pad=20)\n",
        "            ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.set_ylim(0, max(max(ensemble_accs), max(ensemble_f1s), max(ensemble_losses)) * 1.1)\n",
        "\n",
        "        if single_results:\n",
        "            per_class_f1 = []\n",
        "            for model_name in model_names:\n",
        "                per_class_f1.append(single_results[model_name]['f1_per_class'])\n",
        "\n",
        "            per_class_f1 = np.array(per_class_f1)\n",
        "            ax3 = fig.add_subplot(gs[1, 0])\n",
        "            im = ax3.imshow(per_class_f1, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "            ax3.set_xticks(range(len(Config.CLASS_LABELS)))\n",
        "            ax3.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right', fontsize=10)\n",
        "            ax3.set_yticks(range(len(model_names)))\n",
        "            ax3.set_yticklabels(model_names, fontsize=10)\n",
        "            ax3.set_title('Per-Class F1 Scores', fontweight='bold', fontsize=14, pad=20)\n",
        "\n",
        "            cbar = plt.colorbar(im, ax=ax3, shrink=0.8)\n",
        "            cbar.set_label('F1 Score', rotation=270, labelpad=15)\n",
        "\n",
        "            for i in range(len(model_names)):\n",
        "                for j in range(len(Config.CLASS_LABELS)):\n",
        "                    text_color = 'white' if per_class_f1[i, j] < 0.5 else 'black'\n",
        "                    ax3.text(j, i, f'{per_class_f1[i, j]:.2f}',\n",
        "                            ha=\"center\", va=\"center\", color=text_color, fontsize=8)\n",
        "\n",
        "        if ensemble_results:\n",
        "            best_single_f1 = max(f1_scores)\n",
        "            best_single_name = model_names[f1_scores.index(best_single_f1)]\n",
        "            best_ensemble_f1 = max([result['f1'] for result in ensemble_results.values()])\n",
        "            best_ensemble_name = max(ensemble_results.items(), key=lambda x: x[1]['f1'])[0]\n",
        "\n",
        "            ax4 = fig.add_subplot(gs[1, 1])\n",
        "            categories = ['Best Single\\nModel', 'Best Ensemble']\n",
        "            values = [best_single_f1, best_ensemble_f1]\n",
        "            colors = ['lightblue', 'gold']\n",
        "\n",
        "            bars = ax4.bar(categories, values, color=colors, alpha=0.8, width=0.6)\n",
        "            ax4.set_ylabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax4.set_title('Single vs Ensemble Comparison', fontweight='bold', fontsize=14, pad=20)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.set_ylim(0, 1)\n",
        "\n",
        "            for bar, value in zip(bars, values):\n",
        "                ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "                        f'{value:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
        "\n",
        "            improvement = ((best_ensemble_f1 - best_single_f1) / best_single_f1) * 100\n",
        "            ax4.text(0.5, 0.5, f'Improvement:\\n{improvement:.2f}%',\n",
        "                    transform=ax4.transAxes, ha='center', va='center',\n",
        "                    fontsize=14, fontweight='bold',\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"yellow\", alpha=0.8))\n",
        "\n",
        "        plt.suptitle('Fish Species Classification - Model Comparison Analysis',\n",
        "                    fontsize=18, fontweight='bold', y=0.96)\n",
        "        save_path = f\"{self.viz_dir}/enhanced_model_comparison.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced model comparison saved: {save_path}\")\n",
        "        return save_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_lrp_grid(self, single_models, test_loader):\n",
        "        print(\"Generating LRP grid visualization for TP, TN, FP, FN...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # Compute predictions and confusion matrix\n",
        "        model = list(single_models.values())[0]\n",
        "        model.eval()\n",
        "        true_labels = []\n",
        "        pred_labels = []\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                # images, labels = batch['image'].to(Config.DEVICE), batch['label'].to(Config.DEVICE)\n",
        "                # images, labels = batch[0].to(Config.DEVICE), batch[1].to(Config.DEVICE)  # Access tuple elements\n",
        "                # Make it consistent with your data loader format:\n",
        "                if isinstance(batch, dict):\n",
        "                    images, labels = batch['image'].to(Config.DEVICE), batch['label'].to(Config.DEVICE)\n",
        "                elif isinstance(batch, (list, tuple)) and len(batch) == 2:\n",
        "                    images, labels = batch[0].to(Config.DEVICE), batch[1].to(Config.DEVICE)\n",
        "                else:\n",
        "                    raise ValueError(f\"Unexpected batch format: {type(batch)}\")\n",
        "\n",
        "                outputs = model(images)\n",
        "                preds = outputs.argmax(dim=1) if outputs.dim() > 1 else (outputs > 0.5).float()\n",
        "                true_labels.extend(labels.cpu().numpy())\n",
        "                pred_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "        cm = confusion_matrix(true_labels, pred_labels)\n",
        "        classes = Config.CLASS_LABELS\n",
        "        tp = np.diag(cm)\n",
        "        fp = cm.sum(axis=0) - tp\n",
        "        fn = cm.sum(axis=1) - tp\n",
        "        tn = cm.sum() - (fp + fn + tp)\n",
        "        metrics = [tp, tn, fp, fn]\n",
        "\n",
        "        # Collect one image per class per category (TP, TN, FP, FN)\n",
        "        sample_images = {cls: {\"TP\": None, \"TN\": None, \"FP\": None, \"FN\": None} for cls in range(5)}\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                # images, labels = batch['image'].to(Config.DEVICE), batch['label'].to(Config.DEVICE)\n",
        "                # images, labels = batch[0].to(Config.DEVICE), batch[1].to(Config.DEVICE)  # Access tuple elements\n",
        "                # Make it consistent with your data loader format:\n",
        "                if isinstance(batch, dict):\n",
        "                    images, labels = batch['image'].to(Config.DEVICE), batch['label'].to(Config.DEVICE)\n",
        "                elif isinstance(batch, (list, tuple)) and len(batch) == 2:\n",
        "                    images, labels = batch[0].to(Config.DEVICE), batch[1].to(Config.DEVICE)\n",
        "                else:\n",
        "                    raise ValueError(f\"Unexpected batch format: {type(batch)}\")\n",
        "\n",
        "\n",
        "\n",
        "                outputs = model(images)\n",
        "                preds = outputs.argmax(dim=1) if outputs.dim() > 1 else (outputs > 0.5).float()\n",
        "                for img, true, pred in zip(images, labels, preds):\n",
        "                    cls = int(true.item())\n",
        "                    pred_cls = int(pred.item())\n",
        "                    for i in range(5):  # Check for each class\n",
        "                        category = {\n",
        "                            (1, 1): \"TP\",  # Predicted class i, true class i\n",
        "                            (0, 0): \"TN\",  # Predicted not i, true not i\n",
        "                            (1, 0): \"FP\",  # Predicted i, true not i\n",
        "                            (0, 1): \"FN\"   # Predicted not i, true i\n",
        "                        }[(1 if pred_cls == i else 0, 1 if cls == i else 0)]\n",
        "                        if sample_images[cls][category] is None:\n",
        "                            sample_images[cls][category] = (img, true)\n",
        "                    if all(sample_images[c][cat] is not None for c in range(5) for cat in [\"TP\", \"TN\", \"FP\", \"FN\"]):\n",
        "                        break\n",
        "                if all(sample_images[c][cat] is not None for c in range(5) for cat in [\"TP\", \"TN\", \"FP\", \"FN\"]):\n",
        "                    break\n",
        "\n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(5, 4, figsize=(30, 35))  # Large figure for clarity\n",
        "        for i in range(5):  # Classes\n",
        "            for j, category in enumerate([\"TP\", \"TN\", \"FP\", \"FN\"]):\n",
        "                ax = axes[i, j]\n",
        "                if sample_images[i][category] is not None:\n",
        "                    img, true = sample_images[i][category]\n",
        "                    img = img.squeeze().cpu()\n",
        "                    lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, img, i)\n",
        "                    img = img.permute(1, 2, 0).numpy()\n",
        "                    img = np.clip(img, 0, 1)\n",
        "                    img = img[..., [2, 1, 0]] if img.shape[2] == 3 else img  # Convert BGR to RGB\n",
        "                    img = (img * 255).astype(np.uint8)\n",
        "                    ax.imshow(img)\n",
        "                    lrp_img = (lrp_img - lrp_img.min()) / (lrp_img.max() - lrp_img.min() + 1e-8)  # Normalize heatmap\n",
        "                    ax.imshow(lrp_img, cmap='jet', alpha=0.4, vmin=0, vmax=np.percentile(lrp_img, 95))\n",
        "                    ax.set_title(f'{classes[i]} - {category}: {metrics[j][i]}', fontsize=16, fontweight='bold', pad=10)\n",
        "                ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        save_path = f\"{self.viz_dir}/lrp_fish_metrics_grid.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"LRP grid visualization saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_comparative_xai(self, single_models, ensemble_results, test_loader, max_images=5):\n",
        "        \"\"\"Generate comparative XAI visualizations with Grad-CAM++, Integrated Gradients, and LRP in the same row\"\"\"\n",
        "        print(f\"Generating comparative XAI visualizations for {max_images} images...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # Get sample images\n",
        "        # sample_images, sample_labels = next(iter(test_loader))\n",
        "        # sample_images = sample_images[:max_images].to(Config.DEVICE)\n",
        "        # sample_labels = sample_labels[:max_images].numpy()\n",
        "        sample_images = []\n",
        "        sample_labels = []\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            class_mask = np.where(test_loader.dataset.labels == i)[0]\n",
        "            if len(class_mask) > 0:\n",
        "                idx = np.random.choice(class_mask)\n",
        "                image, label = test_loader.dataset[idx]\n",
        "                if image.dim() == 4:\n",
        "                    image = image.squeeze(0)\n",
        "                sample_images.append(image.to(Config.DEVICE))\n",
        "                sample_labels.append(label)\n",
        "        sample_images = sample_images[:max_images]\n",
        "        sample_labels = sample_labels[:max_images]\n",
        "\n",
        "        # Get best ensemble if available\n",
        "        best_ensemble_name = max(ensemble_results.items(), key=lambda x: x[1]['f1'])[0] if ensemble_results else None\n",
        "        best_ensemble = ensemble_results.get(best_ensemble_name, None) if best_ensemble_name else None\n",
        "\n",
        "        for idx, (image, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
        "            try:\n",
        "                # Adjusted figure size with more height per row to prevent text cropping\n",
        "                num_rows = len(single_models) + (1 if best_ensemble else 0)\n",
        "                fig = plt.figure(figsize=(36, 14 * num_rows))  # Increased width and height per row\n",
        "                gs = fig.add_gridspec(num_rows, 4, wspace=0.3, hspace=0.5)  # Increased wspace and hspace for better spacing\n",
        "\n",
        "                # Prepare original image\n",
        "                image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                # Plot original image spanning all rows in first column\n",
        "                ax_orig = fig.add_subplot(gs[:, 0])\n",
        "                ax_orig.imshow(image_np)\n",
        "                ax_orig.set_title(f'Original Image\\nTrue: {Config.CLASS_LABELS[true_label]}',\n",
        "                                fontsize=16, fontweight='bold', pad=30)  # Increased pad for title\n",
        "                ax_orig.axis('off')\n",
        "\n",
        "                # Plot XAI for single models\n",
        "                for row, (model_name, model) in enumerate(single_models.items()):\n",
        "                    model.eval()\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(image.unsqueeze(0))\n",
        "                        probabilities = torch.softmax(outputs, dim=1)\n",
        "                        predicted_class = outputs.argmax(dim=1).item()\n",
        "                        confidence = probabilities[0, predicted_class].item()\n",
        "                        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                    # Generate Grad-CAM++ visualization\n",
        "                    gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(model, image, predicted_class)\n",
        "\n",
        "                    # Plot Grad-CAM++ in second column\n",
        "                    ax_gradcam = fig.add_subplot(gs[row, 1])\n",
        "                    ax_gradcam.imshow(gradcam_img)\n",
        "                    ax_gradcam.set_title(f'{model_name}\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                        fontsize=14, fontweight='bold', pad=30)  # Increased pad\n",
        "                    ax_gradcam.axis('off')\n",
        "\n",
        "                    # Generate Integrated Gradients visualization\n",
        "                    ig_img, _ = xai_visualizer.integrated_gradients(model, image, predicted_class)\n",
        "\n",
        "                    # Plot Integrated Gradients in third column\n",
        "                    ax_ig = fig.add_subplot(gs[row, 2])\n",
        "                    ax_ig.imshow(ig_img)\n",
        "                    ax_ig.set_title(f'{model_name}\\nIntegrated Gradients', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_ig.axis('off')\n",
        "\n",
        "                    # Generate LRP visualization\n",
        "                    lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, image, predicted_class)\n",
        "\n",
        "                    # Plot LRP in fourth column\n",
        "                    ax_lrp = fig.add_subplot(gs[row, 3])\n",
        "                    # ax_lrp.imshow(lrp_img)\n",
        "                    ax_lrp.imshow(cv2.cvtColor(lrp_img, cv2.COLOR_BGR2RGB))\n",
        "                    ax_lrp.set_title(f'{model_name}\\nLRP', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_lrp.axis('off')\n",
        "\n",
        "                # Plot XAI for best ensemble (if available)\n",
        "                if best_ensemble:\n",
        "                    ensemble_models = best_ensemble['models']\n",
        "                    with torch.no_grad():\n",
        "                        model_probs = []\n",
        "                        for model_name in ensemble_models:\n",
        "                            model = single_models[model_name]\n",
        "                            outputs = model(image.unsqueeze(0))\n",
        "                            probs = torch.softmax(outputs, dim=1)\n",
        "                            model_probs.append(probs)\n",
        "                        model_probs = torch.stack(model_probs, dim=1)\n",
        "\n",
        "                        # Load learnable ensemble model if applicable\n",
        "                        if 'learnable_weighted' in best_ensemble_name:\n",
        "                            ensemble_model = LearnableWeightedEnsemble(\n",
        "                                num_models=len(ensemble_models),\n",
        "                                num_classes=Config.NUM_CLASSES\n",
        "                            ).to(Config.DEVICE)\n",
        "                            # ensemble_model.load_state_dict(\n",
        "                            #     torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(ensemble_models)}.pt\")\n",
        "                            # )\n",
        "                            # PROBLEM: This line tries to load a model that may not exist\n",
        "                            # FIX: Add error handling and fallback\n",
        "                            try:\n",
        "                                model_path = f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(ensemble_models)}.pt\"\n",
        "                                if os.path.exists(model_path):\n",
        "                                    ensemble_model.load_state_dict(torch.load(model_path, map_location=Config.DEVICE))\n",
        "                                else:\n",
        "                                    # Fallback to simple weighted average if no saved learnable model\n",
        "                                    weights = best_ensemble.get('weights', np.ones(len(ensemble_models)) / len(ensemble_models))\n",
        "                                    outputs = torch.sum(model_probs * torch.tensor(weights, device=Config.DEVICE).view(1, -1, 1), dim=1)\n",
        "                                    predicted_class = outputs.argmax(dim=1).item()\n",
        "                                    confidence = torch.softmax(outputs, dim=1)[0, predicted_class].item()\n",
        "                            except Exception as e:\n",
        "                                print(f\"Error loading learnable ensemble model: {e}, using simple averaging\")\n",
        "                                weights = best_ensemble.get('weights', np.ones(len(ensemble_models)) / len(ensemble_models))\n",
        "                                outputs = torch.sum(model_probs * torch.tensor(weights, device=Config.DEVICE).view(1, -1, 1), dim=1)\n",
        "                                predicted_class = outputs.argmax(dim=1).item()\n",
        "                                confidence = torch.softmax(outputs, dim=1)[0, predicted_class].item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                            ensemble_model.eval()\n",
        "                            # outputs, _ = ensemble_model(model_probs)\n",
        "                            # TO THIS (ensure correct input format):\n",
        "                            if model_probs.dim() == 3:  # Already correct format\n",
        "                                outputs, learned_weights = ensemble_model(model_probs)\n",
        "                            else:  # Need to reshape\n",
        "                                model_probs_reshaped = model_probs.view(1, len(ensemble_models), Config.NUM_CLASSES)\n",
        "                                outputs, learned_weights = ensemble_model(model_probs_reshaped)\n",
        "\n",
        "                        else:\n",
        "                            weights = best_ensemble.get('weights', np.ones(len(ensemble_models)) / len(ensemble_models))\n",
        "                            outputs = torch.sum(model_probs * torch.tensor(weights, device=Config.DEVICE).view(1, -1, 1), dim=1)\n",
        "\n",
        "                        predicted_class = outputs.argmax(dim=1).item()\n",
        "                        confidence = torch.softmax(outputs, dim=1)[0, predicted_class].item()\n",
        "                        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                    # Approximate ensemble Grad-CAM++ by averaging\n",
        "                    gradcam_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(single_models[model_name], image, predicted_class)\n",
        "                        gradcam_imgs.append(gradcam_img)\n",
        "                    ensemble_gradcam = np.mean(gradcam_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble Grad-CAM++ in second column\n",
        "                    ax_gradcam = fig.add_subplot(gs[num_rows-1, 1])\n",
        "                    ax_gradcam.imshow(ensemble_gradcam)\n",
        "                    ax_gradcam.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                        fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_gradcam.axis('off')\n",
        "\n",
        "                    # Approximate ensemble Integrated Gradients by averaging\n",
        "                    ig_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        ig_img, _ = xai_visualizer.integrated_gradients(single_models[model_name], image, predicted_class)\n",
        "                        ig_imgs.append(ig_img)\n",
        "                    ensemble_ig = np.mean(ig_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble Integrated Gradients in third column\n",
        "                    ax_ig = fig.add_subplot(gs[num_rows-1, 2])\n",
        "                    ax_ig.imshow(ensemble_ig)\n",
        "                    ax_ig.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nIntegrated Gradients', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_ig.axis('off')\n",
        "\n",
        "                    # Approximate ensemble LRP by averaging\n",
        "                    lrp_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(single_models[model_name], image, predicted_class)\n",
        "                        lrp_imgs.append(lrp_img)\n",
        "                    ensemble_lrp = np.mean(lrp_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble LRP in fourth column\n",
        "                    ax_lrp = fig.add_subplot(gs[num_rows-1, 3])\n",
        "                    ax_lrp.imshow(ensemble_lrp)\n",
        "                    ax_lrp.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nLRP', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_lrp.axis('off')\n",
        "\n",
        "                # Adjusted suptitle with increased padding\n",
        "                plt.suptitle(f'Comparative XAI Analysis - Image {idx+1}', fontsize=18, fontweight='bold', y=0.97)\n",
        "                plt.tight_layout(rect=[0, 0, 1, 0.95])  # Added rect to ensure suptitle is not cropped\n",
        "                save_path = f\"{self.viz_dir}/comparative_xai_image_{idx+1}.png\"\n",
        "                plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "                plt.show()\n",
        "                print(f\"Comparative XAI visualization saved: {save_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating comparative XAI for image {idx+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 8. FULLY FIXED XAI VISUALIZATIONS\n",
        "# ================================================================================================================================\n",
        "# Purpose: Implement corrected Grad-CAM++ and LRP with proper tensor handling.\n",
        "\n",
        "class XAIVisualizer:\n",
        "    @staticmethod\n",
        "    def grad_cam_plus_plus(model, image, target_class):\n",
        "        \"\"\"Implement Grad-CAM++ for visualizing important image regions.\"\"\"\n",
        "        if image.dim() == 4:\n",
        "            image = image.squeeze(0)  # Normalize to (C, H, W)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Find the last convolutional layer\n",
        "        target_layer = None\n",
        "        for name, module in model.named_modules():  # Corrected: removed redundant reversed\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                target_layer = module\n",
        "\n",
        "        if target_layer is None:\n",
        "            raise ValueError(\"No convolutional layer found in the model\")\n",
        "\n",
        "        # Hook to capture gradients and activations\n",
        "        gradients = []\n",
        "        activations = []\n",
        "\n",
        "        def forward_hook(module, input, output):\n",
        "            activations.append(output.detach())\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            gradients.append(grad_output[0].detach())\n",
        "\n",
        "        # Register hooks\n",
        "        forward_handle = target_layer.register_forward_hook(forward_hook)\n",
        "        backward_handle = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "        try:\n",
        "            # Forward pass\n",
        "            image_tensor = image.unsqueeze(0).requires_grad_(True)\n",
        "            output = model(image_tensor)\n",
        "\n",
        "            # Backward pass\n",
        "            model.zero_grad()\n",
        "            score = output[0, target_class]\n",
        "            score.backward()\n",
        "\n",
        "            # Get gradients and activations\n",
        "            if not gradients or not activations:\n",
        "                raise ValueError(\"No gradients or activations captured\")\n",
        "\n",
        "            grad = gradients[0]  # Shape: (1, C, H, W)\n",
        "            act = activations[0]  # Shape: (1, C, H, W)\n",
        "\n",
        "            # Grad-CAM++ calculations\n",
        "            alpha_num = grad.pow(2)\n",
        "            alpha_denom = 2.0 * grad.pow(2) + (act * grad.pow(3)).sum(dim=(2, 3), keepdim=True)\n",
        "            alpha_denom = torch.where(alpha_denom != 0, alpha_denom, torch.ones_like(alpha_denom))\n",
        "            alpha = alpha_num / alpha_denom\n",
        "\n",
        "            weights = (alpha * F.relu(grad)).sum(dim=(2, 3))  # Shape: (1, C)\n",
        "            cam = (weights.unsqueeze(-1).unsqueeze(-1) * act).sum(dim=1, keepdim=True)  # Shape: (1, 1, H, W)\n",
        "            cam = F.relu(cam)\n",
        "\n",
        "            # Normalize\n",
        "            cam = cam - cam.min()\n",
        "            cam = cam / (cam.max() + 1e-8)\n",
        "\n",
        "            # Resize to input image size\n",
        "            cam = F.interpolate(cam, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "            cam = cam.squeeze().detach().cpu().numpy()\n",
        "\n",
        "            # Apply colormap\n",
        "            cam = (cam * 255).astype(np.uint8)\n",
        "            heatmap = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
        "\n",
        "            # Convert original image for visualization\n",
        "            image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "            image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "            image_np = np.clip(image_np, 0, 1)\n",
        "            image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "            # Superimpose heatmap\n",
        "            superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "            # superimposed_img = cv2.addWeighted(image_np[:, :, ::-1], 0.6, heatmap, 0.4, 0)  # Convert image_np to BGR for cv2\n",
        "            # superimposed_img = superimposed_img[:, :, ::-1]  # Back to RGB for display\n",
        "\n",
        "        finally:\n",
        "            # Remove hooks\n",
        "            forward_handle.remove()\n",
        "            backward_handle.remove()\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def integrated_gradients(model, image, target_class):\n",
        "        \"\"\"Integrated Gradients implementation.\"\"\"\n",
        "        if image.dim() == 4:\n",
        "            image = image.squeeze(0)  # Normalize to (C, H, W)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Detach the image first to avoid gradient issues\n",
        "        image_detached = image.detach()\n",
        "\n",
        "        # Create baseline (black image)\n",
        "        baseline = torch.zeros_like(image_detached)\n",
        "\n",
        "        # Generate path from baseline to image\n",
        "        num_steps = 30\n",
        "        alphas = torch.linspace(0, 1, num_steps).to(image_detached.device)\n",
        "\n",
        "        gradients = []\n",
        "        for alpha in alphas:\n",
        "            interpolated = baseline + alpha * (image_detached - baseline)\n",
        "            interpolated = interpolated.requires_grad_(True)\n",
        "\n",
        "            output = model(interpolated.unsqueeze(0))\n",
        "            score = output[0, target_class]\n",
        "\n",
        "            # Clear gradients\n",
        "            model.zero_grad()\n",
        "            if interpolated.grad is not None:\n",
        "                interpolated.grad.zero_()\n",
        "\n",
        "            score.backward()\n",
        "\n",
        "            # Detach gradient before storing\n",
        "            if interpolated.grad is not None:\n",
        "                gradients.append(interpolated.grad.detach().clone())\n",
        "\n",
        "            # Clear the gradient to free memory\n",
        "            interpolated.grad = None\n",
        "\n",
        "        if not gradients:\n",
        "            # Fallback: simple gradient\n",
        "            image_grad = image_detached.requires_grad_(True)\n",
        "            output = model(image_grad.unsqueeze(0))\n",
        "            score = output[0, target_class]\n",
        "            model.zero_grad()\n",
        "            score.backward()\n",
        "            gradients = [image_grad.grad.detach().clone()]\n",
        "\n",
        "        # Average gradients\n",
        "        avg_gradients = torch.stack(gradients).mean(dim=0)\n",
        "\n",
        "        # Compute integrated gradients\n",
        "        integrated_gradients = (image_detached - baseline) * avg_gradients\n",
        "\n",
        "        # Sum across color channels\n",
        "        relevance = integrated_gradients.abs().sum(dim=0).cpu().numpy()\n",
        "\n",
        "        # Normalize\n",
        "        relevance = relevance / (relevance.max() + 1e-8)\n",
        "\n",
        "        # Apply colormap\n",
        "        relevance = (relevance * 255).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(relevance, cv2.COLORMAP_JET)\n",
        "\n",
        "        # Convert original image for visualization\n",
        "        image_np = image_detached.permute(1, 2, 0).cpu().numpy()\n",
        "        image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "        # Superimpose heatmap\n",
        "        superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def layer_wise_relevance_propagation(\n",
        "        model,\n",
        "        image,\n",
        "        target_class=None,\n",
        "        device=\"cuda\",\n",
        "        input_size=None,\n",
        "        epsilon=1e-6,\n",
        "        imagenet_norm=True\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Layer-wise Relevance Propagation (LRP) with Captum and gradient fallback.\n",
        "\n",
        "        Args:\n",
        "            model: torch.nn.Module - trained model\n",
        "            image: torch.Tensor - input image (C, H, W) or (1, C, H, W)\n",
        "            target_class: int or None - class index, if None will be predicted\n",
        "            device: str - device (\"cuda\" or \"cpu\")\n",
        "            input_size: int or None - resize for visualization\n",
        "            epsilon: float - small value to avoid division by zero\n",
        "            imagenet_norm: bool - whether to denormalize using ImageNet mean/std\n",
        "\n",
        "        Returns:\n",
        "            superimposed_img (np.ndarray), heatmap (np.ndarray)\n",
        "        \"\"\"\n",
        "        import torch\n",
        "        import numpy as np\n",
        "        import cv2\n",
        "\n",
        "        model.eval()\n",
        "        model.to(device)\n",
        "\n",
        "        # Ensure correct input shape\n",
        "        if image.dim() == 4:\n",
        "            image = image.squeeze(0)\n",
        "        if image.dim() != 3:\n",
        "            raise ValueError(f\"Expected 3D image tensor (C,H,W), got {image.shape}\")\n",
        "\n",
        "        image_tensor = image.unsqueeze(0).to(device).requires_grad_(True)\n",
        "\n",
        "        # Determine target class\n",
        "        if target_class is None:\n",
        "            with torch.no_grad():\n",
        "                output = model(image_tensor)\n",
        "                target_class = output.argmax(dim=1).item()\n",
        "\n",
        "        try:\n",
        "            from captum.attr import LRP\n",
        "\n",
        "            lrp = LRP(model)\n",
        "            attributions = lrp.attribute(image_tensor, target=target_class)\n",
        "            if attributions is None:\n",
        "                raise ValueError(\"LRP attribution returned None\")\n",
        "\n",
        "            relevance = attributions.detach().cpu().squeeze(0)  # (C,H,W)\n",
        "            if relevance.dim() == 3:\n",
        "                relevance = relevance.sum(dim=0)  # (H,W)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Fallback: Gradient-based relevance\n",
        "            try:\n",
        "                model.zero_grad()\n",
        "                image_tensor = image_tensor.detach().requires_grad_(True)\n",
        "                output = model(image_tensor)\n",
        "\n",
        "                target_score = output[0, target_class]\n",
        "                target_score.backward()\n",
        "\n",
        "                if image_tensor.grad is None:\n",
        "                    raise ValueError(\"Gradients are None in fallback.\")\n",
        "\n",
        "                relevance = image_tensor.grad.detach().cpu().squeeze(0)\n",
        "                if relevance.dim() == 3:\n",
        "                    relevance = relevance.clamp(min=0).sum(dim=0)\n",
        "\n",
        "            except Exception as fallback_e:\n",
        "                print(f\"LRP + fallback failed: {fallback_e}\")\n",
        "                # Return original image and blank heatmap\n",
        "                image_np = image.permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "                heatmap = np.zeros_like(image_np, dtype=np.uint8)\n",
        "                return image_np, heatmap\n",
        "\n",
        "        # Normalize relevance\n",
        "        relevance = relevance.clamp(min=0)\n",
        "        if relevance.max() > 0:\n",
        "            relevance = relevance / (relevance.max() + epsilon)\n",
        "\n",
        "        relevance_map = relevance.numpy()\n",
        "        if input_size is not None and relevance_map.shape != (input_size, input_size):\n",
        "            relevance_map = cv2.resize(relevance_map, (input_size, input_size))\n",
        "\n",
        "        relevance_map = (relevance_map * 255).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(relevance_map, cv2.COLORMAP_JET)\n",
        "\n",
        "        # Prepare original image\n",
        "        image_np = image_tensor.detach().squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "        if imagenet_norm:\n",
        "            mean = np.array([0.485, 0.456, 0.406])\n",
        "            std = np.array([0.229, 0.224, 0.225])\n",
        "            image_np = image_np * std + mean\n",
        "\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "        # Superimpose heatmap\n",
        "        superimposed_img = cv2.addWeighted(image_np, 0.7, heatmap, 0.3, 0.0)\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 9. DATA LOADING AND PREPROCESSING\n",
        "# ================================================================================================================================\n",
        "# Purpose: Handle dataset creation, data loading, balancing with SMOTE, and data augmentation.\n",
        "\n",
        "\n",
        "class FishDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "\n",
        "        self.images = self._preprocess_images(images)\n",
        "        self.labels = labels.astype(np.int64)\n",
        "        self.transform = transform #Here means: Medium,Heavy or Any\n",
        "\n",
        "    def _preprocess_images(self, images):\n",
        "        \"\"\"Preprocess images to ensure proper format and normalization\"\"\"\n",
        "        if images.max() > 1.5: #👉 The threshold 1.5 is just a safe cutoff to distinguish between the two cases.\n",
        "            #Because some normalized images can have values slightly above 1.0 (e.g., after augmentations, rounding, or scaling bugs).\n",
        "            images = images.astype(np.float32) / 255.0\n",
        "\n",
        "        if len(images.shape) == 4 and images.shape[1] == 3: #If input is (batch, channels, height, width) → convert to (batch, height, width, channels) (common for TensorFlow).\n",
        "            images = np.transpose(images, (0, 2, 3, 1))\n",
        "        return images.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the total number of samples in the dataset\"\"\"\n",
        "        return len(self.images)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:  #Applies an Albumentations transform pipeline (it returns a dict, so you take ['image']).\n",
        "            image = self.transform(image=image)['image'] #\n",
        "        else:\n",
        "            image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "        #With transform → advanced augmentations.\n",
        "        #Without transform → just convert to PyTorch format.\n",
        "\n",
        "\n",
        "        # Convert label to plain Python int to avoid CUDA tensor creation in workers.That wastes memory and slows down training.\n",
        "        if isinstance(label, np.ndarray):\n",
        "            label = int(label.item())\n",
        "        elif hasattr(label, 'item'):\n",
        "            label = int(label.item())\n",
        "        else:\n",
        "            label = int(label)\n",
        "\n",
        "\n",
        "        return image, label  # Plain Python int, not torch.tensor\n",
        "        # return image, torch.tensor(int(label), dtype=torch.long)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def __getitem__(self, idx):\n",
        "    #     image = self.images[idx]  # H x W x C\n",
        "    #     label = self.labels[idx]\n",
        "\n",
        "    #     # Ensure image has 3 channels\n",
        "    #     if image.ndim == 2:  # grayscale H x W\n",
        "    #         image = np.stack([image]*3, axis=-1)\n",
        "    #     elif image.shape[-1] == 4:  # RGBA\n",
        "    #         image = image[:, :, :3]\n",
        "\n",
        "    #     # Apply Albumentations transform if any\n",
        "    #     if self.transform:\n",
        "    #         image = self.transform(image=image)['image']  # may already be tensor\n",
        "\n",
        "    #     # Convert to PyTorch tensor C x H x W if it's a numpy array\n",
        "    #     if isinstance(image, np.ndarray):\n",
        "    #         image = torch.from_numpy(image).permute(2, 0, 1).float()\n",
        "    #     elif isinstance(image, torch.Tensor) and image.ndim == 3 and image.shape[0] != 3:\n",
        "    #         # If transform returns H x W x C tensor, permute to C x H x W\n",
        "    #         image = image.permute(2, 0, 1).float()\n",
        "    #     # else assume it's already C x H x W\n",
        "\n",
        "    #     # Convert label to tensor\n",
        "    #     label = int(label) if not isinstance(label, torch.Tensor) else label.long()\n",
        "\n",
        "    #     return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # class MyClass:\n",
        "        #     def greet(self):\n",
        "        #         print(\"Hello!\")\n",
        "        # obj = MyClass()\n",
        "        # print(hasattr(obj, 'greet'))   # True, because obj has a method greet\n",
        "        # print(hasattr(obj, 'name'))    # False, no attribute called name\n",
        "        # # Using hasattr with .item()\n",
        "        # import torch\n",
        "        # x = torch.tensor(5)  # scalar tensor\n",
        "        # print(hasattr(x, 'item'))      # True\n",
        "        # print(x.item())                # 5\n",
        "\n",
        "        # return image, torch.tensor(label, dtype=torch.long)  # <-- ensure label is tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DataManager:\n",
        "    @staticmethod  #In Python, @staticmethod is used to define a method that belongs to a class but doesn’t access self or cls.\n",
        "\n",
        "    # class DataManager:\n",
        "    # staticmethod\n",
        "    # def greet(name):\n",
        "    #     return f\"Hello, {name}!\"\n",
        "    # # Call without creating an instance\n",
        "    # print(DataManager.greet(\"Imran\"))  # Output: Hello, Imran!\n",
        "    # # Call with an instance\n",
        "    # dm = DataManager()\n",
        "    # print(dm.greet(\"Imran\"))           # Output: Hello, Imran!\n",
        "\n",
        "    # class MyClass:\n",
        "    #     count = 0\n",
        "\n",
        "    #     staticmethod\n",
        "    #     def greet(name):\n",
        "    #         return f\"Hello, {name}!\"\n",
        "\n",
        "    #     classmethod\n",
        "    #     def increment_count(cls):\n",
        "    #         cls.count += 1\n",
        "    #         return cls.count\n",
        "\n",
        "    # # Static method\n",
        "    # print(MyClass.greet(\"Imran\"))      # Hello, Imran!\n",
        "    # # Class method\n",
        "    # print(MyClass.increment_count())   # 1\n",
        "    # print(MyClass.increment_count())   # 2\n",
        "    #Static method → independent of class/instance.\n",
        "    #Class method → works with the class itself (cls), can modify class variables.\n",
        "\n",
        "\n",
        "    def get_transforms(is_training=True, augmentation_strength='medium'):\n",
        "        \"\"\"Get data transforms with configurable augmentation strength\"\"\"\n",
        "        if is_training:\n",
        "            if augmentation_strength == 'light':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.3),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            elif augmentation_strength == 'heavy':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.7),\n",
        "                    A.VerticalFlip(p=0.5),\n",
        "                    A.RandomRotate90(p=0.7),\n",
        "                    # A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, p=0.8),\n",
        "                    # A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.8),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
        "                    # A.HueSaturationValue(hue_shift_limit=30, sat_shift_limit=40, val_shift_limit=30, p=0.7),\n",
        "                    A.GaussianBlur(blur_limit=(3, 9), p=0.5),\n",
        "                    A.GaussNoise(var_limit=(10.0, 80.0), p=0.4),\n",
        "                    A.CoarseDropout(max_holes=12, max_height=25, max_width=25, p=0.5),\n",
        "                    A.ElasticTransform(p=0.3),\n",
        "                    A.GridDistortion(p=0.3),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "                    A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3, p=0.3),\n",
        "                    A.RandomRain(blur_value=3, p=0.2),\n",
        "                    A.ColorJitter(hue=0.1, p=0.5),\n",
        "\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            else:  # medium\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.5),\n",
        "                    A.VerticalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.5),\n",
        "                    # A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.7),\n",
        "                    # A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.1),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
        "                    # A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.6),\n",
        "                    A.GaussianBlur(blur_limit=(3, 7), p=0.4),\n",
        "                    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "                    A.CoarseDropout(max_holes=8, max_height=20, max_width=20, p=0.4),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "        else:\n",
        "            return A.Compose([\n",
        "                A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def load_and_balance_data():\n",
        "        \"\"\"Load data and apply SMOTE\"\"\"\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "\n",
        "        # # Check GPU availability\n",
        "        # print(\"GPU Available:\", torch.cuda.is_available())\n",
        "        # print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "\n",
        "        # # Define fish classes and dataset paths\n",
        "        # fish_classes = ['ilish', 'chandana', 'sardin', 'sardinella', 'punctatus'] #0,1,2,3,4\n",
        "        # zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip').extractall('/content/.hidden_fish')\n",
        "        # data_dir = '/content/.hidden_fish'\n",
        "\n",
        "        # image_limits = {\n",
        "        #     'ilish': 3000,\n",
        "        #     'chandana': 1185,\n",
        "        #     'sardin': 2899,\n",
        "        #     'sardinella': 370,\n",
        "        #     'punctatus': 953\n",
        "        # }\n",
        "\n",
        "        # # Settings\n",
        "        # total_images = sum(image_limits.values())\n",
        "        # batch_size = 100\n",
        "        # num_threads = 4\n",
        "\n",
        "\n",
        "        # # Output paths\n",
        "        # output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "        # os.makedirs(output_dir, exist_ok=True)\n",
        "        # labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "        # xdata_file = os.path.join(output_dir, 'X_data.npy')\n",
        "\n",
        "        # save_lock = threading.Lock()  # for thread-safe writes -> Prevents race conditions when multiple threads write to the same list.\n",
        "\n",
        "        # # Function to gather image paths\n",
        "        # def get_image_paths(class_name, max_images):\n",
        "        #     path = os.path.join(data_dir, class_name)\n",
        "        #     files = sorted(os.listdir(path))\n",
        "        #     random.shuffle(files)\n",
        "        #     return [os.path.join(path, f) for f in files[:max_images]]\n",
        "\n",
        "        # # Load and preprocess batch\n",
        "        # def load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "        #     end_idx = min(start_idx + batch_size, len(image_paths))\n",
        "        #     batch_paths = image_paths[start_idx:end_idx]\n",
        "        #     batch_images = []\n",
        "\n",
        "        #     for img_path in batch_paths:\n",
        "        #         img = Image.open(img_path).resize((224, 224)).convert('RGB')\n",
        "        #         img_tensor = torch.tensor(np.array(img), dtype=torch.uint8).permute(2, 0, 1)  # C x H x W\n",
        "        #         batch_images.append(img_tensor)\n",
        "\n",
        "        #     batch_tensor = torch.stack(batch_images)  # B x C x H x W\n",
        "        #     batch_labels = np.full((len(batch_images),), class_idx, dtype=np.int32)\n",
        "        #     return batch_tensor, batch_labels\n",
        "\n",
        "        # # Process one batch and return tensors & labels (no file saving)\n",
        "        # def process_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "        #     return load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx)\n",
        "\n",
        "        # def preprocess_and_save_all(overwrite=True):\n",
        "        #     if os.path.exists(labels_file) and os.path.exists(xdata_file) and not overwrite:\n",
        "        #         print(\"Preprocessed data already exists. Set overwrite=True to reprocess.\")\n",
        "        #         return\n",
        "\n",
        "        #     all_images = []\n",
        "        #     all_labels = []\n",
        "        #     processed_count = 0\n",
        "\n",
        "        #     for idx, class_name in enumerate(fish_classes):\n",
        "        #         print(f\"\\nProcessing class: {class_name}\")\n",
        "        #         image_paths = get_image_paths(class_name, image_limits[class_name])\n",
        "        #         total_batches = (len(image_paths) + batch_size - 1) // batch_size\n",
        "        #         #It ensures ceiling division — rounding up, not down.\n",
        "        #         # Normal division: 103 / 20 = 5.15 → floor division // 20 = 5 (❌ missing last 3 images)\n",
        "        #         # This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ✅\n",
        "\n",
        "        #         with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "        #             futures = []\n",
        "        #             for start in range(0, len(image_paths), batch_size):\n",
        "        #                 futures.append(executor.submit(process_batch, image_paths, start, batch_size, idx))\n",
        "\n",
        "        #             for future in tqdm(as_completed(futures), total=total_batches, desc=class_name):#taqaddum (تقدّم) – Arabic for \"progress\".\n",
        "        #                 # futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\n",
        "        #                 # as_completed(futures): Yields each future as it finishes (not in order).\n",
        "\n",
        "        #                 batch_tensor, batch_labels = future.result()\n",
        "        #                 with save_lock: #Locks this section so that only one thread can update the shared lists safely.\n",
        "        #                     all_images.append(batch_tensor)\n",
        "        #                     all_labels.append(batch_labels)\n",
        "        #                     processed_count += batch_tensor.size(0)\n",
        "        #                     print(f\"Processed batch with {batch_tensor.size(0)} images, total processed: {processed_count}/{total_images}\")\n",
        "        #                 gc.collect()\n",
        "\n",
        "        #     # Combine all tensors and labels\n",
        "        #     X = torch.cat(all_images, dim=0).numpy()\n",
        "        #     Y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "        #     # Save final arrays\n",
        "        #     np.save(xdata_file, X, allow_pickle=False)#Malicious .npy -> import os;os.system(\"rm -rf /\")  # ← Dangerous command\n",
        "        #     np.save(labels_file, Y, allow_pickle=False)\n",
        "\n",
        "        #     print(f\"\\n✅ Done! Saved {processed_count} images in {xdata_file}\")\n",
        "        #     print(f\"X_data shape: {X.shape}, Y_labels shape: {Y.shape}\")\n",
        "\n",
        "        #     if processed_count != total_images:\n",
        "        #         raise ValueError(f\"Expected {total_images} images, but processed {processed_count}\")\n",
        "\n",
        "        # # Run preprocessing and save directly to X_data.npy and Y_labels.npy\n",
        "        # preprocess_and_save_all(overwrite=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        X = np.load(Config.DATA_FILE)\n",
        "        Y = np.load(Config.LABELS_FILE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # # Your data path\n",
        "        # output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "        # data_file = os.path.join(output_dir, 'X_data.npy')\n",
        "        # labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "\n",
        "        # # Readable size format\n",
        "        # def sizeof_fmt(num, suffix='B'):\n",
        "        #     for unit in ['', 'K', 'M', 'G', 'T']:\n",
        "        #         if abs(num) < 1024.0:\n",
        "        #             return f\"{num:3.2f} {unit}{suffix}\"\n",
        "        #         num /= 1024.0\n",
        "        #     return f\"{num:.2f} T{suffix}\"\n",
        "\n",
        "        # # Main loader\n",
        "        # def load_preprocessed_data(as_torch=True, normalize=True, to_device=None):\n",
        "        #     # Check file existence #cpu,cuda (CUDA stands for Compute Unified Device Architecture.)\n",
        "        #     for path in [data_file, labels_file]:\n",
        "        #         if not os.path.exists(path):\n",
        "        #             raise FileNotFoundError(f\"Missing: {path}\")\n",
        "\n",
        "        #     # Print file sizes\n",
        "        #     print(f\"📁 X_data.npy: {sizeof_fmt(os.path.getsize(data_file))}\")\n",
        "        #     print(f\"📁 Y_labels.npy: {sizeof_fmt(os.path.getsize(labels_file))}\")\n",
        "\n",
        "        #     # Load with mmap\n",
        "        #     X = np.load(data_file, mmap_mode='r')\n",
        "        #     Y = np.load(labels_file, mmap_mode='r')\n",
        "\n",
        "        #     print(f\"✅ X shape: {X.shape}, dtype: {X.dtype}\")\n",
        "        #     print(f\"✅ Y shape: {Y.shape}, dtype: {Y.dtype}\")\n",
        "\n",
        "        #     # Sanity check\n",
        "        #     if len(X) != len(Y):\n",
        "        #         raise ValueError(\"Mismatch between number of samples in X and Y\")\n",
        "\n",
        "        #     # Convert to torch\n",
        "        #     if as_torch:\n",
        "        #         X = torch.from_numpy(X)\n",
        "        #         Y = torch.from_numpy(Y)\n",
        "\n",
        "        #         if normalize and X.dtype == torch.uint8:\n",
        "        #             X = X.float() / 255.0\n",
        "\n",
        "        #         if to_device:\n",
        "        #             X = X.to(to_device)\n",
        "        #             Y = Y.to(to_device)\n",
        "\n",
        "        #         print(f\"🧠 Torch tensors ready on {to_device or 'CPU'}\")\n",
        "\n",
        "        #     return X, Y\n",
        "\n",
        "        # # 🔁 Example call\n",
        "        # X, Y = load_preprocessed_data(\n",
        "        #     as_torch=True,\n",
        "        #     normalize=True,\n",
        "        #     to_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        # )\n",
        "\n",
        "        # print(f\"\\nOriginal data shape: {X.shape}\")\n",
        "        # # print(f\"Original class distribution: {np.bincount(Y)}\")\n",
        "        # class_dist = np.bincount(Y.cpu().numpy()) if torch.is_tensor(Y) else np.bincount(Y)\n",
        "        # print(f\"Original class distribution: {class_dist}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # print(\"Applying SMOTE for class balancing...\")\n",
        "        # X_flat = X.reshape(X.shape[0], -1)\n",
        "        # smote = SMOTE(random_state=Config.SEED, k_neighbors=min(5, np.bincount(Y).min()-1))\n",
        "        # X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y)\n",
        "        # X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "        # print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        # print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "        # return X_balanced, Y_balanced\n",
        "\n",
        "\n",
        "\n",
        "        # Remove SMOTE completely and use WeightedRandomSampler only\n",
        "        # Using WeightedRandomSampler instead of SMOTE\n",
        "        # Compute weights and create sampler during DataLoader, not here\n",
        "        # return X, Y\n",
        "        # # Example data\n",
        "        # X = torch.randn(100, 3, 32, 32)  # 100 images\n",
        "        # Y = torch.randint(0, 5, (100,))  # 5 classes, imbalanced\n",
        "        # # Compute class weights\n",
        "        # class_counts = torch.bincount(Y)\n",
        "        # class_weights = 1.0 / class_counts.float()\n",
        "        # sample_weights = class_weights[Y]  # assign weight to each sample\n",
        "        # # Create sampler\n",
        "        # sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "        # # Create DataLoader\n",
        "        # dataset = TensorDataset(X, Y)\n",
        "        # loader = DataLoader(dataset, batch_size=16, sampler=sampler)\n",
        "\n",
        "\n",
        "\n",
        "        print(\"Applying SMOTE for class balancing...\")\n",
        "        # Apply SMOTE with reduced k_neighbors and combine with WeightedRandomSampler\n",
        "        X_flat = X.reshape(X.shape[0], -1)\n",
        "        smote = SMOTE(random_state=Config.SEED, k_neighbors=3, sampling_strategy='not majority')\n",
        "        # smote = SMOTE(random_state=Config.SEED, k_neighbors=2, sampling_strategy= 'auto')\n",
        "        X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y)\n",
        "        X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "        # Ensures WeightedRandomSampler is still used in DataLoader\n",
        "        print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "        return X_balanced, Y_balanced\n",
        "        # Benefit: Using a smaller k_neighbors=3 reduces the risk of generating unnatural\n",
        "        # image artifacts, while sampling_strategy='not majority' balances classes more conservatively.\n",
        "        # Retaining WeightedRandomSampler in the DataLoader further ensures balanced sampling during\n",
        "        # training, maintaining smoothness and preventing accuracy drops by avoiding over-reliance\n",
        "        # on SMOTE-generated samples.\n",
        "\n",
        "\n",
        "\n",
        "        # print(\"Applying SMOTE for class balancing...\")\n",
        "\n",
        "        # X_flat = X.cpu().numpy().reshape(X.shape[0], -1) if torch.is_tensor(X) else X.reshape(X.shape[0], -1)\n",
        "        # Y_np = Y.cpu().numpy() if torch.is_tensor(Y) else Y\n",
        "\n",
        "        # smote = SMOTE(random_state=Config.SEED, k_neighbors=3, sampling_strategy='not majority')\n",
        "        # X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y_np)\n",
        "        # X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "\n",
        "        # print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        # print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "        # return X_balanced, Y_balanced\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def create_data_loaders(X, Y, test_size=0.2, batch_size=None, augmentation_strength='medium'):\n",
        "\n",
        "\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(X, Y, test_size=test_size, random_state=Config.SEED, stratify=Y)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=Config.SEED, stratify=y_temp)\n",
        "\n",
        "        print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "        print(f\"Using optimized batch size: {batch_size}\")\n",
        "\n",
        "\n",
        "\n",
        "        train_dataset = FishDataset(X_train, y_train,DataManager.get_transforms(True, augmentation_strength))\n",
        "        val_dataset = FishDataset(X_val, y_val, DataManager.get_transforms(False))\n",
        "        test_dataset = FishDataset(X_test, y_test, DataManager.get_transforms(False))\n",
        "\n",
        "\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "        #compute_class_weight('balanced', ...) gives higher weight to minority classes.\n",
        "        sample_weights = [class_weights[y] for y in y_train]\n",
        "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "        # Samples with higher weights are more likely to be picked in each batch.\n",
        "        # replacement=True allows oversampling of minority classes. ✅\n",
        "\n",
        "\n",
        "        # Conditionally set prefetch_factor based on num_workers\n",
        "        prefetch_factor = 2 if Config.DATALOADER_NUM_WORKERS > 0 else None\n",
        "        pin_memory=Config.PIN_MEMORY if 'cuda' in Config.DEVICE else False\n",
        "        num_workers = Config.DATALOADER_NUM_WORKERS if torch.cuda.is_available() else 0\n",
        "        use_prefetch = num_workers > 0\n",
        "\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            # sampler=sampler, #Imbalanced dataset → use sampler.Balanced dataset → use shuffle=True.\n",
        "            shuffle=True,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "            # persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            # persistent_workers=False,\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "            # persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            # persistent_workers=False,\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "            # persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            # persistent_workers=False, #False is slow but exact reproductivity ensures & workers reset each epoch).\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "\n",
        "        return train_loader, val_loader, test_loader, (X_val, y_val), (X_test, y_test)\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 10. HYPERPARAMETER OPTIMIZATION\n",
        "# ================================================================================================================================\n",
        "# Purpose: Tune model hyperparameters using Optuna.\n",
        "# Add these imports at top of file\n",
        "import psutil  # ADDED: For CPU memory monitoring\n",
        "import gc      # ADDED: For garbage collection\n",
        "\n",
        "class ExpandedHyperparameterOptimizer:\n",
        "    def __init__(self, model_name, train_loader, val_loader):\n",
        "        self.model_name = model_name\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "\n",
        "        self.total_batches_per_epoch = len(train_loader)\n",
        "        self.batch_times = []\n",
        "        self.best_val_acc = 0.0\n",
        "        self.best_val_f1 = 0.0\n",
        "        self.best_trial = 0.0\n",
        "\n",
        "        # ADDED: Memory management attributes\n",
        "        # self.memory_check_interval = 40\n",
        "        # self.force_cleanup_threshold = 95\n",
        "\n",
        "        # self.val_f1 = 0.0\n",
        "        # self.history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_f1': [], 'learning_rates': []}\n",
        "\n",
        "\n",
        "\n",
        "    # def _update_progress(self, batch_idx, batch_loss, batch_acc, trial_params, is_training=True):\n",
        "    #     \"\"\"Display progress during hyperparameter tuning\"\"\"\n",
        "    #     batch_time = time.time()\n",
        "    #     self.batch_times.append(batch_time)\n",
        "\n",
        "    #     if len(self.batch_times) > 1:\n",
        "    #         avg_batch_time = np.mean(np.diff(self.batch_times[-10:]))\n",
        "    #     else:\n",
        "    #         avg_batch_time = 1.0\n",
        "\n",
        "    #     remaining_batches = self.total_batches_per_epoch - (batch_idx + 1)\n",
        "    #     eta_epoch = remaining_batches * avg_batch_time\n",
        "\n",
        "    #     progress_pct = (batch_idx + 1) / self.total_batches_per_epoch * 100\n",
        "    #     bar_length = 30\n",
        "    #     filled_length = int(bar_length * (batch_idx + 1) // self.total_batches_per_epoch)\n",
        "    #     bar = '█' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "    #     eta_str = str(timedelta(seconds=int(eta_epoch)))\n",
        "\n",
        "    #     mode = \"TRAIN\" if is_training else \"VAL  \"\n",
        "\n",
        "    #     # print(f\"\\r{mode} |{bar}| {progress_pct:5.1f}% | \"\n",
        "    #     #       f\"Batch: {batch_idx+1:4d}/{self.total_batches_per_epoch} | \"\n",
        "    #     #       f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
        "    #     #       f\"ETA: {eta_str} | Params: {self._format_params(trial_params)}\", end='', flush=True)\n",
        "\n",
        "    #     import sys\n",
        "    #     # Clear previous lines if not the first batch\n",
        "    #     if batch_idx > 0:\n",
        "    #         print(\"\\033[3A\\033[J\", end='')  # Move up 3 lines and clear from cursor down\n",
        "    #     # Line 1: Mode, progress bar, percentage, and batch info\n",
        "    #     print(f\"{mode} |{bar}| {progress_pct:5.1f}% | Batch: {batch_idx+1:4d}/{self.total_batches_per_epoch}\")\n",
        "    #     # Line 2: Loss, Accuracy, and ETA\n",
        "    #     print(f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | ETA: {eta_str}\")\n",
        "    #     # Line 3: Parameters\n",
        "    #     print(f\"Params: {self._format_params(trial_params)}\")\n",
        "    #     sys.stdout.flush()\n",
        "\n",
        "\n",
        "\n",
        "    # def _format_params(self, params):\n",
        "    #     \"\"\"Format hyperparameters for display\"\"\"\n",
        "    #     formatted = []\n",
        "    #     for key, value in params.items():\n",
        "    #         if key in ['lr', 'weight_decay']:\n",
        "    #             formatted.append(f\"{key}: {value:.4f}\")\n",
        "    #         elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "    #             formatted.append(f\"{key}: {value:.4f}\")\n",
        "    #         else:\n",
        "    #             formatted.append(f\"{key}: {value}\")\n",
        "    #     return \", \".join(formatted)\n",
        "\n",
        "\n",
        "\n",
        "    # best_val_f1 = 0.0  # Track best F1 in this trial                        # Added\n",
        "    # best_val_acc = 0.0  # Track corresponding acc for the best F1           # Added\n",
        "    # patience_counter = 0  # Local patience for early stopping in trial      # Added\n",
        "\n",
        "\n",
        "\n",
        "    def objective(self, trial):\n",
        "        # \"\"\"Optuna objective function with hyperparameters\"\"\"\n",
        "        # gpu_memory = get_available_gpu_memory()\n",
        "        # if gpu_memory > 24:\n",
        "        #     batch_size_options = [32, 64, 96, 128]\n",
        "        # elif gpu_memory > 12:\n",
        "        #     batch_size_options = [32, 64, 96]\n",
        "        # elif gpu_memory > 6:\n",
        "        #     batch_size_options = [32, 64]\n",
        "        # else:\n",
        "        #     batch_size_options = [16, 32]\n",
        "\n",
        "\n",
        "        lr = trial.suggest_float('lr', 1e-6, 5e-4, log=True)\n",
        "        batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 96, 128, 256])\n",
        "        # batch_size = trial.suggest_categorical('batch_size', batch_size_options)  # Use dynamic options\n",
        "        weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
        "        dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
        "        hidden_dim_multiplier = trial.suggest_float('hidden_dim_multiplier', 0.25, 1.0)\n",
        "        augmentation_strength = trial.suggest_categorical('augmentation_strength', ['light', 'medium', 'heavy'])\n",
        "        optimizer_type = trial.suggest_categorical('optimizer_type', ['adamw'])#, 'adam', 'sgd'])\n",
        "        scheduler_type = trial.suggest_categorical('scheduler_type',['cosine', 'plateau'])#, 'step', 'exponential'])\n",
        "        label_smoothing = trial.suggest_float('label_smoothing', 0.05, 0.15)\n",
        "\n",
        "\n",
        "        trial_params = {\n",
        "            'lr': lr, 'weight_decay': weight_decay, 'dropout': dropout,\n",
        "            'hidden_dim_multiplier': hidden_dim_multiplier, 'augmentation_strength': augmentation_strength,\n",
        "            'batch_size': batch_size, 'optimizer_type': optimizer_type, 'scheduler_type': scheduler_type,\n",
        "            'label_smoothing': label_smoothing\n",
        "        }\n",
        "\n",
        "\n",
        "        try:\n",
        "            print(f\"\\nTrial {trial.number+1}/{Config.OPTUNA_TRIALS} parameters for {self.model_name}:\")\n",
        "            for key, value in trial_params.items():\n",
        "                if key in ['lr', 'weight_decay']:\n",
        "                    print(f\"  {key}: {value:.4f}\")\n",
        "                elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                    print(f\"  {key}: {value:.4f}\")\n",
        "                else:\n",
        "                    print(f\"  {key}: {value}\")\n",
        "\n",
        "            # # Conditionally set prefetch_factor based on num_workers\n",
        "            prefetch_factor = 2 if Config.DATALOADER_NUM_WORKERS > 0 else None\n",
        "\n",
        "            temp_train_loader = DataLoader(\n",
        "                self.train_loader.dataset,\n",
        "                batch_size=batch_size,\n",
        "                sampler=self.train_loader.sampler,\n",
        "                num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "                pin_memory=Config.PIN_MEMORY,\n",
        "                prefetch_factor=prefetch_factor,\n",
        "                persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "                worker_init_fn=worker_init_fn  # Add this\n",
        "            )\n",
        "            temp_val_loader = DataLoader(\n",
        "                self.val_loader.dataset,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=False,\n",
        "                num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "                pin_memory=Config.PIN_MEMORY,\n",
        "                prefetch_factor=prefetch_factor,\n",
        "                persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "                worker_init_fn=worker_init_fn  # Add this\n",
        "            )\n",
        "            # temp_train_loader = self.train_loader\n",
        "            # temp_val_loader = self.val_loader\n",
        "\n",
        "\n",
        "\n",
        "            model = ModelFactory.create_model(\n",
        "                self.model_name,\n",
        "                dropout_rate=dropout,\n",
        "                hidden_dim_multiplier=hidden_dim_multiplier\n",
        "            )\n",
        "            model = model.to(Config.DEVICE)\n",
        "\n",
        "\n",
        "            if optimizer_type == 'adam':\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "            elif optimizer_type == 'adamw':\n",
        "                optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "            else:\n",
        "                optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay,momentum=0.9, nesterov=True)\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "            if scheduler_type == 'cosine':\n",
        "                scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.OPTUNA_EPOCHS)\n",
        "            elif scheduler_type == 'step':\n",
        "                scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.7)\n",
        "            else:\n",
        "                scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "\n",
        "\n",
        "            is_best = False\n",
        "            best_val_f1 = 0.0  # Local variable for trial-specific best F1 score\n",
        "            best_val_acc = 0.0  # Local variable for trial-specific best accuracy\n",
        "            patience_counter = 0.0  # Initialize patience counter\n",
        "\n",
        "            for optuna_epoch in range(Config.OPTUNA_EPOCHS):\n",
        "                self.batch_times = []\n",
        "                model.train()\n",
        "\n",
        "                train_correct = 0\n",
        "                train_total = 0\n",
        "                train_loss = 0\n",
        "\n",
        "                train_pbar = tqdm(temp_train_loader, desc=f\"Optuna Epoch {optuna_epoch+1}/{Config.OPTUNA_EPOCHS} Training\", leave=False)\n",
        "\n",
        "                # Corrected training loop in ExpandedHyperparameterOptimizer.objective\n",
        "                for batch_idx, (images, labels) in enumerate(train_pbar): #train_pbar\n",
        "                    if images.dim() == 3:\n",
        "                        images = images.unsqueeze(0)\n",
        "                    if images.dim() != 4:\n",
        "                        raise ValueError(f\"Expected 4D tensor, got {images.shape}\")\n",
        "\n",
        "\n",
        "                    # # ADDED: Memory monitoring every 40 batches\n",
        "                    # if batch_idx % self.memory_check_interval == 0:\n",
        "                    #     try:\n",
        "                    #         cpu_memory = psutil.virtual_memory()\n",
        "                    #         cpu_percent = cpu_memory.percent\n",
        "                    #         if torch.cuda.is_available():\n",
        "                    #             gpu_percent = (torch.cuda.memory_reserved() / torch.cuda.get_device_properties(0).total_memory) * 100\n",
        "                    #         else:\n",
        "                    #             gpu_percent = 0\n",
        "\n",
        "                    #         # Force cleanup at 95% threshold\n",
        "                    #         if cpu_percent >= self.force_cleanup_threshold or gpu_percent >= self.force_cleanup_threshold:\n",
        "                    #             torch.cuda.empty_cache()\n",
        "                    #             torch.cuda.synchronize()\n",
        "                    #             gc.collect()\n",
        "                    #             print(f\"\\nForce cleanup: CPU {cpu_percent:.1f}%, GPU {gpu_percent:.1f}%\")\n",
        "                    #     except:\n",
        "                    #         pass\n",
        "\n",
        "\n",
        "\n",
        "                    # Move data to device with optimized memory format\n",
        "                    images = images.to(Config.DEVICE, non_blocking=True, memory_format=torch.channels_last)\n",
        "                    # images = images.contiguous(memory_format=torch.channels_last)\n",
        "                    labels = labels.to(Config.DEVICE, non_blocking=True)\n",
        "                    # images, labels = images.to(Config.DEVICE, non_blocking=True), labels.to(Config.DEVICE, non_blocking=True)\n",
        "                    # images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    # if torch.cuda.is_available():\n",
        "                    #     torch.cuda.empty_cache()\n",
        "                    # device = Config.DEVICE if hasattr(Config, 'DEVICE') and Config.DEVICE else torch.device('cpu')\n",
        "                    # images, labels = images.to(device), labels.to(device)\n",
        "                    # Fix shape before moving to device\n",
        "                    # if len(images.shape) == 3:\n",
        "                    #     images = images.unsqueeze(0)\n",
        "                    # images = images.to(Config.DEVICE)\n",
        "                    # labels = torch.tensor(labels).to(Config.DEVICE) if not isinstance(labels, torch.Tensor) else labels.to(Config.DEVICE)\n",
        "\n",
        "                    optimizer.zero_grad(set_to_none=True)\n",
        "                    with torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "                        outputs = model(images)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "\n",
        "                    batch_loss = loss.item()\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    train_total += labels.size(0)\n",
        "                    train_correct += (predicted == labels).sum().item()\n",
        "                    train_loss += batch_loss\n",
        "                    batch_acc = train_correct / train_total\n",
        "\n",
        "                    #Show the Training Progress\n",
        "                    # self._update_progress(batch_idx, batch_loss, batch_acc, trial_params, is_training=True)\n",
        "                    train_pbar.set_postfix({'loss': f'{batch_loss:.4f}', 'acc': f'{batch_acc:.4f}'})\n",
        "\n",
        "                    # ENHANCED: Memory cleanup\n",
        "                    del images, labels, outputs, loss, predicted\n",
        "                    # if batch_idx % 40 == 0:\n",
        "                    #     torch.cuda.empty_cache()\n",
        "                    #     gc.collect()  # ADDED: Garbage collection\n",
        "\n",
        "                model.eval()\n",
        "\n",
        "                val_correct = 0\n",
        "                val_total = 0\n",
        "                val_loss = 0\n",
        "                val_predictions = []\n",
        "                val_labels = []\n",
        "\n",
        "                val_pbar = tqdm(temp_val_loader, desc=f\"Optuna Epoch {optuna_epoch+1}/{Config.OPTUNA_EPOCHS} Validation\", total=len(temp_val_loader), leave=False)\n",
        "\n",
        "\n",
        "\n",
        "                from sklearn.metrics import f1_score\n",
        "                # from torchmetrics.functional import F1Score\n",
        "                # GPU-based torchmetrics (commented out)\n",
        "                # f1_metric = F1Score(task=\"multiclass\", num_classes=Config.NUM_CLASSES, average=\"macro\").to(Config.DEVICE)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for batch_idx, (images, labels) in enumerate(val_pbar): #val_pbar\n",
        "                        # # ADDED: Memory check every 5 batches during validation\n",
        "                        # if batch_idx % 40 == 0:\n",
        "                        #     try:\n",
        "                        #         cpu_percent = psutil.virtual_memory().percent\n",
        "                        #         gpu_percent = (torch.cuda.memory_reserved() / torch.cuda.get_device_properties(0).total_memory) * 100 if torch.cuda.is_available() else 0\n",
        "                        #         if cpu_percent >= self.force_cleanup_threshold or gpu_percent >= self.force_cleanup_threshold:\n",
        "                        #             torch.cuda.empty_cache()\n",
        "                        #             gc.collect()\n",
        "                        #     except:\n",
        "                        #         pass\n",
        "                        images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                        outputs = model(images)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        batch_loss = loss.item()\n",
        "                        val_loss += batch_loss\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "                        # outputs = tensor([[1.2, 0.5, 2.1],[0.3, 4.1, 1.0]])\n",
        "                        # _, predicted = torch.max(outputs, 1)\n",
        "                        # print(predicted)  # tensor([2, 1]) → class 2 for first sample, class 1 for second\n",
        "                        val_total += labels.size(0)\n",
        "                        val_correct += (predicted == labels).sum().item()\n",
        "\n",
        "                        # Store predictions and labels on CPU for sklearn F1Score calculation\n",
        "                        val_predictions.extend(predicted.cpu().numpy())\n",
        "                        val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                        # GPU tensor storage (commented out)\n",
        "                        # val_predictions.append(predicted)   # keep tensors on GPU\n",
        "                        # val_labels.append(labels)           # keep tensors on GPU\n",
        "\n",
        "                        batch_acc = val_correct / val_total\n",
        "                        #Show the Validation Progress\n",
        "                        val_pbar.set_postfix({'loss': f'{batch_loss:.4f}', 'acc': f'{batch_acc:.4f}'})\n",
        "                        # ADDED: Memory cleanup for validation\n",
        "                        del images, labels, outputs, loss, predicted\n",
        "                        # if batch_idx % 40 == 0:  # Less frequent cleanup in validation\n",
        "                        #     torch.cuda.empty_cache()\n",
        "\n",
        "                # CPU-based F1Score calculation using sklearn\n",
        "                # val_f1_score = f1_score(val_labels, val_predictions, average='macro')\n",
        "\n",
        "                # GPU-based torchmetrics calculation (commented out)\n",
        "                # val_predictions_tensor = torch.cat(val_predictions).cpu().numpy()\n",
        "                # val_labels_tensor = torch.cat(val_labels).cpu().numpy()\n",
        "\n",
        "                train_acc = train_correct / train_total\n",
        "                val_acc = val_correct / val_total\n",
        "\n",
        "\n",
        "\n",
        "                # self._update_progress(batch_idx, batch_loss, batch_acc, trial_params, is_training=False)  # ✅ is_training=False\n",
        "                # val_f1 = f1_score(val_labels, val_predictions, average='macro')\n",
        "                scheduler.step()\n",
        "\n",
        "\n",
        "                #from torchmetrics.classification import F1Score\n",
        "                #initialize before training loop\n",
        "                # f1_metric = F1Score(task=\"multiclass\", num_classes=Config.NUM_CLASSES, average=\"macro\").to(Config.DEVICE)\n",
        "                # val_f1 = f1_metric.compute().item()   # stays on GPU, returns scalar\n",
        "                val_f1 = f1_score(val_labels, val_predictions, average='macro')\n",
        "\n",
        "\n",
        "                #For Opturna Report Purpose\n",
        "                trial.report(val_f1, step=optuna_epoch)\n",
        "\n",
        "                print(f\"\\nTrial {trial.number+1} Optuna Epoch {optuna_epoch+1} completed for Model: {self.model_name}\"\n",
        "                      f\"\\nOptuna Epoch {optuna_epoch+1}/{Config.OPTUNA_EPOCHS} Summary: \"\n",
        "                      f\"TL: {train_loss/len(temp_train_loader):.6f}, \"\n",
        "                      f\"VL: {val_loss/len(temp_val_loader):.6f}, \"\n",
        "                      f\"TA: {train_acc:.4f}, \"\n",
        "                      f\"VA: {val_acc:.4f}, \"\n",
        "                      f\"VF1: {val_f1:.4f}\\n\")\n",
        "\n",
        "\n",
        "                if val_f1 >= best_val_f1 * 1.001:  # Use self.best_val_f1 for class-level tracking\n",
        "                    # self.best_trial = trial.number + 1\n",
        "                    best_val_f1 = val_f1\n",
        "                    best_val_acc = val_acc\n",
        "                    patience_counter = 0\n",
        "                    is_best = True\n",
        "                    # Optional: Save model checkpoint if needed\n",
        "                    # torch.save(model.state_dict(), f\"{Config.OUTPUT_DIR}/trial_best_model/trial_{trial.number}_best.pt\")\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "\n",
        "                #Early stopping for Epoch Level\n",
        "                if patience_counter >= Config.PATIENCE:\n",
        "                    print(f\"Early stopping at epoch {optuna_epoch + 1}: No improvement >= 0.1% in val_f1 for {Config.PATIENCE} validations\")\n",
        "                    break\n",
        "\n",
        "\n",
        "                #Early stopping for Trial Level\n",
        "                logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "                try:\n",
        "                    # F1-based pruning (Optuna standard)\n",
        "                    if optuna_epoch >= 4:\n",
        "                        trial.report(val_f1, optuna_epoch)\n",
        "\n",
        "                        if trial.should_prune():\n",
        "                            best_f1 = max([t.value for t in trial.study.trials if t.value is not None], default=val_f1)\n",
        "                            msg = (f\"⛔ Trial {trial.number + 1} stopped at epoch {optuna_epoch + 1}: \"  #logging.info(\n",
        "                                  f\"val_f1={val_f1:.4f} is below best_f1={best_f1:.4f}.\"\n",
        "                                  f\"Pruning trial to focus on better candidates.\"\n",
        "                            )\n",
        "                            print(msg)               # show message\n",
        "                            logging.info(msg)        # log message\n",
        "                            trial.set_user_attr(\"pruned_reason\", msg)\n",
        "                            raise optuna.TrialPruned()\n",
        "\n",
        "                    # Custom accuracy-based stopping rule\n",
        "                    if optuna_epoch + 1 >= 5 and val_f1 < 0.90:\n",
        "                        msg = (f\"⛔ Trial {trial.number + 1} stopped at epoch {optuna_epoch + 1}: \"\n",
        "                              f\"val_f1={val_f1:.4f} did not reach even 30% after 5 epochs.So Skipping this epoch....\")\n",
        "                        print(msg)                   # show message\n",
        "                        logging.info(msg)            # log message\n",
        "                        trial.set_user_attr(\"pruned_reason\", msg)\n",
        "                        raise optuna.TrialPruned()\n",
        "\n",
        "\n",
        "                except optuna.TrialPruned as e:\n",
        "                    msg = (f\"⛔ Trial {trial.number + 1} stopped at epoch {optuna_epoch + 1}: \"\n",
        "                           f\"val_f1={val_f1:.4f} is below best_f1={best_f1:.4f}. \"\n",
        "                           f\"Pruning trial to focus on better candidates.\")\n",
        "                    print(msg)   # or logging.info(msg)\n",
        "                    #pass\n",
        "                    raise\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Update class-level tracking\n",
        "            if best_val_f1 > self.best_val_f1  :\n",
        "                self.best_val_f1 = best_val_f1\n",
        "                self.best_val_acc = best_val_acc\n",
        "                self.best_trial = trial.number + 1\n",
        "\n",
        "                # print(f\"\\n\\033[1;31mNew best result found for Trial {self.best_trial}:\\033[0m\")\n",
        "                if (trial.number+1!=1):\n",
        "                    print(f\"\\n\\033[1;31mNew best result found for Trial {self.best_trial}:\\033[0m\")\n",
        "                else:\n",
        "                    print(f\"\\n\\033[1;31mThis is the First Trial. So No Scope for Judgement.\\033[0m\")\n",
        "\n",
        "                print(f\"Validation Accuracy: {self.best_val_acc:.4f}\")\n",
        "                print(f\"Validation F1 Score: {self.best_val_f1:.4f}\")\n",
        "\n",
        "            else:\n",
        "                print(f\"\\nTrial {trial.number+1} did not improved the accuracy.\") # overall best (Current best F1: {self.best_val_f1:.4f})\")\n",
        "\n",
        "\n",
        "            if (trial.number+1>1):\n",
        "                print(f\"\\n\\033[1;31mTrial {self.best_trial} holds best result up to this:\\033[0m\")\n",
        "                print(f\"Validation Accuracy: {self.best_val_acc:.4f}\")\n",
        "                print(f\"Validation F1 Score: {self.best_val_f1:.4f}\")\n",
        "\n",
        "            # ADDED: Trial cleanup before return\n",
        "            try:\n",
        "                del model, optimizer, scheduler, criterion\n",
        "                del temp_train_loader, temp_val_loader\n",
        "                del val_predictions, val_labels\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            return self.best_val_f1  # Return the last epoch's F1 for Optuna to maximize\n",
        "\n",
        "        except Exception as e:\n",
        "            import traceback\n",
        "            print(f\"\\nTrial {trial.number+1} Skipped with : {str(e)}\\n{traceback.format_exc()} cause F1 Not Improving!!!!\")\n",
        "\n",
        "            # ADDED: Emergency cleanup on error\n",
        "            try:\n",
        "                del model, optimizer, scheduler, criterion\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            return 0.0 #✅This is a safe pattern for Optuna trials when an unexpected error occurs and you want to skip the trial without crashing your training loop.\n",
        "\n",
        "\n",
        "\n",
        "    def optimize(self):\n",
        "        print(f\"Optimizing hyperparameters for {self.model_name} : \")\n",
        "\n",
        "        if not OPTUNA_AVAILABLE:\n",
        "            return {\n",
        "                'lr': Config.LEARNING_RATE,\n",
        "                'dropout': 0.5,\n",
        "                'weight_decay': Config.WEIGHT_DECAY,\n",
        "                'hidden_dim_multiplier': 0.5,\n",
        "                'augmentation_strength': 'medium',\n",
        "                'batch_size': Config.BATCH_SIZE,\n",
        "                'optimizer_type': 'adamw',\n",
        "                'scheduler_type': 'cosine',\n",
        "                'label_smoothing': 0.1\n",
        "            }\n",
        "\n",
        "        # Successive Halving Pruner\n",
        "        pruner = optuna.pruners.SuccessiveHalvingPruner(\n",
        "            min_resource=3,        # first rung uses 10 epochs\n",
        "            reduction_factor=4,     # top 1/4 survive each rung\n",
        "            min_early_stopping_rate=0,  # optional, can start from first rung\n",
        "        )\n",
        "        study = optuna.create_study(direction='maximize',pruner=pruner)\n",
        "\n",
        "        # study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner(n_warmup_steps=4))\n",
        "        # study = optuna.create_study(direction='maximize', pruner=optuna.pruners.SuccessiveHalvingPruner(min_resource=1, reduction_factor=4))\n",
        "        # The number of epochs per rung is controlled by min_resource and how you report steps (trial.report(val, step=epoch)).\n",
        "\n",
        "\n",
        "        optuna.logging.set_verbosity(optuna.logging.WARNING)  # Suppress info-level logs\n",
        "        study.optimize(self.objective, n_trials=Config.OPTUNA_TRIALS, timeout=3600)#, callbacks=[callback])\n",
        "\n",
        "        best_params = study.best_trial.params\n",
        "\n",
        "        # print(f\"\\nBest params for {self.model_name}:\")\n",
        "        # for key, value in best_params.items():\n",
        "        #     if key in ['lr', 'weight_decay']:\n",
        "        #         print(f\"  {key}: {value:.4f}\")\n",
        "        #     elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "        #         print(f\"  {key}: {value:.6f}\")\n",
        "        #     else:\n",
        "        #         print(f\"  {key}: {value}\")\n",
        "        # print(f\"Best validation accuracy: {study.best_trial.value:.4f}\")\n",
        "\n",
        "        return best_params\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 11. MODEL EVALUATION (FIXED)\n",
        "# =============================================================================\n",
        "class ModelEvaluator:\n",
        "    @staticmethod\n",
        "    def evaluate_model(model, test_loader, model_name):\n",
        "        try:\n",
        "            print(f\"\\nEvaluating For Model: {model_name}...\")\n",
        "            model.eval()\n",
        "\n",
        "            all_preds = []\n",
        "            all_labels = []\n",
        "            misclassified = []\n",
        "            total_loss = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            all_probs = []\n",
        "\n",
        "            if test_loader is None or len(test_loader.dataset) == 0:\n",
        "                print(f\"Warning: No test data available for {model_name}\")\n",
        "                return ModelEvaluator._create_empty_result(model_name)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "                    # CPU version\n",
        "                    # images, labels = images.cpu(), labels.cpu()\n",
        "                    #GPU version\n",
        "                    # Keep everything on the same device as the model\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "\n",
        "\n",
        "\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    total_loss += loss.item()\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                    # all_preds.extend(predicted.numpy())\n",
        "                    # all_labels.extend(labels.numpy())\n",
        "                    # To this:\n",
        "                    all_preds.extend(predicted.cpu().numpy())\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "                    # Convert logits to probabilities\n",
        "                    prob = torch.softmax(outputs, dim=1)\n",
        "                    # Store probabilities\n",
        "                    all_probs.append(prob.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    # Identify misclassified\n",
        "                    incorrect_mask = predicted != labels\n",
        "                    if incorrect_mask.any():\n",
        "                        incorrect_images = images[incorrect_mask]\n",
        "                        incorrect_labels = labels[incorrect_mask]\n",
        "                        incorrect_preds = predicted[incorrect_mask]\n",
        "                        for img, true_label, pred_label in zip(incorrect_images, incorrect_labels, incorrect_preds):\n",
        "                            misclassified.append({\n",
        "                                'image': img,\n",
        "                                'true_label': int(true_label),\n",
        "                                'pred_label': int(pred_label)\n",
        "                            })\n",
        "                    del images, labels, outputs, loss, predicted\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    # ---------------- GPU VERSION (commented) ----------------\n",
        "                    # images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    # outputs = model(images)\n",
        "                    # loss = criterion(outputs, labels)\n",
        "                    # _, predicted = torch.max(outputs.data, 1)\n",
        "                    # all_preds.append(predicted)\n",
        "                    # all_labels.append(labels)\n",
        "                    # --------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "            # CPU metrics\n",
        "            # Convert to single array\n",
        "            all_probs = np.concatenate(all_probs, axis=0)  # shape: (num_samples, num_classes)\n",
        "            # all_probs = [\n",
        "            #     (32, 5),   # batch 1: 32 samples × 5 classes\n",
        "            #     (32, 5),   # batch 2: 32 samples × 5 classes\n",
        "            #     (16, 5)    # batch 3: 16 samples × 5 classes\n",
        "            # ]\n",
        "            # result shape = (32 + 32 + 16, 5) = (80, 5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            all_preds = np.array(all_preds)\n",
        "            all_labels = np.array(all_labels)\n",
        "            avg_loss = total_loss / len(test_loader)\n",
        "            accuracy = accuracy_score(all_labels, all_preds)\n",
        "            f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "            f1_weighted = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "            precision_macro = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "            recall_macro = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "            f1_per_class = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "            precision_per_class = precision_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "            recall_per_class = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "            conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "            print(f\"{model_name} Evaluation: Acc = {accuracy:.4f}, F1 (Macro) = {f1_macro:.4f}, Loss = {avg_loss:.4f}\")\n",
        "            print(f\"Data shapes - Labels: {all_labels.shape}, Predictions: {all_preds.shape}\")\n",
        "\n",
        "            return {\n",
        "                'all_preds': all_preds,\n",
        "                'all_labels': all_labels,\n",
        "                'all_probs': all_probs,\n",
        "\n",
        "\n",
        "                'model_name': model_name,\n",
        "                'accuracy': accuracy,\n",
        "                'f1_macro': f1_macro,\n",
        "                'f1_weighted': f1_weighted,\n",
        "                'precision_macro': precision_macro,\n",
        "                'recall_macro': recall_macro,\n",
        "                'f1_per_class': f1_per_class,\n",
        "                'precision_per_class': precision_per_class,\n",
        "                'recall_per_class': recall_per_class,\n",
        "                'predictions': all_preds,\n",
        "                'true_labels': all_labels,\n",
        "                # 'probabilities': None,  # CPU version\n",
        "                'probabilities': all_probs,  # correctly collected probabilities\n",
        "                'conf_matrix': conf_matrix,\n",
        "                'loss': avg_loss,\n",
        "                'misclassified': misclassified\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Evaluation error for {model_name}: {e}\")\n",
        "            return ModelEvaluator._create_empty_result(model_name)\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_empty_result(model_name):\n",
        "        return {\n",
        "            'model_name': model_name,\n",
        "            'accuracy': 0.0,\n",
        "            'f1_macro': 0.0,\n",
        "            'f1_weighted': 0.0,\n",
        "            'precision_macro': 0.0,\n",
        "            'recall_macro': 0.0,\n",
        "            'f1_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "            'precision_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "            'recall_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "            'predictions': np.array([]),\n",
        "            'true_labels': np.array([]),\n",
        "            'probabilities': np.array([]),\n",
        "            'conf_matrix': np.zeros((Config.NUM_CLASSES, Config.NUM_CLASSES)),\n",
        "            'loss': 0.0,\n",
        "            'misclassified': []\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 12. MODEL TRAINING\n",
        "# =============================================================================\n",
        "# Purpose: Train individual models with optimized hyperparameters.\n",
        "\n",
        "class EnhancedModelTrainer:\n",
        "    def __init__(self, model, model_name, hyperparameters):\n",
        "        self.model = model.to(Config.DEVICE)\n",
        "        self.model_name = model_name\n",
        "        self.hyperparameters = hyperparameters\n",
        "        self.best_val_acc = 0.0\n",
        "        self.best_val_f1 = 0.0\n",
        "        self.patience_counter = 0\n",
        "\n",
        "        # Resource management\n",
        "        self.resource_manager = ResourceManager()\n",
        "        self.memory_check_interval = 15\n",
        "\n",
        "\n",
        "\n",
        "        self._setup_training_components()\n",
        "\n",
        "\n",
        "\n",
        "        # Initialize history\n",
        "        self.history = {\n",
        "            'train_loss': [], 'train_acc': [], 'val_loss': [],\n",
        "            'val_acc': [], 'val_f1': [], 'learning_rates': []\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _setup_training_components(self):\n",
        "        \"\"\"Setup optimizer, criterion, and scheduler\"\"\"\n",
        "        allowed_keys = ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier',\n",
        "                       'augmentation_strength', 'batch_size', 'optimizer_type',\n",
        "                       'scheduler_type', 'label_smoothing']\n",
        "        self.hyperparameters = {k: v for k, v in self.hyperparameters.items() if k in allowed_keys}\n",
        "\n",
        "        # Optimizer setup\n",
        "        lr = self.hyperparameters.get('lr', Config.LEARNING_RATE)\n",
        "        weight_decay = self.hyperparameters.get('weight_decay', Config.WEIGHT_DECAY)\n",
        "        optimizer_type = self.hyperparameters.get('optimizer_type', 'adamw')\n",
        "\n",
        "        if optimizer_type == 'adamw':\n",
        "            self.optimizer = optim.AdamW(\n",
        "                self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                fused=torch.cuda.is_available()\n",
        "            )\n",
        "        elif optimizer_type == 'adam':\n",
        "            self.optimizer = optim.Adam(\n",
        "                self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                fused=torch.cuda.is_available()\n",
        "            )\n",
        "        else:\n",
        "            self.optimizer = optim.SGD(\n",
        "                self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                momentum=0.9, nesterov=True\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "        # Criterion\n",
        "        label_smoothing = self.hyperparameters.get('label_smoothing', 0.1)\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "        # Scheduler\n",
        "        scheduler_type = self.hyperparameters.get('scheduler_type', 'cosine')\n",
        "        if scheduler_type == 'cosine':\n",
        "            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "                self.optimizer, T_max=Config.EPOCHS, eta_min=1e-6\n",
        "            )\n",
        "        elif scheduler_type == 'plateau':\n",
        "            self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                self.optimizer, mode='min', factor=0.5, patience=5\n",
        "            )\n",
        "        else:\n",
        "            self.scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.95)\n",
        "\n",
        "\n",
        "        # Mixed precision scaler\n",
        "        self.scaler = torch.cuda.amp.GradScaler(enabled=Config.USE_MIXED_PRECISION)\n",
        "\n",
        "\n",
        "\n",
        "    def train_epoch(self, train_loader, progress_tracker):\n",
        "        \"\"\"Enhanced training epoch with smart memory management\"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        batch_count = len(train_loader)\n",
        "\n",
        "        tqdm.write(f\"Total Data: {len(train_loader.dataset):,}  Training : \"\n",
        "                   f\"{batch_count:,} batches, Batch_size: {train_loader.batch_size}\")\n",
        "\n",
        "        try:\n",
        "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "                try:\n",
        "                    # Smart memory management\n",
        "                    if batch_idx % self.memory_check_interval == 0:\n",
        "                        if self.resource_manager.should_cleanup_aggressive():\n",
        "                            self.resource_manager.aggressive_cleanup()\n",
        "                            tqdm.write(f\"  Memory cleanup at batch {batch_idx}\")\n",
        "\n",
        "                    # Move data to device with optimized memory format\n",
        "                    images = images.to(Config.DEVICE, non_blocking=True, memory_format=torch.channels_last)\n",
        "                    # images = images.contiguous(memory_format=torch.channels_last)\n",
        "                    labels = labels.to(Config.DEVICE, non_blocking=True)\n",
        "\n",
        "                    # Forward pass\n",
        "                    self.optimizer.zero_grad(set_to_none=True)\n",
        "                    with torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "                        outputs = self.model(images)\n",
        "                        loss = self.criterion(outputs, labels)\n",
        "\n",
        "                    # Backward pass\n",
        "                    self.scaler.scale(loss).backward()\n",
        "                    self.scaler.unscale_(self.optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                    self.scaler.step(self.optimizer)\n",
        "                    self.scaler.update()\n",
        "\n",
        "                    # Calculate metrics\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    batch_acc = (predicted == labels).float().mean().item()\n",
        "                    batch_loss = loss.item()\n",
        "\n",
        "                    # Update totals\n",
        "                    total_loss += batch_loss * images.size(0)\n",
        "                    total += images.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    # Update progress tracker\n",
        "                    progress_tracker.update_batch(batch_idx, batch_loss, batch_acc, is_training=True, total_batches=batch_count)\n",
        "\n",
        "                    # Progress logging every 50 batches\n",
        "                    # if batch_idx % 40 == 0 and batch_idx > 0:\n",
        "                    #     avg_loss = total_loss / total\n",
        "                    #     avg_acc = correct / total\n",
        "                    #     stats = self.resource_manager.get_memory_stats()\n",
        "                    #     tqdm.write(f\"  Batch {batch_idx:4d}/{batch_count} - \"\n",
        "                    #                f\"Loss: {avg_loss:.4f}, Acc: {avg_acc:.4f}, \"\n",
        "                    #                f\"GPU: {stats['gpu_percent']:.1f}%, CPU: {stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "                    # Memory cleanup for large batches\n",
        "                    del outputs, loss, predicted, images, labels\n",
        "\n",
        "                except Exception as e:\n",
        "                    tqdm.write(f\"Error in batch {batch_idx}: {str(e)}\")\n",
        "                    self.resource_manager.aggressive_cleanup()\n",
        "                    continue\n",
        "\n",
        "            # Final cleanup\n",
        "            self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "            return total_loss / max(1, total), correct / max(1, total)\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Training epoch failed: {str(e)}\")\n",
        "            self.resource_manager.aggressive_cleanup()\n",
        "            return float('inf'), 0.0\n",
        "\n",
        "\n",
        "\n",
        "    def validate_epoch(self, val_loader, progress_tracker):\n",
        "        \"\"\"Enhanced validation epoch with memory optimization\"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        total_samples = 0\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "        batch_count = len(val_loader)\n",
        "\n",
        "        tqdm.write(f\"Validation epoch: {len(val_loader.dataset):,} samples, \"\n",
        "                   f\"{batch_count:,} batches, batch_size: {val_loader.batch_size}\")\n",
        "\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                for batch_idx, (images, labels) in enumerate(val_loader):\n",
        "                    try:\n",
        "                        images = images.to(Config.DEVICE, non_blocking=True, memory_format=torch.channels_last)\n",
        "                        # images = images.contiguous(memory_format=torch.channels_last)\n",
        "                        labels = labels.to(Config.DEVICE, non_blocking=True)\n",
        "\n",
        "                        with torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "                            outputs = self.model(images)\n",
        "                            loss = self.criterion(outputs, labels)\n",
        "\n",
        "                        _, predicted = torch.max(outputs, 1)\n",
        "                        batch_acc = (predicted == labels).float().mean().item()\n",
        "                        batch_loss = loss.item()\n",
        "\n",
        "                        # Store results\n",
        "                        total_loss += batch_loss * images.size(0)\n",
        "                        total_samples += images.size(0)\n",
        "                        all_predictions.extend(predicted.cpu().numpy())\n",
        "                        all_labels.extend(labels.cpu().numpy())\n",
        "                        all_probs.append(torch.softmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "                        # Update progress\n",
        "                        progress_tracker.update_batch(batch_idx, batch_loss, batch_acc,\n",
        "                                                    is_training=False, total_batches=batch_count)\n",
        "\n",
        "                        # Memory cleanup\n",
        "                        del outputs, loss, predicted, images, labels\n",
        "\n",
        "                        # # Periodic memory management\n",
        "                        # if batch_idx % 20 == 0:\n",
        "                        #     self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "                    except Exception as e:\n",
        "                        tqdm.write(f\"Error in validation batch {batch_idx}: {str(e)}\")\n",
        "                        continue\n",
        "\n",
        "            # Calculate final metrics\n",
        "            all_probs = np.concatenate(all_probs, axis=0) if all_probs else np.array([])\n",
        "            val_acc = accuracy_score(all_labels, all_predictions)\n",
        "            val_f1 = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
        "\n",
        "            return total_loss / max(1, total_samples), val_acc, val_f1, all_predictions, all_labels, all_probs\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Validation epoch failed: {str(e)}\")\n",
        "            self.resource_manager.aggressive_cleanup()\n",
        "            return float('inf'), 0.0, 0.0, [], [], np.array([])\n",
        "\n",
        "\n",
        "\n",
        "    def train_main_model(self, train_loader, val_loader, test_loader=None):\n",
        "        \"\"\"Main model training with comprehensive logging\"\"\"\n",
        "        if not train_loader or len(train_loader.dataset) == 0:\n",
        "            tqdm.write(f\"Skipping {self.model_name}: No training data\")\n",
        "            return None, None\n",
        "\n",
        "        if not val_loader or len(val_loader.dataset) == 0:\n",
        "            tqdm.write(f\"Skipping {self.model_name}: No validation data\")\n",
        "            return None, None\n",
        "\n",
        "        tqdm.write(f\"\\nTraining {self.model_name}\")\n",
        "        tqdm.write(f\"Training samples: {len(train_loader.dataset):,}\")\n",
        "        tqdm.write(f\"Validation samples: {len(val_loader.dataset):,}\")\n",
        "        tqdm.write(f\"Total epochs: {Config.EPOCHS}\")\n",
        "        tqdm.write(f\"Batch size: {train_loader.batch_size}\")\n",
        "\n",
        "        # Print hyperparameters\n",
        "        tqdm.write(\"Hyperparameters:\")\n",
        "        for key, value in self.hyperparameters.items():\n",
        "            if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                tqdm.write(f\"  {key}: {value:.4f}\")\n",
        "            else:\n",
        "                tqdm.write(f\"  {key}: {value}\")\n",
        "\n",
        "        # Setup model for training\n",
        "        self.model = self.model.to(Config.DEVICE, memory_format=torch.channels_last)\n",
        "\n",
        "        # Add this line after model creation:\n",
        "        # self.model = torch.compile(self.model, mode=\"max-autotune\")\n",
        "\n",
        "        # torch.backends.cudnn.benchmark = True\n",
        "        # torch.backends.cudnn.deterministic = False\n",
        "\n",
        "\n",
        "        # Progress tracker\n",
        "        progress_tracker = TrainingProgressTracker(self.model_name, Config.EPOCHS, len(train_loader))\n",
        "\n",
        "        # Training loop\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        # # Before loop\n",
        "        # single_models = {}\n",
        "        # single_results = {}\n",
        "\n",
        "        for epoch in range(Config.EPOCHS):\n",
        "            epoch_start_time = time.time()\n",
        "            tqdm.write(f\"\\nEpoch {epoch + 1}/{Config.EPOCHS}\")\n",
        "\n",
        "            progress_tracker.start_epoch(epoch)\n",
        "\n",
        "            # Training phase\n",
        "            train_loss, train_acc = self.train_epoch(train_loader, progress_tracker)\n",
        "\n",
        "            # Validation phase\n",
        "            val_loss, val_acc, val_f1, predictions, labels, probs = self.validate_epoch(val_loader, progress_tracker)\n",
        "\n",
        "            # Learning rate scheduling\n",
        "            if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                self.scheduler.step(val_loss)\n",
        "            else:\n",
        "                self.scheduler.step()\n",
        "\n",
        "            # Progress tracking\n",
        "            is_best = val_f1 > self.best_val_f1 * 1.001\n",
        "            current_lr = self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "            progress_tracker.finish_epoch(train_loss, train_acc, val_loss, val_acc, val_f1, is_best=is_best, lr=current_lr)\n",
        "\n",
        "            # Store history\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "            self.history['val_f1'].append(val_f1)\n",
        "            self.history['learning_rates'].append(current_lr)\n",
        "\n",
        "            # Early stopping and best model saving\n",
        "            # if is_best:\n",
        "            #     self.best_val_f1 = val_f1\n",
        "            #     self.best_val_acc = val_acc\n",
        "            #     self.patience_counter = 0\n",
        "            #     # torch.save(f\"{Config.OUTPUT_DIR}/best_model/{self.model_name}_best.pt\")\n",
        "            #     # Save complete model with architecture and hyperparameters\n",
        "            #     torch.save({\n",
        "            #         'state_dict': self.model.state_dict(),\n",
        "            #         'hyperparameters': self.hyperparameters,\n",
        "            #         'model_name': self.model_name\n",
        "            #     }, f\"{Config.OUTPUT_DIR}/best_model/{self.model_name}_best.pt\")\n",
        "\n",
        "            #     tqdm.write(f\"New best model saved: F1={val_f1:.4f}, Acc={val_acc:.4f}\")\n",
        "            # else:\n",
        "            #     self.patience_counter += 1\n",
        "            # Early stopping and best model saving\n",
        "            if is_best:\n",
        "                self.best_val_f1 = val_f1\n",
        "                self.best_val_acc = val_acc\n",
        "                self.patience_counter = 0\n",
        "\n",
        "                # Create comprehensive checkpoint\n",
        "                checkpoint = {\n",
        "                    # Model architecture and weights\n",
        "                    'state_dict': self.model.state_dict(),\n",
        "                    'model_name': self.model_name,\n",
        "                    'hyperparameters': self.hyperparameters,\n",
        "\n",
        "                    # Training metadata\n",
        "                    'epoch': epoch + 1,\n",
        "                    'best_val_f1': val_f1,\n",
        "                    'best_val_acc': val_acc,\n",
        "                    'optimizer_state': self.optimizer.state_dict(),\n",
        "                    'scheduler_state': self.scheduler.state_dict() if self.scheduler else None,\n",
        "\n",
        "                    # Architecture info for reconstruction\n",
        "                    'num_classes': Config.NUM_CLASSES,\n",
        "                    'dropout_rate': self.hyperparameters.get('dropout', 0.5),\n",
        "                    'hidden_dim_multiplier': self.hyperparameters.get('hidden_dim_multiplier', 0.5),\n",
        "\n",
        "                    # Save format version for future compatibility\n",
        "                    'save_format_version': '1.0'\n",
        "                }\n",
        "\n",
        "                # Save with error handling\n",
        "                try:\n",
        "                    torch.save(checkpoint, f\"{Config.OUTPUT_DIR}/best_model/{self.model_name}_best.pt\")\n",
        "                    tqdm.write(f\"✅ Best model saved: F1={val_f1:.4f}, Acc={val_acc:.4f}\")\n",
        "                except Exception as e:\n",
        "                    tqdm.write(f\"❌ Error saving model {self.model_name}: {e}\")\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Epoch summary\n",
        "            epoch_time = time.time() - epoch_start_time\n",
        "            tqdm.write(f\"\\nEpoch {epoch + 1} Summary:\")\n",
        "            tqdm.write(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "            tqdm.write(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
        "            tqdm.write(f\"  Learning Rate: {current_lr:.6f}\")\n",
        "            tqdm.write(f\"  Epoch Time: {epoch_time:.1f}s\")\n",
        "            tqdm.write(f\"  Best F1 so far: {self.best_val_f1:.4f}\")\n",
        "\n",
        "            # Early stopping check\n",
        "            if self.patience_counter >= Config.PATIENCE:\n",
        "                total_time = time.time() - training_start_time\n",
        "                tqdm.write(f\"Early stopping at epoch {epoch + 1}\")\n",
        "                tqdm.write(f\"Total training time: {total_time:.1f}s\")\n",
        "                break\n",
        "\n",
        "        # # Load best model for evaluation\n",
        "        # best_model_path = f\"{Config.OUTPUT_DIR}/best_model/{self.model_name}_best.pt\"\n",
        "        # if os.path.exists(best_model_path):\n",
        "        #     # self.model.load_state_dict(torch.load(best_model_path, map_location=Config.DEVICE))\n",
        "\n",
        "        #     tqdm.write(f\"Loaded best model from {best_model_path}\")\n",
        "        # else:\n",
        "        #     tqdm.write(\"Warning: Best model not found, using current weights\")\n",
        "        # Load best model for evaluation with robust error handling\n",
        "        best_model_path = f\"{Config.OUTPUT_DIR}/best_model/{self.model_name}_best.pt\"\n",
        "        if os.path.exists(best_model_path):\n",
        "            try:\n",
        "                checkpoint = torch.load(best_model_path, map_location=Config.DEVICE, weights_only=False)\n",
        "\n",
        "                if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
        "                    # New comprehensive format\n",
        "                    self.model.load_state_dict(checkpoint['state_dict'])\n",
        "                    tqdm.write(f\"✅ Loaded best model (v{checkpoint.get('save_format_version', '1.0')})\")\n",
        "                else:\n",
        "                    # Legacy format or direct state_dict\n",
        "                    self.model.load_state_dict(checkpoint)\n",
        "                    tqdm.write(f\"✅ Loaded best model (legacy format)\")\n",
        "\n",
        "            except Exception as e:\n",
        "                tqdm.write(f\"⚠️ Could not load best model: {e}\")\n",
        "                tqdm.write(f\"Continuing with current weights...\")\n",
        "        else:\n",
        "            tqdm.write(f\"⚠️ Best model file not found, using current weights\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Final evaluation\n",
        "        evaluator = ModelEvaluator()\n",
        "        eval_loader = test_loader if test_loader else val_loader\n",
        "\n",
        "        with torch.no_grad():\n",
        "            result = evaluator.evaluate_model(self.model, eval_loader, self.model_name)\n",
        "\n",
        "        # Save results\n",
        "        # result_to_save = {\n",
        "        #     'history': {k: torch.tensor(v, dtype=torch.float32) for k, v in self.history.items()},\n",
        "        #     'result': {\n",
        "        #         'accuracy': torch.tensor(result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "        #         'f1': torch.tensor(result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "        #         'conf_matrix': torch.tensor(result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "        #         'true_labels': torch.tensor(result.get('true_labels', []), dtype=torch.int64),\n",
        "        #         'predictions': torch.tensor(result.get('predictions', []), dtype=torch.int64),\n",
        "        #         'probabilities': torch.tensor(result.get('probabilities', np.zeros((0, Config.NUM_CLASSES))), dtype=torch.float32),\n",
        "        #         'misclassified': [{'image': item['image'].cpu(), 'true_label': item['true_label'], 'pred_label': item['pred_label']}\n",
        "        #                         for item in result.get('misclassified', [])] if result.get('misclassified') else []\n",
        "        #     }\n",
        "        # }\n",
        "\n",
        "        result_to_save = {\n",
        "            'history': {k: torch.as_tensor(v, dtype=torch.float32).detach().cpu() for k, v in self.history.items()},\n",
        "            'result': {\n",
        "                'accuracy': torch.as_tensor(result.get('accuracy', 0.0), dtype=torch.float32).detach().cpu(),\n",
        "                'f1': torch.as_tensor(result.get('f1_macro', 0.0), dtype=torch.float32).detach().cpu(),\n",
        "                'conf_matrix': torch.as_tensor(result.get('conf_matrix', np.array([[]])), dtype=torch.int64).detach().cpu(),\n",
        "                'true_labels': torch.as_tensor(result.get('true_labels', []), dtype=torch.int64).detach().cpu(),\n",
        "                'predictions': torch.as_tensor(result.get('predictions', []), dtype=torch.int64).detach().cpu(),\n",
        "                # 'probabilities': torch.as_tensor(result.get('probabilities', np.zeros((0, Config.NUM_CLASSES))), dtype=torch.float32).detach().cpu(),\n",
        "                'probabilities': torch.as_tensor(\n",
        "                    result.get('probabilities') if result.get('probabilities') is not None else np.zeros((0, Config.NUM_CLASSES)),\n",
        "                    dtype=torch.float32\n",
        "                ).detach().cpu(),\n",
        "                # 'probabilities': torch.as_tensor(result.get('probabilities') if result.get('probabilities') is not None else np.zeros((0, Config.NUM_CLASSES)), dtype=torch.float32).detach().cpu(),\n",
        "                'misclassified': [\n",
        "                    {'image': item['image'].detach().cpu(),\n",
        "                    'true_label': item['true_label'],\n",
        "                    'pred_label': item['pred_label']}\n",
        "                    for item in result.get('misclassified', [])\n",
        "                ] if result.get('misclassified') else []\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "        main_result_path = f\"{Config.OUTPUT_DIR}/model_results/{self.model_name}_main_results.pt\"\n",
        "        torch.save(result_to_save, main_result_path)\n",
        "        tqdm.write(f\"Results saved to {main_result_path}\")\n",
        "\n",
        "        # Training summary\n",
        "        total_training_time = time.time() - training_start_time\n",
        "        tqdm.write(f\"\\nTraining Summary for {self.model_name}:\")\n",
        "        tqdm.write(f\"  Final Accuracy: {result.get('accuracy', 0.0):.4f}\")\n",
        "        tqdm.write(f\"  Final F1 Score: {result.get('f1_macro', 0.0):.4f}\")\n",
        "        tqdm.write(f\"  Best Validation F1: {self.best_val_f1:.4f}\")\n",
        "        tqdm.write(f\"  Total Training Time: {total_training_time:.1f}s\")\n",
        "        tqdm.write(f\"  Epochs Completed: {epoch + 1}/{Config.EPOCHS}\")\n",
        "\n",
        "        # Cleanup\n",
        "        del result_to_save, result, evaluator, eval_loader\n",
        "        self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "        # return self.history, None\n",
        "        # return None, None  # Don't return data since it's saved and also change calling function from main\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def train_kfold(self, train_loader, val_loader, test_loader, n_folds=3):\n",
        "        \"\"\"K-fold cross-validation with detailed logging\"\"\"\n",
        "        if n_folds <= 0:\n",
        "            tqdm.write(f\"Skipping k-fold for {self.model_name}: n_folds <= 0\")\n",
        "            return []\n",
        "\n",
        "\n",
        "        from torch.utils.data import ConcatDataset\n",
        "        combined_dataset = ConcatDataset([\n",
        "            train_loader.dataset,\n",
        "            val_loader.dataset\n",
        "            # test_loader.dataset if test_loader is not None else []\n",
        "        ])\n",
        "        dataset = combined_dataset\n",
        "        test_loader_fold=test_loader\n",
        "\n",
        "        # dataset = train_loader.dataset\n",
        "        total_samples = len(dataset)\n",
        "        min_samples_per_fold = 500\n",
        "\n",
        "        # Adjust folds based on data availability\n",
        "        if total_samples < n_folds * min_samples_per_fold:\n",
        "            n_folds = max(1, total_samples // min_samples_per_fold)\n",
        "            tqdm.write(f\"Adjusted to {n_folds} folds due to insufficient data\")\n",
        "\n",
        "        if n_folds < 2:\n",
        "            tqdm.write(f\"Skipping k-fold: need at least {min_samples_per_fold*2} samples, have {total_samples}\")\n",
        "            return []\n",
        "\n",
        "        # Calculate fold statistics\n",
        "        samples_per_fold = total_samples // n_folds\n",
        "        train_samples_per_fold = total_samples - samples_per_fold\n",
        "\n",
        "        tqdm.write(f\"\\nK-fold Cross-Validation Setup for {self.model_name}:\")\n",
        "        tqdm.write(f\"  Total samples: {total_samples:,}\")\n",
        "        tqdm.write(f\"  Number of folds: {n_folds}\")\n",
        "        tqdm.write(f\"  Samples per fold (validation): {samples_per_fold:,}\")\n",
        "        tqdm.write(f\"  Samples per fold (training): {train_samples_per_fold:,}\")\n",
        "\n",
        "        # Create fold indices\n",
        "        fold_indices = []\n",
        "        for i in range(n_folds):\n",
        "            val_start = i * samples_per_fold\n",
        "            val_end = min(val_start + samples_per_fold, total_samples)\n",
        "            val_idx = list(range(val_start, val_end))\n",
        "            train_idx = list(range(0, val_start)) + list(range(val_end, total_samples))\n",
        "            fold_indices.append((train_idx, val_idx))\n",
        "\n",
        "            tqdm.write(f\"  Fold {i+1}: Train={len(train_idx):,}, Val={len(val_idx):,}\")\n",
        "\n",
        "        # Optimize settings for k-fold\n",
        "        # fold_batch_size = self.resource_manager.optimize_batch_size(64, 1.0)\n",
        "        # Use the ResourceManager method directly\n",
        "        base_batch_size = self.hyperparameters.get('batch_size', Config.BATCH_SIZE)\n",
        "        # Use the same complexity calculation as in main()\n",
        "        model_complexity_map = {\n",
        "            'efficientnet': 1.5,\n",
        "            'resnet': 1.0,\n",
        "            'vgg': 0.8,\n",
        "            'mobilenet': 0.6,\n",
        "            'densenet': 1.3,\n",
        "            'convnext': 1.4\n",
        "        }\n",
        "        model_complexity = model_complexity_map.get(self.model_name.split('_')[0].lower(), 1.0)\n",
        "        fold_batch_size = self.resource_manager.optimize_batch_size(base_batch_size, model_complexity)\n",
        "        # fold_batch_size = self.resource_manager.optimize_batch_size(base_batch_size, model_name=self.model_name)\n",
        "\n",
        "        prefetch_factor = min(4, max(2, self.resource_manager.cpu_memory_gb // 10))\n",
        "        num_workers = min(8, mp.cpu_count() // 2)\n",
        "\n",
        "        tqdm.write(f\"K-fold optimized settings:\")\n",
        "        tqdm.write(f\"  Batch size: {fold_batch_size}\")\n",
        "        tqdm.write(f\"  Workers: {num_workers}\")\n",
        "        tqdm.write(f\"  Prefetch factor: {prefetch_factor}\")\n",
        "\n",
        "        fold_results = []\n",
        "        total_kfold_start = time.time()\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(fold_indices, 1):\n",
        "            fold_start_time = time.time()\n",
        "            tqdm.write(f\"\\nTraining Fold {fold}/{n_folds}\")\n",
        "\n",
        "            try:\n",
        "                # Create fold-specific data loaders\n",
        "                train_subsampler = SubsetRandomSampler(train_idx)\n",
        "                val_subsampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "                train_loader_fold = DataLoader(\n",
        "                    dataset,\n",
        "                    batch_size=fold_batch_size,\n",
        "                    sampler=train_subsampler,\n",
        "                    num_workers=num_workers,\n",
        "                    pin_memory=torch.cuda.is_available(),\n",
        "                    prefetch_factor=prefetch_factor,\n",
        "                    persistent_workers=num_workers > 0,\n",
        "                    worker_init_fn=worker_init_fn if 'worker_init_fn' in globals() else None\n",
        "                )\n",
        "\n",
        "                val_loader_fold = DataLoader(\n",
        "                    dataset,\n",
        "                    batch_size=fold_batch_size,\n",
        "                    sampler=val_subsampler,\n",
        "                    num_workers=num_workers,\n",
        "                    pin_memory=torch.cuda.is_available(),\n",
        "                    prefetch_factor=prefetch_factor,\n",
        "                    persistent_workers=num_workers > 0,\n",
        "                    worker_init_fn=worker_init_fn if 'worker_init_fn' in globals() else None\n",
        "                )\n",
        "\n",
        "                # Create fold model\n",
        "                fold_model = ModelFactory.create_model(\n",
        "                    self.model_name,\n",
        "                    num_classes=Config.NUM_CLASSES,\n",
        "                    dropout_rate=self.hyperparameters.get('dropout', 0.5),\n",
        "                    hidden_dim_multiplier=self.hyperparameters.get('hidden_dim_multiplier', 0.5)\n",
        "                ).to(Config.DEVICE, memory_format=torch.channels_last)\n",
        "\n",
        "                # Create fold trainer\n",
        "                fold_trainer = EnhancedModelTrainer(fold_model, f\"{self.model_name}_fold_{fold}\", self.hyperparameters)\n",
        "\n",
        "                # Train fold\n",
        "                # fold_history, fold_result =\n",
        "                fold_trainer.train_main_model(train_loader_fold, val_loader_fold, test_loader=None)\n",
        "                fold_time = time.time() - fold_start_time\n",
        "\n",
        "                # Save trained model\n",
        "                fold_model_path = f\"{Config.OUTPUT_DIR}/kfold_results/{self.model_name}_fold_{fold}_model.pt\"\n",
        "                torch.save(fold_model.state_dict(), fold_model_path)\n",
        "\n",
        "\n",
        "                # Load the model back (optional but ensures evaluation uses saved model)\n",
        "                fold_model.load_state_dict(torch.load(fold_model_path))\n",
        "                fold_model.to(Config.DEVICE)\n",
        "\n",
        "                # Evaluate the fold\n",
        "                evaluator = ModelEvaluator()\n",
        "                eval_loader = test_loader_fold  # or test_loader if you have it\n",
        "                with torch.no_grad():\n",
        "                    fold_result = evaluator.evaluate_model(fold_model, eval_loader, f\"{self.model_name}_fold_{fold}\")\n",
        "\n",
        "                # # Handle fold results\n",
        "                # if fold_history is None or fold_result is None:\n",
        "                #     tqdm.write(f\"Fold {fold} training failed\")\n",
        "                #     fold_result = {\n",
        "                #         'accuracy': 0.0, 'f1_macro': 0.0, 'conf_matrix': np.array([[]]),\n",
        "                #         'true_labels': [], 'predictions': [], 'probabilities': np.zeros((0, Config.NUM_CLASSES)),\n",
        "                #         'misclassified': []\n",
        "                #     }\n",
        "                #     fold_history = {'val_loss': [], 'val_acc': []}\n",
        "\n",
        "\n",
        "                # # Store results\n",
        "                # fold_results.append({\n",
        "                #     'history': {\n",
        "                #         'val_loss': fold_history.get('val_loss', []),\n",
        "                #         'val_acc': fold_history.get('val_acc', [])\n",
        "                #     },\n",
        "                #     'result': {\n",
        "                #         'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "                #         'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "                #         'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "                #         'misclassified': fold_result.get('misclassified', [])\n",
        "                #     }\n",
        "                # })\n",
        "\n",
        "                # Save fold results\n",
        "                # fold_result_to_save = {\n",
        "                #     'history': {\n",
        "                #         'val_loss': torch.tensor(fold_history.get('val_loss', []), dtype=torch.float32),\n",
        "                #         'val_acc': torch.tensor(fold_history.get('val_acc', []), dtype=torch.float32)\n",
        "                #     },\n",
        "                #     'result': {\n",
        "                #         'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "                #         'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "                #         'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "                #         'misclassified': fold_result.get('misclassified', [])\n",
        "                #     }\n",
        "                # }\n",
        "                # Save fold results\n",
        "                fold_result_to_save = {\n",
        "                    'history': {  # assuming train_main_model updates self.history inside fold_trainer\n",
        "                        'val_loss': torch.tensor(fold_trainer.history.get('val_loss', []), dtype=torch.float32),\n",
        "                        'val_acc': torch.tensor(fold_trainer.history.get('val_acc', []), dtype=torch.float32)\n",
        "                    },\n",
        "                    'result': {\n",
        "                        'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "                        'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "                        'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "                        'misclassified': fold_result.get('misclassified', [])\n",
        "                    }\n",
        "                }\n",
        "\n",
        "\n",
        "\n",
        "                fold_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{self.model_name}_fold_{fold}_results.pt\"\n",
        "                torch.save(fold_result_to_save, fold_result_path)\n",
        "\n",
        "                tqdm.write(f\"Fold {fold} completed in {fold_time:.1f}s - \"\n",
        "                          f\"Accuracy: {fold_result.get('accuracy', 0.0):.4f}, \"\n",
        "                          f\"F1: {fold_result.get('f1_macro', 0.0):.4f}\")\n",
        "\n",
        "                # Cleanup fold\n",
        "                del fold_trainer, fold_model #, fold_history, fold_result\n",
        "                del train_loader_fold, val_loader_fold, train_subsampler, val_subsampler\n",
        "                self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "            except Exception as e:\n",
        "                tqdm.write(f\"Error in fold {fold}: {str(e)}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "\n",
        "        total_kfold_time = time.time() - total_kfold_start\n",
        "        # successful_folds = len(fold_results)\n",
        "\n",
        "        tqdm.write(f\"\\nK-fold Summary for {self.model_name}:\")\n",
        "        # tqdm.write(f\"  Successful folds: {successful_folds}/{n_folds}\")\n",
        "        tqdm.write(f\"  Total k-fold time: {total_kfold_time:.1f}s\")\n",
        "        # tqdm.write(f\"  Average time per fold: {total_kfold_time/max(1,successful_folds):.1f}s\")\n",
        "\n",
        "        # return []\n",
        "        # return fold_results\n",
        "\n",
        "\n",
        "\n",
        "    def cleanup_trainer(self):\n",
        "        \"\"\"Complete cleanup of trainer resources\"\"\"\n",
        "        try:\n",
        "            if hasattr(self, 'model'):\n",
        "                del self.model\n",
        "            if hasattr(self, 'optimizer'):\n",
        "                del self.optimizer\n",
        "            if hasattr(self, 'scheduler'):\n",
        "                del self.scheduler\n",
        "            if hasattr(self, 'criterion'):\n",
        "                del self.criterion\n",
        "            if hasattr(self, 'scaler'):\n",
        "                del self.scaler\n",
        "\n",
        "            self.history.clear()\n",
        "            self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Cleanup error: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# orig_numpy = torch.Tensor.numpy\n",
        "# def patched_numpy(self, *args, **kwargs):\n",
        "#     if self.is_cuda:\n",
        "#         raise RuntimeError(f\"Tried to call .numpy() on CUDA tensor at line ???. Move it to CPU first!\")\n",
        "#     return orig_numpy(self, *args, **kwargs)\n",
        "\n",
        "# torch.Tensor.numpy = patched_numpy\n",
        "\n",
        "class ResourceManager:\n",
        "    \"\"\"Smart resource management for optimal GPU/CPU utilization\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.gpu_memory_gb = 20\n",
        "        self.cpu_memory_gb = 50\n",
        "        self.max_gpu_usage = 0.85  # 85% of 20GB = 17GB\n",
        "        self.max_cpu_usage = 0.90  # 80% of 50GB = 40GB\n",
        "\n",
        "    def get_memory_stats(self):\n",
        "        \"\"\"Get current memory usage statistics\"\"\"\n",
        "        stats = {'cpu_percent': psutil.virtual_memory().percent}\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            stats['gpu_allocated_gb'] = torch.cuda.memory_allocated() / (1024**3)\n",
        "            stats['gpu_reserved_gb'] = torch.cuda.memory_reserved() / (1024**3)\n",
        "            stats['gpu_percent'] = (stats['gpu_reserved_gb'] / self.gpu_memory_gb) * 100\n",
        "        else:\n",
        "            stats.update({'gpu_allocated_gb': 0, 'gpu_reserved_gb': 0, 'gpu_percent': 0})\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def should_cleanup_aggressive(self):\n",
        "        \"\"\"Check if aggressive cleanup is needed\"\"\"\n",
        "        stats = self.get_memory_stats()\n",
        "        return (stats['gpu_percent'] > 90 or stats['cpu_percent'] > 90)\n",
        "\n",
        "    def aggressive_cleanup(self):\n",
        "        \"\"\"Perform comprehensive memory cleanup\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "        gc.collect()\n",
        "        time.sleep(0.1)  # Brief pause for system cleanup\n",
        "\n",
        "    def optimize_batch_size(self, base_size, model_complexity=1.0):\n",
        "        \"\"\"Calculate optimal batch size based on current memory state\"\"\"\n",
        "        stats = self.get_memory_stats()\n",
        "\n",
        "        # Reduce batch size if memory usage is high\n",
        "        memory_factor = max(0.4, 1.0 - (stats['gpu_percent'] / 100))\n",
        "        optimal_size = int(base_size * memory_factor / model_complexity)\n",
        "\n",
        "        return max(32, min(256, optimal_size))  # Keep within reasonable bounds\n",
        "\n",
        "\n",
        "def safe_gpu_convert(data):\n",
        "    \"\"\"Safely convert GPU tensors to CPU numpy arrays or lists\"\"\"\n",
        "    if torch.is_tensor(data):\n",
        "        if data.is_cuda:\n",
        "            data = data.detach().cpu()\n",
        "        if data.dim() == 0:\n",
        "            return data.item()\n",
        "        elif data.dtype == torch.bool or data.dtype == torch.uint8:\n",
        "            return data.numpy()\n",
        "        else:\n",
        "            return data.numpy() if data.dim() > 0 else data.item()\n",
        "    elif isinstance(data, list):\n",
        "        return [safe_gpu_convert(item) for item in data]\n",
        "    elif isinstance(data, dict):\n",
        "        return {k: safe_gpu_convert(v) for k, v in data.items()}\n",
        "    elif isinstance(data, np.ndarray):\n",
        "        return data  # Already numpy\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "\n",
        "# def safe_gpu_convert(data):\n",
        "#     \"\"\"Safely convert GPU tensors to CPU numpy arrays or lists\"\"\"\n",
        "#     if torch.is_tensor(data):\n",
        "#         if data.is_cuda:\n",
        "#             data = data.detach().cpu()\n",
        "#         if data.dim() == 0:\n",
        "#             return data.item()\n",
        "#         elif data.dtype == torch.bool or data.dtype == torch.uint8:\n",
        "#             return data.numpy()\n",
        "#         else:\n",
        "#             return data.numpy() if data.dim() > 0 else data.item()\n",
        "#     elif isinstance(data, list):\n",
        "#         return [safe_gpu_convert(item) for item in data]\n",
        "#     elif isinstance(data, dict):\n",
        "#         converted = {}\n",
        "#         for k, v in data.items():\n",
        "#             # Special handling for data that should remain as lists for boolean evaluation\n",
        "#             if k in ['misclassified', 'train_loss', 'train_acc', 'val_loss', 'val_acc', 'val_f1']:\n",
        "#                 if torch.is_tensor(v):\n",
        "#                     converted[k] = v.detach().cpu().numpy().tolist() if v.dim() > 0 else v.item()\n",
        "#                 else:\n",
        "#                     converted[k] = safe_gpu_convert(v)\n",
        "#             else:\n",
        "#                 converted[k] = safe_gpu_convert(v)\n",
        "#         return converted\n",
        "#     elif isinstance(data, np.ndarray):\n",
        "#         return data  # Already numpy\n",
        "#     else:\n",
        "#         return data\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"\\nStarting Fish Species Classification Pipeline...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Environment setup for maximum performance\n",
        "    setup_environment()\n",
        "\n",
        "\n",
        "\n",
        "    # Set optimal thread count for CPU utilization\n",
        "    print(f\"CPU : {os.cpu_count()}\")\n",
        "    print(f\"USER: {os.getenv('USER')}\")\n",
        "    print(f\"HOME: {os.getenv('HOME')}\")\n",
        "    torch.set_num_threads(min(16, os.cpu_count()))\n",
        "    os.environ['OMP_NUM_THREADS'] = str(min(16, os.cpu_count()))\n",
        "\n",
        "\n",
        "\n",
        "    # OpenMP → Open Multi-Processing.\n",
        "    # OpenMP is a widely used API for parallel programming on CPUs.\n",
        "    # Many scientific libraries (like NumPy, PyTorch, TensorFlow,\n",
        "    # -OpenCV, Scikit-learn) rely on OpenMP to run operations in parallel across CPU cores.\n",
        "    # In main() after line 720:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    # Auto-benchmarks and selects fastest cuDNN algorithms for your specific hardware and input sizes\n",
        "    # Takes ~5-10 seconds at start but can provide 10-20% speedup throughout training\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    # Allows cuDNN to use fastest available algorithms even if they produce slightly different results each run\n",
        "    # Trades reproducibility for speed - essential for maximum performance in production training\n",
        "    # torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    # Uses TensorFloat-32 (19-bit precision) instead of full Float-32 for matrix multiplications\n",
        "    # Provides ~1.6x speedup on Ampere GPUs with negligible accuracy loss for deep learning\n",
        "    # torch.backends.cudnn.allow_tf32 = True\n",
        "    # Enables TF32 precision for cuDNN operations (convolutions, pooling, batch norm)\n",
        "    # Accelerates CNN layers by 1.3-1.6x on RTX 30/40 series and A100+ GPUs\n",
        "    torch.backends.cuda.enable_flash_sdp(True)\n",
        "    # Activates Flash Attention algorithm for memory-efficient attention computations\n",
        "    # Reduces GPU memory usage by 2-4x and increases attention speed, crucial for transformer layers\n",
        "\n",
        "\n",
        "\n",
        "    # GPU optimizations\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "        gpu_props = torch.cuda.get_device_properties(0)\n",
        "        print(f\"GPU: {gpu_props.name}, Memory: {gpu_props.total_memory / 1024**3:.1f}GB\")\n",
        "\n",
        "    # CPU info\n",
        "    print(f\"CPU Cores: {os.cpu_count()}, Using threads: {torch.get_num_threads()}\")\n",
        "\n",
        "    # # Ensure all output directories exist\n",
        "    # os.makedirs(f\"{Config.OUTPUT_DIR}/models\", exist_ok=True)\n",
        "    # os.makedirs(f\"{Config.OUTPUT_DIR}/kfold_results\", exist_ok=True)\n",
        "    # os.makedirs(f\"{Config.OUTPUT_DIR}/visualizations\", exist_ok=True)\n",
        "    # os.makedirs(f\"{Config.OUTPUT_DIR}/model_results\", exist_ok=True)\n",
        "    # os.makedirs(f\"{Config.OUTPUT_DIR}/best_model\", exist_ok=True)\n",
        "\n",
        "    # Initialize resource manager\n",
        "    resource_manager = ResourceManager()\n",
        "\n",
        "    # Load and balance data (only once)\n",
        "    print(\"\\nLoading and balancing data...\")\n",
        "    X, Y = DataManager.load_and_balance_data()\n",
        "    print(f\"Total samples after balancing: {len(X):,}, Labels: {len(Y):,}\")\n",
        "\n",
        "    # Validate data consistency\n",
        "    if len(X) != len(Y):\n",
        "        raise ValueError(f\"Inconsistent data: X has {len(X)} samples, Y has {len(Y)} labels\")\n",
        "    if len(X) == 0:\n",
        "        raise ValueError(\"No data available after loading and balancing\")\n",
        "\n",
        "\n",
        "    # Initialize components\n",
        "    visualizer = EnhancedVisualizations()\n",
        "    single_models = {}\n",
        "    single_results = {}\n",
        "    histories = {}\n",
        "\n",
        "    # Process each model individually\n",
        "    for model_name in Config.MODELS:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"PROCESSING MODEL: {model_name}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Pre-model memory state\n",
        "        pre_stats = resource_manager.get_memory_stats()\n",
        "        print(f\"Pre-training memory - GPU: {pre_stats['gpu_allocated_gb']:.2f}GB ({pre_stats['gpu_percent']:.1f}%), \"\n",
        "              f\"CPU: {pre_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Step 1: Create initial data loaders for hyperparameter optimization\n",
        "            print(f\"\\n1. CREATING INITIAL DATA LOADERS FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(X, Y)\n",
        "\n",
        "            # Validate data loaders\n",
        "            print(f\"Train loader: {len(train_loader.dataset) if train_loader else 0} samples\")\n",
        "            print(f\"Val loader: {len(val_loader.dataset) if val_loader else 0} samples\")\n",
        "            print(f\"Test loader: {len(test_loader.dataset) if test_loader else 0} samples\")\n",
        "\n",
        "            if not train_loader or len(train_loader.dataset) == 0:\n",
        "                print(f\"Skipping {model_name}: No training data available\")\n",
        "                continue #To Go Next Model\n",
        "            if not val_loader or len(val_loader.dataset) == 0:\n",
        "                print(f\"Skipping {model_name}: No validation data available\")\n",
        "                continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Step 2: Optimize hyperparameters\n",
        "            print(f\"\\n2. HYPERPARAMETER OPTIMIZATION FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "            torch.serialization.add_safe_globals([np.core.multiarray.scalar])\n",
        "            torch.set_num_threads(2)  # Reduce CPU threads for GPU workload\n",
        "\n",
        "            # Debug data loader sizes\n",
        "            print(f\"Train loader size: {len(train_loader.dataset)} samples, {len(train_loader)} batches\")\n",
        "            print(f\"Val loader size: {len(val_loader.dataset)} samples, {len(val_loader)} batches\")\n",
        "\n",
        "            try:\n",
        "                optimizer = ExpandedHyperparameterOptimizer(model_name, train_loader, val_loader)\n",
        "                best_params = optimizer.optimize()\n",
        "                del optimizer\n",
        "                resource_manager.aggressive_cleanup()\n",
        "            except Exception as e:\n",
        "                print(f\"Error in hyperparameter optimization for {model_name}: {str(e)}\")\n",
        "                import traceback\n",
        "                # traceback.print_exc()\n",
        "                traceback.format_exc()\n",
        "                print(traceback.format_exc())\n",
        "                #Or Log it\n",
        "                tb_log = traceback.format_exc()\n",
        "                logger.error(tb_log)\n",
        "                best_params = {}  # Fallback to default hyperparameters\n",
        "\n",
        "            print(f\"\\n\\033[1;31m{'='*70}\\033[0m\")\n",
        "            print(f\"\\033[1;31m{model_name.upper()} BEST PARAMETERS:\\033[0m\")\n",
        "            for key, value in best_params.items():\n",
        "                if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                    print(f\"\\033[1;31m  {key}: {value:.4f}\\033[0m\")\n",
        "                else:\n",
        "                    print(f\"\\033[1;31m  {key}: {value}\\033[0m\")\n",
        "            print(f\"\\033[1;31m{'='*70}\\033[0m\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Step 3: Create data loaders with optimized parameters\n",
        "            print(f\"\\n3. RECREATING DATA LOADERS WITH OPTIMIZED PARAMETERS\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Clear previous loaders\n",
        "            del train_loader, val_loader, test_loader\n",
        "            resource_manager.aggressive_cleanup()\n",
        "\n",
        "            # Calculate optimal batch size based on model complexity\n",
        "            model_complexity_map = {\n",
        "                'efficientnet_': 1.5,  # matches efficientnet_b0, efficientnet_b7 etc.\n",
        "                'resnet': 1.0,         # matches resnet18, resnet50 etc.\n",
        "                'vgg': 0.8,            # matches vgg16, vgg19 etc.\n",
        "                'mobilenet_': 0.6,     # matches mobilenet_v2, mobilenet_v3 etc.\n",
        "                'densenet': 1.3,       # matches densenet121, densenet201 etc.\n",
        "                'convnext_': 1.4       # matches convnext_tiny, convnext_base etc.\n",
        "            }\n",
        "\n",
        "            model_complexity = model_complexity_map.get(model_name.split('_')[0].lower(), 1.0) #model_name gets from for loop.\n",
        "            #\"EfficientNet_B0\".split('_')[0].lower() → \"efficientnet\"\n",
        "            base_batch_size = best_params.get('batch_size', Config.BATCH_SIZE)\n",
        "            optimized_batch_size = resource_manager.optimize_batch_size(base_batch_size, model_complexity)\n",
        "\n",
        "            # Recreate with optimized batch size and GPU-optimized settings\n",
        "            train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(\n",
        "                X, Y,\n",
        "                test_size=0.2,\n",
        "                batch_size=optimized_batch_size,\n",
        "                augmentation_strength=best_params.get('augmentation_strength', 'medium')\n",
        "            )\n",
        "\n",
        "            # Optimize data loaders for GPU\n",
        "            optimal_workers = min(16, max(8, os.cpu_count() // 2))\n",
        "            for loader in [train_loader, val_loader, test_loader]:\n",
        "                if loader:\n",
        "                    loader.pin_memory = torch.cuda.is_available()\n",
        "                    loader.num_workers = optimal_workers\n",
        "                    loader.prefetch_factor = 4 if optimal_workers > 0 else 2\n",
        "\n",
        "            # Validate recreated data loaders\n",
        "            print(f\"Recreated - Train: {len(train_loader.dataset)}, Val: {len(val_loader.dataset)}, Test: {len(test_loader.dataset)}\")\n",
        "            print(f\"Optimized batch size: {optimized_batch_size} (complexity factor: {model_complexity})\")\n",
        "\n",
        "            # Additional validation for val_data and test_data tuples\n",
        "            if val_data is not None and len(val_data) == 2:\n",
        "                print(f\"Val data tuple: X={len(val_data[0])}, Y={len(val_data[1])}\")\n",
        "                if len(val_data[0]) != len(val_data[1]):\n",
        "                    print(f\"WARNING: Validation data inconsistency: {len(val_data[0])} samples vs {len(val_data[1])} labels\")\n",
        "\n",
        "            if test_data is not None and len(test_data) == 2:\n",
        "                print(f\"Test data tuple: X={len(test_data[0])}, Y={len(test_data[1])}\")\n",
        "                if len(test_data[0]) != len(test_data[1]):\n",
        "                    print(f\"WARNING: Test data inconsistency: {len(test_data[0])} samples vs {len(test_data[1])} labels\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Step 4: Train main model\n",
        "            print(f\"\\n4. MAIN MODEL TRAINING FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            model = ModelFactory.create_model(\n",
        "                model_name,\n",
        "                num_classes=Config.NUM_CLASSES,\n",
        "                dropout_rate=best_params.get('dropout', 0.5),\n",
        "                hidden_dim_multiplier=best_params.get('hidden_dim_multiplier', 0.5)\n",
        "            ).to(Config.DEVICE, memory_format=torch.channels_last)  # GPU optimization\n",
        "\n",
        "            # Model info\n",
        "            total_model_params = sum(p.numel() for p in model.parameters())\n",
        "            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "            print(f\"Model created: {total_model_params:,} total params, {trainable_params:,} trainable\")\n",
        "\n",
        "            # Additional GPU optimizations\n",
        "            torch.backends.cudnn.benchmark = True\n",
        "            torch.backends.cudnn.deterministic = False\n",
        "            # Tells cuDNN (NVIDIA’s deep learning library) to find the fastest algorithm for your hardware and input size.\n",
        "            # Benchmarking finds the fastest algorithm.\n",
        "            # Non-determinism allows cuDNN to use even faster (but slightly variable) methods.\n",
        "            # Together → maximum training speed, but with non-reproducible results (F1 score may vary slightly between runs).\n",
        "            # For speed → benchmark=True, deterministic=False (your case).\n",
        "            # For reproducibility → benchmark=False, deterministic=True.\n",
        "\n",
        "            trainer = EnhancedModelTrainer(model, model_name, best_params)\n",
        "            # history, result = trainer.train_main_model(train_loader, val_loader, test_loader)\n",
        "            trainer.train_main_model(train_loader, val_loader, test_loader)\n",
        "\n",
        "            # if history is None or result is None: #No Need cause Data is saved to Disk Directly\n",
        "            #     print(f\"Training failed for {model_name}, skipping...\")\n",
        "            #     continue\n",
        "\n",
        "            print(f\"Main model training completed for {model_name}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Step 5: K-fold cross-validation\n",
        "            print(f\"\\n5. K-FOLD CROSS-VALIDATION FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Ensure we have sufficient data for k-fold\n",
        "            total_samples = len(train_loader.dataset)\n",
        "            min_samples_per_fold = 500\n",
        "            max_folds = total_samples // min_samples_per_fold\n",
        "            n_folds = min(3, max_folds) if max_folds > 1 else 0\n",
        "\n",
        "            if n_folds > 1:\n",
        "                print(f\"Performing {n_folds}-fold cross-validation...\")\n",
        "                # fold_results =\n",
        "                trainer.train_kfold(train_loader, val_loader, test_loader,n_folds=n_folds)\n",
        "                print(f\"K-fold validation completed for {model_name}\")\n",
        "            else:\n",
        "                print(f\"Skipping k-fold validation for {model_name}: insufficient data (need >{min_samples_per_fold*2} samples)\")\n",
        "                fold_results = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Step 6: Generate ALL visualizations for this model\n",
        "            print(f\"\\n6. GENERATING COMPLETE VISUALIZATIONS FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Load saved results for plotting (ensuring consistency)\n",
        "            main_result_path = f\"{Config.OUTPUT_DIR}/model_results/{model_name}_main_results.pt\"\n",
        "\n",
        "            try:\n",
        "                if os.path.exists(main_result_path):\n",
        "                    saved_data = torch.load(main_result_path, map_location=Config.DEVICE, weights_only=False)\n",
        "                    history_for_viz = saved_data['history']\n",
        "                    result_for_viz = saved_data['result']\n",
        "                    print(f\"Using saved results for {model_name} visualization\")\n",
        "                else:\n",
        "                    # # Use current result data for visualization\n",
        "                    # history_for_viz = history\n",
        "                    # result_for_viz = result\n",
        "                    result_for_viz = {}\n",
        "                    history_for_viz = {}\n",
        "                    def add_strikethrough(text):\n",
        "                        return ''.join(c + '\\u0336' for c in text)\n",
        "                    print(f\"{add_strikethrough('Using current')} No results for {model_name} visualization\")\n",
        "\n",
        "                print(f\"Result keys: {list(result_for_viz.keys()) if result_for_viz else 'None'}\")\n",
        "\n",
        "                # Convert all data to CPU/numpy for visualization (GPU-safe conversion)\n",
        "                history_viz = safe_gpu_convert(history_for_viz)\n",
        "                result_viz = safe_gpu_convert(result_for_viz)\n",
        "                # history_viz = history_for_viz\n",
        "                # result_viz = result_for_viz\n",
        "\n",
        "\n",
        "\n",
        "                # Validate result data\n",
        "                true_labels = result_viz.get('true_labels', np.array([]))\n",
        "                predictions = result_viz.get('predictions', np.array([]))\n",
        "                probabilities = result_viz.get('probabilities', np.array([]))\n",
        "\n",
        "                # ADD THE CONVERSION LINES HERE:\n",
        "                if torch.is_tensor(true_labels):\n",
        "                    true_labels = true_labels.detach().cpu().numpy()\n",
        "                if torch.is_tensor(predictions):\n",
        "                    predictions = predictions.detach().cpu().numpy()\n",
        "                if torch.is_tensor(probabilities):\n",
        "                    probabilities = probabilities.detach().cpu().numpy()\n",
        "                # ADD THESE ADDITIONAL CONVERSIONS:\n",
        "                # Convert history data to safe formats\n",
        "                for key in ['train_loss', 'train_acc', 'val_loss', 'val_acc', 'val_f1']:\n",
        "                    if key in history_viz and torch.is_tensor(history_viz[key]):\n",
        "                        history_viz[key] = history_viz[key].detach().cpu().numpy().tolist()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                print(f\"Data validation for {model_name}:\")\n",
        "                print(f\"  true_labels: {type(true_labels)}, shape: {getattr(true_labels, 'shape', len(true_labels) if hasattr(true_labels, '__len__') else 'scalar')}\")\n",
        "                print(f\"  predictions: {type(predictions)}, shape: {getattr(predictions, 'shape', len(predictions) if hasattr(predictions, '__len__') else 'scalar')}\")\n",
        "                print(f\"  probabilities: {type(probabilities)}, shape: {getattr(probabilities, 'shape', 'unknown')}\")\n",
        "\n",
        "                # Check if we have valid data for plotting\n",
        "                if (true_labels.size > 0 and predictions.size > 0 and true_labels.shape[0] == predictions.shape[0]):\n",
        "                # if (len(true_labels) > 0 and len(predictions) > 0 and len(true_labels) == len(predictions)):\n",
        "                    plots_generated = 0\n",
        "\n",
        "                    # Training history plot\n",
        "                    # if history_viz.get('train_loss') and len(history_viz['train_loss']) > 0:\n",
        "                    # CORRECTION:\n",
        "                    train_loss = history_viz.get('train_loss')\n",
        "                    if train_loss is not None and hasattr(train_loss, '__len__') and len(train_loss) > 0:\n",
        "                        try:\n",
        "                            # Add this conversion:\n",
        "                            if history_viz.get('train_loss') is not None:\n",
        "                                if isinstance(history_viz['train_loss'], np.ndarray):\n",
        "                                    history_viz['train_loss'] = history_viz['train_loss'].tolist()\n",
        "                            if history_viz.get('train_acc') is not None:\n",
        "                                if isinstance(history_viz['train_acc'], np.ndarray):\n",
        "                                    history_viz['train_acc'] = history_viz['train_acc'].tolist()\n",
        "                            if history_viz.get('val_loss') is not None:\n",
        "                                if isinstance(history_viz['val_loss'], np.ndarray):\n",
        "                                    history_viz['val_loss'] = history_viz['val_loss'].tolist()\n",
        "                            if history_viz.get('val_acc') is not None:\n",
        "                                if isinstance(history_viz['val_acc'], np.ndarray):\n",
        "                                    history_viz['val_acc'] = history_viz['val_acc'].tolist()\n",
        "\n",
        "                            visualizer.plot_single_model_history(history_viz, model_name)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_history.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "                            print(f\"Training history plot generated for {model_name}\")\n",
        "                            plots_generated += 1\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error plotting training history for {model_name}: {e}\")\n",
        "\n",
        "                    try:\n",
        "                        # ROC Curves\n",
        "                        visualizer.plot_roc_curves(result_viz, model_name)\n",
        "                        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_roc.png\", dpi=150, bbox_inches='tight')\n",
        "                        plt.close('all')\n",
        "                        print(f\"ROC curves plot generated for {model_name}\")\n",
        "                        plots_generated += 1\n",
        "\n",
        "                        # Confusion Matrix\n",
        "                        visualizer.plot_confusion_matrix(result_viz, model_name)\n",
        "                        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_confusion.png\", dpi=150, bbox_inches='tight')\n",
        "                        plt.close('all')\n",
        "                        print(f\"Confusion matrix plot generated for {model_name}\")\n",
        "                        plots_generated += 1\n",
        "\n",
        "                        # Misclassified Images\n",
        "                        # CORRECTION:\n",
        "                        misclassified = result_viz.get('misclassified', [])\n",
        "                        if misclassified is not None and len(misclassified) > 0:\n",
        "                        # if result_viz.get('misclassified') and len(result_viz['misclassified']) > 0:\n",
        "                            # Convert any GPU tensors in misclassified images to CPU\n",
        "                            for item in result_viz['misclassified']:\n",
        "                                if isinstance(item, dict) and 'image' in item:\n",
        "                                    if torch.is_tensor(item['image']):\n",
        "                                        item['image'] = item['image'].detach().cpu()\n",
        "                                    elif isinstance(item['image'], np.ndarray):\n",
        "                                        # Optionally transpose if channel-first\n",
        "                                        if item['image'].shape[0] in [1,3]:\n",
        "                                            item['image'] = np.transpose(item['image'], (1, 2, 0))\n",
        "\n",
        "                            visualizer.plot_misclassified_images(result_viz['misclassified'], model_name)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_misclassified.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "                            print(f\"Misclassified images plot generated for {model_name}\")\n",
        "                            plots_generated += 1\n",
        "                        else:\n",
        "                            print(f\"No misclassified images to plot for {model_name}\")\n",
        "\n",
        "                        # XAI Visualization\n",
        "                        if model is not None and test_loader is not None and len(test_loader.dataset) > 0:\n",
        "                            try:\n",
        "                                visualizer.plot_single_model_xai(model, model_name, test_loader)\n",
        "                                plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_xai.png\", dpi=150, bbox_inches='tight')\n",
        "                                plt.close('all')\n",
        "                                print(f\"XAI visualization generated for {model_name}\")\n",
        "                                plots_generated += 1\n",
        "                            except Exception as xai_error:\n",
        "                                print(f\"XAI visualization error for {model_name}: {xai_error}\")\n",
        "                        else:\n",
        "                            print(f\"Skipping XAI visualization for {model_name}: model or test_loader not available\")\n",
        "\n",
        "                    except Exception as plot_error:\n",
        "                        print(f\"Visualization error for {model_name}: {plot_error}\")\n",
        "                        import traceback\n",
        "                        traceback.print_exc()\n",
        "\n",
        "                    print(f\"Generated {plots_generated} main visualization plots for {model_name}\")\n",
        "\n",
        "                else:\n",
        "                    print(f\"Skipping main visualizations for {model_name}: data validation failed\")\n",
        "                    # print(f\"  true_labels length: {len(true_labels) if hasattr(true_labels, '__len__') else 'scalar'}\")\n",
        "                    # print(f\"  predictions length: {len(predictions) if hasattr(predictions, '__len__') else 'scalar'}\")\n",
        "                    # CORRECTION:\n",
        "                    print(f\"  true_labels length: {true_labels.shape[0] if hasattr(true_labels, 'shape') else 'scalar'}\")\n",
        "                    print(f\"  predictions length: {predictions.shape[0] if hasattr(predictions, 'shape') else 'scalar'}\")\n",
        "\n",
        "\n",
        "\n",
        "                # K-fold results plotting (load from saved files)\n",
        "                if n_folds > 1:\n",
        "                    print(f\"Loading and plotting k-fold results for {model_name}...\")\n",
        "                    fold_results_loaded = []\n",
        "\n",
        "                    for fold in range(1, n_folds + 1):\n",
        "                        fold_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{model_name}_fold_{fold}_results.pt\"\n",
        "                        if os.path.exists(fold_result_path):\n",
        "                            try:\n",
        "                                fold_data = torch.load(fold_result_path, map_location=Config.DEVICE, weights_only=False)\n",
        "\n",
        "                                # Convert GPU tensors to CPU/numpy\n",
        "                                fold_converted = {\n",
        "                                    'history': safe_gpu_convert(fold_data['history']),\n",
        "                                    'result': safe_gpu_convert(fold_data['result'])\n",
        "                                }\n",
        "                                fold_results_loaded.append(fold_converted)\n",
        "\n",
        "                            except Exception as e:\n",
        "                                print(f\"Error loading fold {fold} results: {e}\")\n",
        "\n",
        "                    # if fold_results_loaded and len(fold_results_loaded) > 0:\n",
        "                    # CORRECTION:\n",
        "                    if fold_results_loaded is not None and len(fold_results_loaded) > 0:\n",
        "                        try:\n",
        "                            visualizer.plot_kfold_results(fold_results_loaded, model_name, test_loader)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_kfold.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "                            print(f\"K-fold results plot generated for {model_name}\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"Error plotting k-fold results for {model_name}: {e}\")\n",
        "                            import traceback\n",
        "                            traceback.print_exc()\n",
        "                    else:\n",
        "                        print(f\"No k-fold results to plot for {model_name}\")\n",
        "\n",
        "                print(f\"All visualizations completed for {model_name}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in visualization process for {model_name}: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Step 7: Store results and save model\n",
        "            print(f\"\\n7. STORING RESULTS FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # # Store results for later ensemble use\n",
        "            # histories[model_name] = history\n",
        "            # single_results[model_name] = result\n",
        "            # single_models[model_name] = model\n",
        "\n",
        "            # Save model for ensemble\n",
        "            model_state_dict = model.state_dict()\n",
        "            torch.save(model_state_dict, f\"{Config.OUTPUT_DIR}/models/{model_name}_for_ensemble.pt\")\n",
        "            print(f\"Model saved for ensemble: {model_name}\")\n",
        "\n",
        "\n",
        "            # Step 8: Complete memory cleanup for this model\n",
        "            print(f\"\\n8. MEMORY CLEANUP FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Clear all variables specific to this model\n",
        "            trainer.cleanup_trainer()\n",
        "            # del trainer, history, result, model_state_dict\n",
        "            del train_loader, val_loader, test_loader\n",
        "\n",
        "            # Clear visualization data\n",
        "            if 'history_viz' in locals():\n",
        "                del history_viz\n",
        "            if 'result_viz' in locals():\n",
        "                del result_viz\n",
        "            if 'fold_results_loaded' in locals():\n",
        "                del fold_results_loaded\n",
        "            if 'history_for_viz' in locals():\n",
        "                del history_for_viz\n",
        "            if 'result_for_viz' in locals():\n",
        "                del result_for_viz\n",
        "\n",
        "            # Force garbage collection and GPU cleanup\n",
        "            plt.close('all')\n",
        "            resource_manager.aggressive_cleanup()\n",
        "\n",
        "\n",
        "            # Post-model memory state\n",
        "            post_stats = resource_manager.get_memory_stats()\n",
        "            memory_freed = pre_stats['gpu_allocated_gb'] - post_stats['gpu_allocated_gb']\n",
        "\n",
        "            print(f\"Memory cleanup completed for {model_name}:\")\n",
        "            print(f\"  GPU memory freed: {memory_freed:.2f}GB\")\n",
        "            print(f\"  Current GPU usage: {post_stats['gpu_percent']:.1f}%\")\n",
        "            print(f\"  Current CPU usage: {post_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "            print(f\"✓ {model_name} PROCESSING COMPLETED!\")\n",
        "            print(f\"{'='*70}\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {model_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "            # Emergency cleanup\n",
        "            try:\n",
        "                if 'trainer' in locals():\n",
        "                    trainer.cleanup_trainer()\n",
        "                    del trainer\n",
        "                if 'model' in locals():\n",
        "                    del model\n",
        "                resource_manager.aggressive_cleanup()\n",
        "            except:\n",
        "                pass\n",
        "            continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    single_models = {}\n",
        "    single_results = {}\n",
        "\n",
        "    def load_model_safely(model_name, model_path):\n",
        "        \"\"\"Safely load model with multiple fallback strategies\"\"\"\n",
        "        try:\n",
        "            checkpoint = torch.load(model_path, map_location=Config.DEVICE, weights_only=False)\n",
        "\n",
        "            if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
        "                # New comprehensive format - use saved architecture info\n",
        "                model = ModelFactory.create_model(\n",
        "                    model_name,\n",
        "                    num_classes=checkpoint.get('num_classes', Config.NUM_CLASSES),\n",
        "                    dropout_rate=checkpoint.get('dropout_rate', 0.5),\n",
        "                    hidden_dim_multiplier=checkpoint.get('hidden_dim_multiplier', 0.5)\n",
        "                )\n",
        "                model.to(Config.DEVICE)\n",
        "                model.load_state_dict(checkpoint['state_dict'])\n",
        "                return model, f\"new format v{checkpoint.get('save_format_version', '1.0')}\"\n",
        "\n",
        "            elif isinstance(checkpoint, dict):\n",
        "                # Legacy format - try with hyperparameters\n",
        "                hyperparams = checkpoint.get('hyperparameters', {})\n",
        "                model = ModelFactory.create_model(\n",
        "                    model_name,\n",
        "                    num_classes=Config.NUM_CLASSES,\n",
        "                    dropout_rate=hyperparams.get('dropout', 0.5),\n",
        "                    hidden_dim_multiplier=hyperparams.get('hidden_dim_multiplier', 0.5)\n",
        "                )\n",
        "                model.to(Config.DEVICE)\n",
        "                model.load_state_dict(checkpoint)\n",
        "                return model, \"legacy nested format\"\n",
        "\n",
        "            else:\n",
        "                # Try direct loading with parameter combinations\n",
        "                param_combinations = [\n",
        "                    (0.5, 0.5), (0.3, 0.5), (0.7, 0.5),\n",
        "                    (0.5, 0.3), (0.5, 0.7), (0.5, 1.0), (0.5, 1.5)\n",
        "                ]\n",
        "\n",
        "                for dropout, hidden_mult in param_combinations:\n",
        "                    try:\n",
        "                        model = ModelFactory.create_model(\n",
        "                            model_name,\n",
        "                            num_classes=Config.NUM_CLASSES,\n",
        "                            dropout_rate=dropout,\n",
        "                            hidden_dim_multiplier=hidden_mult\n",
        "                        )\n",
        "                        model.to(Config.DEVICE)\n",
        "                        model.load_state_dict(checkpoint)\n",
        "                        return model, f\"direct format (dropout={dropout}, hidden={hidden_mult})\"\n",
        "                    except RuntimeError:\n",
        "                        continue\n",
        "\n",
        "                return None, \"failed all combinations\"\n",
        "\n",
        "        except Exception as e:\n",
        "            return None, f\"loading error: {str(e)}\"\n",
        "\n",
        "    # Load models with enhanced error handling\n",
        "    for model_name in Config.MODELS:\n",
        "        model_path = os.path.join(Config.OUTPUT_DIR, \"best_model\", f\"{model_name}_best.pt\")\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"⚠️  Model file not found: {model_name}\")\n",
        "            continue\n",
        "\n",
        "        model, load_info = load_model_safely(model_name, model_path)\n",
        "\n",
        "        if model is not None:\n",
        "            model.eval()\n",
        "            single_models[model_name] = model\n",
        "            print(f\"✅ Loaded {model_name} ({load_info})\")\n",
        "\n",
        "            # Load evaluation results for visualization compatibility\n",
        "            result_path = f\"{Config.OUTPUT_DIR}/model_results/{model_name}_main_results.pt\"\n",
        "            if os.path.exists(result_path):\n",
        "                try:\n",
        "                    saved_results = torch.load(result_path, map_location='cpu', weights_only=False)\n",
        "                    result_data = saved_results.get('result', {})\n",
        "\n",
        "                    single_results[model_name] = {\n",
        "                        'model_name': model_name,\n",
        "                        'accuracy': float(result_data.get('accuracy', 0.0)),\n",
        "                        'f1_macro': float(result_data.get('f1', 0.0)),\n",
        "                        'f1_weighted': float(result_data.get('f1', 0.0)),  # Add f1_weighted key\n",
        "                        'predictions': result_data.get('predictions', []),\n",
        "                        'true_labels': result_data.get('true_labels', []),\n",
        "                        'probabilities': result_data.get('probabilities', np.zeros((0, Config.NUM_CLASSES))),\n",
        "                        'conf_matrix': result_data.get('conf_matrix', np.zeros((Config.NUM_CLASSES, Config.NUM_CLASSES))),\n",
        "                        'misclassified': result_data.get('misclassified', [])\n",
        "                    }\n",
        "\n",
        "                    # Convert tensors to numpy for visualization compatibility\n",
        "                    for key in ['predictions', 'true_labels', 'probabilities', 'conf_matrix']:\n",
        "                        if torch.is_tensor(single_results[model_name][key]):\n",
        "                            single_results[model_name][key] = single_results[model_name][key].numpy()\n",
        "\n",
        "                    print(f\"📊 Results loaded: Acc={single_results[model_name]['accuracy']:.4f}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️  Could not load results for {model_name}: {e}\")\n",
        "                    single_results[model_name] = {'model_name': model_name, 'accuracy': 0.0, 'f1_macro': 0.0, 'f1_weighted': 0.0}\n",
        "            else:\n",
        "                print(f\"⚠️  No results file for {model_name}\")\n",
        "                single_results[model_name] = {'model_name': model_name, 'accuracy': 0.0, 'f1_macro': 0.0, 'f1_weighted': 0.0}\n",
        "        else:\n",
        "            print(f\"❌ Failed to load {model_name}: {load_info}\")\n",
        "\n",
        "    print(f\"\\n🎯 Ensemble ready: {len(single_models)} models, {len(single_results)} result sets\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Step: Ensemble processing (only if we have trained models)\n",
        "    if single_models:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"ALL MODELS PROCESSED - STARTING ENSEMBLE ANALYSIS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        try:\n",
        "            if (val_data is not None and len(val_data) == 2 and len(val_data[0]) > 0 and len(val_data[1]) > 0 and len(val_data[0]) == len(val_data[1])):\n",
        "\n",
        "                ensemble_manager = EnsembleManager(single_models, val_data)\n",
        "                ensemble_results, best_ensemble = ensemble_manager.test_ensemble_combinations()\n",
        "\n",
        "                # Generate visualizations for ensemble methods\n",
        "                print(\"\\nGenerating visualizations for ensemble methods...\")\n",
        "                for ensemble_name, ensemble_result in ensemble_results.items():\n",
        "                    try:\n",
        "                        # Convert GPU tensors to CPU for visualization\n",
        "                        ensemble_result_viz = safe_gpu_convert(ensemble_result)\n",
        "\n",
        "                        true_labels_ens = ensemble_result_viz.get('true_labels', [])\n",
        "                        predictions_ens = ensemble_result_viz.get('predictions', [])\n",
        "\n",
        "                        if (len(true_labels_ens) > 0 and\n",
        "                            len(predictions_ens) > 0 and\n",
        "                            len(true_labels_ens) == len(predictions_ens)):\n",
        "\n",
        "                            visualizer.plot_roc_curves(ensemble_result_viz, ensemble_name)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{ensemble_name}_roc.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "\n",
        "                            visualizer.plot_confusion_matrix(ensemble_result_viz, ensemble_name)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{ensemble_name}_confusion.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "\n",
        "                            # F1 per class visualization\n",
        "                            from sklearn.metrics import f1_score\n",
        "                            f1_per_class = f1_score(ensemble_result_viz['true_labels'],\n",
        "                                                   ensemble_result_viz['predictions'], average=None)\n",
        "                            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "                            ax.bar(range(Config.NUM_CLASSES), f1_per_class, color='lightgreen', alpha=0.8)\n",
        "                            ax.set_xticks(range(Config.NUM_CLASSES))\n",
        "                            ax.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right')\n",
        "                            ax.set_title(f'F1 Scores per Class - {ensemble_name}',\n",
        "                                       fontsize=14, fontweight='bold', pad=15)\n",
        "                            ax.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
        "                            ax.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
        "                            ax.grid(True, alpha=0.3)\n",
        "                            for i, v in enumerate(f1_per_class):\n",
        "                                ax.text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom', fontsize=10)\n",
        "                            save_path = f\"{Config.OUTPUT_DIR}/visualizations/{ensemble_name}_f1_per_class.png\"\n",
        "                            plt.savefig(save_path, dpi=300, bbox_inches='tight',\n",
        "                                      facecolor='white', edgecolor='none')\n",
        "                            plt.close()\n",
        "                            print(f\"F1 scores per class saved: {save_path}\")\n",
        "                        else:\n",
        "                            print(f\"Skipping visualizations for {ensemble_name}: invalid data\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error generating ensemble visualizations for {ensemble_name}: {e}\")\n",
        "\n",
        "                    # Clear memory\n",
        "                    if 'ensemble_result_viz' in locals():\n",
        "                        del ensemble_result_viz\n",
        "                    resource_manager.aggressive_cleanup()\n",
        "\n",
        "                # Comment out the problematic ensemble test evaluation\n",
        "                print(\"Skipping ensemble test evaluation (method not implemented)\")\n",
        "                # if (best_ensemble and test_data is not None and len(test_data) == 2 and\n",
        "                #     len(test_data[0]) == len(test_data[1]) and len(test_data[0]) > 0):\n",
        "                #     print(\"Evaluating best ensemble on test set...\")\n",
        "                #     # Ensemble test evaluation code commented out\n",
        "\n",
        "            else:\n",
        "                print(\"Skipping ensemble analysis: no valid validation data\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in ensemble processing: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Step 10: Generate 4 comprehensive visualizations (only if we have results)\n",
        "    if single_results:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"GENERATING 4 COMPREHENSIVE ANALYSIS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        try:\n",
        "            # Convert all results to CPU/numpy for final plotting\n",
        "            single_results_viz = safe_gpu_convert(single_results)\n",
        "            ensemble_results_viz = safe_gpu_convert(ensemble_results) if 'ensemble_results' in locals() else {}\n",
        "\n",
        "            # Plot overall model comparison\n",
        "            if single_results_viz and len(single_results_viz) > 0:\n",
        "                visualizer.plot_model_comparison(single_results_viz,ensemble_results_viz)\n",
        "                plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/model_comparison.png\", dpi=300, bbox_inches='tight')\n",
        "                plt.close('all')\n",
        "\n",
        "            # Generate comprehensive report\n",
        "            visualizer.generate_comprehensive_report(\n",
        "                single_results_viz,\n",
        "                ensemble_results_viz,\n",
        "                best_ensemble if 'best_ensemble' in locals() else None\n",
        "            )\n",
        "            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/comprehensive_report.png\", dpi=300, bbox_inches='tight')\n",
        "            plt.close('all')\n",
        "\n",
        "            # Additional visualizations\n",
        "            if 'test_loader' in locals() and test_loader is not None and len(test_loader.dataset) > 0:\n",
        "                try:\n",
        "                    visualizer.plot_comparative_xai(\n",
        "                        single_models,\n",
        "                        ensemble_results_viz,\n",
        "                        test_loader,\n",
        "                        max_images=2\n",
        "                    )\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/comparative_xai.png\", dpi=300, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "\n",
        "                    visualizer.plot_lrp_grid(single_models, test_loader)\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/lrp_grid.png\", dpi=300, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in additional visualizations: {e}\")\n",
        "\n",
        "            print(\"Comprehensive analysis completed successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in comprehensive analysis: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "\n",
        "    # Final cleanup\n",
        "    print(\"\\nFinal cleanup and summary...\")\n",
        "    try:\n",
        "        # Clean up all remaining variables\n",
        "        if 'single_models' in locals():\n",
        "            del single_models\n",
        "        if 'test_loader' in locals():\n",
        "            del test_loader\n",
        "        if 'histories' in locals():\n",
        "            del histories\n",
        "        if 'single_results' in locals():\n",
        "            del single_results\n",
        "        if 'single_results_viz' in locals():\n",
        "            del single_results_viz\n",
        "        if 'ensemble_results' in locals():\n",
        "            del ensemble_results\n",
        "        if 'ensemble_results_viz' in locals():\n",
        "            del ensemble_results_viz\n",
        "        if 'best_ensemble' in locals():\n",
        "            del best_ensemble\n",
        "        if 'visualizer' in locals():\n",
        "            del visualizer\n",
        "\n",
        "        resource_manager.aggressive_cleanup()\n",
        "\n",
        "        # Final memory stats\n",
        "        final_stats = resource_manager.get_memory_stats()\n",
        "        print(f\"Final GPU memory: {final_stats['gpu_allocated_gb']:.2f}GB allocated ({final_stats['gpu_percent']:.1f}%)\")\n",
        "        print(f\"Final CPU usage: {final_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in final cleanup: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PIPELINE COMPLETED!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nGenerated Files:\")\n",
        "    print(f\"- Model checkpoints: {Config.OUTPUT_DIR}/models/\")\n",
        "    print(f\"- Training results: {Config.OUTPUT_DIR}/model_results/\")\n",
        "    print(f\"- K-fold results: {Config.OUTPUT_DIR}/kfold_results/\")\n",
        "    print(f\"- Visualizations: {Config.OUTPUT_DIR}/visualizations/\")\n",
        "    print(f\"- Best models: {Config.OUTPUT_DIR}/best_model/\")\n",
        "\n",
        "\n",
        "# Environment setup and multiprocessing configuration\n",
        "import torch.multiprocessing as mp\n",
        "if __name__ == \"__main__\":\n",
        "    # # Environment setup for maximum performance with 20GB GPU + 50GB CPU\n",
        "    # os.environ['CUDA_LAUNCH_BLOCKING'] = '0'\n",
        "    # os.environ['OMP_NUM_THREADS'] = '16'  # Max CPU utilization\n",
        "    # os.environ['MKL_NUM_THREADS'] = '16'\n",
        "    # os.environ['NUMEXPR_NUM_THREADS'] = '16'\n",
        "\n",
        "    # # Additional GPU optimizations\n",
        "    # if torch.cuda.is_available():\n",
        "    #     torch.backends.cudnn.enabled = True\n",
        "    #     torch.backends.cudnn.benchmark = True\n",
        "    #     torch.backends.cudnn.deterministic = False\n",
        "    #     torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    #     torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "    # Multiprocessing setup for CUDA compatibility\n",
        "    # try:\n",
        "        # import torch.multiprocessing as mp\n",
        "    #     mp.set_start_method('spawn', force=True)\n",
        "    # except RuntimeError:\n",
        "    #     pass  # Already set\n",
        "\n",
        "    # print(\"Environment optimizations applied:\")\n",
        "    # print(f\"CUDNN Enabled: {torch.backends.cudnn.enabled}\")\n",
        "    # print(f\"CUDNN Benchmark: {torch.backends.cudnn.benchmark}\")\n",
        "    # print(f\"Allow TF32 Matmul: {torch.backends.cuda.matmul.allow_tf32}\")\n",
        "    # print(f\"OMP Threads: {os.environ.get('OMP_NUM_THREADS', 'default')}\")\n",
        "\n",
        "    main()"
      ],
      "metadata": {
        "id": "eXcdgsbTh2ED",
        "outputId": "bb827962-f4da-492f-be8c-14a8196cea24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "eXcdgsbTh2ED",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m400.9/400.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.0/63.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pytorch-gradcam (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Optuna Trial\n",
        "=================================================="
      ],
      "metadata": {
        "id": "Uap-g_plcGUX"
      },
      "id": "Uap-g_plcGUX"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "13.Fish Species Classification Pipeline - Hyperparameter Optimization\n",
        "===================================================================================================================\n",
        "\n",
        "This module handles hyperparameter optimization using Optuna for all models.\n",
        "It will find the best parameters for each model and save them to JSON files.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import optuna\n",
        "import numpy as np\n",
        "import gc\n",
        "import time\n",
        "import psutil\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# orig_numpy = torch.Tensor.numpy\n",
        "# def patched_numpy(self, *args, **kwargs):\n",
        "#     if self.is_cuda:\n",
        "#         raise RuntimeError(f\"Tried to call .numpy() on CUDA tensor at line ???. Move it to CPU first!\")\n",
        "#     return orig_numpy(self, *args, **kwargs)\n",
        "\n",
        "# torch.Tensor.numpy = patched_numpy\n",
        "\n",
        "class ResourceManager:\n",
        "    \"\"\"Smart resource management for optimal GPU/CPU utilization\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.gpu_memory_gb = 20\n",
        "        self.cpu_memory_gb = 50\n",
        "        self.max_gpu_usage = 0.85  # 85% of 20GB = 17GB\n",
        "        self.max_cpu_usage = 0.90  # 80% of 50GB = 40GB\n",
        "\n",
        "    def get_memory_stats(self):\n",
        "        \"\"\"Get current memory usage statistics\"\"\"\n",
        "        stats = {'cpu_percent': psutil.virtual_memory().percent}\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            stats['gpu_allocated_gb'] = torch.cuda.memory_allocated() / (1024**3)\n",
        "            stats['gpu_reserved_gb'] = torch.cuda.memory_reserved() / (1024**3)\n",
        "            stats['gpu_percent'] = (stats['gpu_reserved_gb'] / self.gpu_memory_gb) * 100\n",
        "        else:\n",
        "            stats.update({'gpu_allocated_gb': 0, 'gpu_reserved_gb': 0, 'gpu_percent': 0})\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def should_cleanup_aggressive(self):\n",
        "        \"\"\"Check if aggressive cleanup is needed\"\"\"\n",
        "        stats = self.get_memory_stats()\n",
        "        return (stats['gpu_percent'] > 90 or stats['cpu_percent'] > 90)\n",
        "\n",
        "    def aggressive_cleanup(self):\n",
        "        \"\"\"Perform comprehensive memory cleanup\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "        gc.collect()\n",
        "        time.sleep(0.1)  # Brief pause for system cleanup\n",
        "\n",
        "    def optimize_batch_size(self, base_size, model_complexity=1.0):\n",
        "        \"\"\"Calculate optimal batch size based on current memory state\"\"\"\n",
        "        stats = self.get_memory_stats()\n",
        "\n",
        "        # Reduce batch size if memory usage is high\n",
        "        memory_factor = max(0.4, 1.0 - (stats['gpu_percent'] / 100))\n",
        "        optimal_size = int(base_size * memory_factor / model_complexity)\n",
        "\n",
        "        return max(32, min(256, optimal_size))  # Keep within reasonable bounds\n",
        "\n",
        "\n",
        "def safe_gpu_convert(data):\n",
        "    \"\"\"Safely convert GPU tensors to CPU numpy arrays or lists\"\"\"\n",
        "    if torch.is_tensor(data):\n",
        "        if data.is_cuda:\n",
        "            data = data.detach().cpu()\n",
        "        if data.dim() == 0:\n",
        "            return data.item()\n",
        "        elif data.dtype == torch.bool or data.dtype == torch.uint8:\n",
        "            return data.numpy()\n",
        "        else:\n",
        "            return data.numpy() if data.dim() > 0 else data.item()\n",
        "    elif isinstance(data, list):\n",
        "        return [safe_gpu_convert(item) for item in data]\n",
        "    elif isinstance(data, dict):\n",
        "        return {k: safe_gpu_convert(v) for k, v in data.items()}\n",
        "    elif isinstance(data, np.ndarray):\n",
        "        return data  # Already numpy\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"\\nStarting Fish Species Hyperparameter Optimization...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Environment setup for maximum performance\n",
        "    setup_environment()\n",
        "\n",
        "\n",
        "    # Set optimal thread count for CPU utilization\n",
        "    print(f\"CPU : {os.cpu_count()}\")\n",
        "    print(f\"USER: {os.getenv('USER')}\")\n",
        "    print(f\"HOME: {os.getenv('HOME')}\")\n",
        "    torch.set_num_threads(min(16, os.cpu_count()))\n",
        "    os.environ['OMP_NUM_THREADS'] = str(min(16, os.cpu_count()))\n",
        "\n",
        "    # OpenMP → Open Multi-Processing.\n",
        "    # OpenMP is a widely used API for parallel programming on CPUs.\n",
        "    # Many scientific libraries (like NumPy, PyTorch, TensorFlow,\n",
        "    # -OpenCV, Scikit-learn) rely on OpenMP to run operations in parallel across CPU cores.\n",
        "    # In main() after line 720:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    # Auto-benchmarks and selects fastest cuDNN algorithms for your specific hardware and input sizes\n",
        "    # Takes ~5-10 seconds at start but can provide 10-20% speedup throughout training\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    # Allows cuDNN to use fastest available algorithms even if they produce slightly different results each run\n",
        "    # Trades reproducibility for speed - essential for maximum performance in production training\n",
        "    # torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    # Uses TensorFloat-32 (19-bit precision) instead of full Float-32 for matrix multiplications\n",
        "    # Provides ~1.6x speedup on Ampere GPUs with negligible accuracy loss for deep learning\n",
        "    # torch.backends.cudnn.allow_tf32 = True\n",
        "    # Enables TF32 precision for cuDNN operations (convolutions, pooling, batch norm)\n",
        "    # Accelerates CNN layers by 1.3-1.6x on RTX 30/40 series and A100+ GPUs\n",
        "    torch.backends.cuda.enable_flash_sdp(True)\n",
        "    # Activates Flash Attention algorithm for memory-efficient attention computations\n",
        "    # Reduces GPU memory usage by 2-4x and increases attention speed, crucial for transformer layers\n",
        "\n",
        "    # GPU optimizations\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "        gpu_props = torch.cuda.get_device_properties(0)\n",
        "        print(f\"GPU: {gpu_props.name}, Memory: {gpu_props.total_memory / 1024**3:.1f}GB\")\n",
        "\n",
        "    # CPU info\n",
        "    print(f\"CPU Cores: {os.cpu_count()}, Using threads: {torch.get_num_threads()}\")\n",
        "\n",
        "    # Ensure all output directories exist\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/hyperparameters\", exist_ok=True)\n",
        "\n",
        "    # Initialize resource manager\n",
        "    resource_manager = ResourceManager()\n",
        "\n",
        "    # Load and balance data (only once)\n",
        "    print(\"\\nLoading and balancing data...\")\n",
        "    X, Y = DataManager.load_and_balance_data()\n",
        "    print(f\"Total samples after balancing: {len(X):,}, Labels: {len(Y):,}\")\n",
        "\n",
        "    # Validate data consistency\n",
        "    if len(X) != len(Y):\n",
        "        raise ValueError(f\"Inconsistent data: X has {len(X)} samples, Y has {len(Y)} labels\")\n",
        "    if len(X) == 0:\n",
        "        raise ValueError(\"No data available after loading and balancing\")\n",
        "\n",
        "    # Dictionary to store all best parameters\n",
        "    all_best_params = {}\n",
        "\n",
        "    # Process each model individually for hyperparameter optimization\n",
        "    for model_name in Config.MODELS:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"HYPERPARAMETER OPTIMIZATION FOR: {model_name}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Pre-model memory state\n",
        "        pre_stats = resource_manager.get_memory_stats()\n",
        "        print(f\"Pre-training memory - GPU: {pre_stats['gpu_allocated_gb']:.2f}GB ({pre_stats['gpu_percent']:.1f}%), \"\n",
        "              f\"CPU: {pre_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "        try:\n",
        "            # Step 1: Create initial data loaders for hyperparameter optimization\n",
        "            print(f\"\\n1. CREATING INITIAL DATA LOADERS FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(X, Y)\n",
        "\n",
        "            # Validate data loaders\n",
        "            print(f\"Train loader: {len(train_loader.dataset) if train_loader else 0} samples\")\n",
        "            print(f\"Val loader: {len(val_loader.dataset) if val_loader else 0} samples\")\n",
        "            print(f\"Test loader: {len(test_loader.dataset) if test_loader else 0} samples\")\n",
        "\n",
        "            if not train_loader or len(train_loader.dataset) == 0:\n",
        "                print(f\"Skipping {model_name}: No training data available\")\n",
        "                continue #To Go Next Model\n",
        "            if not val_loader or len(val_loader.dataset) == 0:\n",
        "                print(f\"Skipping {model_name}: No validation data available\")\n",
        "                continue\n",
        "\n",
        "            # Step 2: Optimize hyperparameters\n",
        "            print(f\"\\n2. HYPERPARAMETER OPTIMIZATION FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "            torch.serialization.add_safe_globals([np.core.multiarray.scalar])\n",
        "            torch.set_num_threads(2)  # Reduce CPU threads for GPU workload\n",
        "\n",
        "            # Debug data loader sizes\n",
        "            print(f\"Train loader size: {len(train_loader.dataset)} samples, {len(train_loader)} batches\")\n",
        "            print(f\"Val loader size: {len(val_loader.dataset)} samples, {len(val_loader)} batches\")\n",
        "\n",
        "            try:\n",
        "                optimizer = ExpandedHyperparameterOptimizer(model_name, train_loader, val_loader)\n",
        "                best_params = optimizer.optimize()\n",
        "                all_best_params[model_name] = best_params\n",
        "                del optimizer\n",
        "                resource_manager.aggressive_cleanup()\n",
        "            except Exception as e:\n",
        "                print(f\"Error in hyperparameter optimization for {model_name}: {str(e)}\")\n",
        "                import traceback\n",
        "                # traceback.print_exc()\n",
        "                traceback.format_exc()\n",
        "                print(traceback.format_exc())\n",
        "                #Or Log it\n",
        "                tb_log = traceback.format_exc()\n",
        "                # logger.error(tb_log)\n",
        "                best_params = {}  # Fallback to default hyperparameters\n",
        "                all_best_params[model_name] = best_params\n",
        "\n",
        "            print(f\"\\n\\033[1;31m{'='*70}\\033[0m\")\n",
        "            print(f\"\\033[1;31m{model_name.upper()} BEST PARAMETERS:\\033[0m\")\n",
        "            for key, value in best_params.items():\n",
        "                if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                    print(f\"\\033[1;31m  {key}: {value:.4f}\\033[0m\")\n",
        "                else:\n",
        "                    print(f\"\\033[1;31m  {key}: {value}\\033[0m\")\n",
        "            print(f\"\\033[1;31m{'='*70}\\033[0m\")\n",
        "\n",
        "            # Save best parameters to JSON file\n",
        "            params_file = f\"{Config.OUTPUT_DIR}/hyperparameters/{model_name}_best_params.json\"\n",
        "            with open(params_file, 'w') as f:\n",
        "                json.dump(best_params, f, indent=4)\n",
        "            print(f\"Best parameters saved to: {params_file}\")\n",
        "\n",
        "            # Memory cleanup\n",
        "            del train_loader, val_loader, test_loader\n",
        "            resource_manager.aggressive_cleanup()\n",
        "\n",
        "            # Post-model memory state\n",
        "            post_stats = resource_manager.get_memory_stats()\n",
        "            memory_freed = pre_stats['gpu_allocated_gb'] - post_stats['gpu_allocated_gb']\n",
        "\n",
        "            print(f\"Memory cleanup completed for {model_name}:\")\n",
        "            print(f\"  GPU memory freed: {memory_freed:.2f}GB\")\n",
        "            print(f\"  Current GPU usage: {post_stats['gpu_percent']:.1f}%\")\n",
        "            print(f\"  Current CPU usage: {post_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "            print(f\"✓ {model_name} HYPERPARAMETER OPTIMIZATION COMPLETED!\")\n",
        "            print(f\"{'='*70}\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {model_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "            # Emergency cleanup\n",
        "            try:\n",
        "                if 'optimizer' in locals():\n",
        "                    del optimizer\n",
        "                resource_manager.aggressive_cleanup()\n",
        "            except:\n",
        "                pass\n",
        "            continue\n",
        "\n",
        "    # Save all best parameters to master file\n",
        "    master_params_file = f\"{Config.OUTPUT_DIR}/hyperparameters/all_best_params.json\"\n",
        "    with open(master_params_file, 'w') as f:\n",
        "        json.dump(all_best_params, f, indent=4)\n",
        "\n",
        "    print(f\"All best parameters saved to: {master_params_file}\")\n",
        "\n",
        "    # Final cleanup\n",
        "    print(\"\\nFinal cleanup and summary...\")\n",
        "    try:\n",
        "        # Clean up all remaining variables\n",
        "        if 'all_best_params' in locals():\n",
        "            del all_best_params\n",
        "\n",
        "        resource_manager.aggressive_cleanup()\n",
        "\n",
        "        # Final memory stats\n",
        "        final_stats = resource_manager.get_memory_stats()\n",
        "        print(f\"Final GPU memory: {final_stats['gpu_allocated_gb']:.2f}GB allocated ({final_stats['gpu_percent']:.1f}%)\")\n",
        "        print(f\"Final CPU usage: {final_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in final cleanup: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"HYPERPARAMETER OPTIMIZATION COMPLETED!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nGenerated Files:\")\n",
        "    print(f\"- Best parameters: {Config.OUTPUT_DIR}/hyperparameters/\")\n",
        "\n",
        "\n",
        "# Environment setup and multiprocessing configuration\n",
        "import torch.multiprocessing as mp\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "gewZDcBzbnaK"
      },
      "id": "gewZDcBzbnaK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Training"
      ],
      "metadata": {
        "id": "rQ_reeX1cZz4"
      },
      "id": "rQ_reeX1cZz4"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "14.Fish Species Classification Pipeline - Model Training\n",
        "==================================================\n",
        "\n",
        "This module handles the main model training using optimized hyperparameters.\n",
        "It loads the best parameters from JSON files and trains models, saving them as .pt and .keras files.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "import gc\n",
        "import time\n",
        "import psutil\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# orig_numpy = torch.Tensor.numpy\n",
        "# def patched_numpy(self, *args, **kwargs):\n",
        "#     if self.is_cuda:\n",
        "#         raise RuntimeError(f\"Tried to call .numpy() on CUDA tensor at line ???. Move it to CPU first!\")\n",
        "#     return orig_numpy(self, *args, **kwargs)\n",
        "\n",
        "# torch.Tensor.numpy = patched_numpy\n",
        "\n",
        "class ResourceManager:\n",
        "    \"\"\"Smart resource management for optimal GPU/CPU utilization\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.gpu_memory_gb = 20\n",
        "        self.cpu_memory_gb = 50\n",
        "        self.max_gpu_usage = 0.85  # 85% of 20GB = 17GB\n",
        "        self.max_cpu_usage = 0.90  # 80% of 50GB = 40GB\n",
        "\n",
        "    def get_memory_stats(self):\n",
        "        \"\"\"Get current memory usage statistics\"\"\"\n",
        "        stats = {'cpu_percent': psutil.virtual_memory().percent}\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            stats['gpu_allocated_gb'] = torch.cuda.memory_allocated() / (1024**3)\n",
        "            stats['gpu_reserved_gb'] = torch.cuda.memory_reserved() / (1024**3)\n",
        "            stats['gpu_percent'] = (stats['gpu_reserved_gb'] / self.gpu_memory_gb) * 100\n",
        "        else:\n",
        "            stats.update({'gpu_allocated_gb': 0, 'gpu_reserved_gb': 0, 'gpu_percent': 0})\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def should_cleanup_aggressive(self):\n",
        "        \"\"\"Check if aggressive cleanup is needed\"\"\"\n",
        "        stats = self.get_memory_stats()\n",
        "        return (stats['gpu_percent'] > 90 or stats['cpu_percent'] > 90)\n",
        "\n",
        "    def aggressive_cleanup(self):\n",
        "        \"\"\"Perform comprehensive memory cleanup\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "        gc.collect()\n",
        "        time.sleep(0.1)  # Brief pause for system cleanup\n",
        "\n",
        "    def optimize_batch_size(self, base_size, model_complexity=1.0):\n",
        "        \"\"\"Calculate optimal batch size based on current memory state\"\"\"\n",
        "        stats = self.get_memory_stats()\n",
        "\n",
        "        # Reduce batch size if memory usage is high\n",
        "        memory_factor = max(0.4, 1.0 - (stats['gpu_percent'] / 100))\n",
        "        optimal_size = int(base_size * memory_factor / model_complexity)\n",
        "\n",
        "        return max(32, min(256, optimal_size))  # Keep within reasonable bounds\n",
        "\n",
        "\n",
        "def safe_gpu_convert(data):\n",
        "    \"\"\"Safely convert GPU tensors to CPU numpy arrays or lists\"\"\"\n",
        "    if torch.is_tensor(data):\n",
        "        if data.is_cuda:\n",
        "            data = data.detach().cpu()\n",
        "        if data.dim() == 0:\n",
        "            return data.item()\n",
        "        elif data.dtype == torch.bool or data.dtype == torch.uint8:\n",
        "            return data.numpy()\n",
        "        else:\n",
        "            return data.numpy() if data.dim() > 0 else data.item()\n",
        "    elif isinstance(data, list):\n",
        "        return [safe_gpu_convert(item) for item in data]\n",
        "    elif isinstance(data, dict):\n",
        "        return {k: safe_gpu_convert(v) for k, v in data.items()}\n",
        "    elif isinstance(data, np.ndarray):\n",
        "        return data  # Already numpy\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"\\nStarting Fish Species Model Training...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Environment setup for maximum performance\n",
        "    setup_environment()\n",
        "\n",
        "\n",
        "    # Set optimal thread count for CPU utilization\n",
        "    print(f\"CPU : {os.cpu_count()}\")\n",
        "    print(f\"USER: {os.getenv('USER')}\")\n",
        "    print(f\"HOME: {os.getenv('HOME')}\")\n",
        "    torch.set_num_threads(min(16, os.cpu_count()))\n",
        "    os.environ['OMP_NUM_THREADS'] = str(min(16, os.cpu_count()))\n",
        "\n",
        "    # OpenMP → Open Multi-Processing.\n",
        "    # OpenMP is a widely used API for parallel programming on CPUs.\n",
        "    # Many scientific libraries (like NumPy, PyTorch, TensorFlow,\n",
        "    # -OpenCV, Scikit-learn) rely on OpenMP to run operations in parallel across CPU cores.\n",
        "    # In main() after line 720:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    # Auto-benchmarks and selects fastest cuDNN algorithms for your specific hardware and input sizes\n",
        "    # Takes ~5-10 seconds at start but can provide 10-20% speedup throughout training\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    # Allows cuDNN to use fastest available algorithms even if they produce slightly different results each run\n",
        "    # Trades reproducibility for speed - essential for maximum performance in production training\n",
        "    # torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    # Uses TensorFloat-32 (19-bit precision) instead of full Float-32 for matrix multiplications\n",
        "    # Provides ~1.6x speedup on Ampere GPUs with negligible accuracy loss for deep learning\n",
        "    # torch.backends.cudnn.allow_tf32 = True\n",
        "    # Enables TF32 precision for cuDNN operations (convolutions, pooling, batch norm)\n",
        "    # Accelerates CNN layers by 1.3-1.6x on RTX 30/40 series and A100+ GPUs\n",
        "    torch.backends.cuda.enable_flash_sdp(True)\n",
        "    # Activates Flash Attention algorithm for memory-efficient attention computations\n",
        "    # Reduces GPU memory usage by 2-4x and increases attention speed, crucial for transformer layers\n",
        "\n",
        "    # GPU optimizations\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "        gpu_props = torch.cuda.get_device_properties(0)\n",
        "        print(f\"GPU: {gpu_props.name}, Memory: {gpu_props.total_memory / 1024**3:.1f}GB\")\n",
        "\n",
        "    # CPU info\n",
        "    print(f\"CPU Cores: {os.cpu_count()}, Using threads: {torch.get_num_threads()}\")\n",
        "\n",
        "    # Ensure all output directories exist\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/models\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/kfold_results\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/model_results\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/best_model\", exist_ok=True)\n",
        "\n",
        "    # Initialize resource manager\n",
        "    resource_manager = ResourceManager()\n",
        "\n",
        "    # Load and balance data (only once)\n",
        "    print(\"\\nLoading and balancing data...\")\n",
        "    X, Y = DataManager.load_and_balance_data()\n",
        "    print(f\"Total samples after balancing: {len(X):,}, Labels: {len(Y):,}\")\n",
        "\n",
        "    # Validate data consistency\n",
        "    if len(X) != len(Y):\n",
        "        raise ValueError(f\"Inconsistent data: X has {len(X)} samples, Y has {len(Y)} labels\")\n",
        "    if len(X) == 0:\n",
        "        raise ValueError(\"No data available after loading and balancing\")\n",
        "\n",
        "    # Load all best parameters from hyperparameter optimization\n",
        "    master_params_file = f\"{Config.OUTPUT_DIR}/hyperparameters/all_best_params.json\"\n",
        "    if os.path.exists(master_params_file):\n",
        "        with open(master_params_file, 'r') as f:\n",
        "            all_best_params = json.load(f)\n",
        "        print(f\"Loaded best parameters for {len(all_best_params)} models\")\n",
        "    else:\n",
        "        print(\"No hyperparameters found, using default parameters\")\n",
        "        all_best_params = {}\n",
        "\n",
        "    # Process each model individually\n",
        "    for model_name in Config.MODELS:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"TRAINING MODEL: {model_name}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Pre-model memory state\n",
        "        pre_stats = resource_manager.get_memory_stats()\n",
        "        print(f\"Pre-training memory - GPU: {pre_stats['gpu_allocated_gb']:.2f}GB ({pre_stats['gpu_percent']:.1f}%), \"\n",
        "              f\"CPU: {pre_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "        try:\n",
        "            # Load best parameters for this model\n",
        "            if model_name in all_best_params:\n",
        "                best_params = all_best_params[model_name]\n",
        "                print(f\"Using optimized parameters for {model_name}\")\n",
        "            else:\n",
        "                # Load individual parameter file as fallback\n",
        "                params_file = f\"{Config.OUTPUT_DIR}/hyperparameters/{model_name}_best_params.json\"\n",
        "                if os.path.exists(params_file):\n",
        "                    with open(params_file, 'r') as f:\n",
        "                        best_params = json.load(f)\n",
        "                    print(f\"Loaded individual parameters for {model_name}\")\n",
        "                else:\n",
        "                    # Default parameters as last resort\n",
        "                    best_params = {\n",
        "                        'lr': 0.001,\n",
        "                        'weight_decay': 0.0001,\n",
        "                        'dropout': 0.5,\n",
        "                        'batch_size': 32,\n",
        "                        'hidden_dim_multiplier': 0.5,\n",
        "                        'augmentation_strength': 'medium'\n",
        "                    }\n",
        "                    print(f\"Using default parameters for {model_name}\")\n",
        "\n",
        "            # Display parameters being used\n",
        "            print(f\"\\n{model_name.upper()} TRAINING PARAMETERS:\")\n",
        "            for key, value in best_params.items():\n",
        "                if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                    print(f\"  {key}: {value:.4f}\")\n",
        "                else:\n",
        "                    print(f\"  {key}: {value}\")\n",
        "\n",
        "            # Step 1: Create data loaders with optimized parameters\n",
        "            print(f\"\\n1. CREATING DATA LOADERS WITH OPTIMIZED PARAMETERS FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Calculate optimal batch size based on model complexity\n",
        "            model_complexity_map = {\n",
        "                'efficientnet_': 1.5,  # matches efficientnet_b0, efficientnet_b7 etc.\n",
        "                'resnet': 1.0,         # matches resnet18, resnet50 etc.\n",
        "                'vgg': 0.8,            # matches vgg16, vgg19 etc.\n",
        "                'mobilenet_': 0.6,     # matches mobilenet_v2, mobilenet_v3 etc.\n",
        "                'densenet': 1.3,       # matches densenet121, densenet201 etc.\n",
        "                'convnext_': 1.4       # matches convnext_tiny, convnext_base etc.\n",
        "            }\n",
        "\n",
        "            model_complexity = model_complexity_map.get(model_name.split('_')[0].lower(), 1.0) #model_name gets from for loop.\n",
        "            #\"EfficientNet_B0\".split('_')[0].lower() → \"efficientnet\"\n",
        "            base_batch_size = best_params.get('batch_size', Config.BATCH_SIZE)\n",
        "            optimized_batch_size = resource_manager.optimize_batch_size(base_batch_size, model_complexity)\n",
        "\n",
        "            # Create with optimized batch size and GPU-optimized settings\n",
        "            train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(\n",
        "                X, Y,\n",
        "                test_size=0.2,\n",
        "                batch_size=optimized_batch_size,\n",
        "                augmentation_strength=best_params.get('augmentation_strength', 'medium')\n",
        "            )\n",
        "\n",
        "            # Optimize data loaders for GPU\n",
        "            optimal_workers = min(16, max(8, os.cpu_count() // 2))\n",
        "            for loader in [train_loader, val_loader, test_loader]:\n",
        "                if loader:\n",
        "                    loader.pin_memory = torch.cuda.is_available()\n",
        "                    loader.num_workers = optimal_workers\n",
        "                    loader.prefetch_factor = 4 if optimal_workers > 0 else 2\n",
        "\n",
        "            # Validate data loaders\n",
        "            print(f\"Train: {len(train_loader.dataset)}, Val: {len(val_loader.dataset)}, Test: {len(test_loader.dataset)}\")\n",
        "            print(f\"Optimized batch size: {optimized_batch_size} (complexity factor: {model_complexity})\")\n",
        "\n",
        "            if not train_loader or len(train_loader.dataset) == 0:\n",
        "                print(f\"Skipping {model_name}: No training data available\")\n",
        "                continue #To Go Next Model\n",
        "            if not val_loader or len(val_loader.dataset) == 0:\n",
        "                print(f\"Skipping {model_name}: No validation data available\")\n",
        "                continue\n",
        "\n",
        "            # Additional validation for val_data and test_data tuples\n",
        "            if val_data is not None and len(val_data) == 2:\n",
        "                print(f\"Val data tuple: X={len(val_data[0])}, Y={len(val_data[1])}\")\n",
        "                if len(val_data[0]) != len(val_data[1]):\n",
        "                    print(f\"WARNING: Validation data inconsistency: {len(val_data[0])} samples vs {len(val_data[1])} labels\")\n",
        "\n",
        "            if test_data is not None and len(test_data) == 2:\n",
        "                print(f\"Test data tuple: X={len(test_data[0])}, Y={len(test_data[1])}\")\n",
        "                if len(test_data[0]) != len(test_data[1]):\n",
        "                    print(f\"WARNING: Test data inconsistency: {len(test_data[0])} samples vs {len(test_data[1])} labels\")\n",
        "\n",
        "            # Step 2: Train main model\n",
        "            print(f\"\\n2. MAIN MODEL TRAINING FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            model = ModelFactory.create_model(\n",
        "                model_name,\n",
        "                num_classes=Config.NUM_CLASSES,\n",
        "                dropout_rate=best_params.get('dropout', 0.5),\n",
        "                hidden_dim_multiplier=best_params.get('hidden_dim_multiplier', 0.5)\n",
        "            ).to(Config.DEVICE, memory_format=torch.channels_last)  # GPU optimization\n",
        "\n",
        "            # Model info\n",
        "            total_model_params = sum(p.numel() for p in model.parameters())\n",
        "            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "            print(f\"Model created: {total_model_params:,} total params, {trainable_params:,} trainable\")\n",
        "\n",
        "            # Additional GPU optimizations\n",
        "            torch.backends.cudnn.benchmark = True\n",
        "            torch.backends.cudnn.deterministic = False\n",
        "            # Tells cuDNN (NVIDIA's deep learning library) to find the fastest algorithm for your hardware and input size.\n",
        "            # Benchmarking finds the fastest algorithm.\n",
        "            # Non-determinism allows cuDNN to use even faster (but slightly variable) methods.\n",
        "            # Together → maximum training speed, but with non-reproducible results (F1 score may vary slightly between runs).\n",
        "            # For speed → benchmark=True, deterministic=False (your case).\n",
        "            # For reproducibility → benchmark=False, deterministic=True.\n",
        "\n",
        "            trainer = EnhancedModelTrainer(model, model_name, best_params)\n",
        "            # history, result = trainer.train_main_model(train_loader, val_loader, test_loader)\n",
        "            trainer.train_main_model(train_loader, val_loader, test_loader)\n",
        "\n",
        "            # if history is None or result is None: #No Need cause Data is saved to Disk Directly\n",
        "            #     print(f\"Training failed for {model_name}, skipping...\")\n",
        "            #     continue\n",
        "\n",
        "            print(f\"Main model training completed for {model_name}\")\n",
        "\n",
        "            # Step 3: K-fold cross-validation\n",
        "            print(f\"\\n3. K-FOLD CROSS-VALIDATION FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Ensure we have sufficient data for k-fold\n",
        "            total_samples = len(train_loader.dataset)\n",
        "            min_samples_per_fold = 500\n",
        "            max_folds = total_samples // min_samples_per_fold\n",
        "            n_folds = min(3, max_folds) if max_folds > 1 else 0\n",
        "\n",
        "            if n_folds > 1:\n",
        "                print(f\"Performing {n_folds}-fold cross-validation...\")\n",
        "                # fold_results =\n",
        "                trainer.train_kfold(train_loader, val_loader, test_loader,n_folds=n_folds)\n",
        "                print(f\"K-fold validation completed for {model_name}\")\n",
        "            else:\n",
        "                print(f\"Skipping k-fold validation for {model_name}: insufficient data (need >{min_samples_per_fold*2} samples)\")\n",
        "                fold_results = []\n",
        "\n",
        "            # Step 4: Save model in both .pt and .keras formats\n",
        "            print(f\"\\n4. SAVING MODEL FILES FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Save model for ensemble\n",
        "            model_state_dict = model.state_dict()\n",
        "            torch.save(model_state_dict, f\"{Config.OUTPUT_DIR}/models/{model_name}_for_ensemble.pt\")\n",
        "            print(f\"Model saved for ensemble: {model_name}\")\n",
        "\n",
        "            # Save model as .pt file (PyTorch format)\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'model_name': model_name,\n",
        "                'num_classes': Config.NUM_CLASSES,\n",
        "                'hyperparameters': best_params,\n",
        "                'architecture_info': {\n",
        "                    'dropout_rate': best_params.get('dropout', 0.5),\n",
        "                    'hidden_dim_multiplier': best_params.get('hidden_dim_multiplier', 0.5)\n",
        "                }\n",
        "            }, f\"{Config.OUTPUT_DIR}/best_model/{model_name}_best.pt\")\n",
        "            print(f\"Model saved as .pt file: {model_name}_best.pt\")\n",
        "\n",
        "            # Save model as .keras file (if TensorFlow/Keras conversion is available)\n",
        "            try:\n",
        "                # This would require conversion logic if needed\n",
        "                # For now, we'll save a placeholder or skip\n",
        "                print(f\"Keras format saving for {model_name} - conversion logic needed\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not save {model_name} in Keras format: {e}\")\n",
        "\n",
        "            # Step 5: Memory cleanup for this model\n",
        "            print(f\"\\n5. MEMORY CLEANUP FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Clear all variables specific to this model\n",
        "            trainer.cleanup_trainer()\n",
        "            # del trainer, history, result, model_state_dict\n",
        "            del train_loader, val_loader, test_loader\n",
        "            if 'model' in locals():\n",
        "                del model\n",
        "            if 'model_state_dict' in locals():\n",
        "                del model_state_dict\n",
        "\n",
        "            # Force garbage collection and GPU cleanup\n",
        "            resource_manager.aggressive_cleanup()\n",
        "\n",
        "            # Post-model memory state\n",
        "            post_stats = resource_manager.get_memory_stats()\n",
        "            memory_freed = pre_stats['gpu_allocated_gb'] - post_stats['gpu_allocated_gb']\n",
        "\n",
        "            print(f\"Memory cleanup completed for {model_name}:\")\n",
        "            print(f\"  GPU memory freed: {memory_freed:.2f}GB\")\n",
        "            print(f\"  Current GPU usage: {post_stats['gpu_percent']:.1f}%\")\n",
        "            print(f\"  Current CPU usage: {post_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "            print(f\"✓ {model_name} TRAINING COMPLETED!\")\n",
        "            print(f\"{'='*70}\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {model_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "            # Emergency cleanup\n",
        "            try:\n",
        "                if 'trainer' in locals():\n",
        "                    trainer.cleanup_trainer()\n",
        "                    del trainer\n",
        "                if 'model' in locals():\n",
        "                    del model\n",
        "                resource_manager.aggressive_cleanup()\n",
        "            except:\n",
        "                pass\n",
        "            continue\n",
        "\n",
        "    # Final cleanup\n",
        "    print(\"\\nFinal cleanup and summary...\")\n",
        "    try:\n",
        "        # Clean up all remaining variables\n",
        "        if 'X' in locals():\n",
        "            del X\n",
        "        if 'Y' in locals():\n",
        "            del Y\n",
        "        if 'all_best_params' in locals():\n",
        "            del all_best_params\n",
        "\n",
        "        resource_manager.aggressive_cleanup()\n",
        "\n",
        "        # Final memory stats\n",
        "        final_stats = resource_manager.get_memory_stats()\n",
        "        print(f\"Final GPU memory: {final_stats['gpu_allocated_gb']:.2f}GB allocated ({final_stats['gpu_percent']:.1f}%)\")\n",
        "        print(f\"Final CPU usage: {final_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in final cleanup: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"MODEL TRAINING COMPLETED!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nGenerated Files:\")\n",
        "    print(f\"- Model checkpoints: {Config.OUTPUT_DIR}/models/\")\n",
        "    print(f\"- Training results: {Config.OUTPUT_DIR}/model_results/\")\n",
        "    print(f\"- K-fold results: {Config.OUTPUT_DIR}/kfold_results/\")\n",
        "    print(f\"- Best models: {Config.OUTPUT_DIR}/best_model/\")\n",
        "\n",
        "\n",
        "# Environment setup and multiprocessing configuration\n",
        "import torch.multiprocessing as mp\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "n1jro0uqbxGu"
      },
      "id": "n1jro0uqbxGu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Visualization"
      ],
      "metadata": {
        "id": "DcoZXMdccf7h"
      },
      "id": "DcoZXMdccf7h"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "15.Fish Species Classification Pipeline - Visualization Module\n",
        "========================================================\n",
        "\n",
        "This module handles all visualization generation using saved models and results.\n",
        "It loads saved .pt model files and generates comprehensive visualizations.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import time\n",
        "import psutil\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# orig_numpy = torch.Tensor.numpy\n",
        "# def patched_numpy(self, *args, **kwargs):\n",
        "#     if self.is_cuda:\n",
        "#         raise RuntimeError(f\"Tried to call .numpy() on CUDA tensor at line ???. Move it to CPU first!\")\n",
        "#     return orig_numpy(self, *args, **kwargs)\n",
        "\n",
        "# torch.Tensor.numpy = patched_numpy\n",
        "\n",
        "class ResourceManager:\n",
        "    \"\"\"Smart resource management for optimal GPU/CPU utilization\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.gpu_memory_gb = 20\n",
        "        self.cpu_memory_gb = 50\n",
        "        self.max_gpu_usage = 0.85  # 85% of 20GB = 17GB\n",
        "        self.max_cpu_usage = 0.90  # 80% of 50GB = 40GB\n",
        "\n",
        "    def get_memory_stats(self):\n",
        "        \"\"\"Get current memory usage statistics\"\"\"\n",
        "        stats = {'cpu_percent': psutil.virtual_memory().percent}\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            stats['gpu_allocated_gb'] = torch.cuda.memory_allocated() / (1024**3)\n",
        "            stats['gpu_reserved_gb'] = torch.cuda.memory_reserved() / (1024**3)\n",
        "            stats['gpu_percent'] = (stats['gpu_reserved_gb'] / self.gpu_memory_gb) * 100\n",
        "        else:\n",
        "            stats.update({'gpu_allocated_gb': 0, 'gpu_reserved_gb': 0, 'gpu_percent': 0})\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def should_cleanup_aggressive(self):\n",
        "        \"\"\"Check if aggressive cleanup is needed\"\"\"\n",
        "        stats = self.get_memory_stats()\n",
        "        return (stats['gpu_percent'] > 90 or stats['cpu_percent'] > 90)\n",
        "\n",
        "    def aggressive_cleanup(self):\n",
        "        \"\"\"Perform comprehensive memory cleanup\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "        gc.collect()\n",
        "        time.sleep(0.1)  # Brief pause for system cleanup\n",
        "\n",
        "    def optimize_batch_size(self, base_size, model_complexity=1.0):\n",
        "        \"\"\"Calculate optimal batch size based on current memory state\"\"\"\n",
        "        stats = self.get_memory_stats()\n",
        "\n",
        "        # Reduce batch size if memory usage is high\n",
        "        memory_factor = max(0.4, 1.0 - (stats['gpu_percent'] / 100))\n",
        "        optimal_size = int(base_size * memory_factor / model_complexity)\n",
        "\n",
        "        return max(32, min(256, optimal_size))  # Keep within reasonable bounds\n",
        "\n",
        "\n",
        "def safe_gpu_convert(data):\n",
        "    \"\"\"Safely convert GPU tensors to CPU numpy arrays or lists\"\"\"\n",
        "    if torch.is_tensor(data):\n",
        "        if data.is_cuda:\n",
        "            data = data.detach().cpu()\n",
        "        if data.dim() == 0:\n",
        "            return data.item()\n",
        "        elif data.dtype == torch.bool or data.dtype == torch.uint8:\n",
        "            return data.numpy()\n",
        "        else:\n",
        "            return data.numpy() if data.dim() > 0 else data.item()\n",
        "    elif isinstance(data, list):\n",
        "        return [safe_gpu_convert(item) for item in data]\n",
        "    elif isinstance(data, dict):\n",
        "        return {k: safe_gpu_convert(v) for k, v in data.items()}\n",
        "    elif isinstance(data, np.ndarray):\n",
        "        return data  # Already numpy\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "\n",
        "def load_model_safely(model_name, model_path):\n",
        "    \"\"\"Safely load model with multiple fallback strategies\"\"\"\n",
        "    try:\n",
        "        checkpoint = torch.load(model_path, map_location=Config.DEVICE, weights_only=False)\n",
        "\n",
        "        if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
        "            # New comprehensive format - use saved architecture info\n",
        "            model = ModelFactory.create_model(\n",
        "                model_name,\n",
        "                num_classes=checkpoint.get('num_classes', Config.NUM_CLASSES),\n",
        "                dropout_rate=checkpoint.get('dropout_rate', 0.5),\n",
        "                hidden_dim_multiplier=checkpoint.get('hidden_dim_multiplier', 0.5)\n",
        "            )\n",
        "            model.to(Config.DEVICE)\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            return model, f\"new format v{checkpoint.get('save_format_version', '1.0')}\"\n",
        "\n",
        "        elif isinstance(checkpoint, dict):\n",
        "            # Legacy format - try with hyperparameters\n",
        "            hyperparams = checkpoint.get('hyperparameters', {})\n",
        "            model = ModelFactory.create_model(\n",
        "                model_name,\n",
        "                num_classes=Config.NUM_CLASSES,\n",
        "                dropout_rate=hyperparams.get('dropout', 0.5),\n",
        "                hidden_dim_multiplier=hyperparams.get('hidden_dim_multiplier', 0.5)\n",
        "            )\n",
        "            model.to(Config.DEVICE)\n",
        "            model.load_state_dict(checkpoint)\n",
        "            return model, \"legacy nested format\"\n",
        "\n",
        "        else:\n",
        "            # Try direct loading with parameter combinations\n",
        "            param_combinations = [\n",
        "                (0.5, 0.5), (0.3, 0.5), (0.7, 0.5),\n",
        "                (0.5, 0.3), (0.5, 0.7), (0.5, 1.0), (0.5, 1.5)\n",
        "            ]\n",
        "\n",
        "            for dropout, hidden_mult in param_combinations:\n",
        "                try:\n",
        "                    model = ModelFactory.create_model(\n",
        "                        model_name,\n",
        "                        num_classes=Config.NUM_CLASSES,\n",
        "                        dropout_rate=dropout,\n",
        "                        hidden_dim_multiplier=hidden_mult\n",
        "                    )\n",
        "                    model.to(Config.DEVICE)\n",
        "                    model.load_state_dict(checkpoint)\n",
        "                    return model, f\"direct format (dropout={dropout}, hidden={hidden_mult})\"\n",
        "                except RuntimeError:\n",
        "                    continue\n",
        "\n",
        "            return None, \"failed all combinations\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"loading error: {str(e)}\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"\\nStarting Fish Species Visualization Generation...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Environment setup for maximum performance\n",
        "    setup_environment()\n",
        "\n",
        "\n",
        "    # Set optimal thread count for CPU utilization\n",
        "    print(f\"CPU : {os.cpu_count()}\")\n",
        "    print(f\"USER: {os.getenv('USER')}\")\n",
        "    print(f\"HOME: {os.getenv('HOME')}\")\n",
        "    torch.set_num_threads(min(16, os.cpu_count()))\n",
        "    os.environ['OMP_NUM_THREADS'] = str(min(16, os.cpu_count()))\n",
        "\n",
        "    # OpenMP → Open Multi-Processing.\n",
        "    # OpenMP is a widely used API for parallel programming on CPUs.\n",
        "    # Many scientific libraries (like NumPy, PyTorch, TensorFlow,\n",
        "    # -OpenCV, Scikit-learn) rely on OpenMP to run operations in parallel across CPU cores.\n",
        "    # In main() after line 720:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    # Auto-benchmarks and selects fastest cuDNN algorithms for your specific hardware and input sizes\n",
        "    # Takes ~5-10 seconds at start but can provide 10-20% speedup throughout training\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    # Allows cuDNN to use fastest available algorithms even if they produce slightly different results each run\n",
        "    # Trades reproducibility for speed - essential for maximum performance in production training\n",
        "    # torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    # Uses TensorFloat-32 (19-bit precision) instead of full Float-32 for matrix multiplications\n",
        "    # Provides ~1.6x speedup on Ampere GPUs with negligible accuracy loss for deep learning\n",
        "    # torch.backends.cudnn.allow_tf32 = True\n",
        "    # Enables TF32 precision for cuDNN operations (convolutions, pooling, batch norm)\n",
        "    # Accelerates CNN layers by 1.3-1.6x on RTX 30/40 series and A100+ GPUs\n",
        "    torch.backends.cuda.enable_flash_sdp(True)\n",
        "    # Activates Flash Attention algorithm for memory-efficient attention computations\n",
        "    # Reduces GPU memory usage by 2-4x and increases attention speed, crucial for transformer layers\n",
        "\n",
        "    # GPU optimizations\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "        gpu_props = torch.cuda.get_device_properties(0)\n",
        "        print(f\"GPU: {gpu_props.name}, Memory: {gpu_props.total_memory / 1024**3:.1f}GB\")\n",
        "\n",
        "    # CPU info\n",
        "    print(f\"CPU Cores: {os.cpu_count()}, Using threads: {torch.get_num_threads()}\")\n",
        "\n",
        "    # Ensure visualization output directory exists\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/visualizations\", exist_ok=True)\n",
        "\n",
        "    # Initialize resource manager\n",
        "    resource_manager = ResourceManager()\n",
        "\n",
        "    # Load and balance data for visualization (if needed for test data)\n",
        "    print(\"\\nLoading data for visualization...\")\n",
        "    X, Y = DataManager.load_and_balance_data()\n",
        "    print(f\"Total samples: {len(X):,}, Labels: {len(Y):,}\")\n",
        "\n",
        "    # Initialize components\n",
        "    visualizer = EnhancedVisualizations()\n",
        "    single_models = {}\n",
        "    single_results = {}\n",
        "\n",
        "    # Load trained models and results\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"LOADING TRAINED MODELS AND RESULTS\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Load models with enhanced error handling\n",
        "    for model_name in Config.MODELS:\n",
        "        model_path = os.path.join(Config.OUTPUT_DIR, \"best_model\", f\"{model_name}_best.pt\")\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"⚠️  Model file not found: {model_name}\")\n",
        "            continue\n",
        "\n",
        "        model, load_info = load_model_safely(model_name, model_path)\n",
        "\n",
        "        if model is not None:\n",
        "            model.eval()\n",
        "            single_models[model_name] = model\n",
        "            print(f\"✅ Loaded {model_name} ({load_info})\")\n",
        "\n",
        "            # Load evaluation results for visualization compatibility\n",
        "            result_path = f\"{Config.OUTPUT_DIR}/model_results/{model_name}_main_results.pt\"\n",
        "            if os.path.exists(result_path):\n",
        "                try:\n",
        "                    saved_results = torch.load(result_path, map_location='cpu', weights_only=False)\n",
        "                    result_data = saved_results.get('result', {})\n",
        "\n",
        "                    single_results[model_name] = {\n",
        "                        'model_name': model_name,\n",
        "                        'accuracy': float(result_data.get('accuracy', 0.0)),\n",
        "                        'f1_macro': float(result_data.get('f1', 0.0)),\n",
        "                        'f1_weighted': float(result_data.get('f1', 0.0)),  # Add f1_weighted key\n",
        "                        'predictions': result_data.get('predictions', []),\n",
        "                        'true_labels': result_data.get('true_labels', []),\n",
        "                        'probabilities': result_data.get('probabilities', np.zeros((0, Config.NUM_CLASSES))),\n",
        "                        'conf_matrix': result_data.get('conf_matrix', np.zeros((Config.NUM_CLASSES, Config.NUM_CLASSES))),\n",
        "                        'misclassified': result_data.get('misclassified', [])\n",
        "                    }\n",
        "\n",
        "                    # Convert tensors to numpy for visualization compatibility\n",
        "                    for key in ['predictions', 'true_labels', 'probabilities', 'conf_matrix']:\n",
        "                        if torch.is_tensor(single_results[model_name][key]):\n",
        "                            single_results[model_name][key] = single_results[model_name][key].numpy()\n",
        "\n",
        "                    print(f\"📊 Results loaded: Acc={single_results[model_name]['accuracy']:.4f}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️  Could not load results for {model_name}: {e}\")\n",
        "                    single_results[model_name] = {'model_name': model_name, 'accuracy': 0.0, 'f1_macro': 0.0, 'f1_weighted': 0.0}\n",
        "            else:\n",
        "                print(f\"⚠️  No results file for {model_name}\")\n",
        "                single_results[model_name] = {'model_name': model_name, 'accuracy': 0.0, 'f1_macro': 0.0, 'f1_weighted': 0.0}\n",
        "        else:\n",
        "            print(f\"❌ Failed to load {model_name}: {load_info}\")\n",
        "\n",
        "    print(f\"\\n🎯 Loaded: {len(single_models)} models, {len(single_results)} result sets\")\n",
        "\n",
        "    # Create test data loader for visualizations that need it\n",
        "    if len(single_models) > 0:\n",
        "        print(\"\\nCreating test data loader for visualizations...\")\n",
        "        _, _, test_loader, val_data, test_data = DataManager.create_data_loaders(X, Y, test_size=0.2)\n",
        "        print(f\"Test loader created with {len(test_loader.dataset)} samples\")\n",
        "\n",
        "    # Generate visualizations for each model\n",
        "    for model_name in single_models.keys():\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"GENERATING VISUALIZATIONS FOR: {model_name}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Pre-visualization memory state\n",
        "        pre_stats = resource_manager.get_memory_stats()\n",
        "        print(f\"Pre-visualization memory - GPU: {pre_stats['gpu_allocated_gb']:.2f}GB ({pre_stats['gpu_percent']:.1f}%), \"\n",
        "              f\"CPU: {pre_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "        try:\n",
        "            # Load saved results for plotting (ensuring consistency)\n",
        "            main_result_path = f\"{Config.OUTPUT_DIR}/model_results/{model_name}_main_results.pt\"\n",
        "\n",
        "            if os.path.exists(main_result_path):\n",
        "                saved_data = torch.load(main_result_path, map_location=Config.DEVICE, weights_only=False)\n",
        "                history_for_viz = saved_data['history']\n",
        "                result_for_viz = saved_data['result']\n",
        "                print(f\"Using saved results for {model_name} visualization\")\n",
        "            else:\n",
        "                result_for_viz = {}\n",
        "                history_for_viz = {}\n",
        "                def add_strikethrough(text):\n",
        "                    return ''.join(c + '\\u0336' for c in text)\n",
        "                print(f\"{add_strikethrough('Using current')} No results for {model_name} visualization\")\n",
        "\n",
        "            print(f\"Result keys: {list(result_for_viz.keys()) if result_for_viz else 'None'}\")\n",
        "\n",
        "            # Convert all data to CPU/numpy for visualization (GPU-safe conversion)\n",
        "            history_viz = safe_gpu_convert(history_for_viz)\n",
        "            result_viz = safe_gpu_convert(result_for_viz)\n",
        "\n",
        "            # Validate result data\n",
        "            true_labels = result_viz.get('true_labels', np.array([]))\n",
        "            predictions = result_viz.get('predictions', np.array([]))\n",
        "            probabilities = result_viz.get('probabilities', np.array([]))\n",
        "\n",
        "            # ADD THE CONVERSION LINES HERE:\n",
        "            if torch.is_tensor(true_labels):\n",
        "                true_labels = true_labels.detach().cpu().numpy()\n",
        "            if torch.is_tensor(predictions):\n",
        "                predictions = predictions.detach().cpu().numpy()\n",
        "            if torch.is_tensor(probabilities):\n",
        "                probabilities = probabilities.detach().cpu().numpy()\n",
        "            # ADD THESE ADDITIONAL CONVERSIONS:\n",
        "            # Convert history data to safe formats\n",
        "            for key in ['train_loss', 'train_acc', 'val_loss', 'val_acc', 'val_f1']:\n",
        "                if key in history_viz and torch.is_tensor(history_viz[key]):\n",
        "                    history_viz[key] = history_viz[key].detach().cpu().numpy().tolist()\n",
        "\n",
        "            print(f\"Data validation for {model_name}:\")\n",
        "            print(f\"  true_labels: {type(true_labels)}, shape: {getattr(true_labels, 'shape', len(true_labels) if hasattr(true_labels, '__len__') else 'scalar')}\")\n",
        "            print(f\"  predictions: {type(predictions)}, shape: {getattr(predictions, 'shape', len(predictions) if hasattr(predictions, '__len__') else 'scalar')}\")\n",
        "            print(f\"  probabilities: {type(probabilities)}, shape: {getattr(probabilities, 'shape', 'unknown')}\")\n",
        "\n",
        "            # Check if we have valid data for plotting\n",
        "            if (true_labels.size > 0 and predictions.size > 0 and true_labels.shape[0] == predictions.shape[0]):\n",
        "                plots_generated = 0\n",
        "\n",
        "                # Training history plot\n",
        "                train_loss = history_viz.get('train_loss')\n",
        "                if train_loss is not None and hasattr(train_loss, '__len__') and len(train_loss) > 0:\n",
        "                    try:\n",
        "                        # Add this conversion:\n",
        "                        if history_viz.get('train_loss') is not None:\n",
        "                            if isinstance(history_viz['train_loss'], np.ndarray):\n",
        "                                history_viz['train_loss'] = history_viz['train_loss'].tolist()\n",
        "                        if history_viz.get('train_acc') is not None:\n",
        "                            if isinstance(history_viz['train_acc'], np.ndarray):\n",
        "                                history_viz['train_acc'] = history_viz['train_acc'].tolist()\n",
        "                        if history_viz.get('val_loss') is not None:\n",
        "                            if isinstance(history_viz['val_loss'], np.ndarray):\n",
        "                                history_viz['val_loss'] = history_viz['val_loss'].tolist()\n",
        "                        if history_viz.get('val_acc') is not None:\n",
        "                            if isinstance(history_viz['val_acc'], np.ndarray):\n",
        "                                history_viz['val_acc'] = history_viz['val_acc'].tolist()\n",
        "\n",
        "                        visualizer.plot_single_model_history(history_viz, model_name)\n",
        "                        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_history.png\", dpi=150, bbox_inches='tight')\n",
        "                        plt.close('all')\n",
        "                        print(f\"Training history plot generated for {model_name}\")\n",
        "                        plots_generated += 1\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error plotting training history for {model_name}: {e}\")\n",
        "\n",
        "                try:\n",
        "                    # ROC Curves\n",
        "                    visualizer.plot_roc_curves(result_viz, model_name)\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_roc.png\", dpi=150, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "                    print(f\"ROC curves plot generated for {model_name}\")\n",
        "                    plots_generated += 1\n",
        "\n",
        "                    # Confusion Matrix\n",
        "                    visualizer.plot_confusion_matrix(result_viz, model_name)\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_confusion.png\", dpi=150, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "                    print(f\"Confusion matrix plot generated for {model_name}\")\n",
        "                    plots_generated += 1\n",
        "\n",
        "                    # Misclassified Images\n",
        "                    misclassified = result_viz.get('misclassified', [])\n",
        "                    if misclassified is not None and len(misclassified) > 0:\n",
        "                        # Convert any GPU tensors in misclassified images to CPU\n",
        "                        for item in result_viz['misclassified']:\n",
        "                            if isinstance(item, dict) and 'image' in item:\n",
        "                                if torch.is_tensor(item['image']):\n",
        "                                    item['image'] = item['image'].detach().cpu()\n",
        "                                elif isinstance(item['image'], np.ndarray):\n",
        "                                    # Optionally transpose if channel-first\n",
        "                                    if item['image'].shape[0] in [1,3]:\n",
        "                                        item['image'] = np.transpose(item['image'], (1, 2, 0))\n",
        "\n",
        "                        visualizer.plot_misclassified_images(result_viz['misclassified'], model_name)\n",
        "                        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_misclassified.png\", dpi=150, bbox_inches='tight')\n",
        "                        plt.close('all')\n",
        "                        print(f\"Misclassified images plot generated for {model_name}\")\n",
        "                        plots_generated += 1\n",
        "                    else:\n",
        "                        print(f\"No misclassified images to plot for {model_name}\")\n",
        "\n",
        "                    # XAI Visualization\n",
        "                    if model_name in single_models and test_loader is not None and len(test_loader.dataset) > 0:\n",
        "                        try:\n",
        "                            model = single_models[model_name]\n",
        "                            visualizer.plot_single_model_xai(model, model_name, test_loader)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_xai.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "                            print(f\"XAI visualization generated for {model_name}\")\n",
        "                            plots_generated += 1\n",
        "                        except Exception as xai_error:\n",
        "                            print(f\"XAI visualization error for {model_name}: {xai_error}\")\n",
        "                    else:\n",
        "                        print(f\"Skipping XAI visualization for {model_name}: model or test_loader not available\")\n",
        "\n",
        "                except Exception as plot_error:\n",
        "                    print(f\"Visualization error for {model_name}: {plot_error}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "\n",
        "                print(f\"Generated {plots_generated} main visualization plots for {model_name}\")\n",
        "\n",
        "            else:\n",
        "                print(f\"Skipping main visualizations for {model_name}: data validation failed\")\n",
        "                print(f\"  true_labels length: {true_labels.shape[0] if hasattr(true_labels, 'shape') else 'scalar'}\")\n",
        "                print(f\"  predictions length: {predictions.shape[0] if hasattr(predictions, 'shape') else 'scalar'}\")\n",
        "\n",
        "            # K-fold results plotting (load from saved files)\n",
        "            print(f\"Loading and plotting k-fold results for {model_name}...\")\n",
        "            fold_results_loaded = []\n",
        "\n",
        "            # Check for k-fold results\n",
        "            for fold in range(1, 4):  # Assuming max 3 folds\n",
        "                fold_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{model_name}_fold_{fold}_results.pt\"\n",
        "                if os.path.exists(fold_result_path):\n",
        "                    try:\n",
        "                        fold_data = torch.load(fold_result_path, map_location=Config.DEVICE, weights_only=False)\n",
        "\n",
        "                        # Convert GPU tensors to CPU/numpy\n",
        "                        fold_converted = {\n",
        "                            'history': safe_gpu_convert(fold_data['history']),\n",
        "                            'result': safe_gpu_convert(fold_data['result'])\n",
        "                        }\n",
        "                        fold_results_loaded.append(fold_converted)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error loading fold {fold} results: {e}\")\n",
        "\n",
        "            if fold_results_loaded is not None and len(fold_results_loaded) > 0:\n",
        "                try:\n",
        "                    visualizer.plot_kfold_results(fold_results_loaded, model_name, test_loader)\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_kfold.png\", dpi=150, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "                    print(f\"K-fold results plot generated for {model_name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error plotting k-fold results for {model_name}: {e}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "            else:\n",
        "                print(f\"No k-fold results to plot for {model_name}\")\n",
        "\n",
        "            print(f\"All visualizations completed for {model_name}\")\n",
        "\n",
        "            # Memory cleanup for this model's visualizations\n",
        "            if 'history_viz' in locals():\n",
        "                del history_viz\n",
        "            if 'result_viz' in locals():\n",
        "                del result_viz\n",
        "            if 'fold_results_loaded' in locals():\n",
        "                del fold_results_loaded\n",
        "            if 'history_for_viz' in locals():\n",
        "                del history_for_viz\n",
        "            if 'result_for_viz' in locals():\n",
        "                del result_for_viz\n",
        "\n",
        "            # Force garbage collection and GPU cleanup\n",
        "            plt.close('all')\n",
        "            resource_manager.aggressive_cleanup()\n",
        "\n",
        "            # Post-visualization memory state\n",
        "            post_stats = resource_manager.get_memory_stats()\n",
        "            memory_freed = pre_stats['gpu_allocated_gb'] - post_stats['gpu_allocated_gb']\n",
        "\n",
        "            print(f\"Memory cleanup completed for {model_name}:\")\n",
        "            print(f\"  GPU memory freed: {memory_freed:.2f}GB\")\n",
        "            print(f\"  Current GPU usage: {post_stats['gpu_percent']:.1f}%\")\n",
        "            print(f\"  Current CPU usage: {post_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "            print(f\"✓ {model_name} VISUALIZATIONS COMPLETED!\")\n",
        "            print(f\"{'='*70}\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in visualization process for {model_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    # Step: Ensemble processing and visualizations (only if we have trained models)\n",
        "    if single_models and 'val_data' in locals():\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"GENERATING ENSEMBLE VISUALIZATIONS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        try:\n",
        "            if (val_data is not None and len(val_data) == 2 and len(val_data[0]) > 0 and len(val_data[1]) > 0 and len(val_data[0]) == len(val_data[1])):\n",
        "\n",
        "                ensemble_manager = EnsembleManager(single_models, val_data)\n",
        "                ensemble_results, best_ensemble = ensemble_manager.test_ensemble_combinations()\n",
        "\n",
        "                # Generate visualizations for ensemble methods\n",
        "                print(\"\\nGenerating visualizations for ensemble methods...\")\n",
        "                for ensemble_name, ensemble_result in ensemble_results.items():\n",
        "                    try:\n",
        "                        # Convert GPU tensors to CPU for visualization\n",
        "                        ensemble_result_viz = safe_gpu_convert(ensemble_result)\n",
        "\n",
        "                        true_labels_ens = ensemble_result_viz.get('true_labels', [])\n",
        "                        predictions_ens = ensemble_result_viz.get('predictions', [])\n",
        "\n",
        "                        if (len(true_labels_ens) > 0 and\n",
        "                            len(predictions_ens) > 0 and\n",
        "                            len(true_labels_ens) == len(predictions_ens)):\n",
        "\n",
        "                            visualizer.plot_roc_curves(ensemble_result_viz, ensemble_name)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{ensemble_name}_roc.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "\n",
        "                            visualizer.plot_confusion_matrix(ensemble_result_viz, ensemble_name)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{ensemble_name}_confusion.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "\n",
        "                            # F1 per class visualization\n",
        "                            from sklearn.metrics import f1_score\n",
        "                            f1_per_class = f1_score(ensemble_result_viz['true_labels'],\n",
        "                                                   ensemble_result_viz['predictions'], average=None)\n",
        "                            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "                            ax.bar(range(Config.NUM_CLASSES), f1_per_class, color='lightgreen', alpha=0.8)\n",
        "                            ax.set_xticks(range(Config.NUM_CLASSES))\n",
        "                            ax.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right')\n",
        "                            ax.set_title(f'F1 Scores per Class - {ensemble_name}',\n",
        "                                       fontsize=14, fontweight='bold', pad=15)\n",
        "                            ax.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
        "                            ax.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
        "                            ax.grid(True, alpha=0.3)\n",
        "                            for i, v in enumerate(f1_per_class):\n",
        "                                ax.text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom', fontsize=10)\n",
        "                            save_path = f\"{Config.OUTPUT_DIR}/visualizations/{ensemble_name}_f1_per_class.png\"\n",
        "                            plt.savefig(save_path, dpi=300, bbox_inches='tight',\n",
        "                                      facecolor='white', edgecolor='none')\n",
        "                            plt.close()\n",
        "                            print(f\"F1 scores per class saved: {save_path}\")\n",
        "                        else:\n",
        "                            print(f\"Skipping visualizations for {ensemble_name}: invalid data\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error generating ensemble visualizations for {ensemble_name}: {e}\")\n",
        "\n",
        "                    # Clear memory\n",
        "                    if 'ensemble_result_viz' in locals():\n",
        "                        del ensemble_result_viz\n",
        "                    resource_manager.aggressive_cleanup()\n",
        "\n",
        "                # Comment out the problematic ensemble test evaluation\n",
        "                print(\"Skipping ensemble test evaluation (method not implemented)\")\n",
        "                # if (best_ensemble and test_data is not None and len(test_data) == 2 and\n",
        "                #     len(test_data[0]) == len(test_data[1]) and len(test_data[0]) > 0):\n",
        "                #     print(\"Evaluating best ensemble on test set...\")\n",
        "                #     # Ensemble test evaluation code commented out\n",
        "\n",
        "            else:\n",
        "                print(\"Skipping ensemble analysis: no valid validation data\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in ensemble processing: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    # Step: Generate comprehensive visualizations (only if we have results)\n",
        "    if single_results:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"GENERATING COMPREHENSIVE ANALYSIS VISUALIZATIONS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        try:\n",
        "            # Convert all results to CPU/numpy for final plotting\n",
        "            single_results_viz = safe_gpu_convert(single_results)\n",
        "            ensemble_results_viz = safe_gpu_convert(ensemble_results) if 'ensemble_results' in locals() else {}\n",
        "\n",
        "            # Plot overall model comparison\n",
        "            if single_results_viz and len(single_results_viz) > 0:\n",
        "                visualizer.plot_model_comparison(single_results_viz,ensemble_results_viz)\n",
        "                plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/model_comparison.png\", dpi=300, bbox_inches='tight')\n",
        "                plt.close('all')\n",
        "\n",
        "            # Generate comprehensive report\n",
        "            visualizer.generate_comprehensive_report(\n",
        "                single_results_viz,\n",
        "                ensemble_results_viz,\n",
        "                best_ensemble if 'best_ensemble' in locals() else None\n",
        "            )\n",
        "            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/comprehensive_report.png\", dpi=300, bbox_inches='tight')\n",
        "            plt.close('all')\n",
        "\n",
        "            # Additional visualizations\n",
        "            if 'test_loader' in locals() and test_loader is not None and len(test_loader.dataset) > 0:\n",
        "                try:\n",
        "                    visualizer.plot_comparative_xai(\n",
        "                        single_models,\n",
        "                        ensemble_results_viz,\n",
        "                        test_loader,\n",
        "                        max_images=2\n",
        "                    )\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/comparative_xai.png\", dpi=300, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "\n",
        "                    visualizer.plot_lrp_grid(single_models, test_loader)\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/lrp_grid.png\", dpi=300, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in additional visualizations: {e}\")\n",
        "\n",
        "            print(\"Comprehensive analysis completed successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in comprehensive analysis: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    # Final cleanup\n",
        "    print(\"\\nFinal cleanup and summary...\")\n",
        "    try:\n",
        "        # Clean up all remaining variables\n",
        "        if 'single_models' in locals():\n",
        "            del single_models\n",
        "        if 'test_loader' in locals():\n",
        "            del test_loader\n",
        "        if 'single_results' in locals():\n",
        "            del single_results\n",
        "        if 'single_results_viz' in locals():\n",
        "            del single_results_viz\n",
        "        if 'ensemble_results' in locals():\n",
        "            del ensemble_results\n",
        "        if 'ensemble_results_viz' in locals():\n",
        "            del ensemble_results_viz\n",
        "        if 'best_ensemble' in locals():\n",
        "            del best_ensemble\n",
        "        if 'visualizer' in locals():\n",
        "            del visualizer\n",
        "        if 'X' in locals():\n",
        "            del X\n",
        "        if 'Y' in locals():\n",
        "            del Y\n",
        "\n",
        "        resource_manager.aggressive_cleanup()\n",
        "\n",
        "        # Final memory stats\n",
        "        final_stats = resource_manager.get_memory_stats()\n",
        "        print(f\"Final GPU memory: {final_stats['gpu_allocated_gb']:.2f}GB allocated ({final_stats['gpu_percent']:.1f}%)\")\n",
        "        print(f\"Final CPU usage: {final_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in final cleanup: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VISUALIZATION GENERATION COMPLETED!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nGenerated Files:\")\n",
        "    print(f\"- All visualizations: {Config.OUTPUT_DIR}/visualizations/\")\n",
        "\n",
        "\n",
        "# Environment setup and multiprocessing configuration\n",
        "import torch.multiprocessing as mp\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "duEhaAVCb1f7"
      },
      "id": "duEhaAVCb1f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cdd48bb6",
      "metadata": {
        "id": "cdd48bb6"
      },
      "source": [
        "#End"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}