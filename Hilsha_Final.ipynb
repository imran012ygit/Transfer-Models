{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran012x/Transfer-Models/blob/main/Hilsha_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01bea336",
      "metadata": {
        "id": "01bea336"
      },
      "source": [
        "#Colab-connect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "344965bc",
      "metadata": {
        "id": "344965bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd82ee94-6610-46ca-aa68-57617c145c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# # Upload a file\n",
        "# uploaded = files.upload()\n",
        "# # Get the file name\n",
        "# file_name = list(uploaded.keys())[0]\n",
        "# print(f\"Uploaded file: {file_name}\")\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# # with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_224_11k.zip', 'r') as zip_ref:\n",
        "# #     zip_ref.extractall('')\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de009928",
      "metadata": {
        "id": "de009928"
      },
      "source": [
        "#Data Preprocess and Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6f95c03b",
      "metadata": {
        "id": "6f95c03b"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "# from tqdm import tqdm\n",
        "# import random\n",
        "# import gc\n",
        "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "# import threading\n",
        "# import zipfile\n",
        "\n",
        "# # Check GPU availability\n",
        "# print(\"GPU Available:\", torch.cuda.is_available())\n",
        "# print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "# # Define fish classes and dataset paths\n",
        "# fish_classes = ['ilish', 'chandana', 'sardin', 'sardinella', 'punctatus'] #0,1,2,3,4\n",
        "# zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip').extractall('/content/.hidden_fish')\n",
        "# data_dir = '/content/.hidden_fish'\n",
        "\n",
        "# image_limits = {\n",
        "#     'ilish': 3000,\n",
        "#     'chandana': 1185,\n",
        "#     'sardin': 2899,\n",
        "#     'sardinella': 370,\n",
        "#     'punctatus': 953\n",
        "# }\n",
        "\n",
        "# # Settings\n",
        "# total_images = sum(image_limits.values())\n",
        "# batch_size = 100\n",
        "# num_threads = 4\n",
        "\n",
        "\n",
        "# # Output paths\n",
        "# output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "# labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "# xdata_file = os.path.join(output_dir, 'X_data.npy')\n",
        "\n",
        "# save_lock = threading.Lock()  # for thread-safe writes -> Prevents race conditions when multiple threads write to the same list.\n",
        "\n",
        "# # Function to gather image paths\n",
        "# def get_image_paths(class_name, max_images):\n",
        "#     path = os.path.join(data_dir, class_name)\n",
        "#     files = sorted(os.listdir(path))\n",
        "#     random.shuffle(files)\n",
        "#     return [os.path.join(path, f) for f in files[:max_images]]\n",
        "\n",
        "# # Load and preprocess batch\n",
        "# def load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     end_idx = min(start_idx + batch_size, len(image_paths))\n",
        "#     batch_paths = image_paths[start_idx:end_idx]\n",
        "#     batch_images = []\n",
        "\n",
        "#     for img_path in batch_paths:\n",
        "#         img = Image.open(img_path).resize((224, 224)).convert('RGB')\n",
        "#         img_tensor = torch.tensor(np.array(img), dtype=torch.uint8).permute(2, 0, 1)  # C x H x W\n",
        "#         batch_images.append(img_tensor)\n",
        "\n",
        "#     batch_tensor = torch.stack(batch_images)  # B x C x H x W\n",
        "#     batch_labels = np.full((len(batch_images),), class_idx, dtype=np.int32)\n",
        "#     return batch_tensor, batch_labels\n",
        "\n",
        "# # Process one batch and return tensors & labels (no file saving)\n",
        "# def process_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     return load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx)\n",
        "\n",
        "# def preprocess_and_save_all(overwrite=True):\n",
        "#     if os.path.exists(labels_file) and os.path.exists(xdata_file) and not overwrite:\n",
        "#         print(\"Preprocessed data already exists. Set overwrite=True to reprocess.\")\n",
        "#         return\n",
        "\n",
        "#     all_images = []\n",
        "#     all_labels = []\n",
        "#     processed_count = 0\n",
        "\n",
        "#     for idx, class_name in enumerate(fish_classes):\n",
        "#         print(f\"\\nProcessing class: {class_name}\")\n",
        "#         image_paths = get_image_paths(class_name, image_limits[class_name])\n",
        "#         total_batches = (len(image_paths) + batch_size - 1) // batch_size\n",
        "#         #It ensures ceiling division ‚Äî rounding up, not down.\n",
        "#         # Normal division: 103 / 20 = 5.15 ‚Üí floor division // 20 = 5 (‚ùå missing last 3 images)\n",
        "#         # This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ‚úÖ\n",
        "\n",
        "#         with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "#             futures = []\n",
        "#             for start in range(0, len(image_paths), batch_size):\n",
        "#                 futures.append(executor.submit(process_batch, image_paths, start, batch_size, idx))\n",
        "\n",
        "#             for future in tqdm(as_completed(futures), total=total_batches, desc=class_name):#taqaddum (ÿ™ŸÇÿØŸëŸÖ) ‚Äì Arabic for \"progress\".\n",
        "#                 # futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\n",
        "#                 # as_completed(futures): Yields each future as it finishes (not in order).\n",
        "\n",
        "#                 batch_tensor, batch_labels = future.result()\n",
        "#                 with save_lock: #Locks this section so that only one thread can update the shared lists safely.\n",
        "#                     all_images.append(batch_tensor)\n",
        "#                     all_labels.append(batch_labels)\n",
        "#                     processed_count += batch_tensor.size(0)\n",
        "#                     print(f\"Processed batch with {batch_tensor.size(0)} images, total processed: {processed_count}/{total_images}\")\n",
        "#                 gc.collect()\n",
        "\n",
        "#     # Combine all tensors and labels\n",
        "#     X = torch.cat(all_images, dim=0).numpy()\n",
        "#     Y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "#     # Save final arrays\n",
        "#     np.save(xdata_file, X, allow_pickle=False)#Malicious .npy -> import os;os.system(\"rm -rf /\")  # ‚Üê Dangerous command\n",
        "#     np.save(labels_file, Y, allow_pickle=False)\n",
        "\n",
        "#     print(f\"\\n‚úÖ Done! Saved {processed_count} images in {xdata_file}\")\n",
        "#     print(f\"X_data shape: {X.shape}, Y_labels shape: {Y.shape}\")\n",
        "\n",
        "#     if processed_count != total_images:\n",
        "#         raise ValueError(f\"Expected {total_images} images, but processed {processed_count}\")\n",
        "\n",
        "# # Run preprocessing and save directly to X_data.npy and Y_labels.npy\n",
        "# preprocess_and_save_all(overwrite=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0fbbeb4",
      "metadata": {
        "id": "c0fbbeb4"
      },
      "source": [
        "####DATA LOADING...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23d9c0c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23d9c0c0",
        "outputId": "160b79aa-1bef-4b00-b6d3-68740a8ecf87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ X_data.npy: 1.18 GB\n",
            "üìÅ Y_labels.npy: 32.96 KB\n",
            "‚úÖ X shape: (8407, 3, 224, 224), dtype: uint8\n",
            "‚úÖ Y shape: (8407,), dtype: int32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614331559.py:42: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  X = torch.from_numpy(X)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Your data path\n",
        "output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "data_file = os.path.join(output_dir, 'X_data.npy')\n",
        "labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "\n",
        "# Readable size format\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    for unit in ['', 'K', 'M', 'G', 'T']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return f\"{num:3.2f} {unit}{suffix}\"\n",
        "        num /= 1024.0\n",
        "    return f\"{num:.2f} T{suffix}\"\n",
        "\n",
        "# Main loader\n",
        "def load_preprocessed_data(as_torch=True, normalize=True, to_device=None):\n",
        "    # Check file existence #cpu,cuda (CUDA stands for Compute Unified Device Architecture.)\n",
        "    for path in [data_file, labels_file]:\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Missing: {path}\")\n",
        "\n",
        "    # Print file sizes\n",
        "    print(f\"üìÅ X_data.npy: {sizeof_fmt(os.path.getsize(data_file))}\")\n",
        "    print(f\"üìÅ Y_labels.npy: {sizeof_fmt(os.path.getsize(labels_file))}\")\n",
        "\n",
        "    # Load with mmap\n",
        "    X = np.load(data_file, mmap_mode='r')\n",
        "    Y = np.load(labels_file, mmap_mode='r')\n",
        "\n",
        "    print(f\"‚úÖ X shape: {X.shape}, dtype: {X.dtype}\")\n",
        "    print(f\"‚úÖ Y shape: {Y.shape}, dtype: {Y.dtype}\")\n",
        "\n",
        "    # Sanity check\n",
        "    if len(X) != len(Y):\n",
        "        raise ValueError(\"Mismatch between number of samples in X and Y\")\n",
        "\n",
        "    # Convert to torch\n",
        "    if as_torch:\n",
        "        X = torch.from_numpy(X)\n",
        "        Y = torch.from_numpy(Y)\n",
        "\n",
        "        if normalize and X.dtype == torch.uint8:\n",
        "            X = X.float() / 255.0\n",
        "\n",
        "        if to_device:\n",
        "            X = X.to(to_device)\n",
        "            Y = Y.to(to_device)\n",
        "\n",
        "        print(f\"üß† Torch tensors ready on {to_device or 'CPU'}\")\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# üîÅ Example call\n",
        "X, Y = load_preprocessed_data(\n",
        "    as_torch=True,\n",
        "    normalize=True,\n",
        "    to_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "036ead20",
      "metadata": {
        "id": "036ead20"
      },
      "outputs": [],
      "source": [
        "# 1. IMPORTS AND INITIAL SETUP\n",
        "# =============================================================================\n",
        "# Purpose: Import all required libraries and set up warnings to suppress unnecessary messages.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from itertools import combinations\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, f1_score,\n",
        "                             accuracy_score, precision_score, recall_score)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Augmentation\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# Hyperparameter optimization\n",
        "try:\n",
        "    import optuna\n",
        "    OPTUNA_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPTUNA_AVAILABLE = False\n",
        "    print(\"Warning: Optuna not available. Using default hyperparameters.\")\n",
        "\n",
        "# XAI dependencies\n",
        "import torch.autograd as autograd\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9091cf5",
      "metadata": {
        "id": "c9091cf5"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# ---\n",
        "# 2. CONFIGURATION\n",
        "# =============================================================================\n",
        "# Purpose: Define configuration settings and initialize the environment.\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration settings\"\"\"\n",
        "    # Paths - UPDATE THESE TO YOUR ACTUAL PATHS\n",
        "    DATA_FILE = '/content/drive/MyDrive/Hilsha/X_data.npy'\n",
        "    LABELS_FILE = '/content/drive/MyDrive/Hilsha/Y_labels.npy'\n",
        "    OUTPUT_DIR = './fish_classification_results'\n",
        "\n",
        "    # Dataset parameters\n",
        "    NUM_CLASSES = 5\n",
        "    CLASS_LABELS = ['Ilish', 'Chandana', 'Sardin', 'Sardinella', 'Punctatus']\n",
        "    INPUT_SIZE = 224\n",
        "\n",
        "    # Training parameters\n",
        "    BATCH_SIZE = 64\n",
        "    EPOCHS = 30\n",
        "    DATALOADER_NUM_WORKERS = 4\n",
        "    PIN_MEMORY = True\n",
        "    USE_MIXED_PRECISION = True\n",
        "    COMPILE_MODEL = True\n",
        "    PATIENCE = 10\n",
        "    LEARNING_RATE = 1e-4\n",
        "    WEIGHT_DECAY = 1e-4\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    OPTUNA_TRIALS = 15\n",
        "    OPTUNA_EPOCHS = 20\n",
        "\n",
        "    # Models to train\n",
        "    MODELS = ['resnet50', 'efficientnet_b0', 'mobilenet_v3_large',\n",
        "              'vgg16', 'densenet121']\n",
        "\n",
        "    # Ensemble methods\n",
        "    ENSEMBLE_METHODS = ['simple_average', 'weighted_average', 'confidence_based', 'learnable_weighted']\n",
        "\n",
        "    # Device\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    SEED = 42\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"Setup random seeds and directories\"\"\"\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "\n",
        "    directories = [\n",
        "        Config.OUTPUT_DIR,\n",
        "        f\"{Config.OUTPUT_DIR}/models\",\n",
        "        f\"{Config.OUTPUT_DIR}/visualizations\",\n",
        "        f\"{Config.OUTPUT_DIR}/reports\",\n",
        "        f\"{Config.OUTPUT_DIR}/xai_visualizations\"\n",
        "    ]\n",
        "\n",
        "    for directory in directories:\n",
        "        Path(directory).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(f\"Using device: {Config.DEVICE}\")\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(\"-\" * 70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7b1018f3",
      "metadata": {
        "id": "7b1018f3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---\n",
        "# 3. TRAINING PROGRESS TRACKER\n",
        "# =============================================================================\n",
        "# Purpose: Track and display training progress with progress bars and epoch summaries.\n",
        "\n",
        "class TrainingProgressTracker:\n",
        "    \"\"\"Track and display detailed training progress\"\"\"\n",
        "\n",
        "    def __init__(self, model_name, total_epochs, total_batches_per_epoch):\n",
        "        self.model_name = model_name\n",
        "        self.total_epochs = total_epochs\n",
        "        self.total_batches_per_epoch = total_batches_per_epoch\n",
        "        self.start_time = time.time()\n",
        "        self.epoch_start_time = None\n",
        "        self.batch_times = []\n",
        "\n",
        "    def start_epoch(self, epoch):\n",
        "        \"\"\"Start tracking an epoch\"\"\"\n",
        "        self.current_epoch = epoch\n",
        "        self.epoch_start_time = time.time()\n",
        "        self.batch_times = []\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Model: {self.model_name.upper()} | Epoch: {epoch+1}/{self.total_epochs}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "    def update_batch(self, batch_idx, batch_loss, batch_acc, is_training=True):\n",
        "        \"\"\"Update progress for current batch\"\"\"\n",
        "        batch_time = time.time()\n",
        "        self.batch_times.append(batch_time)\n",
        "\n",
        "        # Calculate timing estimates\n",
        "        if len(self.batch_times) > 1:\n",
        "            avg_batch_time = np.mean(np.diff(self.batch_times[-10:]))\n",
        "        else:\n",
        "            avg_batch_time = 1.0\n",
        "\n",
        "        remaining_batches = self.total_batches_per_epoch - (batch_idx + 1)\n",
        "        eta_epoch = remaining_batches * avg_batch_time\n",
        "\n",
        "        # Progress bar\n",
        "        progress_pct = (batch_idx + 1) / self.total_batches_per_epoch * 100\n",
        "        bar_length = 30\n",
        "        filled_length = int(bar_length * (batch_idx + 1) // self.total_batches_per_epoch)\n",
        "        bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "        # Format time\n",
        "        eta_str = str(timedelta(seconds=int(eta_epoch)))\n",
        "\n",
        "        # Display progress\n",
        "        mode = \"TRAIN\" if is_training else \"VAL  \"\n",
        "        print(f\"\\r{mode} |{bar}| {progress_pct:5.1f}% | \"\n",
        "              f\"Batch: {batch_idx+1:4d}/{self.total_batches_per_epoch} | \"\n",
        "              f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
        "              f\"ETA: {eta_str}\", end='', flush=True)\n",
        "\n",
        "    def finish_epoch(self, train_loss, train_acc, val_loss, val_acc, val_f1,\n",
        "                    is_best=False, lr=None):\n",
        "        \"\"\"Finish epoch and display summary\"\"\"\n",
        "        epoch_time = time.time() - self.epoch_start_time\n",
        "        total_time = time.time() - self.start_time\n",
        "\n",
        "        print(f\"\\n{'-'*60}\")\n",
        "        print(f\"EPOCH SUMMARY:\")\n",
        "        print(f\"  Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"  Val Loss:   {val_loss:.6f} | Val Acc:   {val_acc:.4f}\")\n",
        "        print(f\"  Val F1:     {val_f1:.4f} | Epoch Time: {epoch_time:.1f}s\")\n",
        "        if lr:\n",
        "            print(f\"  Learning Rate: {lr:.2e}\")\n",
        "\n",
        "        if is_best:\n",
        "            print(f\"  ‚òÖ NEW BEST MODEL! (F1: {val_f1:.4f})\")\n",
        "\n",
        "        print(f\"  Total Time: {str(timedelta(seconds=int(total_time)))}\")\n",
        "        print(f\"{'-'*60}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ae9e92d",
      "metadata": {
        "id": "0ae9e92d"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---\n",
        "# 4. DATA LOADING AND PREPROCESSING\n",
        "# =============================================================================\n",
        "# Purpose: Handle dataset creation, data loading, balancing with SMOTE, and data augmentation.\n",
        "\n",
        "class FishDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = self._preprocess_images(images)\n",
        "        self.labels = labels.astype(np.int64)\n",
        "        self.transform = transform\n",
        "\n",
        "    def _preprocess_images(self, images):\n",
        "        if images.max() > 1.5:\n",
        "            images = images.astype(np.float32) / 255.0\n",
        "        if len(images.shape) == 4 and images.shape[1] == 3:\n",
        "            images = np.transpose(images, (0, 2, 3, 1))\n",
        "        return images.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "        else:\n",
        "            image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class DataManager:\n",
        "    @staticmethod\n",
        "    def get_transforms(is_training=True, augmentation_strength='medium'):\n",
        "        \"\"\"Get data transforms with configurable augmentation strength\"\"\"\n",
        "        if is_training:\n",
        "            if augmentation_strength == 'light':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.3),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            elif augmentation_strength == 'heavy':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.7),\n",
        "                    A.VerticalFlip(p=0.5),\n",
        "                    A.RandomRotate90(p=0.7),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, p=0.8),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.8),\n",
        "                    A.HueSaturationValue(hue_shift_limit=30, sat_shift_limit=40, val_shift_limit=30, p=0.7),\n",
        "                    A.GaussianBlur(blur_limit=(3, 9), p=0.5),\n",
        "                    A.GaussNoise(var_limit=(10.0, 80.0), p=0.4),\n",
        "                    A.CoarseDropout(max_holes=12, max_height=25, max_width=25, p=0.5),\n",
        "                    A.ElasticTransform(p=0.3),\n",
        "                    A.GridDistortion(p=0.3),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            else:  # medium\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.5),\n",
        "                    A.VerticalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.5),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.7),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
        "                    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.6),\n",
        "                    A.GaussianBlur(blur_limit=(3, 7), p=0.4),\n",
        "                    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "                    A.CoarseDropout(max_holes=8, max_height=20, max_width=20, p=0.4),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "        else:\n",
        "            return A.Compose([\n",
        "                A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "\n",
        "    @staticmethod\n",
        "    def load_and_balance_data():\n",
        "        \"\"\"Load data and apply SMOTE\"\"\"\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "\n",
        "        X = np.load(Config.DATA_FILE)\n",
        "        Y = np.load(Config.LABELS_FILE)\n",
        "\n",
        "        print(f\"Original data shape: {X.shape}\")\n",
        "        print(f\"Original class distribution: {np.bincount(Y)}\")\n",
        "\n",
        "        print(\"Applying SMOTE for class balancing...\")\n",
        "        X_flat = X.reshape(X.shape[0], -1)\n",
        "        smote = SMOTE(random_state=Config.SEED, k_neighbors=min(5, np.bincount(Y).min()-1))\n",
        "        X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y)\n",
        "        X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "\n",
        "        print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "\n",
        "        return X_balanced, Y_balanced\n",
        "\n",
        "    @staticmethod\n",
        "    def create_data_loaders(X, Y, test_size=0.2, batch_size=None, augmentation_strength='medium'):\n",
        "        if batch_size is None:\n",
        "            if torch.cuda.is_available():\n",
        "                gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "                if gpu_memory_gb >= 24:\n",
        "                    batch_size = 128\n",
        "                elif gpu_memory_gb >= 12:\n",
        "                    batch_size = 96\n",
        "                elif gpu_memory_gb >= 8:\n",
        "                    batch_size = 64\n",
        "                else:\n",
        "                    batch_size = 48\n",
        "            else:\n",
        "                batch_size = Config.BATCH_SIZE\n",
        "\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "            X, Y, test_size=test_size, random_state=Config.SEED, stratify=Y\n",
        "        )\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=0.25, random_state=Config.SEED, stratify=y_temp\n",
        "        )\n",
        "\n",
        "        print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "        print(f\"Using optimized batch size: {batch_size}\")\n",
        "\n",
        "        train_dataset = FishDataset(X_train, y_train,\n",
        "                                  DataManager.get_transforms(True, augmentation_strength))\n",
        "        val_dataset = FishDataset(X_val, y_val, DataManager.get_transforms(False))\n",
        "        test_dataset = FishDataset(X_test, y_test, DataManager.get_transforms(False))\n",
        "\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "        sample_weights = [class_weights[y] for y in y_train]\n",
        "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=sampler,\n",
        "            num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            prefetch_factor=2,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            prefetch_factor=2,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            prefetch_factor=2,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "        return train_loader, val_loader, test_loader, (X_val, y_val), (X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "583d6d32",
      "metadata": {
        "id": "583d6d32"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---\n",
        "# 5. MODEL FACTORY\n",
        "# =============================================================================\n",
        "# Purpose: Create different neural network models with customizable architectures.\n",
        "\n",
        "class ModelFactory:\n",
        "    @staticmethod\n",
        "    def create_model(model_name, num_classes=Config.NUM_CLASSES, dropout_rate=0.5,\n",
        "                    hidden_dim_multiplier=0.5):\n",
        "        \"\"\"Create model with configurable architecture\"\"\"\n",
        "\n",
        "        if model_name == 'resnet50':\n",
        "            model = models.resnet50(weights='IMAGENET1K_V2')\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'efficientnet_b0':\n",
        "            model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "            num_features = model.classifier[1].in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'mobilenet_v3_large':\n",
        "            model = models.mobilenet_v3_large(weights='IMAGENET1K_V2')\n",
        "            num_features = 960\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'vgg16':\n",
        "            model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "            hidden_dim = int(4096 * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Linear(512 * 7 * 7, 4096),\n",
        "                nn.ReLU(True),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(4096, hidden_dim),\n",
        "                nn.ReLU(True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'densenet121':\n",
        "            model = models.densenet121(weights='IMAGENET1K_V1')\n",
        "            num_features = model.classifier.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "        return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ca5c696",
      "metadata": {
        "id": "0ca5c696"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---\n",
        "# 6. LEARNABLE WEIGHTED ENSEMBLE MODEL\n",
        "# =============================================================================\n",
        "# Purpose: Define a neural network for learning optimal ensemble weights.\n",
        "\n",
        "class LearnableWeightedEnsemble(nn.Module):\n",
        "    \"\"\"Neural network for learning optimal ensemble weights\"\"\"\n",
        "    def __init__(self, num_models, num_classes, hidden_dim=64):\n",
        "        super(LearnableWeightedEnsemble, self).__init__()\n",
        "        self.num_models = num_models\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.weight_network = nn.Sequential(\n",
        "            nn.Linear(num_models * num_classes, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim // 2, num_models),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "        self.prediction_head = nn.Sequential(\n",
        "            nn.Linear(num_classes, num_classes * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(num_classes * 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, model_predictions):\n",
        "        batch_size = model_predictions.shape[0]\n",
        "\n",
        "        flattened_preds = model_predictions.view(batch_size, -1)\n",
        "\n",
        "        weights = self.weight_network(flattened_preds)\n",
        "\n",
        "        weighted_avg = torch.sum(model_predictions * weights.unsqueeze(-1), dim=1)\n",
        "\n",
        "        final_predictions = self.prediction_head(weighted_avg)\n",
        "\n",
        "        return final_predictions, weights\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97cb257b",
      "metadata": {
        "id": "97cb257b"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---\n",
        "# 7. HYPERPARAMETER OPTIMIZATION\n",
        "# =============================================================================\n",
        "# Purpose: Tune model hyperparameters using Optuna.\n",
        "\n",
        "class ExpandedHyperparameterOptimizer:\n",
        "    def __init__(self, model_name, train_loader, val_loader):\n",
        "        self.model_name = model_name\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.total_batches_per_epoch = len(train_loader)\n",
        "        self.batch_times = []\n",
        "\n",
        "    def _update_progress(self, batch_idx, batch_loss, batch_acc, trial_params, is_training=True):\n",
        "        \"\"\"Display progress during hyperparameter tuning\"\"\"\n",
        "        batch_time = time.time()\n",
        "        self.batch_times.append(batch_time)\n",
        "\n",
        "        if len(self.batch_times) > 1:\n",
        "            avg_batch_time = np.mean(np.diff(self.batch_times[-10:]))\n",
        "        else:\n",
        "            avg_batch_time = 1.0\n",
        "\n",
        "        remaining_batches = self.total_batches_per_epoch - (batch_idx + 1)\n",
        "        eta_epoch = remaining_batches * avg_batch_time\n",
        "\n",
        "        progress_pct = (batch_idx + 1) / self.total_batches_per_epoch * 100\n",
        "        bar_length = 30\n",
        "        filled_length = int(bar_length * (batch_idx + 1) // self.total_batches_per_epoch)\n",
        "        bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "        eta_str = str(timedelta(seconds=int(eta_epoch)))\n",
        "\n",
        "        mode = \"TRAIN\" if is_training else \"VAL  \"\n",
        "        print(f\"\\r{mode} |{bar}| {progress_pct:5.1f}% | \"\n",
        "              f\"Batch: {batch_idx+1:4d}/{self.total_batches_per_epoch} | \"\n",
        "              f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
        "              f\"ETA: {eta_str} | Params: {self._format_params(trial_params)}\", end='', flush=True)\n",
        "\n",
        "    def _format_params(self, params):\n",
        "        \"\"\"Format hyperparameters for display\"\"\"\n",
        "        formatted = []\n",
        "        for key, value in params.items():\n",
        "            if key in ['lr', 'weight_decay']:\n",
        "                formatted.append(f\"{key}: {value:.4f}\")\n",
        "            elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                formatted.append(f\"{key}: {value:.1f}\")\n",
        "            else:\n",
        "                formatted.append(f\"{key}: {value}\")\n",
        "        return \", \".join(formatted)\n",
        "\n",
        "    def objective(self, trial):\n",
        "        \"\"\"Expanded Optuna objective function with more hyperparameters\"\"\"\n",
        "        lr = trial.suggest_float('lr', 1e-5, 5e-3, log=True)\n",
        "        weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
        "        dropout = trial.suggest_float('dropout', 0.2, 0.8)\n",
        "        hidden_dim_multiplier = trial.suggest_float('hidden_dim_multiplier', 0.25, 1.0)\n",
        "        augmentation_strength = trial.suggest_categorical('augmentation_strength',\n",
        "                                                        ['light', 'medium', 'heavy'])\n",
        "        batch_size = trial.suggest_categorical('batch_size', [16, 24, 32, 48, 64])\n",
        "        optimizer_type = trial.suggest_categorical('optimizer_type', ['adam', 'adamw', 'sgd'])\n",
        "        scheduler_type = trial.suggest_categorical('scheduler_type',\n",
        "                                                 ['cosine', 'step', 'exponential'])\n",
        "        label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.2)\n",
        "\n",
        "        trial_params = {\n",
        "            'lr': lr, 'weight_decay': weight_decay, 'dropout': dropout,\n",
        "            'hidden_dim_multiplier': hidden_dim_multiplier, 'augmentation_strength': augmentation_strength,\n",
        "            'batch_size': batch_size, 'optimizer_type': optimizer_type, 'scheduler_type': scheduler_type,\n",
        "            'label_smoothing': label_smoothing\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            print(f\"\\nTrial {trial.number} parameters:\")\n",
        "            for key, value in trial_params.items():\n",
        "                if key in ['lr', 'weight_decay']:\n",
        "                    print(f\"  {key}: {value:.4f}\")\n",
        "                elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                    print(f\"  {key}: {value:.1f}\")\n",
        "                else:\n",
        "                    print(f\"  {key}: {value}\")\n",
        "\n",
        "            temp_train_loader = DataLoader(\n",
        "                self.train_loader.dataset,\n",
        "                batch_size=batch_size,\n",
        "                sampler=self.train_loader.sampler\n",
        "            )\n",
        "            temp_val_loader = DataLoader(\n",
        "                self.val_loader.dataset,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=False\n",
        "            )\n",
        "\n",
        "            model = ModelFactory.create_model(\n",
        "                self.model_name,\n",
        "                dropout_rate=dropout,\n",
        "                hidden_dim_multiplier=hidden_dim_multiplier\n",
        "            )\n",
        "            model = model.to(Config.DEVICE)\n",
        "\n",
        "            if optimizer_type == 'adam':\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "            elif optimizer_type == 'adamw':\n",
        "                optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "            else:\n",
        "                optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                                    momentum=0.9, nesterov=True)\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "            if scheduler_type == 'cosine':\n",
        "                scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.OPTUNA_EPOCHS)\n",
        "            elif scheduler_type == 'step':\n",
        "                scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.7)\n",
        "            else:\n",
        "                scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "            best_val_acc = 0\n",
        "            patience_counter = 0\n",
        "\n",
        "            for epoch in range(Config.OPTUNA_EPOCHS):\n",
        "                self.batch_times = []\n",
        "                model.train()\n",
        "                train_correct = 0\n",
        "                train_total = 0\n",
        "                train_loss = 0\n",
        "\n",
        "                for batch_idx, (images, labels) in enumerate(temp_train_loader):\n",
        "                    if batch_idx > 15:\n",
        "                        break\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "\n",
        "                    batch_loss = loss.item()\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    train_total += labels.size(0)\n",
        "                    train_correct += (predicted == labels).sum().item()\n",
        "                    train_loss += batch_loss\n",
        "\n",
        "                    batch_acc = train_correct / train_total\n",
        "                    self._update_progress(batch_idx, batch_loss, batch_acc, trial_params, is_training=True)\n",
        "\n",
        "                model.eval()\n",
        "                val_correct = 0\n",
        "                val_total = 0\n",
        "                val_loss = 0\n",
        "                val_predictions = []\n",
        "                val_labels = []\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for batch_idx, (images, labels) in enumerate(temp_val_loader):\n",
        "                        if batch_idx > 8:\n",
        "                            break\n",
        "                        images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                        outputs = model(images)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        batch_loss = loss.item()\n",
        "                        val_loss += batch_loss\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "                        val_total += labels.size(0)\n",
        "                        val_correct += (predicted == labels).sum().item()\n",
        "                        val_predictions.extend(predicted.cpu().numpy())\n",
        "                        val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                        batch_acc = val_correct / val_total\n",
        "                        self._update_progress(batch_idx, batch_loss, batch_acc, trial_params, is_training=False)\n",
        "\n",
        "                train_acc = train_correct / train_total\n",
        "                val_acc = val_correct / val_total\n",
        "                val_f1 = f1_score(val_labels, val_predictions, average='macro')\n",
        "                scheduler.step()\n",
        "\n",
        "                print(f\"\\nEpoch {epoch+1}/{Config.OPTUNA_EPOCHS} Summary: \"\n",
        "                      f\"Train Loss: {train_loss/len(temp_train_loader):.6f}, \"\n",
        "                      f\"Train Acc: {train_acc:.4f}, Val Loss: {val_loss/len(temp_val_loader):.6f}, \"\n",
        "                      f\"Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "                if val_acc > best_val_acc:\n",
        "                    best_val_acc = val_acc\n",
        "                    patience_counter = 0\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "\n",
        "                if patience_counter >= 4:\n",
        "                    print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "                trial.report(val_acc, epoch)\n",
        "                if trial.should_prune():\n",
        "                    raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "            return best_val_acc\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nTrial failed: {e}\")\n",
        "            return 0.0\n",
        "\n",
        "    def optimize(self):\n",
        "        print(f\"Optimizing hyperparameters for {self.model_name}...\")\n",
        "\n",
        "        if not OPTUNA_AVAILABLE:\n",
        "            return {\n",
        "                'lr': Config.LEARNING_RATE,\n",
        "                'dropout': 0.5,\n",
        "                'weight_decay': Config.WEIGHT_DECAY,\n",
        "                'hidden_dim_multiplier': 0.5,\n",
        "                'augmentation_strength': 'medium',\n",
        "                'batch_size': Config.BATCH_SIZE,\n",
        "                'optimizer_type': 'adamw',\n",
        "                'scheduler_type': 'cosine',\n",
        "                'label_smoothing': 0.1\n",
        "            }\n",
        "\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(self.objective, n_trials=Config.OPTUNA_TRIALS, timeout=1200)\n",
        "\n",
        "        best_params = study.best_trial.params\n",
        "        print(f\"\\nBest params for {self.model_name}:\")\n",
        "        for key, value in best_params.items():\n",
        "            if key in ['lr', 'weight_decay']:\n",
        "                print(f\"  {key}: {value:.4f}\")\n",
        "            elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                print(f\"  {key}: {value:.1f}\")\n",
        "            else:\n",
        "                print(f\"  {key}: {value}\")\n",
        "        print(f\"Best validation accuracy: {study.best_trial.value:.4f}\")\n",
        "\n",
        "        return best_params\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dccc6ffd",
      "metadata": {
        "id": "dccc6ffd"
      },
      "outputs": [],
      "source": [
        "# 8. MODEL TRAINING (Corrected)\n",
        "# =============================================================================\n",
        "# Purpose: Train individual models with optimized hyperparameters.\n",
        "\n",
        "class EnhancedModelTrainer:\n",
        "    def __init__(self, model, model_name, hyperparameters):\n",
        "        self.model = model.to(Config.DEVICE)\n",
        "        self.model_name = model_name\n",
        "        self.hyperparameters = hyperparameters\n",
        "\n",
        "        self._setup_training_components()\n",
        "\n",
        "        self.best_val_acc = 0.0\n",
        "        self.best_val_f1 = 0.0\n",
        "        self.patience_counter = 0\n",
        "        self.history = {\n",
        "            'train_loss': [], 'train_acc': [],\n",
        "            'val_loss': [], 'val_acc': [], 'val_f1': [],\n",
        "            'learning_rates': []\n",
        "        }\n",
        "\n",
        "    def _setup_training_components(self):\n",
        "        lr = self.hyperparameters.get('lr', Config.LEARNING_RATE)\n",
        "        weight_decay = self.hyperparameters.get('weight_decay', Config.WEIGHT_DECAY)\n",
        "\n",
        "        optimizer_type = self.hyperparameters.get('optimizer_type', 'adamw')\n",
        "        if optimizer_type == 'adam':\n",
        "            self.optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        elif optimizer_type == 'adamw':\n",
        "            self.optimizer = optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        else:\n",
        "            self.optimizer = optim.SGD(self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                                     momentum=0.9, nesterov=True)\n",
        "\n",
        "        label_smoothing = self.hyperparameters.get('label_smoothing', 0.1)\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "        scheduler_type = self.hyperparameters.get('scheduler_type', 'cosine')\n",
        "        if scheduler_type == 'cosine':\n",
        "            self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "                self.optimizer, T_0=10, T_mult=2\n",
        "            )\n",
        "        elif scheduler_type == 'step':\n",
        "            self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.5)\n",
        "        else:\n",
        "            self.scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.95)\n",
        "\n",
        "    def train_epoch(self, train_loader, progress_tracker):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        batch_losses = []\n",
        "        batch_accuracies = []\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(images)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            batch_loss = loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            batch_total = labels.size(0)\n",
        "            batch_correct = (predicted == labels).sum().item()\n",
        "            batch_acc = batch_correct / batch_total\n",
        "\n",
        "            total_loss += batch_loss\n",
        "            total += batch_total\n",
        "            correct += batch_correct\n",
        "\n",
        "            batch_losses.append(batch_loss)\n",
        "            batch_accuracies.append(batch_acc)\n",
        "\n",
        "            progress_tracker.update_batch(batch_idx, batch_loss, batch_acc, is_training=True)\n",
        "\n",
        "        return total_loss / len(train_loader), correct / total\n",
        "\n",
        "    def validate_epoch(self, val_loader, progress_tracker):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (images, labels) in enumerate(val_loader):\n",
        "                images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                outputs = self.model(images)\n",
        "                loss = self.criterion(outputs, labels)\n",
        "\n",
        "                batch_loss = loss.item()\n",
        "                total_loss += batch_loss\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                batch_acc = (predicted == labels).float().mean().item()\n",
        "\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                progress_tracker.update_batch(batch_idx, batch_loss, batch_acc, is_training=False)\n",
        "\n",
        "        if not all_labels:  # Check if validation data is empty\n",
        "            print(f\"Warning: No validation data processed for {self.model_name}\")\n",
        "            return float('inf'), 0.0, 0.0\n",
        "\n",
        "        accuracy = accuracy_score(all_labels, all_predictions)\n",
        "        f1 = f1_score(all_labels, all_predictions, average='macro')\n",
        "\n",
        "        return total_loss / len(val_loader), accuracy, f1\n",
        "\n",
        "    def train(self, train_loader, val_loader):\n",
        "        print(f\"Training {self.model_name} with hyperparameters:\")\n",
        "        for key, value in self.hyperparameters.items():\n",
        "            if key in ['lr', 'weight_decay']:\n",
        "                print(f\"  {key}: {value:.4f}\")\n",
        "            elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                print(f\"  {key}: {value:.1f}\")\n",
        "            else:\n",
        "                print(f\"  {key}: {value}\")\n",
        "\n",
        "        progress_tracker = TrainingProgressTracker(\n",
        "            self.model_name, Config.EPOCHS, len(train_loader)\n",
        "        )\n",
        "\n",
        "        for epoch in range(Config.EPOCHS):\n",
        "            progress_tracker.start_epoch(epoch)\n",
        "\n",
        "            train_loss, train_acc = self.train_epoch(train_loader, progress_tracker)\n",
        "\n",
        "            val_loss, val_acc, val_f1 = self.validate_epoch(val_loader, progress_tracker)\n",
        "\n",
        "            self.scheduler.step()\n",
        "            current_lr = self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "            # Append metrics to history\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "            self.history['val_f1'].append(val_f1)\n",
        "            self.history['learning_rates'].append(current_lr)\n",
        "\n",
        "            is_best = False\n",
        "            if val_f1 > self.best_val_f1:\n",
        "                self.best_val_f1 = val_f1\n",
        "                self.best_val_acc = val_acc\n",
        "                self.patience_counter = 0\n",
        "                is_best = True\n",
        "\n",
        "                torch.save(self.model.state_dict(),\n",
        "                          f\"{Config.OUTPUT_DIR}/models/{self.model_name}_best.pt\")\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "\n",
        "            progress_tracker.finish_epoch(\n",
        "                train_loss, train_acc, val_loss, val_acc, val_f1,\n",
        "                is_best=is_best, lr=current_lr\n",
        "            )\n",
        "\n",
        "            if self.patience_counter >= Config.PATIENCE:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        # Debugging: Print history to verify contents\n",
        "        print(f\"History for {self.model_name}:\")\n",
        "        print(f\"  train_loss: {len(self.history['train_loss'])} entries\")\n",
        "        print(f\"  train_acc: {len(self.history['train_acc'])} entries\")\n",
        "        print(f\"  val_loss: {len(self.history['val_loss'])} entries\")\n",
        "        print(f\"  val_acc: {len(self.history['val_acc'])} entries\")\n",
        "        print(f\"  val_f1: {len(self.history['val_f1'])} entries\")\n",
        "\n",
        "        self.model.load_state_dict(\n",
        "            torch.load(f\"{Config.OUTPUT_DIR}/models/{self.model_name}_best.pt\")\n",
        "        )\n",
        "\n",
        "        print(f\"\\n‚úì {self.model_name} training completed!\")\n",
        "        print(f\"  Best Validation F1: {self.best_val_f1:.4f}\")\n",
        "        print(f\"  Best Validation Accuracy: {self.best_val_acc:.4f}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return self.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "99d5194e",
      "metadata": {
        "id": "99d5194e"
      },
      "outputs": [],
      "source": [
        "# 9. ENSEMBLE METHODS\n",
        "# =============================================================================\n",
        "# Purpose: Implement ensemble methods (simple, weighted, confidence-based, learnable).\n",
        "\n",
        "class EnsembleManager:\n",
        "    def __init__(self, models_dict, val_data):\n",
        "        self.models = models_dict\n",
        "        self.X_val, self.y_val = val_data\n",
        "        self.model_predictions = self._get_predictions()\n",
        "        self.histories = {}\n",
        "\n",
        "    def _get_predictions(self):\n",
        "        print(\"Getting model predictions for ensemble...\")\n",
        "        predictions = {}\n",
        "\n",
        "        val_dataset = FishDataset(self.X_val, self.y_val, DataManager.get_transforms(False))\n",
        "        val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            model.eval()\n",
        "            all_preds = []\n",
        "            all_probs = []\n",
        "            all_losses = []\n",
        "            all_labels = []\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    outputs = model(images)\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    loss = criterion(outputs, labels).item()\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    all_preds.extend(predicted.cpu().numpy())\n",
        "                    all_probs.extend(probabilities.cpu().numpy())\n",
        "                    all_losses.append(loss)\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = correct / total\n",
        "            f1 = f1_score(self.y_val, all_preds, average='macro')\n",
        "            avg_loss = np.mean(all_losses)\n",
        "\n",
        "            predictions[name] = {\n",
        "                'predictions': np.array(all_preds),\n",
        "                'probabilities': np.array(all_probs),\n",
        "                'loss': avg_loss,\n",
        "                'accuracy': accuracy,\n",
        "                'f1': f1,\n",
        "                'true_labels': np.array(all_labels)  # Added true_labels\n",
        "            }\n",
        "\n",
        "            print(f\"  {name}: F1 = {f1:.4f}, Acc = {accuracy:.4f}, Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def simple_average_ensemble(self, model_combo):\n",
        "        selected_probs = [self.model_predictions[name]['probabilities'] for name in model_combo]\n",
        "        avg_probs = np.mean(selected_probs, axis=0)\n",
        "        predictions = np.argmax(avg_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'probabilities': avg_probs,\n",
        "            'true_labels': self.y_val  # Added true_labels\n",
        "        }\n",
        "\n",
        "    def weighted_average_ensemble(self, model_combo):\n",
        "        weights = []\n",
        "        selected_probs = []\n",
        "\n",
        "        for name in model_combo:\n",
        "            f1 = self.model_predictions[name]['f1']\n",
        "            weights.append(f1)\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        weights = np.array(weights) / np.sum(weights)\n",
        "        weighted_probs = np.average(selected_probs, axis=0, weights=weights)\n",
        "        predictions = np.argmax(weighted_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.average([self.model_predictions[name]['loss'] for name in model_combo], weights=weights)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'weights': weights,\n",
        "            'models': model_combo,\n",
        "            'probabilities': weighted_probs,\n",
        "            'true_labels': self.y_val  # Added true_labels\n",
        "        }\n",
        "\n",
        "    def confidence_based_ensemble(self, model_combo):\n",
        "        final_predictions = []\n",
        "        all_probs = []\n",
        "\n",
        "        for i in range(len(self.y_val)):\n",
        "            confidences = []\n",
        "            probs = []\n",
        "\n",
        "            for name in model_combo:\n",
        "                prob = self.model_predictions[name]['probabilities'][i]\n",
        "                confidence = np.max(prob)\n",
        "                confidences.append(confidence)\n",
        "                probs.append(prob)\n",
        "\n",
        "            confidences = np.array(confidences)\n",
        "            weights = confidences / np.sum(confidences) if np.sum(confidences) > 0 else np.ones(len(confidences)) / len(confidences)\n",
        "\n",
        "            final_prob = np.average(probs, axis=0, weights=weights)\n",
        "            final_predictions.append(np.argmax(final_prob))\n",
        "            all_probs.append(final_prob)\n",
        "\n",
        "        predictions = np.array(final_predictions)\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'probabilities': np.array(all_probs),\n",
        "            'true_labels': self.y_val  # Added true_labels\n",
        "        }\n",
        "\n",
        "    def learnable_weighted_ensemble(self, model_combo, epochs=30):\n",
        "        print(f\"Training learnable weighted ensemble with {len(model_combo)} models...\")\n",
        "\n",
        "        selected_probs = []\n",
        "        for name in model_combo:\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        ensemble_input = np.stack(selected_probs, axis=1)\n",
        "\n",
        "        X_ensemble = torch.FloatTensor(ensemble_input).to(Config.DEVICE)\n",
        "        y_ensemble = torch.LongTensor(self.y_val).to(Config.DEVICE)\n",
        "\n",
        "        ensemble_model = LearnableWeightedEnsemble(\n",
        "            num_models=len(model_combo),\n",
        "            num_classes=Config.NUM_CLASSES\n",
        "        ).to(Config.DEVICE)\n",
        "\n",
        "        optimizer = optim.AdamW(ensemble_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "        history = {'train_loss': [], 'train_acc': [], 'val_f1': []}\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            ensemble_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions, weights = ensemble_model(X_ensemble)\n",
        "            loss = criterion(predictions, y_ensemble)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            accuracy = accuracy_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy())\n",
        "            f1 = f1_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy(), average='macro')\n",
        "\n",
        "            history['train_loss'].append(loss.item())\n",
        "            history['train_acc'].append(accuracy)\n",
        "            history['val_f1'].append(f1)\n",
        "\n",
        "            print(f\"Ensemble Epoch {epoch+1}/{epochs}: Loss = {loss.item():.4f}, \"\n",
        "                  f\"Acc = {accuracy:.4f}, F1 = {f1:.4f}\")\n",
        "\n",
        "            if loss.item() < best_loss:\n",
        "                best_loss = loss.item()\n",
        "\n",
        "        ensemble_model.eval()\n",
        "        with torch.no_grad():\n",
        "            final_predictions, learned_weights = ensemble_model(X_ensemble)\n",
        "            predictions = final_predictions.argmax(dim=1).cpu().numpy()\n",
        "            probabilities = torch.softmax(final_predictions, dim=1).cpu().numpy()\n",
        "            avg_weights = learned_weights.mean(dim=0).cpu().numpy()\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        self.histories[f\"learnable_weighted_{'+'.join(model_combo)}\"] = history\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'learned_weights': avg_weights,\n",
        "            'probabilities': probabilities,\n",
        "            'true_labels': self.y_val  # Added true_labels\n",
        "        }\n",
        "\n",
        "    def test_ensemble_combinations(self):\n",
        "        print(\"Testing ensemble combinations...\")\n",
        "\n",
        "        model_names = list(self.models.keys())\n",
        "        all_results = {}\n",
        "        best_result = None\n",
        "        best_score = 0\n",
        "\n",
        "        for size in range(2, min(len(model_names) + 1, 5)):\n",
        "            print(f\"Testing {size}-model combinations...\")\n",
        "\n",
        "            for combo in list(combinations(model_names, size))[:5]:\n",
        "                combo_name = f\"combo_{size}_{'+'.join(combo)}\"\n",
        "\n",
        "                for method_name in Config.ENSEMBLE_METHODS:\n",
        "                    full_name = f\"{combo_name}_{method_name}\"\n",
        "\n",
        "                    try:\n",
        "                        if method_name == 'simple_average':\n",
        "                            result = self.simple_average_ensemble(combo)\n",
        "                        elif method_name == 'weighted_average':\n",
        "                            result = self.weighted_average_ensemble(combo)\n",
        "                        elif method_name == 'confidence_based':\n",
        "                            result = self.confidence_based_ensemble(combo)\n",
        "                        elif method_name == 'learnable_weighted':\n",
        "                            result = self.learnable_weighted_ensemble(combo)\n",
        "\n",
        "                        # Verify result contains required keys\n",
        "                        required_keys = ['accuracy', 'f1', 'loss', 'predictions', 'models', 'probabilities', 'true_labels']\n",
        "                        if not all(key in result for key in required_keys):\n",
        "                            missing = [key for key in required_keys if key not in result]\n",
        "                            print(f\"  {full_name}: Missing keys {missing}\")\n",
        "                            continue\n",
        "\n",
        "                        all_results[full_name] = result\n",
        "                        print(f\"  {full_name}: F1 = {result['f1']:.4f}, Acc = {result['accuracy']:.4f}, \"\n",
        "                              f\"Loss = {result['loss']:.4f}, True Labels Shape = {result['true_labels'].shape}\")\n",
        "\n",
        "                        if result['f1'] > best_score:\n",
        "                            best_score = result['f1']\n",
        "                            best_result = (full_name, result)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"  {full_name}: FAILED - {str(e)}\")\n",
        "\n",
        "        if best_result:\n",
        "            print(f\"\\n‚úì Best ensemble: {best_result[0]} (F1: {best_result[1]['f1']:.4f})\")\n",
        "        else:\n",
        "            print(\"\\nNo valid ensemble results generated.\")\n",
        "\n",
        "        return all_results, best_result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4288d621",
      "metadata": {
        "id": "4288d621"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---\n",
        "# 10. MODEL EVALUATION\n",
        "# =============================================================================\n",
        "# Purpose: Evaluate models on the test set and compute performance metrics.\n",
        "\n",
        "class ModelEvaluator:\n",
        "    @staticmethod\n",
        "    def evaluate_model(model, test_loader, model_name):\n",
        "        model.eval()\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "        all_probabilities = []\n",
        "        total_loss = 0\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        print(f\"Evaluating {model_name} on test set...\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "                images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                total_loss += loss.item()\n",
        "                probabilities = torch.softmax(outputs, dim=1)\n",
        "                predictions = outputs.argmax(dim=1)\n",
        "\n",
        "                all_predictions.extend(predictions.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_probabilities.extend(probabilities.cpu().numpy())\n",
        "\n",
        "        accuracy = accuracy_score(all_labels, all_predictions)\n",
        "        f1_macro = f1_score(all_labels, all_predictions, average='macro')\n",
        "        f1_weighted = f1_score(all_labels, all_predictions, average='weighted')\n",
        "        precision_macro = precision_score(all_labels, all_predictions, average='macro')\n",
        "        recall_macro = recall_score(all_labels, all_predictions, average='macro')\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "        f1_per_class = f1_score(all_labels, all_predictions, average=None)\n",
        "        precision_per_class = precision_score(all_labels, all_predictions, average=None)\n",
        "        recall_per_class = recall_score(all_labels, all_predictions, average=None)\n",
        "\n",
        "        results = {\n",
        "            'model_name': model_name,\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_weighted': f1_weighted,\n",
        "            'precision_macro': precision_macro,\n",
        "            'recall_macro': recall_macro,\n",
        "            'f1_per_class': f1_per_class,\n",
        "            'precision_per_class': precision_per_class,\n",
        "            'recall_per_class': recall_per_class,\n",
        "            'predictions': all_predictions,\n",
        "            'true_labels': all_labels,\n",
        "            'probabilities': np.array(all_probabilities),\n",
        "            'loss': avg_loss\n",
        "        }\n",
        "\n",
        "        print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"  F1 (macro): {f1_macro:.4f}\")\n",
        "        print(f\"  F1 (weighted): {f1_weighted:.4f}\")\n",
        "        print(f\"  Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d58c888e",
      "metadata": {
        "id": "d58c888e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 11. ENHANCED VISUALIZATIONS (Corrected)\n",
        "# =============================================================================\n",
        "# Purpose: Generate visualizations for training history, ROC curves, confusion matrices, and model comparisons.\n",
        "\n",
        "class EnhancedVisualizations:\n",
        "    def __init__(self):\n",
        "        self.viz_dir = f\"{Config.OUTPUT_DIR}/visualizations\"\n",
        "        Path(self.viz_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def plot_training_history(self, histories, model_type='single'):\n",
        "        for model_name, history in histories.items():\n",
        "            print(f\"Plotting history for {model_name}:\")\n",
        "            print(f\"  train_loss: {len(history['train_loss'])} entries\")\n",
        "            print(f\"  train_acc: {len(history['train_acc'])} entries\")\n",
        "            print(f\"  val_loss: {len(history.get('val_loss', []))} entries\")\n",
        "            print(f\"  val_acc: {len(history.get('val_acc', []))} entries\")\n",
        "            print(f\"  val_f1: {len(history.get('val_f1', []))} entries\")\n",
        "\n",
        "            if not history['train_loss']:\n",
        "                print(f\"Skipping {model_name}: No training data available\")\n",
        "                continue\n",
        "\n",
        "            epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "            # Plot training loss\n",
        "            ax1.plot(epochs, history['train_loss'], label='Train Loss', color='blue')\n",
        "            # Plot validation loss only if available\n",
        "            if history.get('val_loss', []):\n",
        "                if len(history['val_loss']) == len(history['train_loss']):\n",
        "                    ax1.plot(epochs, history['val_loss'], label='Val Loss', color='orange')\n",
        "                else:\n",
        "                    print(f\"Warning: val_loss length ({len(history['val_loss'])}) does not match train_loss length ({len(history['train_loss'])}) for {model_name}\")\n",
        "            ax1.set_title(f'{model_name} - Loss vs Epoch')\n",
        "            ax1.set_xlabel('Epoch')\n",
        "            ax1.set_ylabel('Loss')\n",
        "            ax1.legend()\n",
        "            ax1.grid(True)\n",
        "\n",
        "            # Plot training accuracy\n",
        "            ax2.plot(epochs, history['train_acc'], label='Train Acc', color='green')\n",
        "            # Plot validation accuracy only if available\n",
        "            if history.get('val_acc', []):\n",
        "                if len(history['val_acc']) == len(history['train_acc']):\n",
        "                    ax2.plot(epochs, history['val_acc'], label='Val Acc', color='red')\n",
        "                else:\n",
        "                    print(f\"Warning: val_acc length ({len(history['val_acc'])}) does not match train_acc length ({len(history['train_acc'])}) for {model_name}\")\n",
        "            ax2.set_title(f'{model_name} - Accuracy vs Epoch')\n",
        "            ax2.set_xlabel('Epoch')\n",
        "            ax2.set_ylabel('Accuracy')\n",
        "            ax2.legend()\n",
        "            ax2.grid(True)\n",
        "\n",
        "            plt.suptitle(f'{model_type.capitalize()} Model: {model_name}', fontsize=16)\n",
        "            plt.tight_layout()\n",
        "            save_path = f\"{self.viz_dir}/{model_name}_training_history.png\"\n",
        "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "            plt.show()\n",
        "            print(f\"Training history plot saved: {save_path}\")\n",
        "\n",
        "\n",
        "    def plot_roc_curves(self, results, model_name):\n",
        "        fig, ax = plt.subplots(figsize=(10, 6))\n",
        "        if 'true_labels' not in results or 'probabilities' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'probabilities' in results for {model_name}\")\n",
        "            return\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            fpr, tpr, _ = roc_curve(np.array(results['true_labels']) == i, results['probabilities'][:, i])  # Unchanged line\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            ax.plot(fpr, tpr, label=f'Class {Config.CLASS_LABELS[i]} (AUC = {roc_auc:.2f})')\n",
        "        ax.plot([0, 1], [0, 1], 'k--')\n",
        "        ax.set_title(f'{model_name} - ROC Curve')\n",
        "        ax.set_xlabel('False Positive Rate')\n",
        "        ax.set_ylabel('True Positive Rate')\n",
        "        ax.legend()\n",
        "        ax.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def plot_confusion_matrix(self, results, model_name):\n",
        "        if 'true_labels' not in results or 'predictions' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'predictions' in results for {model_name}\")\n",
        "            return\n",
        "        cm = confusion_matrix(results['true_labels'], results['predictions'])\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(10, 8))\n",
        "        sns.heatmap(cm_normalized, annot=cm, fmt='d', cmap='Blues',\n",
        "                    xticklabels=Config.CLASS_LABELS, yticklabels=Config.CLASS_LABELS,\n",
        "                    cbar_kws={'label': 'Normalized Count'})\n",
        "        ax.set_title(f'Confusion Matrix: {model_name}')\n",
        "        ax.set_xlabel('Predicted Label')\n",
        "        ax.set_ylabel('True Label')\n",
        "        plt.xticks(rotation=45, ha='right')\n",
        "        plt.yticks(rotation=0)\n",
        "        plt.tight_layout()\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_confusion_matrix.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(f\"Confusion matrix saved: {save_path}\")\n",
        "\n",
        "    def plot_model_comparison(self, single_results, ensemble_results):\n",
        "        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "        model_names = list(single_results.keys())\n",
        "        accuracies = [single_results[name]['accuracy'] for name in model_names]\n",
        "        f1_scores = [single_results[name]['f1_macro'] for name in model_names]\n",
        "        f1_weighted = [single_results[name]['f1_weighted'] for name in model_names]\n",
        "        losses = [single_results[name]['loss'] for name in model_names]\n",
        "\n",
        "        x = np.arange(len(model_names))\n",
        "        width = 0.2\n",
        "\n",
        "        ax1.bar(x - width*1.5, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "        ax1.bar(x - width/2, f1_scores, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "        ax1.bar(x + width/2, f1_weighted, width, label='F1 (Weighted)', alpha=0.8, color='lightgreen')\n",
        "        ax1.bar(x + width*1.5, losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "        ax1.set_xlabel('Models', fontweight='bold')\n",
        "        ax1.set_ylabel('Score', fontweight='bold')\n",
        "        ax1.set_title('Individual Model Performance', fontweight='bold', fontsize=14)\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, max(max(accuracies), max(f1_scores), max(f1_weighted), max(losses)) * 1.1)\n",
        "\n",
        "        if ensemble_results:\n",
        "            ensemble_items = list(ensemble_results.items())\n",
        "            ensemble_items.sort(key=lambda x: x[1]['f1'], reverse=True)\n",
        "            top_ensembles = ensemble_items[:10]\n",
        "\n",
        "            ensemble_names = [name.split('_')[-1] for name, _ in top_ensembles]\n",
        "            ensemble_f1s = [result['f1'] for _, result in top_ensembles]\n",
        "            ensemble_accs = [result['accuracy'] for _, result in top_ensembles]\n",
        "            ensemble_losses = [result['loss'] for _, result in top_ensembles]\n",
        "\n",
        "            x = np.arange(len(ensemble_names))\n",
        "            ax2.bar(x - width, ensemble_accs, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "            ax2.bar(x, ensemble_f1s, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "            ax2.bar(x + width, ensemble_losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "            ax2.set_xticks(x)\n",
        "            ax2.set_xticklabels([f\"{name}\" for name in ensemble_names], rotation=45, ha='right')\n",
        "            ax2.set_xlabel('Ensemble Methods', fontweight='bold')\n",
        "            ax2.set_ylabel('Score', fontweight='bold')\n",
        "            ax2.set_title('Top Ensemble Methods', fontweight='bold', fontsize=14)\n",
        "            ax2.legend()\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.set_ylim(0, max(max(ensemble_accs), max(ensemble_f1s), max(ensemble_losses)) * 1.1)\n",
        "\n",
        "        if single_results:\n",
        "            per_class_f1 = []\n",
        "            for model_name in model_names:\n",
        "                per_class_f1.append(single_results[model_name]['f1_per_class'])\n",
        "\n",
        "            per_class_f1 = np.array(per_class_f1)\n",
        "            im = ax3.imshow(per_class_f1, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "            ax3.set_xticks(range(len(Config.CLASS_LABELS)))\n",
        "            ax3.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right')\n",
        "            ax3.set_yticks(range(len(model_names)))\n",
        "            ax3.set_yticklabels(model_names)\n",
        "            ax3.set_title('Per-Class F1 Scores', fontweight='bold', fontsize=14)\n",
        "\n",
        "            cbar = plt.colorbar(im, ax=ax3)\n",
        "            cbar.set_label('F1 Score', rotation=270, labelpad=15)\n",
        "\n",
        "            for i in range(len(model_names)):\n",
        "                for j in range(len(Config.CLASS_LABELS)):\n",
        "                    ax3.text(j, i, f'{per_class_f1[i, j]:.2f}',\n",
        "                            ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
        "\n",
        "        if ensemble_results:\n",
        "            best_single_f1 = max(f1_scores)\n",
        "            best_single_name = model_names[f1_scores.index(best_single_f1)]\n",
        "            best_ensemble_f1 = max([result['f1'] for result in ensemble_results.values()])\n",
        "            best_ensemble_name = max(ensemble_results.items(), key=lambda x: x[1]['f1'])[0]\n",
        "\n",
        "            categories = ['Best Single\\nModel', 'Best Ensemble']\n",
        "            values = [best_single_f1, best_ensemble_f1]\n",
        "            colors = ['lightblue', 'gold']\n",
        "\n",
        "            bars = ax4.bar(categories, values, color=colors, alpha=0.8)\n",
        "            ax4.set_ylabel('F1 Score', fontweight='bold')\n",
        "            ax4.set_title('Single vs Ensemble Comparison', fontweight='bold', fontsize=14)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.set_ylim(0, 1)\n",
        "\n",
        "            for bar, value in zip(bars, values):\n",
        "                ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                        f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "            improvement = ((best_ensemble_f1 - best_single_f1) / best_single_f1) * 100\n",
        "            ax4.text(0.5, 0.5, f'Improvement:\\n{improvement:.2f}%',\n",
        "                    transform=ax4.transAxes, ha='center', va='center',\n",
        "                    fontsize=12, fontweight='bold',\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"yellow\", alpha=0.7))\n",
        "\n",
        "            ax4.text(0, best_single_f1/2, best_single_name, ha='center', va='center',\n",
        "                    rotation=90, fontweight='bold')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        save_path = f\"{self.viz_dir}/model_comparison.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(f\"Model comparison saved: {save_path}\")\n",
        "        return save_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a328133",
      "metadata": {
        "id": "6a328133"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---\n",
        "# 12. XAI VISUALIZATIONS\n",
        "# =============================================================================\n",
        "# Purpose: Implement Grad-CAM++ and LRP for visualizing important regions in images.\n",
        "\n",
        "class XAIVisualizer:\n",
        "    @staticmethod\n",
        "    def grad_cam_plus_plus(model, image, target_class):\n",
        "        \"\"\"Implement Grad-CAM++ for visualizing important regions\"\"\"\n",
        "        model.eval()\n",
        "        image = image.unsqueeze(0).to(Config.DEVICE)\n",
        "        image.requires_grad = True\n",
        "\n",
        "        def get_last_conv_layer(model):\n",
        "            if hasattr(model, 'features'):\n",
        "                return model.features[-1]\n",
        "            elif hasattr(model, 'layer4'):\n",
        "                return model.layer4[-1]\n",
        "            elif hasattr(model, 'block'):\n",
        "                return model.block[-1]\n",
        "            else:\n",
        "                for name, module in model.named_modules():\n",
        "                    if isinstance(module, nn.Conv2d):\n",
        "                        last_conv = module\n",
        "                return last_conv\n",
        "\n",
        "        last_conv_layer = get_last_conv_layer(model)\n",
        "\n",
        "        activations = []\n",
        "        def hook_forward(module, input, output):\n",
        "            activations.append(output)\n",
        "\n",
        "        gradients = []\n",
        "        def hook_backward(module, grad_in, grad_out):\n",
        "            gradients.append(grad_out[0])\n",
        "\n",
        "        hook_f = last_conv_layer.register_forward_hook(hook_forward)\n",
        "        hook_b = last_conv_layer.register_backward_hook(hook_backward)\n",
        "\n",
        "        output = model(image)\n",
        "        model.zero_grad()\n",
        "\n",
        "        one_hot = torch.zeros_like(output)\n",
        "        one_hot[0][target_class] = 1.0\n",
        "        output.backward(gradient=one_hot, retain_graph=True)\n",
        "\n",
        "        hook_f.remove()\n",
        "        hook_b.remove()\n",
        "\n",
        "        activation = activations[0].detach().cpu()\n",
        "        gradient = gradients[0].detach().cpu()\n",
        "\n",
        "        alpha_num = gradient.pow(2)\n",
        "        alpha_denom = 2 * gradient.pow(2) + (activation * gradient.pow(3)).sum(dim=(2, 3), keepdim=True)\n",
        "        alpha = alpha_num / (alpha_denom + 1e-7)\n",
        "\n",
        "        weights = torch.relu((alpha * gradient).sum(dim=(2, 3)))\n",
        "        heatmap = torch.sum(weights[:, :, None, None] * activation, dim=1).squeeze()\n",
        "        heatmap = torch.relu(heatmap)\n",
        "        heatmap /= torch.max(heatmap) + 1e-7\n",
        "\n",
        "        heatmap = heatmap.numpy()\n",
        "        heatmap = cv2.resize(heatmap, (image.shape[3], image.shape[2]))\n",
        "        heatmap = (heatmap * 255).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "        image_np = image.squeeze().permute(1, 2, 0).detach().cpu().numpy()\n",
        "        image_np = (image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])) * 255\n",
        "        image_np = image_np.astype(np.uint8)\n",
        "\n",
        "        superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "    @staticmethod\n",
        "    def lrp(model, image, target_class):\n",
        "        \"\"\"Implement Layer-wise Relevance Propagation\"\"\"\n",
        "        model.eval()\n",
        "        image = image.unsqueeze(0).to(Config.DEVICE)\n",
        "        image.requires_grad = True\n",
        "\n",
        "        layers = list(model.modules())[1:]  # Skip the model itself\n",
        "\n",
        "        activations = [image]\n",
        "        def forward_hook(module, inp, out):\n",
        "            activations.append(out)\n",
        "\n",
        "        hooks = []\n",
        "        for layer in layers:\n",
        "            if isinstance(layer, (nn.Conv2d, nn.Linear, nn.ReLU, nn.BatchNorm2d)):\n",
        "                hooks.append(layer.register_forward_hook(forward_hook))\n",
        "\n",
        "        output = model(image)\n",
        "        for hook in hooks:\n",
        "            hook.remove()\n",
        "\n",
        "        relevance = torch.zeros_like(output)\n",
        "        relevance[0, target_class] = output[0, target_class]\n",
        "\n",
        "        for layer, activation in zip(reversed(layers), reversed(activations[:-1])):\n",
        "            if isinstance(layer, nn.Conv2d):\n",
        "                relevance = XAIVisualizer._lrp_conv(layer, activation, relevance)\n",
        "            elif isinstance(layer, nn.Linear):\n",
        "                relevance = XAIVisualizer._lrp_linear(layer, activation, relevance)\n",
        "            elif isinstance(layer, nn.ReLU):\n",
        "                relevance = relevance * (activation > 0).float()\n",
        "            elif isinstance(layer, nn.BatchNorm2d):\n",
        "                relevance = XAIVisualizer._lrp_batchnorm(layer, activation, relevance)\n",
        "\n",
        "        heatmap = relevance.squeeze().detach().cpu().numpy()\n",
        "        heatmap = np.maximum(heatmap, 0)\n",
        "        if heatmap.max() > 0:\n",
        "            heatmap /= heatmap.max()\n",
        "\n",
        "        heatmap = cv2.resize(heatmap, (image.shape[3], image.shape[2]))\n",
        "        heatmap = (heatmap * 255).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n",
        "\n",
        "        image_np = image.squeeze().permute(1, 2, 0).detach().cpu().numpy()\n",
        "        image_np = (image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])) * 255\n",
        "        image_np = image_np.astype(np.uint8)\n",
        "\n",
        "        superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "    @staticmethod\n",
        "    def _lrp_conv(layer, activation, relevance):\n",
        "        weights = layer.weight\n",
        "        positive_weights = torch.clamp(weights, min=0)\n",
        "\n",
        "        activation = activation.detach()\n",
        "        relevance = relevance.detach()\n",
        "\n",
        "        z = F.conv2d(activation, positive_weights, stride=layer.stride, padding=layer.padding)\n",
        "        z = z + 1e-7\n",
        "        s = relevance / z\n",
        "        c = F.conv2d(s, positive_weights, stride=layer.stride, padding=layer.padding)\n",
        "        return activation * c\n",
        "\n",
        "    @staticmethod\n",
        "    def _lrp_linear(layer, activation, relevance):\n",
        "        weights = layer.weight\n",
        "        positive_weights = torch.clamp(weights, min=0)\n",
        "\n",
        "        activation = activation.detach()\n",
        "        relevance = relevance.detach()\n",
        "\n",
        "        z = F.linear(activation, positive_weights)\n",
        "        z = z + 1e-7\n",
        "        s = relevance / z\n",
        "        c = F.linear(s, positive_weights.t())\n",
        "        return activation * c\n",
        "\n",
        "    @staticmethod\n",
        "    def _lrp_batchnorm(layer, activation, relevance):\n",
        "        return relevance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f739ac5",
      "metadata": {
        "id": "9f739ac5"
      },
      "outputs": [],
      "source": [
        "\n",
        "# ---\n",
        "# 13. REAL-WORLD TESTING\n",
        "# =============================================================================\n",
        "# Purpose: Test models on single images with XAI visualizations.\n",
        "\n",
        "class RealWorldTester:\n",
        "    def __init__(self, model, model_name):\n",
        "        self.model = model.to(Config.DEVICE)\n",
        "        self.model_name = model_name\n",
        "        self.xai_visualizer = XAIVisualizer()\n",
        "\n",
        "    def test_image(self, image_path, true_label=None):\n",
        "        \"\"\"Test a single image with XAI visualizations\"\"\"\n",
        "        transform = DataManager.get_transforms(is_training=False)\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(f\"Could not load image: {image_path}\")\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image = transform(image=image)['image']\n",
        "\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = self.model(image.unsqueeze(0).to(Config.DEVICE))\n",
        "            probabilities = torch.softmax(outputs, dim=1)\n",
        "            predicted_class = outputs.argmax(dim=1).item()\n",
        "            confidence = probabilities[0, predicted_class].item()\n",
        "\n",
        "        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "        gradcam_img, gradcam_heatmap = self.xai_visualizer.grad_cam_plus_plus(\n",
        "            self.model, image, predicted_class)\n",
        "        lrp_img, lrp_heatmap = self.xai_visualizer.lrp(self.model, image, predicted_class)\n",
        "\n",
        "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "        ax1.imshow(image.permute(1, 2, 0).numpy() * np.array([0.229, 0.224, 0.225]) +\n",
        "                  np.array([0.485, 0.456, 0.406]))\n",
        "        ax1.set_title(f'Original Image\\nTrue: {true_label if true_label is not None else \"Unknown\"}')\n",
        "        ax1.axis('off')\n",
        "\n",
        "        ax2.imshow(gradcam_img)\n",
        "        ax2.set_title(f'Grad-CAM++\\nPredicted: {predicted_label} ({confidence:.2%})')\n",
        "        ax2.axis('off')\n",
        "\n",
        "        ax3.imshow(lrp_img)\n",
        "        ax3.set_title('LRP')\n",
        "        ax3.axis('off')\n",
        "\n",
        "        plt.suptitle(f'{self.model_name} - Real World Prediction', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        results = {\n",
        "            'model_name': self.model_name,\n",
        "            'predicted_class': predicted_class,\n",
        "            'predicted_label': predicted_label,\n",
        "            'confidence': confidence,\n",
        "            'probabilities': probabilities.cpu().numpy()[0],\n",
        "            'true_label': true_label\n",
        "        }\n",
        "\n",
        "        return results\n",
        "\n",
        "class EnsembleRealWorldTester:\n",
        "    def __init__(self, models_dict, ensemble_method, model_combo, learned_weights=None):\n",
        "        self.models = models_dict\n",
        "        self.ensemble_method = ensemble_method\n",
        "        self.model_combo = model_combo\n",
        "        self.learned_weights = learned_weights\n",
        "        self.xai_visualizer = XAIVisualizer()\n",
        "\n",
        "    def test_image(self, image_path, true_label=None):\n",
        "        transform = DataManager.get_transforms(is_training=False)\n",
        "\n",
        "        image = cv2.imread(image_path)\n",
        "        if image is None:\n",
        "            raise ValueError(f\"Could not load image: {image_path}\")\n",
        "\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "        image_tensor = transform(image=image)['image'].to(Config.DEVICE)\n",
        "\n",
        "        model_predictions = []\n",
        "        gradcam_heatmaps = []\n",
        "        lrp_heatmaps = []\n",
        "\n",
        "        for name in self.model_combo:\n",
        "            model = self.models[name]\n",
        "            model.eval()\n",
        "            with torch.no_grad():\n",
        "                outputs = model(image_tensor.unsqueeze(0))\n",
        "                probabilities = torch.softmax(outputs, dim=1)\n",
        "                model_predictions.append(probabilities.cpu().numpy()[0])\n",
        "\n",
        "            gradcam_img, gradcam_heatmap = self.xai_visualizer.grad_cam_plus_plus(model, image_tensor, outputs.argmax(dim=1).item())\n",
        "            lrp_img, lrp_heatmap = self.xai_visualizer.lrp(model, image_tensor, outputs.argmax(dim=1).item())\n",
        "            gradcam_heatmaps.append(gradcam_heatmap)\n",
        "            lrp_heatmaps.append(lrp_heatmap)\n",
        "\n",
        "        model_predictions = np.array(model_predictions)\n",
        "\n",
        "        if self.ensemble_method == 'simple_average':\n",
        "            final_probs = np.mean(model_predictions, axis=0)\n",
        "        elif self.ensemble_method == 'weighted_average':\n",
        "            weights = np.array([self.models[name].f1_score for name in self.model_combo])\n",
        "            weights = weights / np.sum(weights)\n",
        "            final_probs = np.average(model_predictions, axis=0, weights=weights)\n",
        "        elif self.ensemble_method == 'confidence_based':\n",
        "            confidences = np.max(model_predictions, axis=1)\n",
        "            weights = confidences / np.sum(confidences)\n",
        "            final_probs = np.average(model_predictions, axis=0, weights=weights)\n",
        "        else:  # learnable_weighted\n",
        "            ensemble_model = LearnableWeightedEnsemble(\n",
        "                num_models=len(self.model_combo),\n",
        "                num_classes=Config.NUM_CLASSES\n",
        "            ).to(Config.DEVICE)\n",
        "            if self.learned_weights is not None:\n",
        "                ensemble_model.load_state_dict(self.learned_weights)\n",
        "            ensemble_model.eval()\n",
        "            with torch.no_grad():\n",
        "                predictions, weights = ensemble_model(torch.FloatTensor(model_predictions).unsqueeze(0).to(Config.DEVICE))\n",
        "                final_probs = torch.softmax(predictions, dim=1).cpu().numpy()[0]\n",
        "\n",
        "        predicted_class = np.argmax(final_probs)\n",
        "        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "        confidence = final_probs[predicted_class]\n",
        "\n",
        "        avg_gradcam = np.mean(gradcam_heatmaps, axis=0)\n",
        "        avg_lrp = np.mean(lrp_heatmaps, axis=0)\n",
        "\n",
        "        image_np = image_tensor.permute(1, 2, 0).cpu().numpy()\n",
        "        image_np = (image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])) * 255\n",
        "        image_np = image_np.astype(np.uint8)\n",
        "\n",
        "        superimposed_gradcam = cv2.addWeighted(image_np, 0.6, avg_gradcam, 0.4, 0)\n",
        "        superimposed_lrp = cv2.addWeighted(image_np, 0.6, avg_lrp, 0.4, 0)\n",
        "\n",
        "        fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "        ax1.imshow(image_np)\n",
        "        ax1.set_title(f'Original Image\\nTrue: {true_label if true_label is not None else \"Unknown\"}')\n",
        "        ax1.axis('off')\n",
        "\n",
        "        ax2.imshow(superimposed_gradcam)\n",
        "        ax2.set_title(f'Ensemble Grad-CAM++\\nPredicted: {predicted_label} ({confidence:.2%})')\n",
        "        ax2.axis('off')\n",
        "\n",
        "        ax3.imshow(superimposed_lrp)\n",
        "        ax3.set_title('Ensemble LRP')\n",
        "        ax3.axis('off')\n",
        "\n",
        "        plt.suptitle(f'Ensemble ({self.ensemble_method}) - Real World Prediction', fontsize=16)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        results = {\n",
        "            'ensemble_method': self.ensemble_method,\n",
        "            'models': self.model_combo,\n",
        "            'predicted_class': predicted_class,\n",
        "            'predicted_label': predicted_label,\n",
        "            'confidence': float(confidence),\n",
        "            'probabilities': final_probs,\n",
        "            'true_label': true_label\n",
        "        }\n",
        "\n",
        "        return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b44905a4",
      "metadata": {
        "id": "b44905a4"
      },
      "outputs": [],
      "source": [
        "# 14. COMPREHENSIVE REPORTING (Corrected)\n",
        "# =============================================================================\n",
        "# Purpose: Generate detailed reports summarizing model and ensemble performance.\n",
        "\n",
        "class ComprehensiveReportGenerator:\n",
        "    def __init__(self, output_dir):\n",
        "        self.output_dir = output_dir\n",
        "        self.reports_dir = f\"{output_dir}/reports\"\n",
        "        Path(self.reports_dir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    def generate_detailed_report(self, single_results, ensemble_results, hyperparameter_results, training_histories, ensemble_histories):\n",
        "        best_single = max(single_results.items(), key=lambda x: x[1]['f1_macro'])\n",
        "        best_ensemble = None\n",
        "        if ensemble_results:\n",
        "            best_ensemble = max(ensemble_results.items(), key=lambda x: x[1]['f1'])\n",
        "\n",
        "        summary = {\n",
        "            \"experiment_summary\": {\n",
        "                \"timestamp\": time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                \"models_evaluated\": len(single_results),\n",
        "                \"ensemble_methods_tested\": len(Config.ENSEMBLE_METHODS) if ensemble_results else 0,\n",
        "                \"total_hyperparameter_trials\": Config.OPTUNA_TRIALS * len(Config.MODELS),\n",
        "                \"dataset_info\": {\n",
        "                    \"num_classes\": Config.NUM_CLASSES,\n",
        "                    \"class_labels\": Config.CLASS_LABELS,\n",
        "                    \"input_size\": Config.INPUT_SIZE\n",
        "                }\n",
        "            },\n",
        "            \"best_single_model\": {\n",
        "                \"name\": best_single[0],\n",
        "                \"accuracy\": float(best_single[1]['accuracy']),\n",
        "                \"f1_macro\": float(best_single[1]['f1_macro']),\n",
        "                \"f1_weighted\": float(best_single[1]['f1_weighted']),\n",
        "                \"loss\": float(best_single[1]['loss']),\n",
        "                \"per_class_f1\": {Config.CLASS_LABELS[i]: float(f1) for i, f1 in enumerate(best_single[1]['f1_per_class'])},\n",
        "                \"hyperparameters\": hyperparameter_results.get(best_single[0], {})\n",
        "            },\n",
        "            \"best_ensemble\": {\n",
        "                \"name\": best_ensemble[0] if best_ensemble else \"N/A\",\n",
        "                \"accuracy\": float(best_ensemble[1]['accuracy']) if best_ensemble else 0.0,\n",
        "                \"f1\": float(best_ensemble[1]['f1']) if best_ensemble else 0.0,\n",
        "                \"loss\": float(best_ensemble[1]['loss']) if best_ensemble else 0.0,\n",
        "                \"models\": best_ensemble[1]['models'] if best_ensemble else [],\n",
        "                \"weights\": (best_ensemble[1].get('weights', best_ensemble[1].get('learned_weights', [])).tolist()\n",
        "                           if isinstance(best_ensemble[1].get('weights', best_ensemble[1].get('learned_weights', [])), np.ndarray)\n",
        "                           else best_ensemble[1].get('weights', best_ensemble[1].get('learned_weights', [])))\n",
        "                           if best_ensemble else []\n",
        "            } if ensemble_results else {},\n",
        "            \"single_model_results\": {\n",
        "                name: {\n",
        "                    \"accuracy\": float(result['accuracy']),\n",
        "                    \"f1_macro\": float(result['f1_macro']),\n",
        "                    \"f1_weighted\": float(result['f1_weighted']),\n",
        "                    \"loss\": float(result['loss']),\n",
        "                    \"per_class_f1\": {Config.CLASS_LABELS[i]: float(f1) for i, f1 in enumerate(result['f1_per_class'])},\n",
        "                    \"per_class_precision\": {Config.CLASS_LABELS[i]: float(p) for i, p in enumerate(result['precision_per_class'])},\n",
        "                    \"per_class_recall\": {Config.CLASS_LABELS[i]: float(r) for i, r in enumerate(result['recall_per_class'])}\n",
        "                } for name, result in single_results.items()\n",
        "            },\n",
        "            \"ensemble_results\": {\n",
        "                name: {\n",
        "                    \"accuracy\": float(result['accuracy']),\n",
        "                    \"f1\": float(result['f1']),\n",
        "                    \"loss\": float(result['loss']),\n",
        "                    \"models\": result['models'],\n",
        "                    \"weights\": result.get('weights', result.get('learned_weights', [])).tolist()\n",
        "                              if isinstance(result.get('weights', result.get('learned_weights', [])), np.ndarray)\n",
        "                              else result.get('weights', result.get('learned_weights', []))\n",
        "                } for name, result in ensemble_results.items()\n",
        "            } if ensemble_results else {},\n",
        "            \"training_histories\": {\n",
        "                name: {\n",
        "                    \"train_loss\": history['train_loss'],\n",
        "                    \"train_acc\": history['train_acc'],\n",
        "                    \"val_loss\": history.get('val_loss', []),\n",
        "                    \"val_acc\": history.get('val_acc', []),\n",
        "                    \"val_f1\": history.get('val_f1', []),\n",
        "                    \"learning_rates\": history.get('learning_rates', [])\n",
        "                } for name, history in training_histories.items()\n",
        "            },\n",
        "            \"ensemble_histories\": {\n",
        "                name: {\n",
        "                    \"train_loss\": history.get('train_loss', []),\n",
        "                    \"train_acc\": history.get('train_acc', []),\n",
        "                    \"val_f1\": history.get('val_f1', [])\n",
        "                } for name, history in ensemble_histories.items()\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Save JSON report\n",
        "        json_path = f\"{self.reports_dir}/experiment_report.json\"\n",
        "        with open(json_path, 'w') as f:\n",
        "            json.dump(summary, f, indent=4)\n",
        "\n",
        "        # Generate text summary\n",
        "        text_summary = []\n",
        "        text_summary.append(\"=== Fish Species Classification Experiment Report ===\")\n",
        "        text_summary.append(f\"Timestamp: {summary['experiment_summary']['timestamp']}\")\n",
        "        text_summary.append(f\"Device: {Config.DEVICE}\")\n",
        "        text_summary.append(\"\\nDataset Information:\")\n",
        "        text_summary.append(f\"  Classes: {Config.NUM_CLASSES} ({', '.join(Config.CLASS_LABELS)})\")\n",
        "        text_summary.append(f\"  Input Size: {Config.INPUT_SIZE}x{Config.INPUT_SIZE}\")\n",
        "\n",
        "        text_summary.append(\"\\nBest Single Model:\")\n",
        "        text_summary.append(f\"  Name: {best_single[0]}\")\n",
        "        text_summary.append(f\"  Accuracy: {best_single[1]['accuracy']:.4f}\")\n",
        "        text_summary.append(f\"  F1 (Macro): {best_single[1]['f1_macro']:.4f}\")\n",
        "        text_summary.append(f\"  F1 (Weighted): {best_single[1]['f1_weighted']:.4f}\")\n",
        "        text_summary.append(f\"  Loss: {best_single[1]['loss']:.4f}\")\n",
        "        text_summary.append(\"  Per-class F1:\")\n",
        "        for cls, f1 in summary['best_single_model']['per_class_f1'].items():\n",
        "            text_summary.append(f\"    {cls}: {f1:.4f}\")\n",
        "\n",
        "        if best_ensemble:\n",
        "            text_summary.append(\"\\nBest Ensemble:\")\n",
        "            text_summary.append(f\"  Name: {best_ensemble[0]}\")\n",
        "            text_summary.append(f\"  Accuracy: {best_ensemble[1]['accuracy']:.4f}\")\n",
        "            text_summary.append(f\"  F1: {best_ensemble[1]['f1']:.4f}\")\n",
        "            text_summary.append(f\"  Loss: {best_ensemble[1]['loss']:.4f}\")\n",
        "            text_summary.append(f\"  Models: {', '.join(best_ensemble[1]['models'])}\")\n",
        "            weights = best_ensemble[1].get('weights', best_ensemble[1].get('learned_weights', []))\n",
        "            if len(weights) > 0:  # Corrected line\n",
        "                text_summary.append(\"  Weights:\")\n",
        "                for model, weight in zip(best_ensemble[1]['models'], weights):\n",
        "                    text_summary.append(f\"    {model}: {weight:.4f}\")\n",
        "\n",
        "        text_path = f\"{self.reports_dir}/experiment_summary.txt\"\n",
        "        with open(text_path, 'w') as f:\n",
        "            f.write(\"\\n\".join(text_summary))\n",
        "\n",
        "        print(f\"Report generated: {json_path}\")\n",
        "        print(f\"Summary saved: {text_path}\")\n",
        "\n",
        "        return summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "475e624a",
      "metadata": {
        "id": "475e624a"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# =============================================================================\n",
        "# MAIN EXECUTION\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    setup_environment()\n",
        "\n",
        "    X, Y = DataManager.load_and_balance_data()\n",
        "    train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(X, Y)\n",
        "\n",
        "    models_dict = {}\n",
        "    single_results = {}\n",
        "    hyperparameter_results = {}\n",
        "    training_histories = {}\n",
        "\n",
        "    for model_name in Config.MODELS:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"Processing model: {model_name.upper()}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        optimizer = ExpandedHyperparameterOptimizer(model_name, train_loader, val_loader)\n",
        "        best_params = optimizer.optimize()\n",
        "        hyperparameter_results[model_name] = best_params\n",
        "\n",
        "        model = ModelFactory.create_model(\n",
        "            model_name,\n",
        "            dropout_rate=best_params.get('dropout', 0.5),\n",
        "            hidden_dim_multiplier=best_params.get('hidden_dim_multiplier', 0.5)\n",
        "        )\n",
        "\n",
        "        trainer = EnhancedModelTrainer(model, model_name, best_params)\n",
        "        history = trainer.train(train_loader, val_loader)\n",
        "\n",
        "        models_dict[model_name] = trainer.model\n",
        "        models_dict[model_name].f1_score = trainer.best_val_f1\n",
        "        training_histories[model_name] = history\n",
        "\n",
        "        evaluator = ModelEvaluator()\n",
        "        results = evaluator.evaluate_model(trainer.model, test_loader, model_name)\n",
        "        single_results[model_name] = results\n",
        "\n",
        "    ensemble_manager = EnsembleManager(models_dict, val_data)\n",
        "    ensemble_results, best_ensemble = ensemble_manager.test_ensemble_combinations()\n",
        "\n",
        "    visualizer = EnhancedVisualizations()\n",
        "    for model_name, history in training_histories.items():\n",
        "        visualizer.plot_training_history({model_name: history}, model_type='single')\n",
        "    for model_name, history in ensemble_manager.histories.items():\n",
        "        visualizer.plot_training_history({model_name: history}, model_type='ensemble')\n",
        "\n",
        "    for model_name in single_results:\n",
        "        visualizer.plot_roc_curves(single_results[model_name], model_name)\n",
        "        visualizer.plot_confusion_matrix(single_results[model_name], model_name)\n",
        "\n",
        "    for ensemble_name in list(ensemble_results.keys())[:5]:\n",
        "        visualizer.plot_roc_curves(ensemble_results[ensemble_name], ensemble_name)\n",
        "        visualizer.plot_confusion_matrix(ensemble_results[ensemble_name], ensemble_name)\n",
        "\n",
        "    visualizer.plot_model_comparison(single_results, ensemble_results)\n",
        "\n",
        "    report_generator = ComprehensiveReportGenerator(Config.OUTPUT_DIR)\n",
        "    report = report_generator.generate_detailed_report(\n",
        "        single_results, ensemble_results, hyperparameter_results,\n",
        "        training_histories, ensemble_manager.histories\n",
        "    )\n",
        "\n",
        "    if best_ensemble:\n",
        "        best_ensemble_tester = EnsembleRealWorldTester(\n",
        "            models_dict,\n",
        "            best_ensemble[0].split('_')[-1],\n",
        "            best_ensemble[1]['models'],\n",
        "            best_ensemble[1].get('learned_weights')\n",
        "        )\n",
        "        # Example usage: test_image_path = \"path_to_test_image.jpg\"\n",
        "        # best_ensemble_tester.test_image(test_image_path)\n",
        "\n",
        "    return single_results, ensemble_results, report\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    single_results, ensemble_results, report = main()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd48bb6",
      "metadata": {
        "id": "cdd48bb6"
      },
      "source": [
        "#End"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}