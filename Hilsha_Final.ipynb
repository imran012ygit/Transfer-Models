{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran012x/Transfer-Models/blob/main/Hilsha_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01bea336",
      "metadata": {
        "id": "01bea336"
      },
      "source": [
        "#Colab-connect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "344965bc",
      "metadata": {
        "id": "344965bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5ef6176-30aa-450f-fab5-7b2577a50f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# # Upload a file\n",
        "# uploaded = files.upload()\n",
        "# # Get the file name\n",
        "# file_name = list(uploaded.keys())[0]\n",
        "# print(f\"Uploaded file: {file_name}\")\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# # with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_224_11k.zip', 'r') as zip_ref:\n",
        "# #     zip_ref.extractall('')\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de009928",
      "metadata": {
        "id": "de009928"
      },
      "source": [
        "#Data Preprocess and Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6f95c03b",
      "metadata": {
        "id": "6f95c03b"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "# from tqdm import tqdm\n",
        "# import random\n",
        "# import gc\n",
        "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "# import threading\n",
        "# import zipfile\n",
        "\n",
        "# # Check GPU availability\n",
        "# print(\"GPU Available:\", torch.cuda.is_available())\n",
        "# print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "# # Define fish classes and dataset paths\n",
        "# fish_classes = ['ilish', 'chandana', 'sardin', 'sardinella', 'punctatus'] #0,1,2,3,4\n",
        "# zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip').extractall('/content/.hidden_fish')\n",
        "# data_dir = '/content/.hidden_fish'\n",
        "\n",
        "# image_limits = {\n",
        "#     'ilish': 3000,\n",
        "#     'chandana': 1185,\n",
        "#     'sardin': 2899,\n",
        "#     'sardinella': 370,\n",
        "#     'punctatus': 953\n",
        "# }\n",
        "\n",
        "# # Settings\n",
        "# total_images = sum(image_limits.values())\n",
        "# batch_size = 100\n",
        "# num_threads = 4\n",
        "\n",
        "\n",
        "# # Output paths\n",
        "# output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "# labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "# xdata_file = os.path.join(output_dir, 'X_data.npy')\n",
        "\n",
        "# save_lock = threading.Lock()  # for thread-safe writes -> Prevents race conditions when multiple threads write to the same list.\n",
        "\n",
        "# # Function to gather image paths\n",
        "# def get_image_paths(class_name, max_images):\n",
        "#     path = os.path.join(data_dir, class_name)\n",
        "#     files = sorted(os.listdir(path))\n",
        "#     random.shuffle(files)\n",
        "#     return [os.path.join(path, f) for f in files[:max_images]]\n",
        "\n",
        "# # Load and preprocess batch\n",
        "# def load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     end_idx = min(start_idx + batch_size, len(image_paths))\n",
        "#     batch_paths = image_paths[start_idx:end_idx]\n",
        "#     batch_images = []\n",
        "\n",
        "#     for img_path in batch_paths:\n",
        "#         img = Image.open(img_path).resize((224, 224)).convert('RGB')\n",
        "#         img_tensor = torch.tensor(np.array(img), dtype=torch.uint8).permute(2, 0, 1)  # C x H x W\n",
        "#         batch_images.append(img_tensor)\n",
        "\n",
        "#     batch_tensor = torch.stack(batch_images)  # B x C x H x W\n",
        "#     batch_labels = np.full((len(batch_images),), class_idx, dtype=np.int32)\n",
        "#     return batch_tensor, batch_labels\n",
        "\n",
        "# # Process one batch and return tensors & labels (no file saving)\n",
        "# def process_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     return load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx)\n",
        "\n",
        "# def preprocess_and_save_all(overwrite=True):\n",
        "#     if os.path.exists(labels_file) and os.path.exists(xdata_file) and not overwrite:\n",
        "#         print(\"Preprocessed data already exists. Set overwrite=True to reprocess.\")\n",
        "#         return\n",
        "\n",
        "#     all_images = []\n",
        "#     all_labels = []\n",
        "#     processed_count = 0\n",
        "\n",
        "#     for idx, class_name in enumerate(fish_classes):\n",
        "#         print(f\"\\nProcessing class: {class_name}\")\n",
        "#         image_paths = get_image_paths(class_name, image_limits[class_name])\n",
        "#         total_batches = (len(image_paths) + batch_size - 1) // batch_size\n",
        "#         #It ensures ceiling division ‚Äî rounding up, not down.\n",
        "#         # Normal division: 103 / 20 = 5.15 ‚Üí floor division // 20 = 5 (‚ùå missing last 3 images)\n",
        "#         # This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ‚úÖ\n",
        "\n",
        "#         with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "#             futures = []\n",
        "#             for start in range(0, len(image_paths), batch_size):\n",
        "#                 futures.append(executor.submit(process_batch, image_paths, start, batch_size, idx))\n",
        "\n",
        "#             for future in tqdm(as_completed(futures), total=total_batches, desc=class_name):#taqaddum (ÿ™ŸÇÿØŸëŸÖ) ‚Äì Arabic for \"progress\".\n",
        "#                 # futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\n",
        "#                 # as_completed(futures): Yields each future as it finishes (not in order).\n",
        "\n",
        "#                 batch_tensor, batch_labels = future.result()\n",
        "#                 with save_lock: #Locks this section so that only one thread can update the shared lists safely.\n",
        "#                     all_images.append(batch_tensor)\n",
        "#                     all_labels.append(batch_labels)\n",
        "#                     processed_count += batch_tensor.size(0)\n",
        "#                     print(f\"Processed batch with {batch_tensor.size(0)} images, total processed: {processed_count}/{total_images}\")\n",
        "#                 gc.collect()\n",
        "\n",
        "#     # Combine all tensors and labels\n",
        "#     X = torch.cat(all_images, dim=0).numpy()\n",
        "#     Y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "#     # Save final arrays\n",
        "#     np.save(xdata_file, X, allow_pickle=False)#Malicious .npy -> import os;os.system(\"rm -rf /\")  # ‚Üê Dangerous command\n",
        "#     np.save(labels_file, Y, allow_pickle=False)\n",
        "\n",
        "#     print(f\"\\n‚úÖ Done! Saved {processed_count} images in {xdata_file}\")\n",
        "#     print(f\"X_data shape: {X.shape}, Y_labels shape: {Y.shape}\")\n",
        "\n",
        "#     if processed_count != total_images:\n",
        "#         raise ValueError(f\"Expected {total_images} images, but processed {processed_count}\")\n",
        "\n",
        "# # Run preprocessing and save directly to X_data.npy and Y_labels.npy\n",
        "# preprocess_and_save_all(overwrite=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0fbbeb4",
      "metadata": {
        "id": "c0fbbeb4"
      },
      "source": [
        "####DATA LOADING...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "23d9c0c0",
      "metadata": {
        "id": "23d9c0c0"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import numpy as np\n",
        "# import torch\n",
        "\n",
        "# # Your data path\n",
        "# output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "# data_file = os.path.join(output_dir, 'X_data.npy')\n",
        "# labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "\n",
        "# # Readable size format\n",
        "# def sizeof_fmt(num, suffix='B'):\n",
        "#     for unit in ['', 'K', 'M', 'G', 'T']:\n",
        "#         if abs(num) < 1024.0:\n",
        "#             return f\"{num:3.2f} {unit}{suffix}\"\n",
        "#         num /= 1024.0\n",
        "#     return f\"{num:.2f} T{suffix}\"\n",
        "\n",
        "# # Main loader\n",
        "# def load_preprocessed_data(as_torch=True, normalize=True, to_device=None):\n",
        "#     # Check file existence #cpu,cuda (CUDA stands for Compute Unified Device Architecture.)\n",
        "#     for path in [data_file, labels_file]:\n",
        "#         if not os.path.exists(path):\n",
        "#             raise FileNotFoundError(f\"Missing: {path}\")\n",
        "\n",
        "#     # Print file sizes\n",
        "#     print(f\"üìÅ X_data.npy: {sizeof_fmt(os.path.getsize(data_file))}\")\n",
        "#     print(f\"üìÅ Y_labels.npy: {sizeof_fmt(os.path.getsize(labels_file))}\")\n",
        "\n",
        "#     # Load with mmap\n",
        "#     X = np.load(data_file, mmap_mode='r')\n",
        "#     Y = np.load(labels_file, mmap_mode='r')\n",
        "\n",
        "#     print(f\"‚úÖ X shape: {X.shape}, dtype: {X.dtype}\")\n",
        "#     print(f\"‚úÖ Y shape: {Y.shape}, dtype: {Y.dtype}\")\n",
        "\n",
        "#     # Sanity check\n",
        "#     if len(X) != len(Y):\n",
        "#         raise ValueError(\"Mismatch between number of samples in X and Y\")\n",
        "\n",
        "#     # Convert to torch\n",
        "#     if as_torch:\n",
        "#         X = torch.from_numpy(X)\n",
        "#         Y = torch.from_numpy(Y)\n",
        "\n",
        "#         if normalize and X.dtype == torch.uint8:\n",
        "#             X = X.float() / 255.0\n",
        "\n",
        "#         if to_device:\n",
        "#             X = X.to(to_device)\n",
        "#             Y = Y.to(to_device)\n",
        "\n",
        "#         print(f\"üß† Torch tensors ready on {to_device or 'CPU'}\")\n",
        "\n",
        "#     return X, Y\n",
        "\n",
        "# # üîÅ Example call\n",
        "# X, Y = load_preprocessed_data(\n",
        "#     as_torch=True,\n",
        "#     normalize=True,\n",
        "#     to_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "# )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training...."
      ],
      "metadata": {
        "id": "VtlL2F2petfN"
      },
      "id": "VtlL2F2petfN"
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. IMPORTS AND INITIAL SETUP\n",
        "# =============================================================================\n",
        "# Purpose: Import all required libraries and set up warnings to suppress unnecessary messages.\n",
        "\n",
        "!pip install pytorch-gradcam optuna captum  # Uncomment if running in a new environment\n",
        "!pip install --upgrade captum optuna\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Standard Library\n",
        "# ============================================================\n",
        "import os\n",
        "import sys\n",
        "import gc\n",
        "import time\n",
        "import json\n",
        "import logging\n",
        "import random\n",
        "import warnings\n",
        "import subprocess\n",
        "import threading\n",
        "import traceback\n",
        "from pathlib import Path\n",
        "from itertools import combinations\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# ============================================================\n",
        "# Data Handling & Utilities\n",
        "# ============================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================\n",
        "# Visualization\n",
        "# ============================================================\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# ============================================================\n",
        "# System & Resource Monitoring\n",
        "# ============================================================\n",
        "import psutil\n",
        "import pynvml\n",
        "\n",
        "# ============================================================\n",
        "# Machine Learning\n",
        "# ============================================================\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, f1_score, accuracy_score,\n",
        "    precision_score, recall_score, roc_curve, auc\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Imbalanced data handling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ============================================================\n",
        "# Deep Learning - PyTorch\n",
        "# ============================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, SubsetRandomSampler\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# ============================================================\n",
        "# Augmentation\n",
        "# ============================================================\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "# ============================================================\n",
        "# Hyperparameter Optimization\n",
        "# ============================================================\n",
        "try:\n",
        "    import optuna\n",
        "    OPTUNA_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPTUNA_AVAILABLE = False\n",
        "    print(\"Warning: Optuna not available. Using default hyperparameters.\")\n",
        "\n",
        "# ============================================================\n",
        "# Explainable AI (XAI)\n",
        "# ============================================================\n",
        "import torch.autograd as autograd\n",
        "from captum.attr import LRP\n",
        "\n",
        "# Optuna\n",
        "import optuna\n",
        "import optuna.logging\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class NpEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, torch.Tensor):\n",
        "            return obj.cpu().detach().numpy().tolist()  # Convert tensor to NumPy array, then to list\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return super(NpEncoder, self).default(obj)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 2. CONFIGURATION\n",
        "# =============================================================================\n",
        "# Purpose: Define configuration settings and initialize the environment.\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration settings\"\"\"\n",
        "    # Paths - UPDATE THESE TO YOUR ACTUAL PATHS\n",
        "    DATA_FILE = '/content/drive/MyDrive/Hilsha/X_data.npy'\n",
        "    LABELS_FILE = '/content/drive/MyDrive/Hilsha/Y_labels.npy'\n",
        "    OUTPUT_DIR = './fish_classification_results'\n",
        "\n",
        "    # Dataset parameters\n",
        "    NUM_CLASSES = 5\n",
        "    CLASS_LABELS = ['Ilish', 'Chandana', 'Sardin', 'Sardinella', 'Punctatus']\n",
        "    INPUT_SIZE = 224\n",
        "\n",
        "    # Training parameters\n",
        "    BATCH_SIZE = 32 #64\n",
        "    EPOCHS = 2\n",
        "    DATALOADER_NUM_WORKERS = 1\n",
        "    PIN_MEMORY = True\n",
        "    USE_MIXED_PRECISION = True #True\n",
        "    COMPILE_MODEL = True\n",
        "    PATIENCE = 4 #15\n",
        "    LEARNING_RATE = 1e-5  #1e-4\n",
        "    WEIGHT_DECAY = 1e-4\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    OPTUNA_TRIALS = 1\n",
        "    OPTUNA_EPOCHS = 1\n",
        "\n",
        "    # Models to train\n",
        "    MODELS = ['resnet50','efficientnet_b0','mobilenet_v3_large','vgg16', 'densenet121']\n",
        "\n",
        "    # Ensemble methods\n",
        "    ENSEMBLE_METHODS = ['simple_average', 'weighted_average', 'confidence_based', 'learnable_weighted']\n",
        "\n",
        "    # Device\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    SEED = 42\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_available_cpu_memory():\n",
        "    \"\"\"Get available CPU memory in GB.\"\"\"\n",
        "    mem = psutil.virtual_memory()\n",
        "    return mem.available / 1024**3  # Convert bytes to GB\n",
        "\n",
        "def get_available_gpu_memory():\n",
        "    \"\"\"Get available GPU memory in GB.\"\"\"\n",
        "    pynvml.nvmlInit()\n",
        "    handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "    mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
        "    return mem_info.free / 1024**3  # Convert bytes to GB\n",
        "\n",
        "def adjust_batch_size_and_workers(base_batch_size, base_num_workers):\n",
        "    gpu_memory = get_available_gpu_memory()\n",
        "\n",
        "    # Prioritize GPU memory for batch size\n",
        "    if gpu_memory > 24:  # High-end GPU\n",
        "        batch_size = base_batch_size * 4\n",
        "        num_workers = min(8, psutil.cpu_count())  # Use more workers for high GPU memory\n",
        "    elif gpu_memory > 12:  # Mid-range GPU\n",
        "        batch_size = base_batch_size * 2\n",
        "        num_workers = min(4, psutil.cpu_count())  # Moderate workers\n",
        "    elif gpu_memory > 6:  # Lower-end GPU\n",
        "        batch_size = base_batch_size\n",
        "        num_workers = min(2, psutil.cpu_count())  # Minimal workers\n",
        "    else:  # Very low GPU memory\n",
        "        batch_size = max(8, base_batch_size // 2)\n",
        "        num_workers = 0  # Disable workers to minimize CPU load\n",
        "\n",
        "    print(f\"Adjusted batch_size: {batch_size}, num_workers: {num_workers} \"\n",
        "          f\"(GPU memory: {gpu_memory:.2f} GB)\")\n",
        "    return batch_size, num_workers\n",
        "\n",
        "\n",
        "def setup_environment():\n",
        "\n",
        "    \"\"\"Setup random seeds, directories, and dynamically adjust batch size and workers\"\"\"\n",
        "\n",
        "    os.environ['PYTHONHASHSEED'] = str(Config.SEED)  # For hash seed reproducibility\n",
        "    random.seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    torch.cuda.manual_seed_all(Config.SEED)  # For multi-GPU if applicable\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "\n",
        "    directories = [\n",
        "        Config.OUTPUT_DIR,\n",
        "        f\"{Config.OUTPUT_DIR}/models\",\n",
        "        f\"{Config.OUTPUT_DIR}/visualizations\",\n",
        "        f\"{Config.OUTPUT_DIR}/reports\",\n",
        "        f\"{Config.OUTPUT_DIR}/xai_visualizations\"\n",
        "    ]\n",
        "\n",
        "    for directory in directories:\n",
        "        Path(directory).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Dynamically adjust batch size and workers\n",
        "    Config.BATCH_SIZE, Config.DATALOADER_NUM_WORKERS = adjust_batch_size_and_workers(\n",
        "        Config.BATCH_SIZE, Config.DATALOADER_NUM_WORKERS\n",
        "    )\n",
        "\n",
        "    print(f\"Using device: {Config.DEVICE}\")\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"Dynamic BATCH_SIZE: {Config.BATCH_SIZE}, DATALOADER_NUM_WORKERS: {Config.DATALOADER_NUM_WORKERS}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    seed = Config.SEED + worker_id\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "#Guard for GPU determinism (optional, but helpful if you want exact reproducibility across runs):\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 3. TRAINING PROGRESS TRACKER\n",
        "# =============================================================================\n",
        "# Purpose: Track and display training progress with progress bars and epoch summaries.\n",
        "\n",
        "class TrainingProgressTracker:\n",
        "    \"\"\"Track and display detailed training progress\"\"\"\n",
        "\n",
        "    def __init__(self, model_name, total_epochs, total_batches_per_epoch):\n",
        "        self.model_name = model_name\n",
        "        self.total_epochs = total_epochs\n",
        "        self.total_batches_per_epoch = total_batches_per_epoch\n",
        "        self.start_time = time.time()\n",
        "        self.epoch_start_time = None\n",
        "        self.batch_times = []\n",
        "\n",
        "    def start_epoch(self, epoch):\n",
        "        \"\"\"Start tracking an epoch\"\"\"\n",
        "        self.current_epoch = epoch\n",
        "        self.epoch_start_time = time.time()\n",
        "        self.batch_times = []\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Model: {self.model_name.upper()} | Epoch: {epoch+1}/{self.total_epochs}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "\n",
        "\n",
        "    def update_batch(self, batch_idx, batch_loss, batch_acc, is_training=True,total_batches=None):\n",
        "        \"\"\"Update progress for current batch\"\"\"\n",
        "        batch_time = time.time()\n",
        "        self.batch_times.append(batch_time)\n",
        "\n",
        "        # Calculate timing estimates\n",
        "        if len(self.batch_times) > 1:\n",
        "            avg_batch_time = np.mean(np.diff(self.batch_times[-10:]))\n",
        "        else:\n",
        "            avg_batch_time = 1.0\n",
        "\n",
        "        total_batches = total_batches if total_batches is not None else self.total_batches_per_epoch\n",
        "        remaining_batches = total_batches - (batch_idx + 1)\n",
        "\n",
        "\n",
        "        # remaining_batches = self.total_batches_per_epoch - (batch_idx + 1)\n",
        "        eta_epoch = remaining_batches * avg_batch_time\n",
        "\n",
        "        # Progress bar\n",
        "        # progress_pct = (batch_idx + 1) / self.total_batches_per_epoch * 100\n",
        "        progress_pct = (batch_idx + 1) / total_batches * 100\n",
        "        bar_length = 30\n",
        "\n",
        "        # filled_length = int(bar_length * (batch_idx + 1) // self.total_batches_per_epoch)\n",
        "        filled_length = int(bar_length * (batch_idx + 1) // total_batches)\n",
        "        bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "        # Format time\n",
        "        eta_str = str(timedelta(seconds=int(eta_epoch)))\n",
        "\n",
        "        # Display progress\n",
        "        mode = \"TRAIN\" if is_training else \"VAL  \"\n",
        "\n",
        "        print(f\"\\r{mode} |{bar}| {progress_pct:5.1f}% | \"\n",
        "              f\"Batch: {batch_idx+1:4d}/{total_batches} | \"\n",
        "              f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
        "              f\"ETA: {eta_str}\", end='', flush=True)\n",
        "\n",
        "\n",
        "    def finish_epoch(self, train_loss, train_acc, val_loss, val_acc, val_f1,\n",
        "                    is_best=False, lr=None):\n",
        "        \"\"\"Finish epoch and display summary\"\"\"\n",
        "        epoch_time = time.time() - self.epoch_start_time\n",
        "        total_time = time.time() - self.start_time\n",
        "\n",
        "        print(f\"\\n{'-'*60}\")\n",
        "        print(f\"EPOCH SUMMARY:\")\n",
        "        print(f\"  Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"  Val Loss:   {val_loss:.6f} | Val Acc:   {val_acc:.4f}\")\n",
        "        print(f\"  Val F1:     {val_f1:.4f} | Epoch Time: {epoch_time:.1f}s\")\n",
        "        if lr:\n",
        "            print(f\"  Learning Rate: {lr:.2e}\")\n",
        "\n",
        "        if is_best:\n",
        "            print(f\"  ‚òÖ NEW BEST MODEL! (F1: {val_f1:.4f})\")\n",
        "\n",
        "        print(f\"  Total Time: {str(timedelta(seconds=int(total_time)))}\")\n",
        "        print(f\"{'-'*60}\")\n",
        "\n",
        "\n",
        "# ---\n",
        "# 4. DATA LOADING AND PREPROCESSING\n",
        "# =============================================================================\n",
        "# Purpose: Handle dataset creation, data loading, balancing with SMOTE, and data augmentation.\n",
        "\n",
        "\n",
        "class FishDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = self._preprocess_images(images)\n",
        "        self.labels = labels.astype(np.int64)\n",
        "        self.transform = transform\n",
        "\n",
        "    def _preprocess_images(self, images):\n",
        "        \"\"\"Preprocess images to ensure proper format and normalization\"\"\"\n",
        "        if images.max() > 1.5:\n",
        "            images = images.astype(np.float32) / 255.0\n",
        "        if len(images.shape) == 4 and images.shape[1] == 3:\n",
        "            images = np.transpose(images, (0, 2, 3, 1))\n",
        "        return images.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the total number of samples in the dataset\"\"\"\n",
        "        return len(self.images)\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "        else:\n",
        "            image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "\n",
        "        # Convert label to plain Python int to avoid CUDA tensor creation in workers\n",
        "        if isinstance(label, np.ndarray):\n",
        "            label = int(label.item())\n",
        "        elif hasattr(label, 'item'):\n",
        "            label = int(label.item())\n",
        "        else:\n",
        "            label = int(label)\n",
        "\n",
        "        return image, label  # Plain Python int, not torch.tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DataManager:\n",
        "    @staticmethod\n",
        "    def get_transforms(is_training=True, augmentation_strength='medium'):\n",
        "        \"\"\"Get data transforms with configurable augmentation strength\"\"\"\n",
        "        if is_training:\n",
        "            if augmentation_strength == 'light':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.3),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            elif augmentation_strength == 'heavy':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.7),\n",
        "                    A.VerticalFlip(p=0.5),\n",
        "                    A.RandomRotate90(p=0.7),\n",
        "                    # A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, p=0.8),\n",
        "                    # A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.8),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
        "                    A.HueSaturationValue(hue_shift_limit=30, sat_shift_limit=40, val_shift_limit=30, p=0.7),\n",
        "                    A.GaussianBlur(blur_limit=(3, 9), p=0.5),\n",
        "                    A.GaussNoise(var_limit=(10.0, 80.0), p=0.4),\n",
        "                    A.CoarseDropout(max_holes=12, max_height=25, max_width=25, p=0.5),\n",
        "                    A.ElasticTransform(p=0.3),\n",
        "                    A.GridDistortion(p=0.3),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "                    A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3, p=0.3),\n",
        "                    A.RandomRain(blur_value=3, p=0.2),\n",
        "                    A.ColorJitter(hue=0.1, p=0.5),\n",
        "\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            else:  # medium\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.5),\n",
        "                    A.VerticalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.5),\n",
        "                    # A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.7),\n",
        "                    # A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.1),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
        "                    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.6),\n",
        "                    A.GaussianBlur(blur_limit=(3, 7), p=0.4),\n",
        "                    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "                    A.CoarseDropout(max_holes=8, max_height=20, max_width=20, p=0.4),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "        else:\n",
        "            return A.Compose([\n",
        "                A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "\n",
        "    @staticmethod\n",
        "    def load_and_balance_data():\n",
        "        \"\"\"Load data and apply SMOTE\"\"\"\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "\n",
        "        X = np.load(Config.DATA_FILE)\n",
        "        Y = np.load(Config.LABELS_FILE)\n",
        "\n",
        "        print(f\"Original data shape: {X.shape}\")\n",
        "        print(f\"Original class distribution: {np.bincount(Y)}\")\n",
        "\n",
        "\n",
        "        # print(\"Applying SMOTE for class balancing...\")\n",
        "        # X_flat = X.reshape(X.shape[0], -1)\n",
        "        # smote = SMOTE(random_state=Config.SEED, k_neighbors=min(5, np.bincount(Y).min()-1))\n",
        "        # X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y)\n",
        "        # X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "        # print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        # print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "        # return X_balanced, Y_balanced\n",
        "\n",
        "\n",
        "        # # Remove SMOTE completely and use WeightedRandomSampler only\n",
        "        # # Just return original data\n",
        "        # print(\"Using WeightedRandomSampler for class balancing instead of SMOTE...\")\n",
        "        # return X, Y\n",
        "\n",
        "\n",
        "        print(\"Applying SMOTE for class balancing...\")\n",
        "        # Apply SMOTE with reduced k_neighbors and combine with WeightedRandomSampler\n",
        "        X_flat = X.reshape(X.shape[0], -1)\n",
        "        smote = SMOTE(random_state=Config.SEED, k_neighbors=3, sampling_strategy='not majority')\n",
        "        # smote = SMOTE(random_state=Config.SEED, k_neighbors=2, sampling_strategy= 'auto')\n",
        "        X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y)\n",
        "        X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "        # Ensure WeightedRandomSampler is still used in DataLoader\n",
        "        print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "        return X_balanced, Y_balanced\n",
        "        # Benefit: Using a smaller k_neighbors=3 reduces the risk of generating unnatural\n",
        "        # image artifacts, while sampling_strategy='not majority' balances classes more conservatively.\n",
        "        # Retaining WeightedRandomSampler in the DataLoader further ensures balanced sampling during\n",
        "        # training, maintaining smoothness and preventing accuracy drops by avoiding over-reliance\n",
        "        # on SMOTE-generated samples.\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def create_data_loaders(X, Y, test_size=0.2, batch_size=None, augmentation_strength='medium'):\n",
        "        if batch_size is None:\n",
        "            if torch.cuda.is_available():\n",
        "                gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "                if gpu_memory_gb >= 24:\n",
        "                    batch_size = 128\n",
        "                elif gpu_memory_gb >= 12:\n",
        "                    batch_size = 96\n",
        "                elif gpu_memory_gb >= 8:\n",
        "                    batch_size = 64\n",
        "                else:\n",
        "                    batch_size = 48\n",
        "            else:\n",
        "                batch_size = Config.BATCH_SIZE\n",
        "\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(X, Y, test_size=test_size, random_state=Config.SEED, stratify=Y)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=Config.SEED, stratify=y_temp)\n",
        "\n",
        "        print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "        print(f\"Using optimized batch size: {batch_size}\")\n",
        "\n",
        "\n",
        "\n",
        "        train_dataset = FishDataset(X_train, y_train,DataManager.get_transforms(True, augmentation_strength))\n",
        "        val_dataset = FishDataset(X_val, y_val, DataManager.get_transforms(False))\n",
        "        test_dataset = FishDataset(X_test, y_test, DataManager.get_transforms(False))\n",
        "\n",
        "\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "        sample_weights = [class_weights[y] for y in y_train]\n",
        "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "\n",
        "\n",
        "        # Conditionally set prefetch_factor based on num_workers\n",
        "        prefetch_factor = 2 if Config.DATALOADER_NUM_WORKERS > 0 else None\n",
        "        pin_memory=Config.PIN_MEMORY if 'cuda' in Config.DEVICE else False\n",
        "        num_workers = Config.DATALOADER_NUM_WORKERS if torch.cuda.is_available() else 0\n",
        "        use_prefetch = num_workers > 0\n",
        "\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            # sampler=sampler, #Imbalanced dataset ‚Üí use sampler.Balanced dataset ‚Üí use shuffle=True.\n",
        "            shuffle=True,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "            persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            # persistent_workers=False,\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "            persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            # persistent_workers=False,\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "            persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            # persistent_workers=False, #False is slow but exact reproductivity ensures & workers reset each epoch).\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "\n",
        "        return train_loader, val_loader, test_loader, (X_val, y_val), (X_test, y_test)\n",
        "\n",
        "# ---\n",
        "# 5. MODEL FACTORY\n",
        "# =============================================================================\n",
        "# Purpose: Create different neural network models with customizable architectures.\n",
        "\n",
        "class ModelFactory:\n",
        "    @staticmethod\n",
        "    def create_model(model_name, num_classes=Config.NUM_CLASSES, dropout_rate=0.5,\n",
        "                    hidden_dim_multiplier=0.5):\n",
        "        \"\"\"Create model with configurable architecture\"\"\"\n",
        "\n",
        "        if model_name == 'resnet50':\n",
        "            model = models.resnet50(weights='IMAGENET1K_V2')\n",
        "            # Partial unfreeze for better accuracy: unfreeze layer4 and fc\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                # if \"layer4\" in name or \"fc\" in name:\n",
        "                if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'efficientnet_b0':\n",
        "            model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: last blocks\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"_blocks.15\" in name or \"_blocks.16\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = model.classifier[1].in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'mobilenet_v3_large':\n",
        "            model = models.mobilenet_v3_large(weights='IMAGENET1K_V2')\n",
        "            # Partial unfreeze: last features\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"features.12\" in name or \"features.13\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = 960\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'vgg16':\n",
        "            model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: classifier and last features\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"classifier\" in name or \"features.28\" in name:\n",
        "                    param.requires_grad = True\n",
        "            hidden_dim = int(4096 * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Linear(512 * 7 * 7, 4096),\n",
        "                nn.ReLU(True),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(4096, hidden_dim),\n",
        "                nn.ReLU(True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'densenet121':\n",
        "            model = models.densenet121(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: denseblock4 and classifier\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"denseblock4\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = model.classifier.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "\n",
        "        elif model_name == 'cnn':\n",
        "            # class SimpleCNN(nn.Module):\n",
        "\n",
        "            class SimpleCNN(nn.Module):\n",
        "                def __init__(self, num_classes=5, dropout_rate=0.3, hidden_dim_multiplier=0.3):\n",
        "                    super(SimpleCNN, self).__init__()\n",
        "\n",
        "                    # More conservative feature extractor to prevent overfitting\n",
        "                    self.features = nn.Sequential(\n",
        "                        # Block 1 - Start small\n",
        "                        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.1),  # Spatial dropout in conv layers\n",
        "                        nn.MaxPool2d(2, 2),  # 224 -> 112\n",
        "\n",
        "                        # Block 2\n",
        "                        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.15),\n",
        "                        nn.MaxPool2d(2, 2),  # 112 -> 56\n",
        "\n",
        "                        # Block 3\n",
        "                        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.2),\n",
        "                        nn.MaxPool2d(2, 2),  # 56 -> 28\n",
        "\n",
        "                        # Block 4 - Add one more conv before pooling\n",
        "                        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.25),\n",
        "                        nn.MaxPool2d(2, 2),  # 28 -> 14\n",
        "\n",
        "                        # Block 5 - Final feature extraction\n",
        "                        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(256),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.3),\n",
        "                        nn.AdaptiveAvgPool2d((7, 7))  # Fixed spatial size\n",
        "                    )\n",
        "\n",
        "                    # Calculate features after adaptive pooling\n",
        "                    conv_output_size = 256 * 7 * 7  # 12544\n",
        "\n",
        "                    # Much smaller hidden dimension to prevent overfitting\n",
        "                    hidden_dim = int(conv_output_size * hidden_dim_multiplier)\n",
        "                    hidden_dim = max(64, min(hidden_dim, 512))  # Smaller range\n",
        "\n",
        "                    # Simple but effective classifier\n",
        "                    self.classifier = nn.Sequential(\n",
        "                        nn.Dropout(dropout_rate),\n",
        "                        nn.Linear(conv_output_size, hidden_dim),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.BatchNorm1d(hidden_dim),\n",
        "                        nn.Dropout(dropout_rate * 0.5),\n",
        "                        nn.Linear(hidden_dim, num_classes)\n",
        "                    )\n",
        "\n",
        "                    # Initialize weights properly\n",
        "                    self._initialize_weights()\n",
        "\n",
        "                def _initialize_weights(self):\n",
        "                    for m in self.modules():\n",
        "                        if isinstance(m, nn.Conv2d):\n",
        "                            # Use smaller initialization for better gradient flow\n",
        "                            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "                        elif isinstance(m, nn.Linear):\n",
        "                            # Smaller initialization for linear layers\n",
        "                            nn.init.xavier_uniform_(m.weight, gain=0.5)\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "                        elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
        "                            if m.weight is not None:\n",
        "                                nn.init.ones_(m.weight)\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "\n",
        "                def forward(self, x):\n",
        "                    # Feature extraction\n",
        "                    x = self.features(x)\n",
        "\n",
        "                    # Flatten\n",
        "                    x = torch.flatten(x, 1)\n",
        "\n",
        "                    # Classification with gradient clipping\n",
        "                    x = self.classifier(x)\n",
        "\n",
        "                    # Clip outputs to prevent extreme values\n",
        "                    x = torch.clamp(x, min=-10, max=10)\n",
        "\n",
        "                    return x\n",
        "\n",
        "\n",
        "            # Example usage\n",
        "            model = SimpleCNN(num_classes=num_classes, dropout_rate=dropout_rate, hidden_dim_multiplier=hidden_dim_multiplier)\n",
        "            model = model.to(Config.DEVICE)  # Move to device right after creation\n",
        "\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 6. LEARNABLE WEIGHTED ENSEMBLE MODEL\n",
        "# =============================================================================\n",
        "# Purpose: Define a neural network for learning optimal ensemble weights.\n",
        "\n",
        "\n",
        "class LearnableWeightedEnsemble(nn.Module):\n",
        "    \"\"\"Ensemble model with per-class adaptive weights and attention\"\"\"\n",
        "    def __init__(self, num_models, num_classes, hidden_dim=128, num_heads=4):\n",
        "        super(LearnableWeightedEnsemble, self).__init__()\n",
        "        self.num_models = num_models\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Attention mechanism to learn relations between model predictions\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=num_classes, num_heads=num_heads, batch_first=True)\n",
        "\n",
        "        # Weight network outputs per-class weights for each model\n",
        "        self.weight_network = nn.Sequential(\n",
        "            nn.Linear(num_classes, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes),\n",
        "            nn.Sigmoid()  # Per-class weight scaling\n",
        "        )\n",
        "\n",
        "        # Prediction head: combines weighted predictions + raw predictions\n",
        "        self.prediction_head = nn.Sequential(\n",
        "            nn.Linear(num_classes * (num_models + 1), hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(num_classes * 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, model_predictions):\n",
        "        \"\"\"\n",
        "        model_predictions: (batch, num_models, num_classes)\n",
        "        Returns:\n",
        "            final_predictions: logits for classification\n",
        "            weights: learned per-class weights for each model\n",
        "        \"\"\"\n",
        "        batch_size = model_predictions.size(0)\n",
        "\n",
        "        # --- Step 1: Attention over model predictions --- #The model looks at how predictions of different models relate to each other.\n",
        "        attn_output, _ = self.attention(model_predictions, model_predictions, model_predictions)\n",
        "        # shape: (batch, num_models, num_classes)\n",
        "\n",
        "\n",
        "        # --- Step 2: Per-class weights for each model ---\n",
        "        #Learns a weight for each model for each class.\n",
        "        #softmax ensures weights across models sum to 1 for each class.\n",
        "        #Basically: ‚ÄúFor class 0, I trust model 2 more; for class 1, I trust model 0 more.‚Äù\n",
        "        weights = self.weight_network(attn_output)  # (batch, num_models, num_classes)\n",
        "        weights = F.softmax(weights, dim=1)  # normalize over models\n",
        "\n",
        "\n",
        "        # --- Step 3: Weighted average across models ---\n",
        "        #Combines the models‚Äô predictions using the learned weights ‚Üí smarter than a plain average.\n",
        "        weighted_avg = torch.sum(model_predictions * weights, dim=1)  # (batch, num_classes)\n",
        "\n",
        "\n",
        "        # --- Step 4: Residual connection with raw predictions ---\n",
        "        #Combines the weighted average and all raw predictions.Gives the network more info to refine the final prediction.\n",
        "        flat_preds = model_predictions.view(batch_size, -1)  # (batch, num_models * num_classes)\n",
        "        final_input = torch.cat([weighted_avg, flat_preds], dim=1)  # (batch, num_classes + num_models*num_classes)\n",
        "\n",
        "\n",
        "        # --- Step 5: Final refined prediction ---\n",
        "        #A small feed-forward network refines the predictions.Output: (batch_size, num_classes) ‚Üí logits for each class.\n",
        "        final_predictions = self.prediction_head(final_input)  # (batch, num_classes)\n",
        "\n",
        "        return final_predictions, weights\n",
        "        #It learns which model is best for each class, combines their predictions smartly using attention, and produces a refined final prediction.\n",
        "\n",
        "    def entropy_regularization(self, weights):\n",
        "        \"\"\"Encourage diverse weight usage (optional loss term).\"\"\"\n",
        "        # weights: (batch, num_models, num_classes)\n",
        "        entropy = -torch.sum(weights * torch.log(weights + 1e-8), dim=1)  # (batch, num_classes)\n",
        "        return torch.mean(entropy)\n",
        "\n",
        "# ======================================================\n",
        "# Example usage\n",
        "# ======================================================\n",
        "# if __name__ == \"__main__\":\n",
        "#     batch_size = 8\n",
        "#     num_models = 3\n",
        "#     num_classes = 5\n",
        "\n",
        "#     # Dummy predictions from 3 base models\n",
        "#     dummy_preds = torch.rand(batch_size, num_models, num_classes)\n",
        "\n",
        "#     model = ImprovedWeightedEnsemble(num_models=num_models, num_classes=num_classes)\n",
        "\n",
        "#     final_preds, weights = model(dummy_preds)\n",
        "\n",
        "#     print(\"Final predictions shape:\", final_preds.shape)  # (batch, num_classes)\n",
        "#     print(\"Weights shape:\", weights.shape)  # (batch, num_models, num_classes)\n",
        "\n",
        "#     # Optional entropy regularization\n",
        "#     entropy_loss = model.entropy_regularization(weights)\n",
        "#     print(\"Entropy reg loss:\", entropy_loss.item())\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 7. HYPERPARAMETER OPTIMIZATION\n",
        "# =============================================================================\n",
        "# Purpose: Tune model hyperparameters using Optuna.\n",
        "# Add these imports at top of file\n",
        "import psutil  # ADDED: For CPU memory monitoring\n",
        "import gc      # ADDED: For garbage collection\n",
        "\n",
        "class ExpandedHyperparameterOptimizer:\n",
        "    def __init__(self, model_name, train_loader, val_loader):\n",
        "        self.model_name = model_name\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.total_batches_per_epoch = len(train_loader)\n",
        "        self.batch_times = []\n",
        "        self.best_val_acc = 0.0\n",
        "        self.best_val_f1 = 0.0\n",
        "        self.best_trial = 0.0\n",
        "\n",
        "        # ADDED: Memory management attributes\n",
        "        self.memory_check_interval = 10\n",
        "        self.force_cleanup_threshold = 95\n",
        "\n",
        "        # self.val_f1 = 0.0\n",
        "        # self.history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': [], 'val_f1': [], 'learning_rates': []}\n",
        "\n",
        "    def _update_progress(self, batch_idx, batch_loss, batch_acc, trial_params, is_training=True):\n",
        "        \"\"\"Display progress during hyperparameter tuning\"\"\"\n",
        "        batch_time = time.time()\n",
        "        self.batch_times.append(batch_time)\n",
        "\n",
        "        if len(self.batch_times) > 1:\n",
        "            avg_batch_time = np.mean(np.diff(self.batch_times[-10:]))\n",
        "        else:\n",
        "            avg_batch_time = 1.0\n",
        "\n",
        "        remaining_batches = self.total_batches_per_epoch - (batch_idx + 1)\n",
        "        eta_epoch = remaining_batches * avg_batch_time\n",
        "\n",
        "        progress_pct = (batch_idx + 1) / self.total_batches_per_epoch * 100\n",
        "        bar_length = 30\n",
        "        filled_length = int(bar_length * (batch_idx + 1) // self.total_batches_per_epoch)\n",
        "        bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "        eta_str = str(timedelta(seconds=int(eta_epoch)))\n",
        "\n",
        "        mode = \"TRAIN\" if is_training else \"VAL  \"\n",
        "        print(f\"\\r{mode} |{bar}| {progress_pct:5.1f}% | \"\n",
        "              f\"Batch: {batch_idx+1:4d}/{self.total_batches_per_epoch} | \"\n",
        "              f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
        "              f\"ETA: {eta_str} | Params: {self._format_params(trial_params)}\", end='', flush=True)\n",
        "\n",
        "    def _format_params(self, params):\n",
        "        \"\"\"Format hyperparameters for display\"\"\"\n",
        "        formatted = []\n",
        "        for key, value in params.items():\n",
        "            if key in ['lr', 'weight_decay']:\n",
        "                formatted.append(f\"{key}: {value:.4f}\")\n",
        "            elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                formatted.append(f\"{key}: {value:.4f}\")\n",
        "            else:\n",
        "                formatted.append(f\"{key}: {value}\")\n",
        "        return \", \".join(formatted)\n",
        "\n",
        "    # best_val_f1 = 0.0  # Track best F1 in this trial                        # Added\n",
        "    # best_val_acc = 0.0  # Track corresponding acc for the best F1           # Added\n",
        "    # patience_counter = 0  # Local patience for early stopping in trial      # Added\n",
        "\n",
        "    def objective(self, trial):\n",
        "        # \"\"\"Optuna objective function with hyperparameters\"\"\"\n",
        "        gpu_memory = get_available_gpu_memory()\n",
        "        if gpu_memory > 24:\n",
        "            batch_size_options = [32, 64, 96, 128]\n",
        "        elif gpu_memory > 12:\n",
        "            batch_size_options = [32, 64, 96]\n",
        "        elif gpu_memory > 6:\n",
        "            batch_size_options = [32, 64]\n",
        "        else:\n",
        "            batch_size_options = [16, 32]\n",
        "\n",
        "        # lr = trial.suggest_float('lr', 1e-6, 5e-4, log=True)\n",
        "        # weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-3, log=True)\n",
        "        # dropout = trial.suggest_float('dropout', 0.1, 0.5)\n",
        "        # hidden_dim_multiplier = trial.suggest_float('hidden_dim_multiplier', 0.25, 1.0)\n",
        "        # augmentation_strength = trial.suggest_categorical('augmentation_strength', ['light', 'medium', 'heavy'])\n",
        "        # # batch_size = trial.suggest_categorical('batch_size', batch_size_options)  # Use dynamic options\n",
        "        # batch_size = trial.suggest_categorical('batch_size', [32, 64, 96, 128])\n",
        "        # optimizer_type = trial.suggest_categorical('optimizer_type', ['adamw'])#, 'adam', 'sgd'])\n",
        "        # scheduler_type = trial.suggest_categorical('scheduler_type',['cosine', 'plateau'])#, 'step', 'exponential'])\n",
        "        # label_smoothing = trial.suggest_float('label_smoothing', 0.1, 0.2)\n",
        "        # lr = trial.suggest_float(\"lr\", 1e-5, 5e-4, log=True)   # tighter than 1e-6‚Äì5e-4\n",
        "        lr = trial.suggest_loguniform(\"lr\", 1e-6, 1e-4)\n",
        "        batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 96, 128, 256])\n",
        "        weight_decay = trial.suggest_float(\"weight_decay\", 1e-6, 1e-4, log=True)\n",
        "        dropout = trial.suggest_float(\"dropout\", 0.2, 0.5)     # avoid very low dropout\n",
        "        hidden_dim_multiplier = trial.suggest_float(\"hidden_dim_multiplier\", 0.5, 1.0)  # avoid too tiny heads\n",
        "        augmentation_strength = trial.suggest_categorical(\"augmentation_strength\", [\"light\", \"medium\",\"heavy\"])\n",
        "        # batch_size = trial.suggest_categorical(\"batch_size\", [64, 96, 128])  # skip 32 if GPU is large\n",
        "        optimizer_type = trial.suggest_categorical(\"optimizer_type\", [\"adamw\"])\n",
        "        scheduler_type = trial.suggest_categorical(\"scheduler_type\", [\"cosine\"])\n",
        "        label_smoothing = trial.suggest_float(\"label_smoothing\", 0.05, 0.15)  # smaller range\n",
        "\n",
        "        trial_params = {\n",
        "            'lr': lr, 'weight_decay': weight_decay, 'dropout': dropout,\n",
        "            'hidden_dim_multiplier': hidden_dim_multiplier, 'augmentation_strength': augmentation_strength,\n",
        "            'batch_size': batch_size, 'optimizer_type': optimizer_type, 'scheduler_type': scheduler_type,\n",
        "            'label_smoothing': label_smoothing\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            print(f\"\\nTrial {trial.number+1}/{Config.OPTUNA_TRIALS} parameters for {self.model_name}:\")\n",
        "            for key, value in trial_params.items():\n",
        "                if key in ['lr', 'weight_decay']:\n",
        "                    print(f\"  {key}: {value:.4f}\")\n",
        "                elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                    print(f\"  {key}: {value:.4f}\")\n",
        "                else:\n",
        "                    print(f\"  {key}: {value}\")\n",
        "\n",
        "            # # Conditionally set prefetch_factor based on num_workers\n",
        "            # prefetch_factor = 2 if Config.DATALOADER_NUM_WORKERS > 0 else None\n",
        "\n",
        "            # temp_train_loader = DataLoader(\n",
        "            #     self.train_loader.dataset,\n",
        "            #     batch_size=batch_size,\n",
        "            #     sampler=self.train_loader.sampler,\n",
        "            #     num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            #     pin_memory=Config.PIN_MEMORY,\n",
        "            #     prefetch_factor=prefetch_factor,\n",
        "            #     persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            #     worker_init_fn=worker_init_fn  # Add this\n",
        "            # )\n",
        "            # temp_val_loader = DataLoader(\n",
        "            #     self.val_loader.dataset,\n",
        "            #     batch_size=batch_size,\n",
        "            #     shuffle=False,\n",
        "            #     num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            #     pin_memory=Config.PIN_MEMORY,\n",
        "            #     prefetch_factor=prefetch_factor,\n",
        "            #     persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            #     worker_init_fn=worker_init_fn  # Add this\n",
        "            # )\n",
        "            temp_train_loader = self.train_loader\n",
        "            temp_val_loader = self.val_loader\n",
        "\n",
        "            model = ModelFactory.create_model(\n",
        "                self.model_name,\n",
        "                dropout_rate=dropout,\n",
        "                hidden_dim_multiplier=hidden_dim_multiplier\n",
        "            )\n",
        "            model = model.to(Config.DEVICE)\n",
        "\n",
        "            if optimizer_type == 'adam':\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "            elif optimizer_type == 'adamw':\n",
        "                optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "            else:\n",
        "                optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                                    momentum=0.9, nesterov=True)\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "            if scheduler_type == 'cosine':\n",
        "                scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.OPTUNA_EPOCHS)\n",
        "            elif scheduler_type == 'step':\n",
        "                scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.7)\n",
        "            else:\n",
        "                scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "            is_best = False\n",
        "            best_val_f1 = 0.0  # Local variable for trial-specific best F1 score\n",
        "            best_val_acc = 0.0  # Local variable for trial-specific best accuracy\n",
        "            patience_counter = 0.0  # Initialize patience counter\n",
        "\n",
        "            for optuna_epoch in range(Config.OPTUNA_EPOCHS):\n",
        "                self.batch_times = []\n",
        "                model.train()\n",
        "\n",
        "                train_correct = 0\n",
        "                train_total = 0\n",
        "                train_loss = 0\n",
        "\n",
        "                train_pbar = tqdm(temp_train_loader, desc=f\"Optuna Epoch {optuna_epoch+1}/{Config.OPTUNA_EPOCHS} Training\", leave=False)\n",
        "\n",
        "                # Corrected training loop in ExpandedHyperparameterOptimizer.objective\n",
        "                for batch_idx, (images, labels) in enumerate(train_pbar):\n",
        "                    # ADDED: Memory monitoring every 10 batches\n",
        "                    if batch_idx % self.memory_check_interval == 0:\n",
        "                        try:\n",
        "                            cpu_memory = psutil.virtual_memory()\n",
        "                            cpu_percent = cpu_memory.percent\n",
        "                            if torch.cuda.is_available():\n",
        "                                gpu_percent = (torch.cuda.memory_reserved() / torch.cuda.get_device_properties(0).total_memory) * 100\n",
        "                            else:\n",
        "                                gpu_percent = 0\n",
        "\n",
        "                            # Force cleanup at 95% threshold\n",
        "                            if cpu_percent >= self.force_cleanup_threshold or gpu_percent >= self.force_cleanup_threshold:\n",
        "                                torch.cuda.empty_cache()\n",
        "                                torch.cuda.synchronize()\n",
        "                                gc.collect()\n",
        "                                print(f\"\\nForce cleanup: CPU {cpu_percent:.1f}%, GPU {gpu_percent:.1f}%\")\n",
        "                        except:\n",
        "                            pass\n",
        "\n",
        "                    images, labels = images.to(Config.DEVICE, non_blocking=True), labels.to(Config.DEVICE, non_blocking=True)\n",
        "                    optimizer.zero_grad(set_to_none=True)\n",
        "                    with torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "                        outputs = model(images)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "\n",
        "                    batch_loss = loss.item()\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    train_total += labels.size(0)\n",
        "                    train_correct += (predicted == labels).sum().item()\n",
        "                    train_loss += batch_loss\n",
        "                    batch_acc = train_correct / train_total\n",
        "\n",
        "                    # train_pbar.set_postfix({'loss': f'{batch_loss:.4f}', 'acc': f'{batch_acc:.4f}'})\n",
        "\n",
        "                    # ENHANCED: Memory cleanup\n",
        "                    del images, labels, outputs, loss, predicted\n",
        "                    if batch_idx % 10 == 0:\n",
        "                        torch.cuda.empty_cache()\n",
        "                        # gc.collect()  # ADDED: Garbage collection\n",
        "\n",
        "                model.eval()\n",
        "\n",
        "                val_correct = 0\n",
        "                val_total = 0\n",
        "                val_loss = 0\n",
        "                val_predictions = []\n",
        "                val_labels = []\n",
        "\n",
        "                val_pbar = tqdm(temp_val_loader, desc=f\"Optuna Epoch {optuna_epoch+1}/{Config.OPTUNA_EPOCHS} Validation\", total=len(temp_val_loader), leave=False)\n",
        "                with torch.no_grad():\n",
        "                    for batch_idx, (images, labels) in enumerate(val_pbar):\n",
        "                        # ADDED: Memory check every 5 batches during validation\n",
        "                        if batch_idx % 5 == 0:\n",
        "                            try:\n",
        "                                cpu_percent = psutil.virtual_memory().percent\n",
        "                                gpu_percent = (torch.cuda.memory_reserved() / torch.cuda.get_device_properties(0).total_memory) * 100 if torch.cuda.is_available() else 0\n",
        "                                if cpu_percent >= self.force_cleanup_threshold or gpu_percent >= self.force_cleanup_threshold:\n",
        "                                    torch.cuda.empty_cache()\n",
        "                                    gc.collect()\n",
        "                            except:\n",
        "                                pass\n",
        "\n",
        "                        images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                        outputs = model(images)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        batch_loss = loss.item()\n",
        "                        val_loss += batch_loss\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "                        val_total += labels.size(0)\n",
        "                        val_correct += (predicted == labels).sum().item()\n",
        "                        val_predictions.extend(predicted.cpu().numpy())\n",
        "                        val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                        batch_acc = val_correct / val_total\n",
        "\n",
        "                        # val_pbar.set_postfix({'loss': f'{batch_loss:.4f}', 'acc': f'{batch_acc:.4f}'})\n",
        "\n",
        "                        # ADDED: Memory cleanup for validation\n",
        "                        del images, labels, outputs, loss, predicted\n",
        "                        # if batch_idx % 15 == 0:  # Less frequent cleanup in validation\n",
        "                        #     torch.cuda.empty_cache()\n",
        "\n",
        "                train_acc = train_correct / train_total\n",
        "                val_acc = val_correct / val_total\n",
        "                val_f1 = f1_score(val_labels, val_predictions, average='macro')\n",
        "                scheduler.step()\n",
        "\n",
        "                print(f\"\\nTrial {trial.number+1} Optuna Epoch {optuna_epoch+1} completed for Model: {self.model_name}\"\n",
        "                      f\"\\nOptuna Epoch {optuna_epoch+1}/{Config.OPTUNA_EPOCHS} Summary: \"\n",
        "                      f\"TL: {train_loss/len(temp_train_loader):.6f}, \"\n",
        "                      f\"VL: {val_loss/len(temp_val_loader):.6f}, \"\n",
        "                      f\"TA: {train_acc:.4f}, \"\n",
        "                      f\"VA: {val_acc:.4f}, \"\n",
        "                      f\"VF1: {val_f1:.4f}\\n\")\n",
        "\n",
        "                if val_f1 >= best_val_f1 * 1.001:  # Use self.best_val_f1 for class-level tracking\n",
        "                    # self.best_trial = trial.number + 1\n",
        "                    best_val_f1 = val_f1\n",
        "                    best_val_acc = val_acc\n",
        "                    patience_counter = 0\n",
        "                    is_best = True\n",
        "                    # Optional: Save model checkpoint if needed\n",
        "                    # torch.save(model.state_dict(), f\"{Config.OUTPUT_DIR}/trial_best_model/trial_{trial.number}_best.pt\")\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "\n",
        "                #Early stopping for Epoch Level\n",
        "                if patience_counter >= Config.PATIENCE:\n",
        "                    print(f\"Early stopping at epoch {optuna_epoch + 1}: No improvement >= 0.1% in val_f1 for {Config.PATIENCE} validations\")\n",
        "                    break\n",
        "\n",
        "                # #Early stopping for Trial Level\n",
        "                # if optuna_epoch >= 4:\n",
        "                #     trial.report(val_f1, optuna_epoch)\n",
        "                #     if trial.should_prune():\n",
        "                #         best_f1 = max([t.value for t in trial.study.trials if t.value is not None], default=val_f1)\n",
        "                #         logging.info(\n",
        "                #             f\"Trial {trial.number + 1} (epoch {optuna_epoch + 1}) \"\n",
        "                #             f\"val_f1={val_f1:.4f} is unpromising compared to best_f1={best_f1:.4f}. \"\n",
        "                #             f\"Pruning trial to focus on better candidates.\"\n",
        "                #         )\n",
        "                #         raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "                # Early stopping / pruning for epoch level\n",
        "                # Make sure logging is enabled\n",
        "                logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
        "\n",
        "                # # F1-based pruning (Optuna standard)\n",
        "                # if optuna_epoch >= 4:\n",
        "                #     trial.report(val_f1, optuna_epoch)\n",
        "\n",
        "                #     if trial.should_prune():\n",
        "                #         best_f1 = max([t.value for t in trial.study.trials if t.value is not None], default=val_f1)\n",
        "                #         msg = (f\"‚õî Trial {trial.number + 1} stopped at epoch {optuna_epoch + 1}: \"\n",
        "                #               f\"val_f1={val_f1:.4f} is below best_f1={best_f1:.4f}.\")\n",
        "                #         logging.info(msg)   # üëà will print\n",
        "                #         trial.set_user_attr(\"pruned_reason\", msg)\n",
        "                #         raise optuna.TrialPruned()\n",
        "                # # Custom accuracy-based stopping rule\n",
        "                # if optuna_epoch+1 >= 5 and val_acc < 0.30:\n",
        "                #     msg = (f\"‚õî Trial {trial.number + 1} stopped at epoch {optuna_epoch + 1}: \"\n",
        "                #           f\"val_acc={val_acc:.4f} did not reach 30% after 5 epochs.\")\n",
        "                #     logging.info(msg)       # üëà will print\n",
        "                #     trial.set_user_attr(\"pruned_reason\", msg)\n",
        "                #     raise optuna.TrialPruned()\n",
        "                try:\n",
        "                    # F1-based pruning (Optuna standard)\n",
        "                    if optuna_epoch >= 4:\n",
        "                        trial.report(val_f1, optuna_epoch)\n",
        "\n",
        "                        if trial.should_prune():\n",
        "                            best_f1 = max([t.value for t in trial.study.trials if t.value is not None], default=val_f1)\n",
        "                            msg = (f\"‚õî Trial {trial.number + 1} stopped at epoch {optuna_epoch + 1}: \"\n",
        "                                  f\"val_f1={val_f1:.4f} is below best_f1={best_f1:.4f}.\")\n",
        "                            print(msg)               # show message\n",
        "                            logging.info(msg)        # log message\n",
        "                            trial.set_user_attr(\"pruned_reason\", msg)\n",
        "                            raise optuna.TrialPruned()\n",
        "\n",
        "                    # Custom accuracy-based stopping rule\n",
        "                    if optuna_epoch + 1 >= 5 and val_f1 < 0.30:\n",
        "                        msg = (f\"‚õî Trial {trial.number + 1} stopped at epoch {optuna_epoch + 1}: \"\n",
        "                              f\"val_f1={val_f1:.4f} did not reach even 30% after 5 epochs.So Skipping this epoch....\")\n",
        "                        print(msg)                   # show message\n",
        "                        logging.info(msg)            # log message\n",
        "                        trial.set_user_attr(\"pruned_reason\", msg)\n",
        "                        raise optuna.TrialPruned()\n",
        "\n",
        "                except optuna.TrialPruned as e:\n",
        "                    # Catch the pruning exception to suppress traceback\n",
        "                    # Optionally, you can just pass here because message is already printed/logged\n",
        "                    # pass\n",
        "                    raise\n",
        "\n",
        "            # Update class-level tracking\n",
        "            if best_val_f1 > self.best_val_f1  :\n",
        "                if (trial.number+1>0):\n",
        "                    self.best_val_f1 = best_val_f1\n",
        "                    self.best_val_acc = best_val_acc\n",
        "                    self.best_trial = trial.number + 1\n",
        "\n",
        "                    # print(f\"\\n\\033[1;31mNew best result found for Trial {self.best_trial}:\\033[0m\")\n",
        "                    if (trial.number+1!=1):\n",
        "                        print(f\"\\n\\033[1;31mNew best result found for Trial {self.best_trial}:\\033[0m\")\n",
        "                    print(f\"Validation Accuracy: {self.best_val_acc:.4f}\")\n",
        "                    print(f\"Validation F1 Score: {self.best_val_f1:.4f}\")\n",
        "                else:\n",
        "                    print(f\"\\n\\033[1;31mThis is the First Trial. So No Scope for Improvement Judgement.\\033[0m\")\n",
        "                    # print(f\"\\nThis is the First Trial.So No Scope for Improvement Judgement.\")\n",
        "            else:\n",
        "                if (trial.number+1>1):\n",
        "                    print(f\"\\nTrial {trial.number+1} did not improved the accuracy.\") # overall best (Current best F1: {self.best_val_f1:.4f})\")\n",
        "                else:\n",
        "                    print(f\"\\n\\033[1;31mThis is the First Trial. So No Scope for Improvement Judgement.\\033[0m\")\n",
        "                    #print(f\"\\nThis is the First Trial.So No Scope for Improvement Judgement.\")\n",
        "\n",
        "            if (trial.number+1>1):\n",
        "                print(f\"\\n\\033[1;31mTrial {self.best_trial} holds best result up to this:\\033[0m\")\n",
        "                print(f\"  Validation Accuracy: {self.best_val_acc:.4f}\")\n",
        "                print(f\"  Validation F1 Score: {self.best_val_f1:.4f}\")\n",
        "\n",
        "            # ADDED: Trial cleanup before return\n",
        "            try:\n",
        "                del model, optimizer, scheduler, criterion\n",
        "                del temp_train_loader, temp_val_loader\n",
        "                del val_predictions, val_labels\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            return best_val_f1  # Return the last epoch's F1 for Optuna to maximize\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"\\nTrial {trial.number+1} Skipped with : {str(e)}\\n{traceback.format_exc()} cause F1 Not Improving!!!!\")\n",
        "\n",
        "            # ADDED: Emergency cleanup on error\n",
        "            try:\n",
        "                del model, optimizer, scheduler, criterion\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            return 0.0\n",
        "\n",
        "\n",
        "\n",
        "    def optimize(self):\n",
        "        print(f\"Optimizing hyperparameters for {self.model_name}...\")\n",
        "\n",
        "        if not OPTUNA_AVAILABLE:\n",
        "            return {\n",
        "                'lr': Config.LEARNING_RATE,\n",
        "                'dropout': 0.5,\n",
        "                'weight_decay': Config.WEIGHT_DECAY,\n",
        "                'hidden_dim_multiplier': 0.5,\n",
        "                'augmentation_strength': 'medium',\n",
        "                'batch_size': Config.BATCH_SIZE,\n",
        "                'optimizer_type': 'adamw',\n",
        "                'scheduler_type': 'cosine',\n",
        "                'label_smoothing': 0.1\n",
        "            }\n",
        "\n",
        "        study = optuna.create_study(direction='maximize', pruner=optuna.pruners.MedianPruner(n_warmup_steps=4))\n",
        "        # study = optuna.create_study(direction='maximize', pruner=optuna.pruners.SuccessiveHalvingPruner(min_resource=1, reduction_factor=4))\n",
        "        optuna.logging.set_verbosity(optuna.logging.WARNING)  # Suppress info-level logs\n",
        "        study.optimize(self.objective, n_trials=Config.OPTUNA_TRIALS, timeout=3600)#, callbacks=[callback])\n",
        "\n",
        "        best_params = study.best_trial.params\n",
        "\n",
        "        # print(f\"\\nBest params for {self.model_name}:\")\n",
        "        # for key, value in best_params.items():\n",
        "        #     if key in ['lr', 'weight_decay']:\n",
        "        #         print(f\"  {key}: {value:.4f}\")\n",
        "        #     elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "        #         print(f\"  {key}: {value:.6f}\")\n",
        "        #     else:\n",
        "        #         print(f\"  {key}: {value}\")\n",
        "        # print(f\"Best validation accuracy: {study.best_trial.value:.4f}\")\n",
        "\n",
        "        return best_params\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 8. MODEL TRAINING\n",
        "# =============================================================================\n",
        "# Purpose: Train individual models with optimized hyperparameters.\n",
        "\n",
        "\n",
        "class EnhancedModelTrainer:\n",
        "    def __init__(self, model, model_name, hyperparameters):\n",
        "        self.model = model.to(Config.DEVICE)\n",
        "        self.model_name = model_name\n",
        "        self.hyperparameters = hyperparameters\n",
        "        self.best_val_acc = 0.0\n",
        "        self.best_val_f1 = 0.0\n",
        "        self.patience_counter = 0.0\n",
        "        self.progress_tracker = None  # Ensure attribute exists\n",
        "\n",
        "\n",
        "\n",
        "        # Add these to __init__ method\n",
        "        self.memory_check_interval = 10\n",
        "        self.force_cleanup_threshold = 95\n",
        "\n",
        "\n",
        "\n",
        "        os.makedirs(f\"{Config.OUTPUT_DIR}/kfold_results\", exist_ok=True)\n",
        "        os.makedirs(f\"{Config.OUTPUT_DIR}/models\", exist_ok=True)\n",
        "        self._setup_training_components()\n",
        "\n",
        "        # Initialize history to track metrics\n",
        "        self.history = {\n",
        "            'train_loss': [],\n",
        "            'train_acc': [],\n",
        "            'val_loss': [],\n",
        "            'val_acc': [],\n",
        "            'val_f1': [],\n",
        "            'learning_rates': []\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "    def cleanup_model(self):\n",
        "        \"\"\"Complete model and trainer cleanup\"\"\"\n",
        "        try:\n",
        "            # Clear model from GPU\n",
        "            if hasattr(self, 'model'):\n",
        "                del self.model\n",
        "            if hasattr(self, 'optimizer'):\n",
        "                del self.optimizer\n",
        "            if hasattr(self, 'scheduler'):\n",
        "                del self.scheduler\n",
        "            if hasattr(self, 'criterion'):\n",
        "                del self.criterion\n",
        "            if hasattr(self, 'scaler'):\n",
        "                del self.scaler\n",
        "\n",
        "            # Clear history data\n",
        "            self.history.clear()\n",
        "\n",
        "            # GPU cleanup\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "            gc.collect()\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Cleanup error: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _setup_training_components(self):\n",
        "        allowed_keys = ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier',\n",
        "                       'augmentation_strength', 'batch_size', 'optimizer_type',\n",
        "                       'scheduler_type', 'label_smoothing']\n",
        "        self.hyperparameters = {k: v for k, v in self.hyperparameters.items() if k in allowed_keys}\n",
        "\n",
        "        for key in ['dropout', 'hidden_dim_multiplier', 'augmentation_strength', 'batch_size']:\n",
        "            if key not in self.hyperparameters:\n",
        "                tqdm.write(f\"Warning: {key} not found in hyperparameters, ensure it is handled elsewhere.\")\n",
        "\n",
        "        lr = self.hyperparameters.get('lr', Config.LEARNING_RATE)\n",
        "        weight_decay = self.hyperparameters.get('weight_decay', Config.WEIGHT_DECAY)\n",
        "        optimizer_type = self.hyperparameters.get('optimizer_type', 'adamw')\n",
        "\n",
        "        if optimizer_type == 'adam':\n",
        "            self.optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay, fused=True)\n",
        "        elif optimizer_type == 'adamw':\n",
        "            self.optimizer = optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay, fused=True)\n",
        "        else:\n",
        "            self.optimizer = optim.SGD(self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                                     momentum=0.9, nesterov=True)\n",
        "\n",
        "\n",
        "        label_smoothing = self.hyperparameters.get('label_smoothing', 0.1)\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "\n",
        "        scheduler_type = self.hyperparameters.get('scheduler_type', 'cosine')\n",
        "        if scheduler_type == 'cosine':\n",
        "            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "                self.optimizer, T_max=Config.EPOCHS, eta_min=1e-6)\n",
        "        elif scheduler_type == 'plateau':\n",
        "            self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                self.optimizer, mode='min', factor=0.5, patience=5\n",
        "            )\n",
        "        else:\n",
        "            self.scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.95)\n",
        "\n",
        "\n",
        "\n",
        "    def train_epoch(self, train_loader, progress_tracker):\n",
        "        \"\"\"Train one epoch with proper progress tracking using tqdm\"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        batch_losses = []\n",
        "        batch_accuracies = []\n",
        "        self.scaler = torch.cuda.amp.GradScaler(enabled=Config.USE_MIXED_PRECISION)\n",
        "        self.progress_tracker = progress_tracker\n",
        "\n",
        "        # Debug data loader\n",
        "        tqdm.write(f\"train_epoch: Starting for {self.model_name}, {len(train_loader)} batches, \"\n",
        "                   f\"dataset size: {len(train_loader.dataset)}\")\n",
        "\n",
        "        try:\n",
        "            # with tqdm(train_loader,\n",
        "            #           desc=f\"TRAIN {progress_tracker.current_epoch+1}/{progress_tracker.total_epochs}\",\n",
        "            #           total=len(train_loader), leave=True, dynamic_ncols=True,\n",
        "            #           position=0, file=sys.stdout) as pbar:\n",
        "\n",
        "\n",
        "            # for batch_idx, (images, labels) in enumerate (train_loader):#(pbar):\n",
        "            #     try:\n",
        "            #         images, labels = images.to(Config.DEVICE, non_blocking=True), labels.to(Config.DEVICE, non_blocking=True)\n",
        "            #         self.optimizer.zero_grad(set_to_none=True)\n",
        "            #         with torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "            #             outputs = self.model(images)\n",
        "            #             loss = self.criterion(outputs, labels)\n",
        "            #         self.scaler.scale(loss).backward()\n",
        "            #         self.scaler.unscale_(self.optimizer)\n",
        "            #         torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "            #         self.scaler.step(self.optimizer)\n",
        "            #         self.scaler.update()\n",
        "            #         _, predicted = torch.max(outputs, 1)\n",
        "            #         batch_acc = accuracy_score(labels.cpu().numpy(), predicted.cpu().numpy())\n",
        "            #         batch_loss = loss.item()\n",
        "\n",
        "            #         # Update progress tracker\n",
        "            #         self.progress_tracker.update_batch(batch_idx, batch_loss, batch_acc,is_training=True, total_batches=len(train_loader))\n",
        "\n",
        "            #         batch_losses.append(batch_loss)\n",
        "            #         batch_accuracies.append(batch_acc)\n",
        "            #         total_loss += batch_loss * images.size(0)\n",
        "            #         total += images.size(0)\n",
        "            #         correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "            #         # # ‚úÖ Memory management (added)\n",
        "            #         # del images, labels, outputs, loss, predicted  # free up GPU memory\n",
        "            #         # torch.cuda.empty_cache()                     # release unused memory\n",
        "            #         # gc.collect()                                 # force Python garbage collection\n",
        "\n",
        "            #         # Update tqdm progress bar\n",
        "            #         # pbar.set_postfix({'Loss': f'{batch_loss:.4f}', 'Acc': f'{batch_acc:.4f}'}, refresh=True)\n",
        "\n",
        "            #         # Memory cleanup\n",
        "            #         del outputs, loss, predicted, images, labels\n",
        "\n",
        "            #     except Exception as e:\n",
        "            #         tqdm.write(f\"Error in batch {batch_idx+1}/{len(train_loader)}: {str(e)}\")\n",
        "            #         continue\n",
        "            # Add these imports at top of file\n",
        "\n",
        "\n",
        "            # Your modified training loop - exact same structure, just enhanced\n",
        "            for batch_idx, (images, labels) in enumerate (train_loader):#(pbar):\n",
        "                try:\n",
        "                    # Memory monitoring and dynamic management inline\n",
        "                    if batch_idx % self.memory_check_interval == 0:\n",
        "                        try:\n",
        "                            # Check system resources\n",
        "                            cpu_memory = psutil.virtual_memory()\n",
        "                            cpu_usage_percent = cpu_memory.percent\n",
        "                            cpu_available_gb = cpu_memory.available / (1024**3)\n",
        "\n",
        "                            if torch.cuda.is_available():\n",
        "                                gpu_memory_reserved = torch.cuda.memory_reserved() / (1024**3)\n",
        "                                gpu_memory_total = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "                                gpu_usage_percent = (gpu_memory_reserved / gpu_memory_total) * 100\n",
        "                            else:\n",
        "                                gpu_usage_percent = 0\n",
        "\n",
        "                            # Force cleanup if hitting critical limits (95%+ as requested)\n",
        "                            if cpu_usage_percent >= self.force_cleanup_threshold or gpu_usage_percent >= self.force_cleanup_threshold:\n",
        "                                if torch.cuda.is_available():\n",
        "                                    torch.cuda.empty_cache()\n",
        "                                    torch.cuda.synchronize()\n",
        "                                gc.collect()\n",
        "                            #     tqdm.write(f\"üßπ Force cleanup: CPU {cpu_usage_percent:.1f}%, GPU {gpu_usage_percent:.1f}%\")\n",
        "\n",
        "                            # # Log status every 50 batches\n",
        "                            # if batch_idx % 50 == 0:\n",
        "                            #     tqdm.write(f\"üíæ Memory: CPU {cpu_usage_percent:.1f}%, GPU {gpu_usage_percent:.1f}%, Available RAM {cpu_available_gb:.1f}GB\")\n",
        "\n",
        "                        except Exception as mem_e:\n",
        "                            tqdm.write(f\"Memory check error: {mem_e}\")\n",
        "\n",
        "                    images, labels = images.to(Config.DEVICE, non_blocking=True), labels.to(Config.DEVICE, non_blocking=True)\n",
        "                    self.optimizer.zero_grad(set_to_none=True)\n",
        "                    with torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "                        outputs = self.model(images)\n",
        "                        loss = self.criterion(outputs, labels)\n",
        "                    self.scaler.scale(loss).backward()\n",
        "                    self.scaler.unscale_(self.optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                    self.scaler.step(self.optimizer)\n",
        "                    self.scaler.update()\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    batch_acc = accuracy_score(labels.cpu().numpy(), predicted.cpu().numpy())\n",
        "                    batch_loss = loss.item()\n",
        "\n",
        "                    # Update progress tracker\n",
        "                    self.progress_tracker.update_batch(batch_idx, batch_loss, batch_acc,is_training=True, total_batches=len(train_loader))\n",
        "                    batch_losses.append(batch_loss)\n",
        "                    batch_accuracies.append(batch_acc)\n",
        "                    total_loss += batch_loss * images.size(0)\n",
        "                    total += images.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    # Enhanced memory cleanup with dynamic checking\n",
        "                    try:\n",
        "                        # Quick memory check for cleanup decision\n",
        "                        current_cpu = psutil.virtual_memory().percent if batch_idx % 5 == 0 else 0\n",
        "                        current_gpu = (torch.cuda.memory_reserved() / torch.cuda.get_device_properties(0).total_memory * 100) if torch.cuda.is_available() and batch_idx % 5 == 0 else 0\n",
        "\n",
        "                        # Memory cleanup\n",
        "                        del outputs, loss, predicted, images, labels\n",
        "\n",
        "                        # Aggressive cleanup if memory high\n",
        "                        if current_cpu >= 85 or current_gpu >= 80 or batch_idx % 20 == 0:\n",
        "                            if torch.cuda.is_available():\n",
        "                                torch.cuda.empty_cache()\n",
        "                            gc.collect()\n",
        "\n",
        "                        # Force cleanup if critical (95%+ as requested)\n",
        "                        if current_cpu >= self.force_cleanup_threshold or current_gpu >= self.force_cleanup_threshold:\n",
        "                            if torch.cuda.is_available():\n",
        "                                torch.cuda.empty_cache()\n",
        "                                torch.cuda.synchronize()\n",
        "                            gc.collect()\n",
        "                            # Force delete any remaining variables\n",
        "                            try:\n",
        "                                import sys\n",
        "                                frame = sys._getframe()\n",
        "                                for var_name in list(frame.f_locals.keys()):\n",
        "                                    if var_name.startswith(('temp_', 'intermediate_', 'cache_')):\n",
        "                                        del frame.f_locals[var_name]\n",
        "                            except:\n",
        "                                pass\n",
        "                            tqdm.write(f\"‚ö†Ô∏è Critical cleanup executed: CPU {current_cpu:.1f}%, GPU {current_gpu:.1f}%\")\n",
        "\n",
        "                    except Exception as cleanup_e:\n",
        "                        # Fallback cleanup on error\n",
        "                        try:\n",
        "                            del outputs, loss, predicted, images, labels\n",
        "                            if torch.cuda.is_available():\n",
        "                                torch.cuda.empty_cache()\n",
        "                            gc.collect()\n",
        "                        except:\n",
        "                            pass\n",
        "                        tqdm.write(f\"Cleanup error: {cleanup_e}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    tqdm.write(f\"Error in batch {batch_idx+1}/{len(train_loader)}: {str(e)}\")\n",
        "                    # Emergency cleanup on batch error\n",
        "                    try:\n",
        "                        # Force cleanup everything possible\n",
        "                        try:\n",
        "                            del images, labels, outputs, loss, predicted\n",
        "                        except:\n",
        "                            pass\n",
        "                        if torch.cuda.is_available():\n",
        "                            torch.cuda.empty_cache()\n",
        "                            torch.cuda.synchronize()\n",
        "                        gc.collect()\n",
        "                        tqdm.write(\"Emergency cleanup performed after error\")\n",
        "                    except Exception as emergency_e:\n",
        "                        tqdm.write(f\"Emergency cleanup failed: {emergency_e}\")\n",
        "                    continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Final memory cleanup\n",
        "            torch.cuda.empty_cache()\n",
        "            return total_loss / max(1, total), correct / max(1, total)\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Error in train_epoch for {self.model_name}: {str(e)}\")\n",
        "            torch.cuda.empty_cache()\n",
        "            return float('inf'), 0.0\n",
        "\n",
        "\n",
        "\n",
        "    def validate_epoch(self, val_loader, progress_tracker):\n",
        "        \"\"\"Validate one epoch with proper progress tracking using tqdm\"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        total_samples = 0\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "        self.progress_tracker = progress_tracker\n",
        "\n",
        "        # Debug data loader\n",
        "        tqdm.write(f\"validate_epoch: Starting for {self.model_name}, {len(val_loader)} batches, \"\n",
        "                   f\"dataset size: {len(val_loader.dataset)}\")\n",
        "\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                # with tqdm(val_loader,\n",
        "                #           desc=f\"VAL {progress_tracker.current_epoch+1}/{progress_tracker.total_epochs}\",\n",
        "                #           total=len(val_loader), leave=True, dynamic_ncols=True,\n",
        "                #           position=0, file=sys.stdout) as pbar:\n",
        "                for batch_idx, (images, labels) in enumerate (val_loader):#(pbar):\n",
        "                    try:\n",
        "                        images, labels = images.to(Config.DEVICE, non_blocking=True), labels.to(Config.DEVICE, non_blocking=True)\n",
        "                        with torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "                            outputs = self.model(images)\n",
        "                            loss = self.criterion(outputs, labels)\n",
        "                        _, predicted = torch.max(outputs, 1)\n",
        "                        batch_acc = accuracy_score(labels.cpu().numpy(), predicted.cpu().numpy())\n",
        "                        batch_f1 = f1_score(labels.cpu().numpy(), predicted.cpu().numpy(), average='macro', zero_division=0)\n",
        "                        batch_loss = loss.item()\n",
        "                        total_loss += batch_loss * images.size(0)\n",
        "                        total_samples += images.size(0)\n",
        "                        all_predictions.extend(predicted.cpu().numpy())\n",
        "                        all_labels.extend(labels.cpu().numpy())\n",
        "                        all_probs.append(torch.softmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "\n",
        "                        self.progress_tracker.update_batch(batch_idx, batch_loss, batch_acc,is_training=False, total_batches=len(val_loader))\n",
        "\n",
        "                        # Update tqdm progress bar\n",
        "                        # pbar.set_postfix({'Loss': f'{batch_loss:.4f}', 'Acc': f'{batch_acc:.4f}'}, refresh=True)\n",
        "\n",
        "                        # Memory cleanup\n",
        "                        del outputs, loss, predicted, images, labels\n",
        "\n",
        "                    except Exception as e:\n",
        "                        tqdm.write(f\"Error in batch {batch_idx+1}/{len(val_loader)}: {str(e)}\")\n",
        "                        continue\n",
        "\n",
        "            # Final memory cleanup\n",
        "            torch.cuda.empty_cache()\n",
        "            all_probs = np.concatenate(all_probs, axis=0) if all_probs else np.array([])\n",
        "            return total_loss / max(1, total_samples), accuracy_score(all_labels, all_predictions), f1_score(all_labels, all_predictions, average='macro', zero_division=0), all_predictions, all_labels, all_probs\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Error in validate_epoch for {self.model_name}: {str(e)}\")\n",
        "            torch.cuda.empty_cache()\n",
        "            return float('inf'), 0.0, 0.0, [], [], np.array([])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def validate_every_n_epochs(self):\n",
        "        \"\"\"Return the number of epochs between validations.\"\"\"\n",
        "        return 1\n",
        "\n",
        "\n",
        "\n",
        "    def train_main_model(self, train_loader, val_loader, test_loader=None):\n",
        "        \"\"\"Train main model only and save results\"\"\"\n",
        "        if train_loader is None or len(train_loader.dataset) == 0:\n",
        "            tqdm.write(f\"Skipping {self.model_name}: No training data available\")\n",
        "            return None, None\n",
        "\n",
        "        if val_loader is None or len(val_loader.dataset) == 0:\n",
        "            tqdm.write(f\"Skipping {self.model_name}: No validation data available\")\n",
        "            return None, None\n",
        "\n",
        "        tqdm.write(f\"Training {self.model_name} with hyperparameters:\")\n",
        "        for key, value in self.hyperparameters.items():\n",
        "            if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                tqdm.write(f\"  {key}: {value:.4f}\")\n",
        "            else:\n",
        "                tqdm.write(f\"  {key}: {value}\")\n",
        "\n",
        "        # Initialize history and tracking\n",
        "        # self.history = {\n",
        "        #     'train_loss': [], 'train_acc': [],\n",
        "        #     'val_loss': [], 'val_acc': [], 'val_f1': [],\n",
        "        #     'learning_rates': []\n",
        "        # }\n",
        "        # self.best_val_f1 = 0.0\n",
        "        # self.best_val_acc = 0.0\n",
        "        # self.patience_counter = 0.0\n",
        "\n",
        "        # Setup training components with GPU optimizations\n",
        "        self.model = self.model.to(Config.DEVICE, memory_format=torch.channels_last)\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "\n",
        "        self._setup_training_components()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Main training loop\n",
        "        tqdm.write(f\"\\nTraining main model: {self.model_name}\")\n",
        "        progress_tracker = TrainingProgressTracker(self.model_name, Config.EPOCHS, len(train_loader))\n",
        "\n",
        "\n",
        "        last_val_loss, last_val_acc, last_val_f1 = float('inf'), 0.0, 0.0\n",
        "        for epoch in range(Config.EPOCHS):\n",
        "            progress_tracker.start_epoch(epoch)\n",
        "            train_loss, train_acc = self.train_epoch(train_loader, progress_tracker)\n",
        "\n",
        "            if epoch % self.validate_every_n_epochs() == 0 or epoch == Config.EPOCHS - 1:\n",
        "                val_loss, val_acc, val_f1, all_predictions, all_labels, all_probs = self.validate_epoch(val_loader, progress_tracker)\n",
        "                last_val_loss, last_val_acc, last_val_f1 = val_loss, val_acc, val_f1\n",
        "\n",
        "\n",
        "                # Update progress tracker with epoch-level metrics\n",
        "                is_best = val_f1 > self.best_val_f1 * 1.001  # Strict improvement\n",
        "                progress_tracker.finish_epoch(train_loss, train_acc, val_loss, val_acc, val_f1,is_best=is_best,lr=self.optimizer.param_groups[0]['lr'])\n",
        "\n",
        "\n",
        "                if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                    self.scheduler.step(val_loss)\n",
        "                else:\n",
        "                    self.scheduler.step()\n",
        "            else:\n",
        "                val_loss, val_acc, val_f1 = last_val_loss, last_val_acc, last_val_f1\n",
        "\n",
        "            tqdm.write(f\"Epoch {epoch + 1}: Val F1: {val_f1:.4f}, Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "            current_lr = self.optimizer.param_groups[0]['lr']\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "            self.history['val_f1'].append(val_f1)\n",
        "            self.history['learning_rates'].append(current_lr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Early stopping\n",
        "            if val_f1 > self.best_val_f1 * 1.001:  # Strict improvement\n",
        "                self.best_val_f1 = val_f1\n",
        "                self.best_val_acc = val_acc\n",
        "                self.patience_counter = 0\n",
        "                torch.save(self.model.state_dict(), f\"{Config.OUTPUT_DIR}/best_model/{self.model_name}_best.pt\")\n",
        "                tqdm.write(f\"New best model saved with Val F1: {val_f1:.4f}\")\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "\n",
        "            if self.patience_counter >= Config.PATIENCE:\n",
        "                tqdm.write(f\"Early stopping at epoch {epoch + 1}: No improvement >= 0.1% in val_f1 for {Config.PATIENCE} validations\\n\")\n",
        "                break\n",
        "\n",
        "\n",
        "\n",
        "        # Load best model\n",
        "        model_path = f\"{Config.OUTPUT_DIR}/best_model/{self.model_name}_best.pt\"\n",
        "        if os.path.exists(model_path):\n",
        "            self.model.load_state_dict(torch.load(model_path, map_location=Config.DEVICE))\n",
        "        else:\n",
        "            tqdm.write(f\"Warning: Best model weights {model_path} not found. Using current model state.\")\n",
        "\n",
        "\n",
        "        # Model evaluation\n",
        "        evaluator = ModelEvaluator()\n",
        "        eval_loader = test_loader if test_loader is not None else val_loader\n",
        "        with torch.no_grad():\n",
        "            result = evaluator.evaluate_model(self.model, eval_loader, self.model_name)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Save results with proper tensor handling\n",
        "        result_to_save = {\n",
        "            'history': {\n",
        "                'train_loss': torch.tensor(self.history['train_loss'], dtype=torch.float32),\n",
        "                'train_acc': torch.tensor(self.history['train_acc'], dtype=torch.float32),\n",
        "                'val_loss': torch.tensor(self.history['val_loss'], dtype=torch.float32),\n",
        "                'val_acc': torch.tensor(self.history['val_acc'], dtype=torch.float32),\n",
        "                'val_f1': torch.tensor(self.history['val_f1'], dtype=torch.float32),\n",
        "                'learning_rates': torch.tensor(self.history['learning_rates'], dtype=torch.float32)\n",
        "            },\n",
        "            'result': {\n",
        "                'accuracy': torch.tensor(result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "                'f1': torch.tensor(result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "                'conf_matrix': torch.tensor(result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "                'true_labels': torch.tensor(result.get('true_labels', []), dtype=torch.int64),\n",
        "                'predictions': torch.tensor(result.get('predictions', []), dtype=torch.int64),\n",
        "                'probabilities': torch.tensor(result.get('probabilities', np.zeros((0, Config.NUM_CLASSES))), dtype=torch.float32),\n",
        "                'misclassified': [{'image': item['image'].cpu(), 'true_label': item['true_label'], 'pred_label': item['pred_label']}\n",
        "                                for item in result.get('misclassified', [])] if result.get('misclassified') else []\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Save main model results\n",
        "        main_result_path = f\"{Config.OUTPUT_DIR}/model_results/{self.model_name}_main_results.pt\"\n",
        "        torch.save(result_to_save, main_result_path)\n",
        "        tqdm.write(f\"Saved main model results to {main_result_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # ‚úÖ Memory cleanup after saving (added)\n",
        "        del result_to_save, result, evaluator, eval_loader\n",
        "        torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "        # At the beginning of train_main_model method, add:\n",
        "        result = None\n",
        "\n",
        "        return self.history, result\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def train_kfold(self, train_loader, val_loader, n_folds=3):\n",
        "    #     \"\"\"Perform k-fold cross-validation separately\"\"\"\n",
        "    #     if n_folds == 0:\n",
        "    #         tqdm.write(f\"\\033[1;31mSkipping k-fold cross-validation for {self.model_name}\\033[0m\")\n",
        "    #         return []\n",
        "\n",
        "    #     dataset = train_loader.dataset\n",
        "    #     train_size = len(dataset)\n",
        "\n",
        "    #     if train_size < n_folds * 50:  # Need at least 50 samples per fold\n",
        "    #         tqdm.write(f\"Insufficient data for {n_folds}-fold CV. Using {max(1, train_size // 50)} folds\")\n",
        "    #         n_folds = max(1, train_size // 50)\n",
        "\n",
        "    #     val_size = train_size // n_folds\n",
        "    #     fold_indices = []\n",
        "    #     for i in range(n_folds):\n",
        "    #         val_start = i * val_size\n",
        "    #         val_end = min(val_start + val_size, train_size)\n",
        "    #         val_idx = list(range(val_start, val_end))\n",
        "    #         train_idx = list(range(0, val_start)) + list(range(val_end, train_size))\n",
        "    #         fold_indices.append((train_idx, val_idx))\n",
        "\n",
        "\n",
        "    #     tqdm.write(f\"Computed {n_folds} folds, train_size={train_size}, val_size={val_size}\")\n",
        "    #     # ADD AFTER: tqdm.write(f\"Computed {n_folds} folds, train_size={train_size}, val_size={val_size}\")\n",
        "    #     fold_batch_size = min(128, max(32, self.hyperparameters.get('batch_size', Config.BATCH_SIZE)))\n",
        "    #     total_train_batches = (train_size - val_size) // fold_batch_size + 1\n",
        "    #     total_val_batches = val_size // fold_batch_size + 1\n",
        "    #     tqdm.write(f\"Total: {train_size} samples, {fold_batch_size} batch_size, {n_folds} folds\")\n",
        "    #     tqdm.write(f\"Per fold: Train={train_size-val_size} samples ({total_train_batches} batches), Val={val_size} samples ({total_val_batches} batches)\")\n",
        "\n",
        "    #     tqdm.write(f\"\\n\\033[1;31mStarting {n_folds}-fold cross-validation for {self.model_name}\\033[0m\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #     prefetch_factor = 2 if Config.DATALOADER_NUM_WORKERS > 0 else None\n",
        "    #     pin_memory=Config.PIN_MEMORY if 'cuda' in Config.DEVICE else False\n",
        "    #     num_workers = Config.DATALOADER_NUM_WORKERS if torch.cuda.is_available() else 0\n",
        "    #     use_prefetch = num_workers > 0\n",
        "\n",
        "    #     fold_results = []\n",
        "    #     for fold, (train_idx, val_idx) in enumerate(fold_indices, 1):\n",
        "    #         # tqdm.write(f\"\\nTraining Fold {fold}/{n_folds}\")\n",
        "    #         # REPLACE: tqdm.write(f\"\\nTraining Fold {fold}/{n_folds}\")\n",
        "    #         # WITH:\n",
        "    #         train_batches = len(train_idx) // fold_batch_size + 1\n",
        "    #         val_batches = len(val_idx) // fold_batch_size + 1\n",
        "    #         tqdm.write(f\"\\nFold {fold}/{n_folds}: Train={len(train_idx)} samples ({train_batches} batches), Val={len(val_idx)} samples ({val_batches} batches)\")\n",
        "\n",
        "\n",
        "\n",
        "    #         # Create fold-specific DataLoaders with GPU optimizations\n",
        "    #         fold_batch_size = min(128, max(32, self.hyperparameters.get('batch_size', Config.BATCH_SIZE)))  # Larger batches for GPU\n",
        "    #         train_subsampler = SubsetRandomSampler(train_idx)\n",
        "    #         val_subsampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "    #         # Subset datasets for this fold\n",
        "    #         # train_dataset_fold = Subset(dataset, train_idx)\n",
        "    #         # val_dataset_fold = Subset(dataset, val_idx)\n",
        "\n",
        "\n",
        "    #         # train_loader_fold = DataLoader(\n",
        "    #         #     dataset,\n",
        "    #         #     batch_size=fold_batch_size,\n",
        "    #         #     sampler=train_subsampler,\n",
        "    #         #     num_workers=2,  # Reduced workers\n",
        "    #         #     pin_memory=True,\n",
        "    #         #     persistent_workers=False,\n",
        "    #         #     prefetch_factor=2\n",
        "    #         # )\n",
        "    #         # val_loader_fold = DataLoader(\n",
        "    #         #     dataset,\n",
        "    #         #     batch_size=fold_batch_size,\n",
        "    #         #     sampler=val_subsampler,\n",
        "    #         #     num_workers=2,\n",
        "    #         #     pin_memory=True,\n",
        "    #         #     persistent_workers=False,\n",
        "    #         #     prefetch_factor=2\n",
        "    #         # )\n",
        "\n",
        "    #         train_loader_fold = DataLoader(\n",
        "    #             dataset,\n",
        "    #             batch_size=fold_batch_size,\n",
        "    #             # sampler=sampler, #Imbalanced dataset ‚Üí use sampler.Balanced dataset ‚Üí use shuffle=True.\n",
        "    #             # shuffle=True,\n",
        "    #             sampler=train_subsampler,\n",
        "    #             num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "    #             pin_memory=torch.cuda.is_available(),\n",
        "    #             prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "    #             persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "    #             # persistent_workers=False,\n",
        "    #             worker_init_fn=worker_init_fn  # Add this\n",
        "    #         )\n",
        "\n",
        "    #         val_loader_fold = DataLoader(\n",
        "    #             dataset,\n",
        "    #             batch_size=fold_batch_size,\n",
        "    #             sampler=val_subsampler,\n",
        "    #             # shuffle=False,\n",
        "    #             num_workers=num_workers,\n",
        "    #             pin_memory=torch.cuda.is_available(),\n",
        "    #             prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "    #             persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "    #             # persistent_workers=False,\n",
        "    #             worker_init_fn=worker_init_fn  # Add this\n",
        "    #         )\n",
        "\n",
        "\n",
        "    #         # Initialize model for this fold\n",
        "    #         fold_model = ModelFactory.create_model(\n",
        "    #             self.model_name,\n",
        "    #             num_classes=Config.NUM_CLASSES,\n",
        "    #             dropout_rate=self.hyperparameters.get('dropout', 0.5),\n",
        "    #             hidden_dim_multiplier=self.hyperparameters.get('hidden_dim_multiplier', 0.5)\n",
        "    #             # augmentation_strength=self.hyperparameters.get('augmentation_strength', 'medium')\n",
        "    #         ).to(Config.DEVICE, memory_format=torch.channels_last)\n",
        "\n",
        "    #         fold_trainer = EnhancedModelTrainer(fold_model, self.model_name, self.hyperparameters)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #        # Train the fold\n",
        "    #         fold_history, fold_result = fold_trainer.train_main_model(\n",
        "    #             train_loader_fold, val_loader_fold, test_loader=None\n",
        "    #         )\n",
        "\n",
        "    #         # Check if fold training failed\n",
        "    #         if fold_history is None or fold_result is None:\n",
        "    #             tqdm.write(f\"Fold {fold} training failed, skipping...\")\n",
        "    #             fold_result = {\n",
        "    #                 'accuracy': 0.0,\n",
        "    #                 'f1_macro': 0.0,\n",
        "    #                 'conf_matrix': np.array([[]]),\n",
        "    #                 'true_labels': [],\n",
        "    #                 'predictions': [],\n",
        "    #                 'probabilities': np.zeros((0, Config.NUM_CLASSES)),\n",
        "    #                 'misclassified': []\n",
        "    #             }\n",
        "    #             fold_history = {\n",
        "    #                 'val_loss': [],\n",
        "    #                 'val_acc': []\n",
        "    #             }\n",
        "\n",
        "    #         # Validate fold results before saving\n",
        "    #         if not fold_history.get('val_loss') or not fold_history.get('val_acc') or not fold_result.get('true_labels'):\n",
        "    #             tqdm.write(f\"Fold {fold} has empty results, using defaults\")\n",
        "    #             fold_result = {\n",
        "    #                 'accuracy': 0.0,\n",
        "    #                 'f1_macro': 0.0,\n",
        "    #                 'conf_matrix': np.array([[]]),\n",
        "    #                 'true_labels': [],\n",
        "    #                 'predictions': [],\n",
        "    #                 'probabilities': np.zeros((0, Config.NUM_CLASSES)),\n",
        "    #                 'misclassified': []\n",
        "    #             }\n",
        "    #             fold_history = {\n",
        "    #                 'val_loss': [],\n",
        "    #                 'val_acc': []\n",
        "    #             }\n",
        "\n",
        "    #         # Store fold results\n",
        "    #         fold_results.append({\n",
        "    #             'history': {\n",
        "    #                 'val_loss': fold_history['val_loss'],\n",
        "    #                 'val_acc': fold_history['val_acc']\n",
        "    #             },\n",
        "    #             'result': {\n",
        "    #                 'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "    #                 'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "    #                 'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "    #                 'true_labels': torch.tensor(fold_result.get('true_labels', []), dtype=torch.int64),\n",
        "    #                 'predictions': torch.tensor(fold_result.get('predictions', []), dtype=torch.int64),\n",
        "    #                 'probabilities': torch.tensor(fold_result.get('probabilities', np.zeros((0, Config.NUM_CLASSES))), dtype=torch.float32),\n",
        "    #                 'misclassified': [{'image': item['image'].cpu(), 'true_label': item['true_label'], 'pred_label': item['pred_label']}\n",
        "    #                                 for item in fold_result.get('misclassified', [])] if fold_result.get('misclassified') else []\n",
        "    #             }\n",
        "    #         })\n",
        "\n",
        "    #         # Save fold results\n",
        "    #         fold_result_to_save = {\n",
        "    #             'history': {\n",
        "    #                 'val_loss': torch.tensor(fold_history['val_loss'], dtype=torch.float32),\n",
        "    #                 'val_acc': torch.tensor(fold_history['val_acc'], dtype=torch.float32)\n",
        "    #             },\n",
        "    #             'result': {\n",
        "    #                 'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "    #                 'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "    #                 'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "    #                 'true_labels': torch.tensor(fold_result.get('true_labels', []), dtype=torch.int64),\n",
        "    #                 'predictions': torch.tensor(fold_result.get('predictions', []), dtype=torch.int64),\n",
        "    #                 'probabilities': torch.tensor(fold_result.get('probabilities', np.zeros((0, Config.NUM_CLASSES))), dtype=torch.float32),\n",
        "    #                 'misclassified': [{'image': item['image'].cpu(), 'true_label': item['true_label'], 'pred_label': item['pred_label']}\n",
        "    #                                 for item in fold_result.get('misclassified', [])] if fold_result.get('misclassified') else []\n",
        "    #             }\n",
        "    #         }\n",
        "\n",
        "    #         fold_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{self.model_name}_fold_{fold}_results.pt\"\n",
        "    #         torch.save(fold_result_to_save, fold_result_path)\n",
        "    #         tqdm.write(f\"Saved fold {fold} results to {fold_result_path}\")\n",
        "    #         # # Train the fold\n",
        "    #         # fold_history, fold_result = fold_trainer.train_main_model(\n",
        "    #         #     train_loader_fold, val_loader_fold, test_loader=None\n",
        "    #         # )\n",
        "\n",
        "    #         # # if fold_history is None or fold_result is None:\n",
        "    #         # #     tqdm.write(f\"Fold {fold} training failed, skipping...\")\n",
        "    #         # #     continue\n",
        "\n",
        "    #         # # Store fold results\n",
        "    #         # fold_results.append({\n",
        "    #         #     'history': {\n",
        "    #         #         'val_loss': fold_history['val_loss'],\n",
        "    #         #         'val_acc': fold_history['val_acc']\n",
        "    #         #     },\n",
        "    #         #     'result': {\n",
        "    #         #         'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "    #         #         'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "    #         #         'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "    #         #         'true_labels': torch.tensor(fold_result.get('true_labels', []), dtype=torch.int64),\n",
        "    #         #         'predictions': torch.tensor(fold_result.get('predictions', []), dtype=torch.int64),\n",
        "    #         #         'probabilities': torch.tensor(fold_result.get('probabilities', np.zeros((0, Config.NUM_CLASSES))), dtype=torch.float32),\n",
        "    #         #         'misclassified': [{'image': item['image'].cpu(), 'true_label': item['true_label'], 'pred_label': item['pred_label']}\n",
        "    #         #                         for item in fold_result.get('misclassified', [])] if fold_result.get('misclassified') else []\n",
        "    #         #     }\n",
        "    #         # })\n",
        "\n",
        "    #         # # Save fold results\n",
        "    #         # fold_result_to_save = {\n",
        "    #         #     'history': {\n",
        "    #         #         'val_loss': torch.tensor(fold_history['val_loss'], dtype=torch.float32),\n",
        "    #         #         'val_acc': torch.tensor(fold_history['val_acc'], dtype=torch.float32)\n",
        "    #         #     },\n",
        "    #         #     'result': {\n",
        "    #         #         'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "    #         #         'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "    #         #         'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "    #         #         'true_labels': torch.tensor(fold_result.get('true_labels', []), dtype=torch.int64),\n",
        "    #         #         'predictions': torch.tensor(fold_result.get('predictions', []), dtype=torch.int64),\n",
        "    #         #         'probabilities': torch.tensor(fold_result.get('probabilities', np.zeros((0, Config.NUM_CLASSES))), dtype=torch.float32),\n",
        "    #         #         'misclassified': [{'image': item['image'].cpu(), 'true_label': item['true_label'], 'pred_label': item['pred_label']}\n",
        "    #         #                         for item in fold_result.get('misclassified', [])] if fold_result.get('misclassified') else []\n",
        "    #         #     }\n",
        "    #         # }\n",
        "\n",
        "    #         # fold_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{self.model_name}_fold_{fold}_results.pt\"\n",
        "    #         # torch.save(fold_result_to_save, fold_result_path)\n",
        "    #         # tqdm.write(f\"Saved fold {fold} results to {fold_result_path}\")\n",
        "\n",
        "    #         # Aggressive cleanup after fold\n",
        "    #         del fold_history, fold_result, fold_model, fold_trainer\n",
        "    #         del train_loader_fold, val_loader_fold, train_subsampler, val_subsampler\n",
        "    #         torch.cuda.empty_cache()\n",
        "    #         torch.cuda.synchronize()\n",
        "    #         gc.collect()\n",
        "\n",
        "    #     # return fold_results\n",
        "    #     return None\n",
        "\n",
        "\n",
        "    def train_kfold(self, train_loader, val_loader, n_folds=3):\n",
        "        \"\"\"Perform k-fold cross-validation separately\"\"\"\n",
        "        if n_folds == 0:\n",
        "            tqdm.write(f\"\\033[1;31mSkipping k-fold cross-validation for {self.model_name}\\033[0m\")\n",
        "            return []\n",
        "\n",
        "        dataset = train_loader.dataset\n",
        "        train_size = len(dataset)\n",
        "\n",
        "        if train_size < n_folds * 50:  # Need at least 50 samples per fold\n",
        "            tqdm.write(f\"Insufficient data for {n_folds}-fold CV. Using {max(1, train_size // 50)} folds\")\n",
        "            n_folds = max(1, train_size // 50)\n",
        "\n",
        "        val_size = train_size // n_folds\n",
        "        fold_indices = []\n",
        "        for i in range(n_folds):\n",
        "            val_start = i * val_size\n",
        "            val_end = min(val_start + val_size, train_size)\n",
        "            val_idx = list(range(val_start, val_end))\n",
        "            train_idx = list(range(0, val_start)) + list(range(val_end, train_size))\n",
        "            fold_indices.append((train_idx, val_idx))\n",
        "\n",
        "        tqdm.write(f\"Computed {n_folds} folds, train_size={train_size}, val_size={val_size}\")\n",
        "        fold_batch_size = min(128, max(32, self.hyperparameters.get('batch_size', Config.BATCH_SIZE)))\n",
        "        total_train_batches = (train_size - val_size) // fold_batch_size + 1\n",
        "        total_val_batches = val_size // fold_batch_size + 1\n",
        "        tqdm.write(f\"Total: {train_size} samples, {fold_batch_size} batch_size, {n_folds} folds\")\n",
        "        tqdm.write(f\"Per fold: Train={train_size-val_size} samples ({total_train_batches} batches), Val={val_size} samples ({total_val_batches} batches)\")\n",
        "\n",
        "        tqdm.write(f\"\\n\\033[1;31mStarting {n_folds}-fold cross-validation for {self.model_name}\\033[0m\")\n",
        "\n",
        "        prefetch_factor = 2 if Config.DATALOADER_NUM_WORKERS > 0 else None\n",
        "        pin_memory=Config.PIN_MEMORY if 'cuda' in Config.DEVICE else False\n",
        "        num_workers = Config.DATALOADER_NUM_WORKERS if torch.cuda.is_available() else 0\n",
        "        use_prefetch = num_workers > 0\n",
        "\n",
        "        fold_results = []\n",
        "        for fold, (train_idx, val_idx) in enumerate(fold_indices, 1):\n",
        "            train_batches = len(train_idx) // fold_batch_size + 1\n",
        "            val_batches = len(val_idx) // fold_batch_size + 1\n",
        "            tqdm.write(f\"\\nFold {fold}/{n_folds}: Train={len(train_idx)} samples ({train_batches} batches), Val={len(val_idx)} samples ({val_batches} batches)\")\n",
        "\n",
        "            # Create fold-specific DataLoaders with GPU optimizations\n",
        "            fold_batch_size = min(128, max(32, self.hyperparameters.get('batch_size', Config.BATCH_SIZE)))  # Larger batches for GPU\n",
        "            train_subsampler = SubsetRandomSampler(train_idx)\n",
        "            val_subsampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "            # train_dataset_fold = Subset(dataset, train_idx)\n",
        "            # val_dataset_fold = Subset(dataset, val_idx)\n",
        "\n",
        "            # train_loader_fold = DataLoader(\n",
        "            #     dataset,\n",
        "            #     batch_size=fold_batch_size,\n",
        "            #     sampler=train_subsampler,\n",
        "            #     num_workers=2,  # Reduced workers\n",
        "            #     pin_memory=True,\n",
        "            #     persistent_workers=False,\n",
        "            #     prefetch_factor=2\n",
        "            # )\n",
        "            # val_loader_fold = DataLoader(\n",
        "            #     dataset,\n",
        "            #     batch_size=fold_batch_size,\n",
        "            #     sampler=val_subsampler,\n",
        "            #     num_workers=2,\n",
        "            #     pin_memory=True,\n",
        "            #     persistent_workers=False,\n",
        "            #     prefetch_factor=2\n",
        "            # )\n",
        "\n",
        "            train_loader_fold = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=fold_batch_size,\n",
        "                sampler=train_subsampler,\n",
        "                num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "                pin_memory=torch.cuda.is_available(),\n",
        "                prefetch_factor=2 if use_prefetch else None,\n",
        "                persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "                worker_init_fn=worker_init_fn\n",
        "            )\n",
        "\n",
        "            val_loader_fold = DataLoader(\n",
        "                dataset,\n",
        "                batch_size=fold_batch_size,\n",
        "                sampler=val_subsampler,\n",
        "                num_workers=num_workers,\n",
        "                pin_memory=torch.cuda.is_available(),\n",
        "                prefetch_factor=2 if use_prefetch else None,\n",
        "                persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "                worker_init_fn=worker_init_fn\n",
        "            )\n",
        "\n",
        "            # Initialize model for this fold\n",
        "            fold_model = ModelFactory.create_model(\n",
        "                self.model_name,\n",
        "                num_classes=Config.NUM_CLASSES,\n",
        "                dropout_rate=self.hyperparameters.get('dropout', 0.5),\n",
        "                hidden_dim_multiplier=self.hyperparameters.get('hidden_dim_multiplier', 0.5)\n",
        "            ).to(Config.DEVICE, memory_format=torch.channels_last)\n",
        "\n",
        "            fold_trainer = EnhancedModelTrainer(fold_model, self.model_name, self.hyperparameters)\n",
        "\n",
        "            # Train the fold\n",
        "            fold_history, fold_result = fold_trainer.train_main_model(\n",
        "                train_loader_fold, val_loader_fold, test_loader=None\n",
        "            )\n",
        "\n",
        "            # Check if fold training failed\n",
        "            if fold_history is None or fold_result is None:\n",
        "                tqdm.write(f\"Fold {fold} training failed, skipping...\")\n",
        "                fold_result = {\n",
        "                    'accuracy': 0.0,\n",
        "                    'f1_macro': 0.0,\n",
        "                    'conf_matrix': np.array([[]]),\n",
        "                    'true_labels': [],\n",
        "                    'predictions': [],\n",
        "                    'probabilities': np.zeros((0, Config.NUM_CLASSES)),\n",
        "                    'misclassified': []\n",
        "                }\n",
        "                fold_history = {\n",
        "                    'val_loss': [],\n",
        "                    'val_acc': []\n",
        "                }\n",
        "\n",
        "            # Validate fold results before saving\n",
        "            if not fold_history.get('val_loss') or not fold_history.get('val_acc') or not fold_result.get('true_labels'):\n",
        "                tqdm.write(f\"Fold {fold} has empty results, using defaults\")\n",
        "                fold_result = {\n",
        "                    'accuracy': 0.0,\n",
        "                    'f1_macro': 0.0,\n",
        "                    'conf_matrix': np.array([[]]),\n",
        "                    'true_labels': [],\n",
        "                    'predictions': [],\n",
        "                    'probabilities': np.zeros((0, Config.NUM_CLASSES)),\n",
        "                    'misclassified': []\n",
        "                }\n",
        "                fold_history = {\n",
        "                    'val_loss': [],\n",
        "                    'val_acc': []\n",
        "                }\n",
        "\n",
        "            # Debug: Print result content before saving\n",
        "            tqdm.write(f\"Saving fold {fold} - val_loss: {len(fold_history['val_loss'])}, true_labels: {len(fold_result.get('true_labels', []))}\")\n",
        "\n",
        "            # Store fold results\n",
        "            fold_results.append({\n",
        "                'history': {\n",
        "                    'val_loss': fold_history['val_loss'],\n",
        "                    'val_acc': fold_history['val_acc']\n",
        "                },\n",
        "                'result': {\n",
        "                    'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "                    'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "                    'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "                    'true_labels': torch.tensor(fold_result.get('true_labels', []), dtype=torch.int64),\n",
        "                    'predictions': torch.tensor(fold_result.get('predictions', []), dtype=torch.int64),\n",
        "                    'probabilities': torch.tensor(fold_result.get('probabilities', np.zeros((0, Config.NUM_CLASSES))), dtype=torch.float32),\n",
        "                    'misclassified': [{'image': item['image'].cpu(), 'true_label': item['true_label'], 'pred_label': item['pred_label']}\n",
        "                                    for item in fold_result.get('misclassified', [])] if fold_result.get('misclassified') else []\n",
        "                }\n",
        "            })\n",
        "\n",
        "            # Save fold results\n",
        "            fold_result_to_save = {\n",
        "                'history': {\n",
        "                    'val_loss': torch.tensor(fold_history['val_loss'], dtype=torch.float32),\n",
        "                    'val_acc': torch.tensor(fold_history['val_acc'], dtype=torch.float32)\n",
        "                },\n",
        "                'result': {\n",
        "                    'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "                    'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "                    'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "                    'true_labels': torch.tensor(fold_result.get('true_labels', []), dtype=torch.int64),\n",
        "                    'predictions': torch.tensor(fold_result.get('predictions', []), dtype=torch.int64),\n",
        "                    'probabilities': torch.tensor(fold_result.get('probabilities', np.zeros((0, Config.NUM_CLASSES))), dtype=torch.float32),\n",
        "                    'misclassified': [{'image': item['image'].cpu(), 'true_label': item['true_label'], 'pred_label': item['pred_label']}\n",
        "                                    for item in fold_result.get('misclassified', [])] if fold_result.get('misclassified') else []\n",
        "                }\n",
        "            }\n",
        "\n",
        "            fold_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{self.model_name}_fold_{fold}_results.pt\"\n",
        "            torch.save(fold_result_to_save, fold_result_path)\n",
        "            tqdm.write(f\"Saved fold {fold} results to {fold_result_path}\")\n",
        "\n",
        "        # # Train the fold\n",
        "        # fold_history, fold_result = fold_trainer.train_main_model(\n",
        "        #     train_loader_fold, val_loader_fold, test_loader=None\n",
        "        # )\n",
        "\n",
        "        # # if fold_history is None or fold_result is None:\n",
        "        # #     tqdm.write(f\"Fold {fold} training failed, skipping...\")\n",
        "        # #     continue\n",
        "\n",
        "        # # Store fold results\n",
        "        # fold_results.append({\n",
        "        #     'history': {\n",
        "        #         'val_loss': fold_history['val_loss'],\n",
        "        #         'val_acc': fold_history['val_acc']\n",
        "        #     },\n",
        "        #     'result': {\n",
        "        #         'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "        #         'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "        #         'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "        #         'true_labels': torch.tensor(fold_result.get('true_labels', []), dtype=torch.int64),\n",
        "        #         'predictions': torch.tensor(fold_result.get('predictions', []), dtype=torch.int64),\n",
        "        #         'probabilities': torch.tensor(fold_result.get('probabilities', np.zeros((0, Config.NUM_CLASSES))), dtype=torch.float32),\n",
        "        #         'misclassified': [{'image': item['image'].cpu(), 'true_label': item['true_label'], 'pred_label': item['pred_label'}\n",
        "        #                         for item in fold_result.get('misclassified', [])] if fold_result.get('misclassified') else []\n",
        "        #     }\n",
        "        # })\n",
        "\n",
        "        # # Save fold results\n",
        "        # fold_result_to_save = {\n",
        "        #     'history': {\n",
        "        #         'val_loss': torch.tensor(fold_history['val_loss'], dtype=torch.float32),\n",
        "        #         'val_acc': torch.tensor(fold_history['val_acc'], dtype=torch.float32)\n",
        "        #     },\n",
        "        #     'result': {\n",
        "        #         'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "        #         'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "        #         'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "        #         'true_labels': torch.tensor(fold_result.get('true_labels', []), dtype=torch.int64),\n",
        "        #         'predictions': torch.tensor(fold_result.get('predictions', []), dtype=torch.int64),\n",
        "        #         'probabilities': torch.tensor(fold_result.get('probabilities', np.zeros((0, Config.NUM_CLASSES))), dtype=torch.float32),\n",
        "        #         'misclassified': [{'image': item['image'].cpu(), 'true_label': item['true_label'], 'pred_label': item['pred_label'}\n",
        "        #                         for item in fold_result.get('misclassified', [])] if fold_result.get('misclassified') else []\n",
        "        #     }\n",
        "        # }\n",
        "\n",
        "        # fold_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{self.model_name}_fold_{fold}_results.pt\"\n",
        "        # torch.save(fold_result_to_save, fold_result_path)\n",
        "        # tqdm.write(f\"Saved fold {fold} results to {fold_result_path}\")\n",
        "\n",
        "        # Aggressive cleanup after fold\n",
        "        del fold_history, fold_result, fold_model, fold_trainer\n",
        "        del train_loader_fold, val_loader_fold, train_subsampler, val_subsampler\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "        gc.collect()\n",
        "\n",
        "        return fold_results\n",
        "\n",
        "\n",
        "    # def train(self, train_loader, val_loader, test_loader=None, visualizer=None, n_folds=3):\n",
        "    #     \"\"\"Original train method preserved for compatibility\"\"\"\n",
        "    #     history, result = self.train_main_model(train_loader, val_loader, test_loader)\n",
        "    #     fold_results = self.train_kfold(train_loader, val_loader, n_folds)\n",
        "    #     return history, result, self.model, fold_results\n",
        "\n",
        "\n",
        "# ---\n",
        "# 9. MODEL EVALUATION (FIXED)\n",
        "# =============================================================================\n",
        "class ModelEvaluator:\n",
        "    def evaluate_model(self, model, test_loader, model_name):\n",
        "        print(f\"Evaluating For Model: {model_name}...\")\n",
        "        try:\n",
        "            model.eval()\n",
        "            model.to(Config.DEVICE)\n",
        "\n",
        "            all_preds = []\n",
        "            all_labels = []\n",
        "            all_probs = []\n",
        "            misclassified = []\n",
        "            total_loss = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            # Check if test_loader is valid\n",
        "            if test_loader is None or len(test_loader.dataset) == 0:\n",
        "                print(f\"Warning: No test data available for {model_name}\")\n",
        "                return self._create_empty_result(model_name)\n",
        "\n",
        "            with torch.no_grad(), torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "                for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "                    images, labels = images.to(Config.DEVICE, non_blocking=True), labels.to(Config.DEVICE, non_blocking=True)\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                    # Collect batch results\n",
        "                    batch_loss = loss.item()\n",
        "                    total_loss += batch_loss\n",
        "\n",
        "                    batch_preds = predicted.cpu().numpy()\n",
        "                    batch_labels = labels.cpu().numpy()\n",
        "                    batch_probs = probabilities.cpu().numpy()\n",
        "\n",
        "                    all_preds.extend(batch_preds)\n",
        "                    all_labels.extend(batch_labels)\n",
        "                    all_probs.append(batch_probs)\n",
        "\n",
        "                    # Identify misclassified images\n",
        "                    incorrect_mask = predicted != labels\n",
        "                    if incorrect_mask.any():\n",
        "                        incorrect_images = images[incorrect_mask].cpu()\n",
        "                        incorrect_labels = labels[incorrect_mask].cpu().numpy()\n",
        "                        incorrect_preds = predicted[incorrect_mask].cpu().numpy()\n",
        "                        for img, true_label, pred_label in zip(incorrect_images, incorrect_labels, incorrect_preds):\n",
        "                            misclassified.append({\n",
        "                                'image': img,\n",
        "                                'true_label': int(true_label),\n",
        "                                'pred_label': int(pred_label)\n",
        "                            })\n",
        "\n",
        "                    # Memory cleanup\n",
        "                    del outputs, loss, predicted, probabilities\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "            if not all_labels or not all_preds:\n",
        "                print(f\"Warning: No test data processed for {model_name}\")\n",
        "                return self._create_empty_result(model_name)\n",
        "\n",
        "            if len(all_labels) != len(all_preds):\n",
        "                print(f\"Error: Data mismatch for {model_name} - labels: {len(all_labels)}, predictions: {len(all_preds)}\")\n",
        "                return self._create_empty_result(model_name)\n",
        "\n",
        "            all_preds = np.array(all_preds)\n",
        "            all_labels = np.array(all_labels)\n",
        "            all_probs = np.vstack(all_probs) if all_probs else np.zeros((0, Config.NUM_CLASSES))\n",
        "\n",
        "            accuracy = accuracy_score(all_labels, all_preds)\n",
        "            avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "            try:\n",
        "                f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "                f1_weighted = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "                precision_macro = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "                recall_macro = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "                f1_per_class = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "                precision_per_class = precision_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "                recall_per_class = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "                conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "            except Exception as e:\n",
        "                print(f\"Warning: Metrics computation failed for {model_name}: {e}\")\n",
        "                f1_macro = f1_weighted = precision_macro = recall_macro = 0.0\n",
        "                f1_per_class = precision_per_class = recall_per_class = np.zeros(Config.NUM_CLASSES)\n",
        "                conf_matrix = np.zeros((Config.NUM_CLASSES, Config.NUM_CLASSES))\n",
        "\n",
        "            print(f\"{model_name} Evaluation: Acc = {accuracy:.4f}, F1 (Macro) = {f1_macro:.4f}, Loss = {avg_loss:.4f}\")\n",
        "            print(f\"Data shapes - Labels: {all_labels.shape}, Predictions: {all_preds.shape}, Probabilities: {all_probs.shape}\")\n",
        "\n",
        "            return {\n",
        "                'model_name': model_name,\n",
        "                'accuracy': accuracy,\n",
        "                'f1_macro': f1_macro,\n",
        "                'f1_weighted': f1_weighted,\n",
        "                'precision_macro': precision_macro,\n",
        "                'recall_macro': recall_macro,\n",
        "                'f1_per_class': f1_per_class,\n",
        "                'precision_per_class': precision_per_class,\n",
        "                'recall_per_class': recall_per_class,\n",
        "                'predictions': all_preds,\n",
        "                'true_labels': all_labels,\n",
        "                'probabilities': all_probs,\n",
        "                'conf_matrix': conf_matrix,\n",
        "                'loss': avg_loss,\n",
        "                'misclassified': misclassified\n",
        "            }\n",
        "        except Exception as e:\n",
        "            print(f\"Evaluation error for {model_name}: {e}\")\n",
        "            return self._create_empty_result(model_name)\n",
        "# class ModelEvaluator:\n",
        "#     def evaluate_model(self, model, test_loader, model_name):\n",
        "#         print(f\"Evaluating For Model: {model_name}...\")\n",
        "#         model.eval()\n",
        "#         model.to(Config.DEVICE)\n",
        "\n",
        "#         all_preds = []\n",
        "#         all_labels = []\n",
        "#         all_probs = []\n",
        "#         misclassified = []\n",
        "#         total_loss = 0\n",
        "#         criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#         # Check if test_loader is valid\n",
        "#         if test_loader is None or len(test_loader.dataset) == 0:\n",
        "#             print(f\"Warning: No test data available for {model_name}\")\n",
        "#             return self._create_empty_result(model_name)\n",
        "\n",
        "#         with torch.no_grad(), torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "#             for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "#                 images, labels = images.to(Config.DEVICE, non_blocking=True), labels.to(Config.DEVICE, non_blocking=True)\n",
        "#                 outputs = model(images)\n",
        "#                 loss = criterion(outputs, labels)\n",
        "\n",
        "#                 probabilities = torch.softmax(outputs, dim=1)\n",
        "#                 _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "#                 # Collect batch results\n",
        "#                 batch_loss = loss.item()\n",
        "#                 total_loss += batch_loss\n",
        "\n",
        "#                 # FIXED: Proper data collection\n",
        "#                 batch_preds = predicted.cpu().numpy()\n",
        "#                 batch_labels = labels.cpu().numpy()\n",
        "#                 batch_probs = probabilities.cpu().numpy()\n",
        "\n",
        "#                 all_preds.extend(batch_preds)\n",
        "#                 all_labels.extend(batch_labels)\n",
        "#                 all_probs.append(batch_probs)\n",
        "\n",
        "#                 # Identify misclassified images\n",
        "#                 incorrect_mask = predicted != labels\n",
        "#                 if incorrect_mask.any():\n",
        "#                     incorrect_images = images[incorrect_mask].cpu()\n",
        "#                     incorrect_labels = labels[incorrect_mask].cpu().numpy()\n",
        "#                     incorrect_preds = predicted[incorrect_mask].cpu().numpy()\n",
        "#                     for img, true_label, pred_label in zip(incorrect_images, incorrect_labels, incorrect_preds):\n",
        "#                         misclassified.append({\n",
        "#                             'image': img,\n",
        "#                             'true_label': int(true_label),  # Ensure int type\n",
        "#                             'pred_label': int(pred_label)   # Ensure int type\n",
        "#                         })\n",
        "\n",
        "#                 # Memory cleanup\n",
        "#                 del outputs, loss, predicted, probabilities\n",
        "#                 torch.cuda.empty_cache()\n",
        "\n",
        "#         # FIXED: Better validation of collected data\n",
        "#         if not all_labels or not all_preds:\n",
        "#             print(f\"Warning: No test data processed for {model_name}\")\n",
        "#             return self._create_empty_result(model_name)\n",
        "\n",
        "#         if len(all_labels) != len(all_preds):\n",
        "#             print(f\"Error: Data mismatch for {model_name} - labels: {len(all_labels)}, predictions: {len(all_preds)}\")\n",
        "#             return self._create_empty_result(model_name)\n",
        "\n",
        "#         # Convert to numpy arrays\n",
        "#         all_preds = np.array(all_preds)\n",
        "#         all_labels = np.array(all_labels)\n",
        "#         all_probs = np.vstack(all_probs) if all_probs else np.zeros((0, Config.NUM_CLASSES))\n",
        "\n",
        "#         # Compute metrics\n",
        "#         accuracy = accuracy_score(all_labels, all_preds)\n",
        "#         avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "#         try:\n",
        "#             f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "#             f1_weighted = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "#             precision_macro = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "#             recall_macro = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "#             f1_per_class = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "#             precision_per_class = precision_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "#             recall_per_class = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "\n",
        "#             # Create confusion matrix\n",
        "#             conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print(f\"Warning: Metrics computation failed for {model_name}: {e}\")\n",
        "#             f1_macro = f1_weighted = precision_macro = recall_macro = 0.0\n",
        "#             f1_per_class = precision_per_class = recall_per_class = np.zeros(Config.NUM_CLASSES)\n",
        "#             conf_matrix = np.zeros((Config.NUM_CLASSES, Config.NUM_CLASSES))\n",
        "\n",
        "#         print(f\"{model_name} Evaluation: Acc = {accuracy:.4f}, F1 (Macro) = {f1_macro:.4f}, Loss = {avg_loss:.4f}\")\n",
        "#         print(f\"Data shapes - Labels: {all_labels.shape}, Predictions: {all_preds.shape}, Probabilities: {all_probs.shape}\")\n",
        "\n",
        "#         return {\n",
        "#             'model_name': model_name,\n",
        "#             'accuracy': accuracy,\n",
        "#             'f1_macro': f1_macro,\n",
        "#             'f1_weighted': f1_weighted,\n",
        "#             'precision_macro': precision_macro,\n",
        "#             'recall_macro': recall_macro,\n",
        "#             'f1_per_class': f1_per_class,\n",
        "#             'precision_per_class': precision_per_class,\n",
        "#             'recall_per_class': recall_per_class,\n",
        "#             'predictions': all_preds,      # FIXED: Return numpy array directly\n",
        "#             'true_labels': all_labels,     # FIXED: Return numpy array directly\n",
        "#             'probabilities': all_probs,    # FIXED: Return numpy array directly\n",
        "#             'conf_matrix': conf_matrix,    # FIXED: Added confusion matrix\n",
        "#             'loss': avg_loss,\n",
        "#             'misclassified': misclassified\n",
        "#         }\n",
        "\n",
        "#     def _create_empty_result(self, model_name):\n",
        "#         \"\"\"Helper method to create consistent empty results\"\"\"\n",
        "#         return {\n",
        "#             'model_name': model_name,\n",
        "#             'accuracy': 0.0,\n",
        "#             'f1_macro': 0.0,\n",
        "#             'f1_weighted': 0.0,\n",
        "#             'precision_macro': 0.0,\n",
        "#             'recall_macro': 0.0,\n",
        "#             'f1_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "#             'precision_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "#             'recall_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "#             'predictions': np.array([]),\n",
        "#             'true_labels': np.array([]),\n",
        "#             'probabilities': np.zeros((0, Config.NUM_CLASSES)),\n",
        "#             'conf_matrix': np.zeros((Config.NUM_CLASSES, Config.NUM_CLASSES)),\n",
        "#             'loss': float('inf'),\n",
        "#             'misclassified': []\n",
        "#         }\n",
        "\n",
        "\n",
        "# ---\n",
        "# 10. ENSEMBLE METHODS\n",
        "# =============================================================================\n",
        "# Purpose: Implement ensemble methods (simple, weighted, confidence-based, learnable).\n",
        "\n",
        "class EnsembleManager:\n",
        "    def __init__(self, models_dict, val_data):\n",
        "        self.models = models_dict\n",
        "        self.X_val, self.y_val = val_data\n",
        "        self.model_predictions = self._get_predictions()\n",
        "        self.histories = {}\n",
        "\n",
        "    def _get_predictions(self):\n",
        "        print(\"Getting model predictions for ensemble...\")\n",
        "        predictions = {}\n",
        "\n",
        "        val_dataset = FishDataset(self.X_val, self.y_val, DataManager.get_transforms(False))\n",
        "        val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            model.eval()\n",
        "            all_preds = []\n",
        "            all_probs = []\n",
        "            all_losses = []\n",
        "            all_labels = []\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    outputs = model(images)\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    loss = criterion(outputs, labels).item()\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    all_preds.extend(predicted.cpu().numpy())\n",
        "                    all_probs.extend(probabilities.cpu().numpy())\n",
        "                    all_losses.append(loss)\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = correct / total\n",
        "            f1 = f1_score(self.y_val, all_preds, average='macro')\n",
        "            avg_loss = np.mean(all_losses)\n",
        "\n",
        "            predictions[name] = {\n",
        "                'predictions': np.array(all_preds),\n",
        "                'probabilities': np.array(all_probs),\n",
        "                'loss': avg_loss,\n",
        "                'accuracy': accuracy,\n",
        "                'f1': f1,\n",
        "                'true_labels': np.array(all_labels)\n",
        "            }\n",
        "\n",
        "            print(f\"  {name}: F1 = {f1:.4f}, Acc = {accuracy:.4f}, Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def simple_average_ensemble(self, model_combo):\n",
        "        selected_probs = [self.model_predictions[name]['probabilities'] for name in model_combo]\n",
        "        avg_probs = np.mean(selected_probs, axis=0)\n",
        "        predictions = np.argmax(avg_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        avg_probs = np.mean(selected_probs, axis=0) if selected_probs else np.zeros((len(self.y_val), Config.NUM_CLASSES))\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            # 'probabilities': avg_probs,\n",
        "            'probabilities': avg_probs if avg_probs.ndim == 2 else np.zeros((0, Config.NUM_CLASSES)),\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def weighted_average_ensemble(self, model_combo):\n",
        "        weights = []\n",
        "        selected_probs = []\n",
        "\n",
        "        for name in model_combo:\n",
        "            f1 = self.model_predictions[name]['f1']\n",
        "            weights.append(f1)\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        weights = np.array(weights) / np.sum(weights)\n",
        "        weighted_probs = np.average(selected_probs, axis=0, weights=weights)\n",
        "        predictions = np.argmax(weighted_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.average([self.model_predictions[name]['loss'] for name in model_combo], weights=weights)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'weights': weights,\n",
        "            'models': model_combo,\n",
        "            'probabilities': weighted_probs,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def confidence_based_ensemble(self, model_combo):\n",
        "        final_predictions = []\n",
        "        all_probs = []\n",
        "\n",
        "        for i in range(len(self.y_val)):\n",
        "            confidences = []\n",
        "            probs = []\n",
        "\n",
        "            for name in model_combo:\n",
        "                prob = self.model_predictions[name]['probabilities'][i]\n",
        "                confidence = np.max(prob)\n",
        "                confidences.append(confidence)\n",
        "                probs.append(prob)\n",
        "\n",
        "            confidences = np.array(confidences)\n",
        "            weights = confidences / np.sum(confidences) if np.sum(confidences) > 0 else np.ones(len(confidences)) / len(confidences)\n",
        "\n",
        "            final_prob = np.average(probs, axis=0, weights=weights)\n",
        "            final_predictions.append(np.argmax(final_prob))\n",
        "            all_probs.append(final_prob)\n",
        "\n",
        "        predictions = np.array(final_predictions)\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'probabilities': np.array(all_probs),\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def learnable_weighted_ensemble(self, model_combo, epochs=30):\n",
        "        print(f\"Training learnable weighted ensemble with {len(model_combo)} models...\")\n",
        "\n",
        "        selected_probs = []\n",
        "        for name in model_combo:\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        ensemble_input = np.stack(selected_probs, axis=1)\n",
        "\n",
        "        X_ensemble = torch.FloatTensor(ensemble_input).to(Config.DEVICE)\n",
        "        y_ensemble = torch.LongTensor(self.y_val).to(Config.DEVICE)\n",
        "\n",
        "        ensemble_model = LearnableWeightedEnsemble(\n",
        "            num_models=len(model_combo),\n",
        "            num_classes=Config.NUM_CLASSES\n",
        "        ).to(Config.DEVICE)\n",
        "\n",
        "        optimizer = optim.AdamW(ensemble_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "        history = {'train_loss': [], 'train_acc': [], 'val_f1': []}\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            ensemble_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions, weights = ensemble_model(X_ensemble)\n",
        "            loss = criterion(predictions, y_ensemble)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            accuracy = accuracy_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy())\n",
        "            f1 = f1_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy(), average='macro')\n",
        "\n",
        "            history['train_loss'].append(loss.item())\n",
        "            history['train_acc'].append(accuracy)\n",
        "            history['val_f1'].append(f1)\n",
        "\n",
        "            print(f\"Ensemble Epoch {epoch+1}/{epochs}: Loss = {loss.item():.4f}, \"\n",
        "                  f\"Acc = {accuracy:.4f}, F1 = {f1:.4f}\")\n",
        "\n",
        "            if loss.item() < best_loss:\n",
        "                best_loss = loss.item()\n",
        "                torch.save(ensemble_model.state_dict(), f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\")\n",
        "\n",
        "        ensemble_model.load_state_dict(torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\"))\n",
        "        ensemble_model.eval()\n",
        "        with torch.no_grad():\n",
        "            final_predictions, learned_weights = ensemble_model(X_ensemble)\n",
        "            predictions = final_predictions.argmax(dim=1).cpu().numpy()\n",
        "            probabilities = torch.softmax(final_predictions, dim=1).cpu().numpy()\n",
        "            avg_weights = learned_weights.mean(dim=0).cpu().numpy()\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        self.histories[f\"learnable_weighted_{'+'.join(model_combo)}\"] = history\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'learned_weights': avg_weights,\n",
        "            'probabilities': probabilities,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def test_ensemble_combinations(self):\n",
        "        print(\"Testing ensemble combinations...\")\n",
        "\n",
        "        model_names = list(self.models.keys())\n",
        "        all_results = {}\n",
        "        best_result = None\n",
        "        best_score = 0\n",
        "\n",
        "        for size in range(2, min(len(model_names) + 1, 5)):\n",
        "            print(f\"Testing {size}-model combinations...\")\n",
        "\n",
        "            for combo in list(combinations(model_names, size))[:5]:\n",
        "                combo_name = f\"combo_{size}_{'+'.join(combo)}\"\n",
        "\n",
        "                for method_name in Config.ENSEMBLE_METHODS:\n",
        "                    full_name = f\"{combo_name}_{method_name}\"\n",
        "\n",
        "                    try:\n",
        "                        if method_name == 'simple_average':\n",
        "                            result = self.simple_average_ensemble(combo)\n",
        "                        elif method_name == 'weighted_average':\n",
        "                            result = self.weighted_average_ensemble(combo)\n",
        "                        elif method_name == 'confidence_based':\n",
        "                            result = self.confidence_based_ensemble(combo)\n",
        "                        elif method_name == 'learnable_weighted':\n",
        "                            result = self.learnable_weighted_ensemble(combo)\n",
        "\n",
        "                        # Verify result contains required keys\n",
        "                        required_keys = ['accuracy', 'f1', 'loss', 'predictions', 'models', 'probabilities', 'true_labels']\n",
        "                        if not all(key in result for key in required_keys):\n",
        "                            missing = [key for key in required_keys if key not in result]\n",
        "                            print(f\"  {full_name}: Missing keys {missing}\")\n",
        "                            continue\n",
        "                        # Ensure probabilities is 2D\n",
        "                        if 'probabilities' in result and (result['probabilities'].ndim != 2 or result['probabilities'].shape[1] != Config.NUM_CLASSES):\n",
        "                            result['probabilities'] = np.zeros((len(result['true_labels']), Config.NUM_CLASSES))\n",
        "\n",
        "                        all_results[full_name] = result\n",
        "                        print(f\"  {full_name}: F1 = {result['f1']:.4f}, Acc = {result['accuracy']:.4f}, \"\n",
        "                              f\"Loss = {result['loss']:.4f}, True Labels Shape = {result['true_labels'].shape}\")\n",
        "\n",
        "                        if result['f1'] > best_score:\n",
        "                            best_score = result['f1']\n",
        "                            best_result = (full_name, result)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"  {full_name}: FAILED - {str(e)}\")\n",
        "\n",
        "        if best_result:\n",
        "            print(f\"\\n‚úì Best ensemble: {best_result[0]} (F1: {best_result[1]['f1']:.4f})\")\n",
        "        else:\n",
        "            print(\"\\nNo valid ensemble results generated.\")\n",
        "\n",
        "        return all_results, best_result\n",
        "\n",
        "\n",
        "# ---\n",
        "# 11. ENHANCED VISUALIZATIONS\n",
        "# =============================================================================\n",
        "# Purpose: Generate visualizations for training history, ROC curves, confusion matrices, model comparisons, and XAI visualizations.\n",
        "\n",
        "class EnhancedVisualizations:\n",
        "    def __init__(self):\n",
        "        self.viz_dir = f\"{Config.OUTPUT_DIR}/visualizations\"\n",
        "        Path(self.viz_dir).mkdir(parents=True, exist_ok=True)\n",
        "        # Set better matplotlib parameters for spacing\n",
        "        plt.rcParams.update({\n",
        "            'figure.autolayout': True,\n",
        "            'axes.titlepad': 20,\n",
        "            'axes.labelpad': 10,\n",
        "            'xtick.major.pad': 8,\n",
        "            'ytick.major.pad': 8\n",
        "        })\n",
        "\n",
        "\n",
        "    def plot_single_model_history(self, history, model_name, alpha=0.2):  # (range: 0.1‚Äì0.3; lower = smoother, higher = more responsive)\n",
        "        \"\"\"Plot training history for individual model with better spacing\"\"\"\n",
        "        if not history['train_loss']:\n",
        "            print(f\"Skipping {model_name}: No training data available\")\n",
        "            return\n",
        "\n",
        "        # def smooth_ema(values, alpha):\n",
        "        #     \"\"\"Apply exponential moving average (EMA) smoothing to a list of values.\"\"\"\n",
        "        #     if not values:\n",
        "        #         return values\n",
        "        #     smoothed = [values[0]]\n",
        "        #     for val in values[1:]:\n",
        "        #         smoothed.append(alpha * val + (1 - alpha) * smoothed[-1])\n",
        "        #     return smoothed\n",
        "        def smooth_ema(values, alpha=0.1):\n",
        "            \"\"\"\n",
        "            Apply exponential moving average smoothing to a list or tensor of values.\n",
        "\n",
        "            Args:\n",
        "                values: List, NumPy array, or PyTorch tensor of numerical values\n",
        "                alpha: Smoothing factor (default: 0.1)\n",
        "\n",
        "            Returns:\n",
        "                List of smoothed values\n",
        "            \"\"\"\n",
        "            # Convert tensor to list if necessary\n",
        "            if torch.is_tensor(values):\n",
        "                values = values.cpu().numpy().tolist()\n",
        "            elif isinstance(values, np.ndarray):\n",
        "                values = values.tolist()\n",
        "\n",
        "            if not values:  # Check if the list is empty\n",
        "                return []\n",
        "\n",
        "            smoothed = [values[0]]\n",
        "            for i in range(1, len(values)):\n",
        "                smoothed.append(alpha * values[i] + (1 - alpha) * smoothed[-1])\n",
        "\n",
        "            return smoothed\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "        # Create subplot with more space\n",
        "        fig = plt.figure(figsize=(16, 10))\n",
        "        gs = fig.add_gridspec(2, 2, hspace=0.4, wspace=0.3)\n",
        "\n",
        "        # Loss plot\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        smoothed_train_loss = smooth_ema(history['train_loss'], alpha)\n",
        "        smoothed_val_loss = smooth_ema(history.get('val_loss', []), alpha)\n",
        "        ax1.plot(epochs, smoothed_train_loss, 'b-', linewidth=2, label='Train Loss', marker='o', markersize=4)\n",
        "        if smoothed_val_loss:\n",
        "            ax1.plot(epochs, smoothed_val_loss, 'r-', linewidth=2, label='Val Loss', marker='s', markersize=4)\n",
        "        ax1.set_title(f'{model_name} - Loss vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "        ax1.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
        "        ax1.legend(frameon=True, shadow=True, fontsize=11)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.tick_params(labelsize=10)\n",
        "\n",
        "        # Accuracy plot\n",
        "        ax2 = fig.add_subplot(gs[0, 1])\n",
        "        ax2.plot(epochs, history['train_acc'], 'g-', linewidth=2, label='Train Acc', marker='o', markersize=4)\n",
        "        if history.get('val_acc', []):\n",
        "            ax2.plot(epochs, history['val_acc'], 'm-', linewidth=2, label='Val Acc', marker='s', markersize=4)\n",
        "        ax2.set_title(f'{model_name} - Accuracy vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax2.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "        ax2.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "        ax2.legend(frameon=True, shadow=True, fontsize=11)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.tick_params(labelsize=10)\n",
        "\n",
        "        # F1 Score plot\n",
        "        ax3 = fig.add_subplot(gs[1, 0])\n",
        "        smoothed_val_f1 = smooth_ema(history.get('val_f1', []), alpha)\n",
        "        if smoothed_val_f1:\n",
        "            ax3.plot(epochs, smoothed_val_f1, 'orange', linewidth=2, label='Val F1', marker='d', markersize=4)\n",
        "            ax3.set_title(f'{model_name} - F1 Score vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "            ax3.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "            ax3.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
        "            ax3.legend(frameon=True, shadow=True, fontsize=11)\n",
        "            ax3.grid(True, alpha=0.3)\n",
        "            ax3.tick_params(labelsize=10)\n",
        "\n",
        "        # Learning Rate plot\n",
        "        ax4 = fig.add_subplot(gs[1, 1])\n",
        "        smoothed_lr = smooth_ema(history.get('learning_rates', []), alpha)\n",
        "        if smoothed_lr:\n",
        "            ax4.plot(epochs, smoothed_lr, 'purple', linewidth=2, label='Learning Rate', marker='x', markersize=6)\n",
        "            ax4.set_title(f'{model_name} - Learning Rate vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "            ax4.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "            ax4.set_ylabel('Learning Rate', fontsize=12, fontweight='bold')\n",
        "            ax4.legend(frameon=True, shadow=True, fontsize=11)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.tick_params(labelsize=10)\n",
        "            ax4.set_yscale('log')\n",
        "\n",
        "        plt.suptitle(f'{model_name} Training Progress', fontsize=18, fontweight='bold', y=0.98)\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_individual_training_history.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Individual training history saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "    def plot_single_model_xai(self, model, model_name, test_loader, max_images=5):\n",
        "        \"\"\"Generate XAI visualizations for a single model using Grad-CAM++, Integrated Gradients, and LRP\"\"\"\n",
        "        print(f\"Generating XAI visualizations for {model_name}...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # # Get sample images\n",
        "        # sample_images, sample_labels = next(iter(test_loader))\n",
        "        # sample_images = sample_images[:max_images].to(Config.DEVICE)\n",
        "        # sample_labels = sample_labels[:max_images].numpy()\n",
        "\n",
        "        # Get sample images\n",
        "        sample_images = []\n",
        "        sample_labels = []\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            class_mask = np.where(test_loader.dataset.labels == i)[0]\n",
        "            if len(class_mask) > 0:\n",
        "                idx = np.random.choice(class_mask)\n",
        "                image, label = test_loader.dataset[idx]\n",
        "                if image.dim() == 4:\n",
        "                    image = image.squeeze(0)\n",
        "                sample_images.append(image.to(Config.DEVICE))\n",
        "                sample_labels.append(label)\n",
        "\n",
        "\n",
        "        for idx, (image, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
        "            try:\n",
        "                # Create figure with larger size for clearer images\n",
        "                fig = plt.figure(figsize=(24, 8))  # Standard size for clear visualization\n",
        "                gs = fig.add_gridspec(1, 4, wspace=0.15, hspace=0.2)  # 4 columns: Original, Grad-CAM++, Integrated Gradients, LRP\n",
        "\n",
        "                # Prepare original image\n",
        "                image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                # Plot original image\n",
        "                ax_orig = fig.add_subplot(gs[0, 0])\n",
        "                ax_orig.imshow(image_np)\n",
        "                ax_orig.set_title(f'Original Image\\nTrue: {Config.CLASS_LABELS[true_label]}',\n",
        "                                 fontsize=14, fontweight='bold', pad=15)\n",
        "                ax_orig.axis('off')\n",
        "\n",
        "                # Forward pass for prediction\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(image.unsqueeze(0))\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    predicted_class = outputs.argmax(dim=1).item()\n",
        "                    confidence = probabilities[0, predicted_class].item()\n",
        "                    predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                # Generate Grad-CAM++ visualization\n",
        "                gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(model, image, predicted_class)\n",
        "                ax_gradcam = fig.add_subplot(gs[0, 1])\n",
        "                ax_gradcam.imshow(gradcam_img)\n",
        "                ax_gradcam.set_title(f'{model_name}\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                    fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_gradcam.axis('off')\n",
        "\n",
        "                # Generate Integrated Gradients visualization\n",
        "                ig_img, _ = xai_visualizer.integrated_gradients(model, image, predicted_class)\n",
        "                ax_ig = fig.add_subplot(gs[0, 2])\n",
        "                ax_ig.imshow(ig_img)\n",
        "                ax_ig.set_title(f'{model_name}\\nIntegrated Gradients', fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_ig.axis('off')\n",
        "\n",
        "                # Generate LRP visualization\n",
        "                lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, image, predicted_class)\n",
        "                ax_lrp = fig.add_subplot(gs[0, 3])\n",
        "                # ax_lrp.imshow(lrp_img)\n",
        "                ax_lrp.imshow(cv2.cvtColor(lrp_img, cv2.COLOR_BGR2RGB))\n",
        "                ax_lrp.set_title(f'{model_name}\\nLRP', fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_lrp.axis('off')\n",
        "\n",
        "                plt.suptitle(f'XAI Analysis for {model_name} - Image {idx+1}', fontsize=16, fontweight='bold', y=0.95)\n",
        "                save_path = f\"{self.viz_dir}/{model_name}_xai_image_{idx+1}.png\"\n",
        "                plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "                plt.show()\n",
        "                print(f\"XAI visualization saved: {save_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating XAI for {model_name}, image {idx+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "    def plot_confusion_matrix(self, results, model_name):\n",
        "        \"\"\"Enhanced confusion matrix with better spacing\"\"\"\n",
        "        if 'true_labels' not in results or 'predictions' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'predictions' in results for {model_name}\")\n",
        "            return\n",
        "\n",
        "        cm = confusion_matrix(results['true_labels'], results['predictions'])\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        # Create figure with better spacing\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "        # Use better color scheme and formatting\n",
        "        sns.heatmap(cm_normalized, annot=cm, fmt='d', cmap='Blues',\n",
        "                    xticklabels=Config.CLASS_LABELS, yticklabels=Config.CLASS_LABELS,\n",
        "                    cbar_kws={'label': 'Normalized Count', 'shrink': 0.8},\n",
        "                    square=True, linewidths=0.5, annot_kws={'size': 12})\n",
        "\n",
        "        # === Move colorbar label to the top ===\n",
        "        cbar = ax.collections[0].colorbar\n",
        "        cbar.ax.yaxis.set_label_position('left')   # keep label aligned left of bar\n",
        "        cbar.set_label(\"Normalized Count\", rotation=0, labelpad=15)\n",
        "        cbar.ax.yaxis.set_label_coords(-1.2, 1.02)  # fine-tune position (x, y)\n",
        "\n",
        "        ax.set_title(f'Confusion Matrix: {model_name}', fontsize=16, fontweight='bold', pad=25)\n",
        "        ax.set_xlabel('Predicted Label', fontsize=14, fontweight='bold', labelpad=15)\n",
        "        ax.set_ylabel('True Label', fontsize=14, fontweight='bold', labelpad=15)\n",
        "\n",
        "        # Rotate labels for better readability\n",
        "        plt.xticks(rotation=45, ha='right', fontsize=12)\n",
        "        plt.yticks(rotation=0, fontsize=12)\n",
        "\n",
        "        # Add performance metrics as text\n",
        "        accuracy = accuracy_score(results['true_labels'], results['predictions'])\n",
        "        f1_macro = f1_score(results['true_labels'], results['predictions'], average='macro')\n",
        "        f1_weighted = f1_score(results['true_labels'], results['predictions'], average='weighted')\n",
        "\n",
        "        metrics_text = f'Accuracy: {accuracy:.4f}\\nF1 (Macro): {f1_macro:.4f}\\nF1 (Weighted): {f1_weighted:.4f}'\n",
        "        ax.text(1.15, 0.5, metrics_text, transform=ax.transAxes, fontsize=12,\n",
        "                verticalalignment='center', bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_enhanced_confusion_matrix.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced confusion matrix saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_roc_curves(self, results, model_name):\n",
        "        \"\"\"Plot ROC curves for multi-class classification.\"\"\"\n",
        "        import numpy as np\n",
        "        \"\"\"Enhanced ROC curves with better spacing and styling for multiclass\"\"\"\n",
        "        if 'true_labels' not in results or 'probabilities' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'probabilities' in results for {model_name}\")\n",
        "            return\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, Config.NUM_CLASSES))\n",
        "        probabilities = np.array(results['probabilities'])\n",
        "        if len(results['true_labels']) == 0 or probabilities.size == 0 or probabilities.ndim != 2 or probabilities.shape[1] != Config.NUM_CLASSES:\n",
        "            print(f\"Warning: Invalid or empty probabilities shape {probabilities.shape} for {model_name}. Skipping ROC plot.\")\n",
        "            ax.text(0.5, 0.5, 'No data available for ROC', horizontalalignment='center', verticalalignment='center', fontsize=12)\n",
        "            return\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, Config.NUM_CLASSES))\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            y_true_bin = (np.array(results['true_labels']) == i).astype(int)\n",
        "            y_score = probabilities[:, i]\n",
        "\n",
        "            fpr, tpr, _ = roc_curve(y_true_bin, y_score)\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            ax.plot(fpr, tpr, color=colors[i], linewidth=2,\n",
        "                    label=f'{Config.CLASS_LABELS[i]} (AUC = {roc_auc:.4f})')\n",
        "\n",
        "        # Diagonal line\n",
        "        ax.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.6, label='Random Classifier')\n",
        "\n",
        "        ax.set_title(f'{model_name} - ROC Curves', fontsize=16, fontweight='bold', pad=20)\n",
        "        ax.set_xlabel('False Positive Rate', fontsize=14, fontweight='bold', labelpad=10)\n",
        "        ax.set_ylabel('True Positive Rate', fontsize=14, fontweight='bold', labelpad=10)\n",
        "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', frameon=True, shadow=True, fontsize=11)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_xlim([0.0, 1.0])\n",
        "        ax.set_ylim([0.0, 1.05])\n",
        "\n",
        "        # Compute micro-average ROC curve\n",
        "        y_true_bin = label_binarize(results['true_labels'], classes=range(Config.NUM_CLASSES))\n",
        "        fpr_micro, tpr_micro, _ = roc_curve(y_true_bin.ravel(), results['probabilities'].ravel())\n",
        "        roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
        "        ax.plot(fpr_micro, tpr_micro, 'deeppink', linestyle=':', linewidth=4,\n",
        "                label=f'Micro-average (AUC = {roc_auc_micro:.4f})')\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_enhanced_roc_curves.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced ROC curves saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_misclassified_images(self, misclassified, model_name):\n",
        "        \"\"\"Plot up to 4 misclassified images in a 2x2 grid with improved visibility.\"\"\"\n",
        "        import matplotlib.pyplot as plt\n",
        "        import numpy as np\n",
        "\n",
        "        if not misclassified:\n",
        "            print(f\"No misclassified images for {model_name}\")\n",
        "            return\n",
        "\n",
        "        # Select up to 4 misclassified images\n",
        "        misclassified = misclassified[:4]\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(10, 10))  # Slightly smaller size\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for idx, item in enumerate(misclassified):\n",
        "            image = item['image'].permute(1, 2, 0).cpu().numpy()  # Convert CHW -> HWC\n",
        "\n",
        "            # Normalize for display\n",
        "            if image.max() > 1.0:\n",
        "                image = image / 255.0\n",
        "            else:\n",
        "                image = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
        "            image = np.clip(image, 0, 1)\n",
        "\n",
        "            # Grayscale vs RGB\n",
        "            if image.shape[2] == 1:\n",
        "                image = image.squeeze()\n",
        "                axes[idx].imshow(image, cmap='gray')\n",
        "            else:\n",
        "                axes[idx].imshow(image)\n",
        "\n",
        "            # Titles with color\n",
        "            true_label = Config.CLASS_LABELS[item['true_label']]\n",
        "            pred_label = Config.CLASS_LABELS[item['pred_label']]\n",
        "            axes[idx].set_title(\n",
        "                f\"True: {true_label}\\nPred: {pred_label}\",\n",
        "                fontsize=11,\n",
        "                fontweight=\"bold\",\n",
        "                pad=12,\n",
        "                color=\"darkred\" if true_label != pred_label else \"darkgreen\"\n",
        "            )\n",
        "\n",
        "            axes[idx].axis(\"off\")\n",
        "            # Add white border around each image\n",
        "            for spine in axes[idx].spines.values():\n",
        "                spine.set_edgecolor(\"lightgray\")\n",
        "                spine.set_linewidth(3)\n",
        "\n",
        "        # Hide unused subplots (if <4 images)\n",
        "        for idx in range(len(misclassified), 4):\n",
        "            axes[idx].axis(\"off\")\n",
        "\n",
        "        plt.suptitle(\n",
        "            f\"Misclassified Images for {model_name}\",\n",
        "            fontsize=16,\n",
        "            fontweight=\"bold\",\n",
        "            y=0.99,\n",
        "            color=\"navy\"\n",
        "        )\n",
        "        plt.subplots_adjust(wspace=0.3, hspace=0.4)  # Increase padding between plots\n",
        "        save_path = f\"{self.viz_dir}/misclassified_{model_name}.png\"\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\", dpi=300, facecolor=\"white\")\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "        print(f\"Saved misclassified images plot for {model_name} at {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # # Alternative simpler version if the above still has issues\n",
        "    # def plot_misclassified_images_simple(self, misclassified, model_name):\n",
        "    #     \"\"\"Simplified version with basic image processing.\"\"\"\n",
        "    #     if not misclassified:\n",
        "    #         print(f\"No misclassified images for {model_name}\")\n",
        "    #         return\n",
        "\n",
        "    #     misclassified = misclassified[:4]\n",
        "    #     fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
        "    #     axes = axes.flatten()\n",
        "\n",
        "    #     for idx, item in enumerate(misclassified):\n",
        "    #         if idx >= 4:\n",
        "    #             break\n",
        "\n",
        "    #         # Get image tensor\n",
        "    #         image = item['image'].cpu().detach().numpy()\n",
        "\n",
        "    #         # Handle different tensor formats\n",
        "    #         if len(image.shape) == 3:\n",
        "    #             if image.shape[0] <= 3:  # Channels first (C, H, W)\n",
        "    #                 image = np.transpose(image, (1, 2, 0))\n",
        "\n",
        "    #         # Simple normalization to [0, 1]\n",
        "    #         image = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
        "\n",
        "    #         # Display\n",
        "    #         if len(image.shape) == 3 and image.shape[2] == 1:\n",
        "    #             axes[idx].imshow(image.squeeze(), cmap='gray')\n",
        "    #         else:\n",
        "    #             axes[idx].imshow(image, cmap='gray' if len(image.shape) == 2 else None)\n",
        "\n",
        "    #         axes[idx].set_title(f\"True: {item['true_label']}\\nPred: {item['pred_label']}\")\n",
        "    #         axes[idx].axis('off')\n",
        "\n",
        "    #     # Hide unused subplots\n",
        "    #     for idx in range(len(misclassified), 4):\n",
        "    #         axes[idx].axis('off')\n",
        "\n",
        "    #     plt.suptitle(f\"Misclassified Images - {model_name}\")\n",
        "    #     plt.tight_layout()\n",
        "    #     plt.show()\n",
        "    #     plt.close()\n",
        "\n",
        "\n",
        "\n",
        "    def plot_kfold_results(self, fold_results, model_name, test_loader):\n",
        "        \"\"\"Plot k-fold results: 2x2 grid per fold and 1x2 comparison across folds.\"\"\"\n",
        "        n_folds = len(fold_results)\n",
        "        plt.style.use('seaborn-v0_8')  # Use modern Seaborn style\n",
        "\n",
        "        # 2x2 Grid Plot for Each Fold\n",
        "        for fold in range(n_folds):\n",
        "            fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "            fig.suptitle(f'{model_name} - Fold {fold+1} Metrics', fontsize=16)\n",
        "            history = fold_results[fold]['history']\n",
        "\n",
        "            # Plot Validation Accuracy\n",
        "            axes[0, 0].plot(history['val_acc'], label='Validation Accuracy', marker='s')\n",
        "            axes[0, 0].set_title('Validation Accuracy')\n",
        "            axes[0, 0].set_xlabel('Epoch')\n",
        "            axes[0, 0].set_ylabel('Accuracy')\n",
        "            axes[0, 0].legend()\n",
        "            axes[0, 0].grid(True)\n",
        "\n",
        "            # Plot Validation Loss\n",
        "            axes[0, 1].plot(history['val_loss'], label='Validation Loss', marker='s')\n",
        "            axes[0, 1].set_title('Validation Loss')\n",
        "            axes[0, 1].set_xlabel('Epoch')\n",
        "            axes[0, 1].set_ylabel('Loss')\n",
        "            axes[0, 1].legend()\n",
        "            axes[0, 1].grid(True)\n",
        "\n",
        "            # Hide unused subplots\n",
        "            axes[1, 0].set_visible(False)\n",
        "            axes[1, 1].set_visible(False)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        # 1x2 Comparison Plot Across Folds\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        fig.suptitle(f'{model_name} - Cross-Fold Comparison', fontsize=16)\n",
        "\n",
        "        # Plot Validation Accuracy Across Folds\n",
        "        for fold in range(n_folds):\n",
        "            history = fold_results[fold]['history']\n",
        "            axes[0].plot(history['val_acc'], label=f'Fold {fold+1}', marker='s')\n",
        "        axes[0].set_title('Validation Accuracy Across Folds')\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Accuracy')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True)\n",
        "\n",
        "        # Plot Validation Loss Across Folds\n",
        "        for fold in range(n_folds):\n",
        "            history = fold_results[fold]['history']\n",
        "            axes[1].plot(history['val_loss'], label=f'Fold {fold+1}', marker='s')\n",
        "        axes[1].set_title('Validation Loss Across Folds')\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('Loss')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def plot_model_results(self, model_name, fold_results, test_loader):\n",
        "        \"\"\"Plot model results: ROC curves, confusion matrix, misclassified images, XAI, and k-fold results.\"\"\"\n",
        "        print(f\"Generating plots for {model_name}\")\n",
        "\n",
        "        # Plot single-model results using first fold's result\n",
        "        first_result = fold_results[0]['result']\n",
        "        self.plot_roc_curves(first_result, model_name)\n",
        "        self.plot_confusion_matrix(first_result, model_name)\n",
        "        self.plot_misclassified_images(first_result['misclassified'], model_name)\n",
        "\n",
        "        # Recreate model for XAI plotting\n",
        "        model = ModelFactory.create_model(\n",
        "            model_name,\n",
        "            num_classes=Config.NUM_CLASSES,\n",
        "            dropout_rate=0.5,  # Use default or pass from hyperparameters\n",
        "            hidden_dim_multiplier=0.5\n",
        "        ).to(Config.DEVICE)\n",
        "        self.plot_single_model_xai(model, model_name, test_loader)\n",
        "\n",
        "        # Plot k-fold results\n",
        "        self.plot_kfold_results(fold_results, model_name, test_loader)\n",
        "\n",
        "        print(\"Completed plotting k-fold results\")\n",
        "\n",
        "        # Clean up\n",
        "        del model, fold_results, first_result\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "        gc.collect()\n",
        "        # print(f\"Plotting memory cleared: {torch.cuda.memory_summary()}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def generate_comprehensive_report(self, single_results, ensemble_results, best_ensemble):\n",
        "        \"\"\"Generate a comprehensive visual report\"\"\"\n",
        "        # fig = plt.figure(figsize=(24, 16))\n",
        "        fig = plt.figure(figsize=(30, 20))\n",
        "        gs = fig.add_gridspec(3, 4, hspace=0.4, wspace=0.3, top=0.92, bottom=0.08, left=0.05, right=0.95)\n",
        "\n",
        "        # Title\n",
        "        fig.suptitle('Fish Species Classification - Comprehensive Analysis Report',\n",
        "                    fontsize=24, fontweight='bold', y=0.96)\n",
        "\n",
        "        # 1. Model Performance Comparison\n",
        "        ax1 = fig.add_subplot(gs[0, :2])\n",
        "        model_names = list(single_results.keys())\n",
        "        accuracies = [single_results[name]['accuracy'] for name in model_names]\n",
        "        f1_scores = [single_results[name]['f1_macro'] for name in model_names]\n",
        "\n",
        "        x = np.arange(len(model_names))\n",
        "        width = 0.35\n",
        "\n",
        "        bars1 = ax1.bar(x - width/2, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "        bars2 = ax1.bar(x + width/2, f1_scores, width, label='F1 Score', alpha=0.8, color='lightcoral')\n",
        "\n",
        "        ax1.set_xlabel('Models', fontweight='bold', fontsize=12)\n",
        "        ax1.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "        ax1.set_title('Individual Model Performance', fontweight='bold', fontsize=14, pad=15)\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "        ax1.legend(fontsize=11)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, 1.1)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar in bars1 + bars2:\n",
        "            height = bar.get_height()\n",
        "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                    f'{height:.4f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        # 2. Best vs Worst Model Comparison\n",
        "        ax2 = fig.add_subplot(gs[0, 2:])\n",
        "        if ensemble_results and best_ensemble:\n",
        "            best_single_f1 = max(f1_scores)\n",
        "            worst_single_f1 = min(f1_scores)\n",
        "            best_ensemble_f1 = best_ensemble[1]['f1']\n",
        "\n",
        "            categories = ['Worst Single', 'Best Single', 'Best Ensemble']\n",
        "            values = [worst_single_f1, best_single_f1, best_ensemble_f1]\n",
        "            colors = ['lightcoral', 'lightblue', 'gold']\n",
        "\n",
        "            bars = ax2.bar(categories, values, color=colors, alpha=0.8)\n",
        "            ax2.set_ylabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax2.set_title('Performance Comparison', fontweight='bold', fontsize=14, pad=15)\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.set_ylim(0, max(values) * 1.1)\n",
        "\n",
        "            for bar, value in zip(bars, values):\n",
        "                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                        f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "        # 3. Per-class Performance Heatmap\n",
        "        ax3 = fig.add_subplot(gs[1, :2])\n",
        "        per_class_f1 = []\n",
        "        for model_name in model_names:\n",
        "            per_class_f1.append(single_results[model_name]['f1_per_class'])\n",
        "\n",
        "        per_class_f1 = np.array(per_class_f1)\n",
        "        im = ax3.imshow(per_class_f1, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "        ax3.set_xticks(range(len(Config.CLASS_LABELS)))\n",
        "        ax3.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right')\n",
        "        ax3.set_yticks(range(len(model_names)))\n",
        "        ax3.set_yticklabels(model_names)\n",
        "        ax3.set_title('Per-Class F1 Scores Heatmap', fontweight='bold', fontsize=14, pad=15)\n",
        "\n",
        "        # Add colorbar\n",
        "        cbar = plt.colorbar(im, ax=ax3, shrink=0.8)\n",
        "        cbar.set_label('F1 Score', rotation=270, labelpad=15)\n",
        "\n",
        "        # Add text annotations\n",
        "        for i in range(len(model_names)):\n",
        "            for j in range(len(Config.CLASS_LABELS)):\n",
        "                text_color = 'white' if per_class_f1[i, j] < 0.5 else 'black'\n",
        "                ax3.text(j, i, f'{per_class_f1[i, j]:.2f}',\n",
        "                        ha=\"center\", va=\"center\", color=text_color, fontsize=8, fontweight='bold')\n",
        "\n",
        "        # 4. Ensemble Methods Performance\n",
        "        ax4 = fig.add_subplot(gs[1, 2:])\n",
        "        if ensemble_results:\n",
        "            ensemble_items = list(ensemble_results.items())\n",
        "            ensemble_items.sort(key=lambda x: x[1]['f1'], reverse=True)\n",
        "            top_ensembles = ensemble_items[:8]\n",
        "\n",
        "            ensemble_names = [name.split('_')[-1] for name, _ in top_ensembles]\n",
        "            ensemble_f1s = [result['f1'] for _, result in top_ensembles]\n",
        "\n",
        "            bars = ax4.barh(range(len(ensemble_names)), ensemble_f1s, alpha=0.8, color='lightgreen')\n",
        "            ax4.set_yticks(range(len(ensemble_names)))\n",
        "            ax4.set_yticklabels(ensemble_names)\n",
        "            ax4.set_xlabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax4.set_title('Top Ensemble Methods', fontweight='bold', fontsize=14, pad=15)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "\n",
        "            for bar, value in zip(bars, ensemble_f1s):\n",
        "                ax4.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,\n",
        "                        f'{value:.4f}', ha='left', va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "        # 5. Summary Statistics Table\n",
        "        ax5 = fig.add_subplot(gs[2, :])\n",
        "        ax5.axis('off')\n",
        "\n",
        "        # Create summary data\n",
        "        summary_data = []\n",
        "        for model_name in model_names:\n",
        "            result = single_results[model_name]\n",
        "            summary_data.append([\n",
        "                model_name,\n",
        "                f\"{result['accuracy']:.4f}\",\n",
        "                f\"{result['f1_macro']:.4f}\",\n",
        "                f\"{result['f1_weighted']:.4f}\",\n",
        "                f\"{result['precision_macro']:.4f}\",\n",
        "                f\"{result['recall_macro']:.4f}\"\n",
        "            ])\n",
        "\n",
        "        if ensemble_results and best_ensemble:\n",
        "            best_result = best_ensemble[1]\n",
        "            summary_data.append([\n",
        "                f\"Best Ensemble\\n({best_ensemble[0]})\",\n",
        "                f\"{best_result['accuracy']:.4f}\",\n",
        "                f\"{best_result['f1']:.4f}\",\n",
        "                \"N/A\",\n",
        "                \"N/A\",\n",
        "                \"N/A\"\n",
        "            ])\n",
        "\n",
        "        columns = ['Model', 'Accuracy', 'F1 (Macro)', 'F1 (Weighted)', 'Precision', 'Recall']\n",
        "\n",
        "        table = ax5.table(cellText=summary_data, colLabels=columns, loc='center', cellLoc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1.2, 2)\n",
        "\n",
        "        # Style the table\n",
        "        for i in range(len(columns)):\n",
        "            table[(0, i)].set_facecolor('#4CAF50')\n",
        "            table[(0, i)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "        for i in range(1, len(summary_data) + 1):\n",
        "            for j in range(len(columns)):\n",
        "                if i % 2 == 0:\n",
        "                    table[(i, j)].set_facecolor('#f0f0f0')\n",
        "                else:\n",
        "                    table[(i, j)].set_facecolor('white')\n",
        "\n",
        "        ax5.set_title('Model Performance Summary', fontweight='bold', fontsize=16, pad=20)\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/comprehensive_report.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Comprehensive report saved: {save_path}\")\n",
        "        return save_path\n",
        "\n",
        "\n",
        "\n",
        "    def plot_model_comparison(self, single_results, ensemble_results):\n",
        "        \"\"\"Enhanced model comparison with better spacing\"\"\"\n",
        "        # fig = plt.figure(figsize=(20, 16))\n",
        "        fig = plt.figure(figsize=(30, 20))\n",
        "        gs = fig.add_gridspec(2, 2, hspace=0.4, wspace=0.3, top=0.92, bottom=0.08)\n",
        "\n",
        "        model_names = list(single_results.keys())\n",
        "        accuracies = [single_results[name]['accuracy'] for name in model_names]\n",
        "        f1_scores = [single_results[name]['f1_macro'] for name in model_names]\n",
        "        f1_weighted = [single_results[name]['f1_weighted'] for name in model_names]\n",
        "        losses = [single_results[name]['loss'] for name in model_names]\n",
        "\n",
        "        x = np.arange(len(model_names))\n",
        "        width = 0.2\n",
        "\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        bars1 = ax1.bar(x - width*1.5, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "        bars2 = ax1.bar(x - width/2, f1_scores, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "        bars3 = ax1.bar(x + width/2, f1_weighted, width, label='F1 (Weighted)', alpha=0.8, color='lightgreen')\n",
        "        bars4 = ax1.bar(x + width*1.5, losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "        ax1.set_xlabel('Models', fontweight='bold', fontsize=12)\n",
        "        ax1.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "        ax1.set_title('Individual Model Performance', fontweight='bold', fontsize=14, pad=20)\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(model_names, rotation=45, ha='right', fontsize=10)\n",
        "        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, max(max(accuracies), max(f1_scores), max(f1_weighted), max(losses)) * 1.1)\n",
        "\n",
        "        if ensemble_results:\n",
        "            ensemble_items = list(ensemble_results.items())\n",
        "            ensemble_items.sort(key=lambda x: x[1]['f1'], reverse=True)\n",
        "            top_ensembles = ensemble_items[:10]\n",
        "\n",
        "            ensemble_names = [name.split('_')[-1] for name, _ in top_ensembles]\n",
        "            ensemble_f1s = [result['f1'] for _, result in top_ensembles]\n",
        "            ensemble_accs = [result['accuracy'] for _, result in top_ensembles]\n",
        "            ensemble_losses = [result['loss'] for _, result in top_ensembles]\n",
        "\n",
        "            x = np.arange(len(ensemble_names))\n",
        "            ax2 = fig.add_subplot(gs[0, 1])\n",
        "            ax2.bar(x - width, ensemble_accs, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "            ax2.bar(x, ensemble_f1s, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "            ax2.bar(x + width, ensemble_losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "            ax2.set_xticks(x)\n",
        "            ax2.set_xticklabels([f\"{name}\" for name in ensemble_names], rotation=45, ha='right', fontsize=10)\n",
        "            ax2.set_xlabel('Ensemble Methods', fontweight='bold', fontsize=12)\n",
        "            ax2.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "            ax2.set_title('Top Ensemble Methods', fontweight='bold', fontsize=14, pad=20)\n",
        "            ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.set_ylim(0, max(max(ensemble_accs), max(ensemble_f1s), max(ensemble_losses)) * 1.1)\n",
        "\n",
        "        if single_results:\n",
        "            per_class_f1 = []\n",
        "            for model_name in model_names:\n",
        "                per_class_f1.append(single_results[model_name]['f1_per_class'])\n",
        "\n",
        "            per_class_f1 = np.array(per_class_f1)\n",
        "            ax3 = fig.add_subplot(gs[1, 0])\n",
        "            im = ax3.imshow(per_class_f1, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "            ax3.set_xticks(range(len(Config.CLASS_LABELS)))\n",
        "            ax3.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right', fontsize=10)\n",
        "            ax3.set_yticks(range(len(model_names)))\n",
        "            ax3.set_yticklabels(model_names, fontsize=10)\n",
        "            ax3.set_title('Per-Class F1 Scores', fontweight='bold', fontsize=14, pad=20)\n",
        "\n",
        "            cbar = plt.colorbar(im, ax=ax3, shrink=0.8)\n",
        "            cbar.set_label('F1 Score', rotation=270, labelpad=15)\n",
        "\n",
        "            for i in range(len(model_names)):\n",
        "                for j in range(len(Config.CLASS_LABELS)):\n",
        "                    text_color = 'white' if per_class_f1[i, j] < 0.5 else 'black'\n",
        "                    ax3.text(j, i, f'{per_class_f1[i, j]:.2f}',\n",
        "                            ha=\"center\", va=\"center\", color=text_color, fontsize=8)\n",
        "\n",
        "        if ensemble_results:\n",
        "            best_single_f1 = max(f1_scores)\n",
        "            best_single_name = model_names[f1_scores.index(best_single_f1)]\n",
        "            best_ensemble_f1 = max([result['f1'] for result in ensemble_results.values()])\n",
        "            best_ensemble_name = max(ensemble_results.items(), key=lambda x: x[1]['f1'])[0]\n",
        "\n",
        "            ax4 = fig.add_subplot(gs[1, 1])\n",
        "            categories = ['Best Single\\nModel', 'Best Ensemble']\n",
        "            values = [best_single_f1, best_ensemble_f1]\n",
        "            colors = ['lightblue', 'gold']\n",
        "\n",
        "            bars = ax4.bar(categories, values, color=colors, alpha=0.8, width=0.6)\n",
        "            ax4.set_ylabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax4.set_title('Single vs Ensemble Comparison', fontweight='bold', fontsize=14, pad=20)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.set_ylim(0, 1)\n",
        "\n",
        "            for bar, value in zip(bars, values):\n",
        "                ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "                        f'{value:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
        "\n",
        "            improvement = ((best_ensemble_f1 - best_single_f1) / best_single_f1) * 100\n",
        "            ax4.text(0.5, 0.5, f'Improvement:\\n{improvement:.2f}%',\n",
        "                    transform=ax4.transAxes, ha='center', va='center',\n",
        "                    fontsize=14, fontweight='bold',\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"yellow\", alpha=0.8))\n",
        "\n",
        "        plt.suptitle('Fish Species Classification - Model Comparison Analysis',\n",
        "                    fontsize=18, fontweight='bold', y=0.96)\n",
        "        save_path = f\"{self.viz_dir}/enhanced_model_comparison.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced model comparison saved: {save_path}\")\n",
        "        return save_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_lrp_grid(self, single_models, test_loader):\n",
        "        print(\"Generating LRP grid visualization for TP, TN, FP, FN...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # Compute predictions and confusion matrix\n",
        "        model = list(single_models.values())[0]\n",
        "        model.eval()\n",
        "        true_labels = []\n",
        "        pred_labels = []\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                # images, labels = batch['image'].to(Config.DEVICE), batch['label'].to(Config.DEVICE)\n",
        "                images, labels = batch[0].to(Config.DEVICE), batch[1].to(Config.DEVICE)  # Access tuple elements\n",
        "                outputs = model(images)\n",
        "                preds = outputs.argmax(dim=1) if outputs.dim() > 1 else (outputs > 0.5).float()\n",
        "                true_labels.extend(labels.cpu().numpy())\n",
        "                pred_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "        cm = confusion_matrix(true_labels, pred_labels)\n",
        "        classes = Config.CLASS_LABELS\n",
        "        tp = np.diag(cm)\n",
        "        fp = cm.sum(axis=0) - tp\n",
        "        fn = cm.sum(axis=1) - tp\n",
        "        tn = cm.sum() - (fp + fn + tp)\n",
        "        metrics = [tp, tn, fp, fn]\n",
        "\n",
        "        # Collect one image per class per category (TP, TN, FP, FN)\n",
        "        sample_images = {cls: {\"TP\": None, \"TN\": None, \"FP\": None, \"FN\": None} for cls in range(5)}\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                # images, labels = batch['image'].to(Config.DEVICE), batch['label'].to(Config.DEVICE)\n",
        "                images, labels = batch[0].to(Config.DEVICE), batch[1].to(Config.DEVICE)  # Access tuple elements\n",
        "                outputs = model(images)\n",
        "                preds = outputs.argmax(dim=1) if outputs.dim() > 1 else (outputs > 0.5).float()\n",
        "                for img, true, pred in zip(images, labels, preds):\n",
        "                    cls = int(true.item())\n",
        "                    pred_cls = int(pred.item())\n",
        "                    for i in range(5):  # Check for each class\n",
        "                        category = {\n",
        "                            (1, 1): \"TP\",  # Predicted class i, true class i\n",
        "                            (0, 0): \"TN\",  # Predicted not i, true not i\n",
        "                            (1, 0): \"FP\",  # Predicted i, true not i\n",
        "                            (0, 1): \"FN\"   # Predicted not i, true i\n",
        "                        }[(1 if pred_cls == i else 0, 1 if cls == i else 0)]\n",
        "                        if sample_images[cls][category] is None:\n",
        "                            sample_images[cls][category] = (img, true)\n",
        "                    if all(sample_images[c][cat] is not None for c in range(5) for cat in [\"TP\", \"TN\", \"FP\", \"FN\"]):\n",
        "                        break\n",
        "                if all(sample_images[c][cat] is not None for c in range(5) for cat in [\"TP\", \"TN\", \"FP\", \"FN\"]):\n",
        "                    break\n",
        "\n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(5, 4, figsize=(30, 35))  # Large figure for clarity\n",
        "        for i in range(5):  # Classes\n",
        "            for j, category in enumerate([\"TP\", \"TN\", \"FP\", \"FN\"]):\n",
        "                ax = axes[i, j]\n",
        "                if sample_images[i][category] is not None:\n",
        "                    img, true = sample_images[i][category]\n",
        "                    img = img.squeeze().cpu()\n",
        "                    lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, img, i)\n",
        "                    img = img.permute(1, 2, 0).numpy()\n",
        "                    img = np.clip(img, 0, 1)\n",
        "                    img = img[..., [2, 1, 0]] if img.shape[2] == 3 else img  # Convert BGR to RGB\n",
        "                    img = (img * 255).astype(np.uint8)\n",
        "                    ax.imshow(img)\n",
        "                    lrp_img = (lrp_img - lrp_img.min()) / (lrp_img.max() - lrp_img.min() + 1e-8)  # Normalize heatmap\n",
        "                    ax.imshow(lrp_img, cmap='jet', alpha=0.4, vmin=0, vmax=np.percentile(lrp_img, 95))\n",
        "                    ax.set_title(f'{classes[i]} - {category}: {metrics[j][i]}', fontsize=16, fontweight='bold', pad=10)\n",
        "                ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        save_path = f\"{self.viz_dir}/lrp_fish_metrics_grid.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"LRP grid visualization saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_comparative_xai(self, single_models, ensemble_results, test_loader, max_images=5):\n",
        "        \"\"\"Generate comparative XAI visualizations with Grad-CAM++, Integrated Gradients, and LRP in the same row\"\"\"\n",
        "        print(f\"Generating comparative XAI visualizations for {max_images} images...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # Get sample images\n",
        "        # sample_images, sample_labels = next(iter(test_loader))\n",
        "        # sample_images = sample_images[:max_images].to(Config.DEVICE)\n",
        "        # sample_labels = sample_labels[:max_images].numpy()\n",
        "        sample_images = []\n",
        "        sample_labels = []\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            class_mask = np.where(test_loader.dataset.labels == i)[0]\n",
        "            if len(class_mask) > 0:\n",
        "                idx = np.random.choice(class_mask)\n",
        "                image, label = test_loader.dataset[idx]\n",
        "                if image.dim() == 4:\n",
        "                    image = image.squeeze(0)\n",
        "                sample_images.append(image.to(Config.DEVICE))\n",
        "                sample_labels.append(label)\n",
        "        sample_images = sample_images[:max_images]\n",
        "        sample_labels = sample_labels[:max_images]\n",
        "\n",
        "        # Get best ensemble if available\n",
        "        best_ensemble_name = max(ensemble_results.items(), key=lambda x: x[1]['f1'])[0] if ensemble_results else None\n",
        "        best_ensemble = ensemble_results.get(best_ensemble_name, None) if best_ensemble_name else None\n",
        "\n",
        "        for idx, (image, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
        "            try:\n",
        "                # Adjusted figure size with more height per row to prevent text cropping\n",
        "                num_rows = len(single_models) + (1 if best_ensemble else 0)\n",
        "                fig = plt.figure(figsize=(36, 14 * num_rows))  # Increased width and height per row\n",
        "                gs = fig.add_gridspec(num_rows, 4, wspace=0.3, hspace=0.5)  # Increased wspace and hspace for better spacing\n",
        "\n",
        "                # Prepare original image\n",
        "                image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                # Plot original image spanning all rows in first column\n",
        "                ax_orig = fig.add_subplot(gs[:, 0])\n",
        "                ax_orig.imshow(image_np)\n",
        "                ax_orig.set_title(f'Original Image\\nTrue: {Config.CLASS_LABELS[true_label]}',\n",
        "                                fontsize=16, fontweight='bold', pad=30)  # Increased pad for title\n",
        "                ax_orig.axis('off')\n",
        "\n",
        "                # Plot XAI for single models\n",
        "                for row, (model_name, model) in enumerate(single_models.items()):\n",
        "                    model.eval()\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(image.unsqueeze(0))\n",
        "                        probabilities = torch.softmax(outputs, dim=1)\n",
        "                        predicted_class = outputs.argmax(dim=1).item()\n",
        "                        confidence = probabilities[0, predicted_class].item()\n",
        "                        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                    # Generate Grad-CAM++ visualization\n",
        "                    gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(model, image, predicted_class)\n",
        "\n",
        "                    # Plot Grad-CAM++ in second column\n",
        "                    ax_gradcam = fig.add_subplot(gs[row, 1])\n",
        "                    ax_gradcam.imshow(gradcam_img)\n",
        "                    ax_gradcam.set_title(f'{model_name}\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                        fontsize=14, fontweight='bold', pad=30)  # Increased pad\n",
        "                    ax_gradcam.axis('off')\n",
        "\n",
        "                    # Generate Integrated Gradients visualization\n",
        "                    ig_img, _ = xai_visualizer.integrated_gradients(model, image, predicted_class)\n",
        "\n",
        "                    # Plot Integrated Gradients in third column\n",
        "                    ax_ig = fig.add_subplot(gs[row, 2])\n",
        "                    ax_ig.imshow(ig_img)\n",
        "                    ax_ig.set_title(f'{model_name}\\nIntegrated Gradients', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_ig.axis('off')\n",
        "\n",
        "                    # Generate LRP visualization\n",
        "                    lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, image, predicted_class)\n",
        "\n",
        "                    # Plot LRP in fourth column\n",
        "                    ax_lrp = fig.add_subplot(gs[row, 3])\n",
        "                    # ax_lrp.imshow(lrp_img)\n",
        "                    ax_lrp.imshow(cv2.cvtColor(lrp_img, cv2.COLOR_BGR2RGB))\n",
        "                    ax_lrp.set_title(f'{model_name}\\nLRP', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_lrp.axis('off')\n",
        "\n",
        "                # Plot XAI for best ensemble (if available)\n",
        "                if best_ensemble:\n",
        "                    ensemble_models = best_ensemble['models']\n",
        "                    with torch.no_grad():\n",
        "                        model_probs = []\n",
        "                        for model_name in ensemble_models:\n",
        "                            model = single_models[model_name]\n",
        "                            outputs = model(image.unsqueeze(0))\n",
        "                            probs = torch.softmax(outputs, dim=1)\n",
        "                            model_probs.append(probs)\n",
        "                        model_probs = torch.stack(model_probs, dim=1)\n",
        "\n",
        "                        # Load learnable ensemble model if applicable\n",
        "                        if 'learnable_weighted' in best_ensemble_name:\n",
        "                            ensemble_model = LearnableWeightedEnsemble(\n",
        "                                num_models=len(ensemble_models),\n",
        "                                num_classes=Config.NUM_CLASSES\n",
        "                            ).to(Config.DEVICE)\n",
        "                            ensemble_model.load_state_dict(\n",
        "                                torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(ensemble_models)}.pt\")\n",
        "                            )\n",
        "                            ensemble_model.eval()\n",
        "                            outputs, _ = ensemble_model(model_probs)\n",
        "                        else:\n",
        "                            weights = best_ensemble.get('weights', np.ones(len(ensemble_models)) / len(ensemble_models))\n",
        "                            outputs = torch.sum(model_probs * torch.tensor(weights, device=Config.DEVICE).view(1, -1, 1), dim=1)\n",
        "\n",
        "                        predicted_class = outputs.argmax(dim=1).item()\n",
        "                        confidence = torch.softmax(outputs, dim=1)[0, predicted_class].item()\n",
        "                        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                    # Approximate ensemble Grad-CAM++ by averaging\n",
        "                    gradcam_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(single_models[model_name], image, predicted_class)\n",
        "                        gradcam_imgs.append(gradcam_img)\n",
        "                    ensemble_gradcam = np.mean(gradcam_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble Grad-CAM++ in second column\n",
        "                    ax_gradcam = fig.add_subplot(gs[num_rows-1, 1])\n",
        "                    ax_gradcam.imshow(ensemble_gradcam)\n",
        "                    ax_gradcam.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                        fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_gradcam.axis('off')\n",
        "\n",
        "                    # Approximate ensemble Integrated Gradients by averaging\n",
        "                    ig_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        ig_img, _ = xai_visualizer.integrated_gradients(single_models[model_name], image, predicted_class)\n",
        "                        ig_imgs.append(ig_img)\n",
        "                    ensemble_ig = np.mean(ig_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble Integrated Gradients in third column\n",
        "                    ax_ig = fig.add_subplot(gs[num_rows-1, 2])\n",
        "                    ax_ig.imshow(ensemble_ig)\n",
        "                    ax_ig.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nIntegrated Gradients', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_ig.axis('off')\n",
        "\n",
        "                    # Approximate ensemble LRP by averaging\n",
        "                    lrp_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(single_models[model_name], image, predicted_class)\n",
        "                        lrp_imgs.append(lrp_img)\n",
        "                    ensemble_lrp = np.mean(lrp_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble LRP in fourth column\n",
        "                    ax_lrp = fig.add_subplot(gs[num_rows-1, 3])\n",
        "                    ax_lrp.imshow(ensemble_lrp)\n",
        "                    ax_lrp.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nLRP', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_lrp.axis('off')\n",
        "\n",
        "                # Adjusted suptitle with increased padding\n",
        "                plt.suptitle(f'Comparative XAI Analysis - Image {idx+1}', fontsize=18, fontweight='bold', y=0.97)\n",
        "                plt.tight_layout(rect=[0, 0, 1, 0.95])  # Added rect to ensure suptitle is not cropped\n",
        "                save_path = f\"{self.viz_dir}/comparative_xai_image_{idx+1}.png\"\n",
        "                plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "                plt.show()\n",
        "                print(f\"Comparative XAI visualization saved: {save_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating comparative XAI for image {idx+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "\n",
        "\n",
        "# ---\n",
        "# 12. FULLY FIXED XAI VISUALIZATIONS\n",
        "# =============================================================================\n",
        "# Purpose: Implement corrected Grad-CAM++ and LRP with proper tensor handling.\n",
        "\n",
        "class XAIVisualizer:\n",
        "    @staticmethod\n",
        "    def grad_cam_plus_plus(model, image, target_class):\n",
        "        \"\"\"Implement Grad-CAM++ for visualizing important image regions.\"\"\"\n",
        "        if image.dim() == 4:\n",
        "            image = image.squeeze(0)  # Normalize to (C, H, W)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Find the last convolutional layer\n",
        "        target_layer = None\n",
        "        for name, module in model.named_modules():  # Corrected: removed redundant reversed\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                target_layer = module\n",
        "\n",
        "        if target_layer is None:\n",
        "            raise ValueError(\"No convolutional layer found in the model\")\n",
        "\n",
        "        # Hook to capture gradients and activations\n",
        "        gradients = []\n",
        "        activations = []\n",
        "\n",
        "        def forward_hook(module, input, output):\n",
        "            activations.append(output.detach())\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            gradients.append(grad_output[0].detach())\n",
        "\n",
        "        # Register hooks\n",
        "        forward_handle = target_layer.register_forward_hook(forward_hook)\n",
        "        backward_handle = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "        try:\n",
        "            # Forward pass\n",
        "            image_tensor = image.unsqueeze(0).requires_grad_(True)\n",
        "            output = model(image_tensor)\n",
        "\n",
        "            # Backward pass\n",
        "            model.zero_grad()\n",
        "            score = output[0, target_class]\n",
        "            score.backward()\n",
        "\n",
        "            # Get gradients and activations\n",
        "            if not gradients or not activations:\n",
        "                raise ValueError(\"No gradients or activations captured\")\n",
        "\n",
        "            grad = gradients[0]  # Shape: (1, C, H, W)\n",
        "            act = activations[0]  # Shape: (1, C, H, W)\n",
        "\n",
        "            # Grad-CAM++ calculations\n",
        "            alpha_num = grad.pow(2)\n",
        "            alpha_denom = 2.0 * grad.pow(2) + (act * grad.pow(3)).sum(dim=(2, 3), keepdim=True)\n",
        "            alpha_denom = torch.where(alpha_denom != 0, alpha_denom, torch.ones_like(alpha_denom))\n",
        "            alpha = alpha_num / alpha_denom\n",
        "\n",
        "            weights = (alpha * F.relu(grad)).sum(dim=(2, 3))  # Shape: (1, C)\n",
        "            cam = (weights.unsqueeze(-1).unsqueeze(-1) * act).sum(dim=1, keepdim=True)  # Shape: (1, 1, H, W)\n",
        "            cam = F.relu(cam)\n",
        "\n",
        "            # Normalize\n",
        "            cam = cam - cam.min()\n",
        "            cam = cam / (cam.max() + 1e-8)\n",
        "\n",
        "            # Resize to input image size\n",
        "            cam = F.interpolate(cam, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "            cam = cam.squeeze().detach().cpu().numpy()\n",
        "\n",
        "            # Apply colormap\n",
        "            cam = (cam * 255).astype(np.uint8)\n",
        "            heatmap = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
        "\n",
        "            # Convert original image for visualization\n",
        "            image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "            image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "            image_np = np.clip(image_np, 0, 1)\n",
        "            image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "            # Superimpose heatmap\n",
        "            superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "            # superimposed_img = cv2.addWeighted(image_np[:, :, ::-1], 0.6, heatmap, 0.4, 0)  # Convert image_np to BGR for cv2\n",
        "            # superimposed_img = superimposed_img[:, :, ::-1]  # Back to RGB for display\n",
        "\n",
        "        finally:\n",
        "            # Remove hooks\n",
        "            forward_handle.remove()\n",
        "            backward_handle.remove()\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def integrated_gradients(model, image, target_class):\n",
        "        \"\"\"Integrated Gradients implementation.\"\"\"\n",
        "        if image.dim() == 4:\n",
        "            image = image.squeeze(0)  # Normalize to (C, H, W)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Detach the image first to avoid gradient issues\n",
        "        image_detached = image.detach()\n",
        "\n",
        "        # Create baseline (black image)\n",
        "        baseline = torch.zeros_like(image_detached)\n",
        "\n",
        "        # Generate path from baseline to image\n",
        "        num_steps = 30\n",
        "        alphas = torch.linspace(0, 1, num_steps).to(image_detached.device)\n",
        "\n",
        "        gradients = []\n",
        "        for alpha in alphas:\n",
        "            interpolated = baseline + alpha * (image_detached - baseline)\n",
        "            interpolated = interpolated.requires_grad_(True)\n",
        "\n",
        "            output = model(interpolated.unsqueeze(0))\n",
        "            score = output[0, target_class]\n",
        "\n",
        "            # Clear gradients\n",
        "            model.zero_grad()\n",
        "            if interpolated.grad is not None:\n",
        "                interpolated.grad.zero_()\n",
        "\n",
        "            score.backward()\n",
        "\n",
        "            # Detach gradient before storing\n",
        "            if interpolated.grad is not None:\n",
        "                gradients.append(interpolated.grad.detach().clone())\n",
        "\n",
        "            # Clear the gradient to free memory\n",
        "            interpolated.grad = None\n",
        "\n",
        "        if not gradients:\n",
        "            # Fallback: simple gradient\n",
        "            image_grad = image_detached.requires_grad_(True)\n",
        "            output = model(image_grad.unsqueeze(0))\n",
        "            score = output[0, target_class]\n",
        "            model.zero_grad()\n",
        "            score.backward()\n",
        "            gradients = [image_grad.grad.detach().clone()]\n",
        "\n",
        "        # Average gradients\n",
        "        avg_gradients = torch.stack(gradients).mean(dim=0)\n",
        "\n",
        "        # Compute integrated gradients\n",
        "        integrated_gradients = (image_detached - baseline) * avg_gradients\n",
        "\n",
        "        # Sum across color channels\n",
        "        relevance = integrated_gradients.abs().sum(dim=0).cpu().numpy()\n",
        "\n",
        "        # Normalize\n",
        "        relevance = relevance / (relevance.max() + 1e-8)\n",
        "\n",
        "        # Apply colormap\n",
        "        relevance = (relevance * 255).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(relevance, cv2.COLORMAP_JET)\n",
        "\n",
        "        # Convert original image for visualization\n",
        "        image_np = image_detached.permute(1, 2, 0).cpu().numpy()\n",
        "        image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "        # Superimpose heatmap\n",
        "        superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def layer_wise_relevance_propagation(\n",
        "        model,\n",
        "        image,\n",
        "        target_class=None,\n",
        "        device=\"cuda\",\n",
        "        input_size=None,\n",
        "        epsilon=1e-6,\n",
        "        imagenet_norm=True\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Layer-wise Relevance Propagation (LRP) with Captum and gradient fallback.\n",
        "\n",
        "        Args:\n",
        "            model: torch.nn.Module - trained model\n",
        "            image: torch.Tensor - input image (C, H, W) or (1, C, H, W)\n",
        "            target_class: int or None - class index, if None will be predicted\n",
        "            device: str - device (\"cuda\" or \"cpu\")\n",
        "            input_size: int or None - resize for visualization\n",
        "            epsilon: float - small value to avoid division by zero\n",
        "            imagenet_norm: bool - whether to denormalize using ImageNet mean/std\n",
        "\n",
        "        Returns:\n",
        "            superimposed_img (np.ndarray), heatmap (np.ndarray)\n",
        "        \"\"\"\n",
        "        import torch\n",
        "        import numpy as np\n",
        "        import cv2\n",
        "\n",
        "        model.eval()\n",
        "        model.to(device)\n",
        "\n",
        "        # Ensure correct input shape\n",
        "        if image.dim() == 4:\n",
        "            image = image.squeeze(0)\n",
        "        if image.dim() != 3:\n",
        "            raise ValueError(f\"Expected 3D image tensor (C,H,W), got {image.shape}\")\n",
        "\n",
        "        image_tensor = image.unsqueeze(0).to(device).requires_grad_(True)\n",
        "\n",
        "        # Determine target class\n",
        "        if target_class is None:\n",
        "            with torch.no_grad():\n",
        "                output = model(image_tensor)\n",
        "                target_class = output.argmax(dim=1).item()\n",
        "\n",
        "        try:\n",
        "            from captum.attr import LRP\n",
        "\n",
        "            lrp = LRP(model)\n",
        "            attributions = lrp.attribute(image_tensor, target=target_class)\n",
        "            if attributions is None:\n",
        "                raise ValueError(\"LRP attribution returned None\")\n",
        "\n",
        "            relevance = attributions.detach().cpu().squeeze(0)  # (C,H,W)\n",
        "            if relevance.dim() == 3:\n",
        "                relevance = relevance.sum(dim=0)  # (H,W)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Fallback: Gradient-based relevance\n",
        "            try:\n",
        "                model.zero_grad()\n",
        "                image_tensor = image_tensor.detach().requires_grad_(True)\n",
        "                output = model(image_tensor)\n",
        "\n",
        "                target_score = output[0, target_class]\n",
        "                target_score.backward()\n",
        "\n",
        "                if image_tensor.grad is None:\n",
        "                    raise ValueError(\"Gradients are None in fallback.\")\n",
        "\n",
        "                relevance = image_tensor.grad.detach().cpu().squeeze(0)\n",
        "                if relevance.dim() == 3:\n",
        "                    relevance = relevance.clamp(min=0).sum(dim=0)\n",
        "\n",
        "            except Exception as fallback_e:\n",
        "                print(f\"LRP + fallback failed: {fallback_e}\")\n",
        "                # Return original image and blank heatmap\n",
        "                image_np = image.permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "                heatmap = np.zeros_like(image_np, dtype=np.uint8)\n",
        "                return image_np, heatmap\n",
        "\n",
        "        # Normalize relevance\n",
        "        relevance = relevance.clamp(min=0)\n",
        "        if relevance.max() > 0:\n",
        "            relevance = relevance / (relevance.max() + epsilon)\n",
        "\n",
        "        relevance_map = relevance.numpy()\n",
        "        if input_size is not None and relevance_map.shape != (input_size, input_size):\n",
        "            relevance_map = cv2.resize(relevance_map, (input_size, input_size))\n",
        "\n",
        "        relevance_map = (relevance_map * 255).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(relevance_map, cv2.COLORMAP_JET)\n",
        "\n",
        "        # Prepare original image\n",
        "        image_np = image_tensor.detach().squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "        if imagenet_norm:\n",
        "            mean = np.array([0.485, 0.456, 0.406])\n",
        "            std = np.array([0.229, 0.224, 0.225])\n",
        "            image_np = image_np * std + mean\n",
        "\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "        # Superimpose heatmap\n",
        "        superimposed_img = cv2.addWeighted(image_np, 0.7, heatmap, 0.3, 0.0)\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "\n",
        "# ---\n",
        "# MAIN EXECUTION\n",
        "# =============================================================================\n",
        "# Purpose: Orchestrate the entire pipeline: data loading, model training, ensemble creation, evaluation, and visualization.\n",
        "\n",
        "def main():\n",
        "    print(\"Starting Fish Species Classification Pipeline...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "\n",
        "    # matplotlib.use('Agg')  # Use non-interactive backend for better GPU performance\n",
        "    os.system('find . -name \"*.pyc\" -delete')\n",
        "    os.system('find . -name \"__pycache__\" -type d -exec rm -rf {} +')\n",
        "\n",
        "    setup_environment()\n",
        "    %matplotlib inline\n",
        "\n",
        "\n",
        "    # Ensure all output directories exist\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/best_model\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/model_results\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/kfold_results\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/visualizations\", exist_ok=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Load and balance data (only once)\n",
        "    print(\"Loading and balancing data...\")\n",
        "    X, Y = DataManager.load_and_balance_data()\n",
        "    print(f\"Total samples after balancing: {len(X)}, Labels: {len(Y)}\")\n",
        "\n",
        "    # Validate data consistency\n",
        "    if len(X) != len(Y):\n",
        "        raise ValueError(f\"Inconsistent data: X has {len(X)} samples, Y has {len(Y)} labels\")\n",
        "    if len(X) == 0:\n",
        "        raise ValueError(\"No data available after loading and balancing\")\n",
        "\n",
        "    # Initialize components\n",
        "    visualizer = EnhancedVisualizations()\n",
        "    single_models = {}\n",
        "    single_results = {}\n",
        "    histories = {}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Process each model individually\n",
        "    for model_name in Config.MODELS:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"PROCESSING MODEL: {model_name}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "\n",
        "        try:\n",
        "            # Step 1: Create initial data loaders for hyperparameter optimization\n",
        "            print(f\"\\n1. CREATING INITIAL DATA LOADERS FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(X, Y)\n",
        "\n",
        "            # Validate data loaders\n",
        "            print(f\"Train loader: {len(train_loader.dataset) if train_loader else 0} samples\")\n",
        "            print(f\"Val loader: {len(val_loader.dataset) if val_loader else 0} samples\")\n",
        "            print(f\"Test loader: {len(test_loader.dataset) if test_loader else 0} samples\")\n",
        "\n",
        "            if not train_loader or len(train_loader.dataset) == 0:\n",
        "                print(f\"Skipping {model_name}: No training data available\")\n",
        "                continue\n",
        "            if not val_loader or len(val_loader.dataset) == 0:\n",
        "                print(f\"Skipping {model_name}: No validation data available\")\n",
        "                continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # # Step 2: Optimize hyperparameters\n",
        "            print(f\"\\n2. HYPERPARAMETER OPTIMIZATION FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "\n",
        "            optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "            torch.serialization.add_safe_globals([np.core.multiarray.scalar])\n",
        "            torch.set_num_threads(2)  # Reduce CPU threads for GPU workload\n",
        "\n",
        "            # Debug data loader sizes\n",
        "            print(f\"Train loader size: {len(train_loader.dataset)} samples, {len(train_loader)} batches\")\n",
        "            print(f\"Val loader size: {len(val_loader.dataset)} samples, {len(val_loader)} batches\")\n",
        "\n",
        "            try:\n",
        "                optimizer = ExpandedHyperparameterOptimizer(model_name, train_loader, val_loader)\n",
        "                best_params = optimizer.optimize()\n",
        "            except Exception as e:\n",
        "                print(f\"Error in hyperparameter optimization for {model_name}: {str(e)}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                best_params = {}  # Fallback to default hyperparameters\n",
        "\n",
        "\n",
        "            # Clear optimizer and temporary data\n",
        "            del optimizer\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            print(f\"\\n\\033[1;31m{'='*70}\\033[0m\")\n",
        "            print(f\"\\033[1;31m{model_name.upper()} BEST PARAMETERS Finalized:\\033[0m\")\n",
        "            for key, value in best_params.items():\n",
        "                if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                    print(f\"\\033[1;31m  {key}: {value:.4f}\\033[0m\")\n",
        "                else:\n",
        "                    print(f\"\\033[1;31m  {key}: {value}\\033[0m\")\n",
        "            print(f\"\\033[1;31m{'='*70}\\033[0m\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Step 3: Create data loaders with optimized parameters\n",
        "            print(f\"\\n3. RECREATING DATA LOADERS WITH OPTIMIZED PARAMETERS\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Clear previous loaders\n",
        "            del train_loader, val_loader, test_loader\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            # Recreate with optimized batch size and GPU-optimized settings\n",
        "            train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(\n",
        "                X, Y,\n",
        "                test_size=0.2,\n",
        "                batch_size=min(128, max(32, best_params.get('batch_size', Config.BATCH_SIZE))),  # Larger batches\n",
        "                augmentation_strength=best_params.get('augmentation_strength', 'medium')\n",
        "            )\n",
        "\n",
        "            # Check if data loaders are defined\n",
        "            if not all(loader is not None for loader in [train_loader, val_loader, test_loader]):\n",
        "                print(f\"Skipping loader optimization for {model_name}: one or more data loaders are undefined\")\n",
        "                continue\n",
        "\n",
        "            # Optimize data loaders for GPU\n",
        "            for loader in [train_loader, val_loader, test_loader]:\n",
        "                if loader:\n",
        "                    loader.pin_memory = True\n",
        "                    # if hasattr(loader, 'persistent_workers'):\n",
        "                    #     loader.persistent_workers = False\n",
        "\n",
        "            # Validate recreated data loaders\n",
        "            print(f\"Recreated - Train: {len(train_loader.dataset)}, Val: {len(val_loader.dataset)}, Test: {len(test_loader.dataset)}\")\n",
        "\n",
        "            # Additional validation for val_data and test_data tuples\n",
        "            if val_data is not None and len(val_data) == 2:\n",
        "                print(f\"Val data tuple: X={len(val_data[0])}, Y={len(val_data[1])}\")\n",
        "                if len(val_data[0]) != len(val_data[1]):\n",
        "                    print(f\"WARNING: Validation data inconsistency: {len(val_data[0])} samples vs {len(val_data[1])} labels\")\n",
        "\n",
        "            if test_data is not None and len(test_data) == 2:\n",
        "                print(f\"Test data tuple: X={len(test_data[0])}, Y={len(test_data[1])}\")\n",
        "                if len(test_data[0]) != len(test_data[1]):\n",
        "                    print(f\"WARNING: Test data inconsistency: {len(test_data[0])} samples vs {len(test_data[1])} labels\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Step 4: Train main model\n",
        "            print(f\"\\n4. MAIN MODEL TRAINING FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            model = ModelFactory.create_model(\n",
        "                model_name,\n",
        "                num_classes=Config.NUM_CLASSES,\n",
        "                dropout_rate=best_params.get('dropout', 0.5),\n",
        "                hidden_dim_multiplier=best_params.get('hidden_dim_multiplier', 0.5)\n",
        "            ).to(Config.DEVICE, memory_format=torch.channels_last)  # GPU optimization\n",
        "\n",
        "            # Additional GPU optimizations\n",
        "            torch.backends.cudnn.benchmark = True\n",
        "            torch.backends.cudnn.deterministic = False\n",
        "\n",
        "\n",
        "            trainer = None  # Add this line before your existing code\n",
        "            trainer = EnhancedModelTrainer(model, model_name, best_params)\n",
        "            # def load_saved_results(self):\n",
        "            #     \"\"\"Load previously saved training results\"\"\"\n",
        "            #     main_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{self.model_name}_main_results.pt\"\n",
        "\n",
        "            #     if os.path.exists(main_result_path):\n",
        "            #         try:\n",
        "            #             saved_data = torch.load(main_result_path, map_location=Config.DEVICE)\n",
        "            #             history = saved_data['history']\n",
        "            #             result = saved_data['result']\n",
        "            #             tqdm.write(f\"Loaded results from {main_result_path}\")\n",
        "            #             return history, result\n",
        "            #         except Exception as e:\n",
        "            #             tqdm.write(f\"Failed to load {main_result_path}: {e}\")\n",
        "            #             return None, None\n",
        "            #     else:\n",
        "            #         tqdm.write(f\"No saved results found at {main_result_path}\")\n",
        "            #         return None, None\n",
        "            # # history, result = trainer.train_main_model(train_loader, val_loader, test_loader)\n",
        "            # # Train the model (saves results internally)\n",
        "            trainer.train_main_model(train_loader, val_loader, test_loader)\n",
        "            # # Load the saved results\n",
        "            # history, result = load_saved_results()\n",
        "            # Load directly from the saved location\n",
        "            main_result_path = f\"{Config.OUTPUT_DIR}/model_results/{trainer.model_name}_main_results.pt\"\n",
        "            if os.path.exists(main_result_path):\n",
        "                try:\n",
        "                    saved_data = torch.load(main_result_path, map_location=Config.DEVICE)\n",
        "                    history = saved_data['history']\n",
        "                    result = saved_data['result']\n",
        "                    print(f\"Loaded results from {main_result_path}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Failed to load {main_result_path}: {e}\")\n",
        "                    history, result = None, None\n",
        "            else:\n",
        "                print(f\"No saved results found at {main_result_path}\")\n",
        "                history, result = None, None\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            if history is None or result is None:\n",
        "                print(f\"Training failed for {model_name}, skipping...\")\n",
        "                continue\n",
        "\n",
        "            print(f\"Main model training completed for {model_name}\")\n",
        "\n",
        "            # Store results\n",
        "            histories[model_name] = history\n",
        "            single_results[model_name] = result\n",
        "\n",
        "\n",
        "            # After: history, result = trainer.train_main_model(...)\n",
        "            # Add:\n",
        "            trainer.cleanup_model()\n",
        "            del trainer\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # # Step 5: K-fold cross-validation\n",
        "            # print(f\"\\n5. K-FOLD CROSS-VALIDATION FOR {model_name}\")\n",
        "            # print(\"-\"*50)\n",
        "\n",
        "            # # Ensure we have sufficient data for k-fold\n",
        "            # min_samples_per_fold = 500\n",
        "            # max_folds = len(train_loader.dataset) // min_samples_per_fold\n",
        "            # n_folds = min(3, max_folds) if max_folds > 1 else 0\n",
        "\n",
        "            # if n_folds > 1:\n",
        "            #     print(f\"Performing {n_folds}-fold cross-validation...\")\n",
        "\n",
        "\n",
        "            #     trainer = None  # Add this line before your existing code\n",
        "            #     # Create the trainer object\n",
        "            #     trainer = EnhancedModelTrainer(model, model_name, best_params)\n",
        "            #     # Train k-fold (saves results internally)\n",
        "            #     trainer.train_kfold(train_loader, val_loader, n_folds=n_folds)\n",
        "\n",
        "            #     # Load all fold results\n",
        "            #     fold_results = []\n",
        "            #     for fold in range(1, n_folds + 1):\n",
        "            #         fold_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{trainer.model_name}_fold_{fold}_results.pt\"\n",
        "            #         if os.path.exists(fold_result_path):\n",
        "            #             try:\n",
        "            #                 fold_data = torch.load(fold_result_path, map_location=Config.DEVICE)\n",
        "            #                 fold_results.append(fold_data)\n",
        "            #                 print(f\"Loaded fold {fold} results from {fold_result_path}\")\n",
        "            #             except Exception as e:\n",
        "            #                 print(f\"Failed to load fold {fold}: {e}\")\n",
        "            #         else:\n",
        "            #             print(f\"Fold {fold} results not found at {fold_result_path}\")\n",
        "\n",
        "            #     print(f\"Loaded {len(fold_results)} fold results for {trainer.model_name}\")\n",
        "            #     # fold_results = trainer.train_kfold(train_loader, val_loader, n_folds=n_folds)\n",
        "            #     print(f\"K-fold validation completed for {model_name}\")\n",
        "\n",
        "\n",
        "            #     # Free memory used in k-fold\n",
        "            #     torch.cuda.empty_cache()\n",
        "            #     gc.collect()\n",
        "\n",
        "            # else:\n",
        "            #     print(f\"Skipping k-fold validation for {model_name}: insufficient data (need >{min_samples_per_fold*2} samples)\")\n",
        "            #     fold_results = []\n",
        "            # Step 5: K-fold cross-validation\n",
        "            print(f\"\\n5. K-FOLD CROSS-VALIDATION FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            min_samples_per_fold = 500\n",
        "            max_folds = len(train_loader.dataset) // min_samples_per_fold\n",
        "            n_folds = min(3, max_folds) if max_folds > 1 else 0\n",
        "\n",
        "            if n_folds > 1:\n",
        "                print(f\"Performing {n_folds}-fold cross-validation...\")\n",
        "                trainer = EnhancedModelTrainer(model, model_name, best_params)\n",
        "                fold_results = trainer.train_kfold(train_loader, val_loader, n_folds=n_folds)  # Use returned results\n",
        "\n",
        "                # Load all fold results\n",
        "                fold_results_loaded = []\n",
        "                for fold in range(1, n_folds + 1):\n",
        "                    fold_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{trainer.model_name}_fold_{fold}_results.pt\"\n",
        "                    if os.path.exists(fold_result_path):\n",
        "                        try:\n",
        "                            fold_data = torch.load(fold_result_path, map_location=Config.DEVICE, weights_only=False)\n",
        "                            fold_results_loaded.append({\n",
        "                                'history': {\n",
        "                                    'val_loss': fold_data['history']['val_loss'].tolist() if hasattr(fold_data['history']['val_loss'], 'tolist') else fold_data['history']['val_loss'],\n",
        "                                    'val_acc': fold_data['history']['val_acc'].tolist() if hasattr(fold_data['history']['val_acc'], 'tolist') else fold_data['history']['val_acc']\n",
        "                                },\n",
        "                                'result': {\n",
        "                                    'accuracy': fold_data['result']['accuracy'].cpu().item() if hasattr(fold_data['result']['accuracy'], 'cpu') else fold_data['result']['accuracy'],\n",
        "                                    'f1': fold_data['result']['f1'].cpu().item() if hasattr(fold_data['result']['f1'], 'cpu') else fold_data['result']['f1'],\n",
        "                                    'conf_matrix': fold_data['result']['conf_matrix'].cpu().numpy() if hasattr(fold_data['result']['conf_matrix'], 'cpu') else fold_data['result']['conf_matrix'],\n",
        "                                    'misclassified': fold_data['result']['misclassified']\n",
        "                                }\n",
        "                            })\n",
        "                            print(f\"Loaded fold {fold} results from {fold_result_path}\")\n",
        "                        except Exception as e:\n",
        "                            print(f\"Failed to load fold {fold}: {e}\")\n",
        "                    else:\n",
        "                        print(f\"Fold {fold} results not found at {fold_result_path}\")\n",
        "\n",
        "                # Use returned results if loaded results are empty\n",
        "                if not fold_results_loaded and fold_results:\n",
        "                    print(f\"Using returned fold results for {model_name}\")\n",
        "                    fold_results_loaded = fold_results\n",
        "\n",
        "                # Validate loaded fold results\n",
        "                if not fold_results_loaded or all(not fold_data['history'].get('val_loss') for fold_data in fold_results_loaded):\n",
        "                    print(f\"Skipping k-fold plotting for {model_name}: no valid fold results loaded\")\n",
        "                else:\n",
        "                    try:\n",
        "                        visualizer.plot_kfold_results(fold_results_loaded, model_name, test_loader)\n",
        "                        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_kfold.png\", dpi=150, bbox_inches='tight')\n",
        "                        plt.close('all')\n",
        "                        print(f\"K-fold results plot generated for {model_name}\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error plotting k-fold results for {model_name}: {e}\")\n",
        "\n",
        "                print(f\"Loaded {len(fold_results_loaded)} fold results for {trainer.model_name}\")\n",
        "                print(f\"K-fold validation completed for {model_name}\")\n",
        "\n",
        "                # Free memory used in k-fold\n",
        "                torch.cuda.empty_cache()\n",
        "                gc.collect()\n",
        "            else:\n",
        "                print(f\"Skipping k-fold validation for {model_name}: insufficient data (need >{min_samples_per_fold*2} samples)\")\n",
        "                fold_results = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Step 6: Load saved results for plotting\n",
        "            print(f\"\\n6. LOADING RESULTS AND GENERATING PLOTS FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            main_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{model_name}_main_results.pt\"\n",
        "\n",
        "            try:\n",
        "                # Use current result data for visualization\n",
        "                history_for_viz = history\n",
        "                result_for_viz = result\n",
        "\n",
        "                print(f\"Using current results for {model_name} visualization\")\n",
        "                print(f\"Result keys: {list(result_for_viz.keys()) if result_for_viz else 'None'}\")\n",
        "\n",
        "                # Validate result data\n",
        "                true_labels = result_for_viz.get('true_labels', np.array([]))\n",
        "                predictions = result_for_viz.get('predictions', np.array([]))\n",
        "                probabilities = result_for_viz.get('probabilities', np.array([]))\n",
        "\n",
        "                print(f\"Data validation for {model_name}:\")\n",
        "                print(f\"  true_labels: {type(true_labels)}, shape: {getattr(true_labels, 'shape', len(true_labels) if hasattr(true_labels, '__len__') else 'scalar')}\")\n",
        "                print(f\"  predictions: {type(predictions)}, shape: {getattr(predictions, 'shape', len(predictions) if hasattr(predictions, '__len__') else 'scalar')}\")\n",
        "                print(f\"  probabilities: {type(probabilities)}, shape: {getattr(probabilities, 'shape', 'unknown')}\")\n",
        "\n",
        "                # Check if we have valid data for plotting\n",
        "                if (len(true_labels) > 0 and len(predictions) > 0 and len(true_labels) == len(predictions)):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                #     # Step 7: Generate all plots for this model\n",
        "                #     print(f\"\\n7. GENERATING VISUALIZATIONS FOR {model_name}\")\n",
        "                #     print(\"-\"*50)\n",
        "\n",
        "                #     # Training history plot\n",
        "                #     # if history_for_viz.get('train_loss') and len(history_for_viz['train_loss']) > 0:\n",
        "\n",
        "                #     # Convert tensors to lists for easier handling\n",
        "                #     if torch.is_tensor(history_for_viz.get('train_loss')):\n",
        "                #         history_for_viz['train_loss'] = history_for_viz['train_loss'].cpu().tolist()\n",
        "                #         try:\n",
        "                #             visualizer.plot_single_model_history(history_for_viz, model_name)\n",
        "                #             plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_history.png\", dpi=150, bbox_inches='tight')\n",
        "                #             plt.close('all')\n",
        "                #             print(f\"Training history plot generated for {model_name}\")\n",
        "                #         except Exception as e:\n",
        "                #             print(f\"Error plotting training history for {model_name}: {e}\")\n",
        "\n",
        "                #     try:\n",
        "                #         # ROC Curves\n",
        "                #         visualizer.plot_roc_curves(result_for_viz, model_name)\n",
        "                #         plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_roc.png\", dpi=150, bbox_inches='tight')\n",
        "                #         plt.close('all')\n",
        "                #         print(f\"ROC curves plot generated for {model_name}\")\n",
        "\n",
        "                #         # Confusion Matrix\n",
        "                #         visualizer.plot_confusion_matrix(result_for_viz, model_name)\n",
        "                #         plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_confusion.png\", dpi=150, bbox_inches='tight')\n",
        "                #         plt.close('all')\n",
        "                #         print(f\"Confusion matrix plot generated for {model_name}\")\n",
        "\n",
        "                #         # Misclassified Images\n",
        "                #         if result_for_viz.get('misclassified') and len(result_for_viz['misclassified']) > 0:\n",
        "                #             visualizer.plot_misclassified_images(result_for_viz['misclassified'], model_name)\n",
        "                #             plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_misclassified.png\", dpi=150, bbox_inches='tight')\n",
        "                #             plt.close('all')\n",
        "                #             print(f\"Misclassified images plot generated for {model_name}\")\n",
        "                #         else:\n",
        "                #             print(f\"No misclassified images to plot for {model_name}\")\n",
        "\n",
        "                #         # XAI Visualization\n",
        "                #         if model is not None and test_loader is not None and len(test_loader.dataset) > 0:\n",
        "                #             visualizer.plot_single_model_xai(model, model_name, test_loader)\n",
        "                #             plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_xai.png\", dpi=150, bbox_inches='tight')\n",
        "                #             plt.close('all')\n",
        "                #             print(f\"XAI visualization generated for {model_name}\")\n",
        "                #         else:\n",
        "                #             print(f\"Skipping XAI visualization for {model_name}: model or test_loader not available\")\n",
        "\n",
        "                #     except Exception as plot_error:\n",
        "                #         print(f\"Visualization error for {model_name}: {plot_error}\")\n",
        "                #         import traceback\n",
        "                #         traceback.print_exc()\n",
        "\n",
        "                # else:\n",
        "                #     print(f\"Skipping visualizations for {model_name}: data validation failed\")\n",
        "                #     print(f\"  true_labels length: {len(true_labels) if hasattr(true_labels, '__len__') else 'scalar'}\")\n",
        "                #     print(f\"  predictions length: {len(predictions) if hasattr(predictions, '__len__') else 'scalar'}\")\n",
        "                # Step 7: Generate all plots for this model\n",
        "                    print(f\"\\n7. GENERATING VISUALIZATIONS FOR {model_name}\")\n",
        "                    print(\"-\"*50)\n",
        "\n",
        "                    # FIX 1: Proper tensor checking and conversion for all history items\n",
        "                    for key in ['train_loss', 'val_loss', 'train_acc', 'val_acc']:\n",
        "                        if key in history_for_viz and torch.is_tensor(history_for_viz[key]):\n",
        "                            history_for_viz[key] = history_for_viz[key].cpu().tolist()\n",
        "\n",
        "                    # FIX 2: Check if history data exists before plotting\n",
        "                    if history_for_viz and any(key in history_for_viz for key in ['train_loss', 'val_loss']):\n",
        "\n",
        "                    # FIX 3: Convert tensor data in result_for_viz before plotting\n",
        "                        try:\n",
        "\n",
        "                            # def convert_to_list(obj):\n",
        "                            #     if isinstance(obj, torch.Tensor):\n",
        "                            #         return obj.cpu().numpy().tolist()\n",
        "                            #     elif isinstance(obj, list):\n",
        "                            #         return [convert_to_list(item) for item in obj]\n",
        "                            #     elif isinstance(obj, dict):\n",
        "                            #         return {key: convert_to_list(value) for key, value in obj.items()}\n",
        "                            #     else:\n",
        "                            #         return obj\n",
        "\n",
        "                            # # In your main script, before visualization\n",
        "                            # history_for_viz = convert_to_list(history_for_viz)\n",
        "\n",
        "\n",
        "                            # Convert tensors to numpy/lists for visualization\n",
        "                            if 'true_labels' in result_for_viz and torch.is_tensor(result_for_viz['true_labels']):\n",
        "                                result_for_viz['true_labels'] = result_for_viz['true_labels'].cpu().numpy()\n",
        "                            if 'predictions' in result_for_viz and torch.is_tensor(result_for_viz['predictions']):\n",
        "                                result_for_viz['predictions'] = result_for_viz['predictions'].cpu().numpy()\n",
        "                            if 'probabilities' in result_for_viz and torch.is_tensor(result_for_viz['probabilities']):\n",
        "                                result_for_viz['probabilities'] = result_for_viz['probabilities'].cpu().numpy()\n",
        "                            if 'conf_matrix' in result_for_viz and torch.is_tensor(result_for_viz['conf_matrix']):\n",
        "                                result_for_viz['conf_matrix'] = result_for_viz['conf_matrix'].cpu().numpy()\n",
        "                            # try:\n",
        "                            visualizer.plot_single_model_history(history_for_viz, model_name)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_history.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "                            print(f\"Training history plot generated for {model_name}\")\n",
        "                            # except Exception as e:\n",
        "                            #     print(f\"Error plotting training history for {model_name}: {e}\")\n",
        "\n",
        "                            # # FIX 3: Convert tensor data in result_for_viz before plotting\n",
        "                            # try:\n",
        "                            #     # Convert tensors to numpy/lists for visualization\n",
        "                            #     if 'true_labels' in result_for_viz and torch.is_tensor(result_for_viz['true_labels']):\n",
        "                            #         result_for_viz['true_labels'] = result_for_viz['true_labels'].cpu().numpy()\n",
        "                            #     if 'predictions' in result_for_viz and torch.is_tensor(result_for_viz['predictions']):\n",
        "                            #         result_for_viz['predictions'] = result_for_viz['predictions'].cpu().numpy()\n",
        "                            #     if 'probabilities' in result_for_viz and torch.is_tensor(result_for_viz['probabilities']):\n",
        "                            #         result_for_viz['probabilities'] = result_for_viz['probabilities'].cpu().numpy()\n",
        "                            #     if 'conf_matrix' in result_for_viz and torch.is_tensor(result_for_viz['conf_matrix']):\n",
        "                            #         result_for_viz['conf_matrix'] = result_for_viz['conf_matrix'].cpu().numpy()\n",
        "\n",
        "                            # ROC Curves\n",
        "                            visualizer.plot_roc_curves(result_for_viz, model_name)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_roc.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "                            print(f\"ROC curves plot generated for {model_name}\")\n",
        "\n",
        "                            # Confusion Matrix\n",
        "                            visualizer.plot_confusion_matrix(result_for_viz, model_name)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_confusion.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "                            print(f\"Confusion matrix plot generated for {model_name}\")\n",
        "\n",
        "                            # Misclassified Images\n",
        "                            if result_for_viz.get('misclassified') and len(result_for_viz['misclassified']) > 0:\n",
        "                                # FIX 4: Handle tensor images in misclassified data\n",
        "                                for item in result_for_viz['misclassified']:\n",
        "                                    if torch.is_tensor(item.get('image')):\n",
        "                                        item['image'] = item['image'].cpu()\n",
        "\n",
        "                                visualizer.plot_misclassified_images(result_for_viz['misclassified'], model_name)\n",
        "                                plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_misclassified.png\", dpi=150, bbox_inches='tight')\n",
        "                                plt.close('all')\n",
        "                                print(f\"Misclassified images plot generated for {model_name}\")\n",
        "                            else:\n",
        "                                print(f\"No misclassified images to plot for {model_name}\")\n",
        "\n",
        "                            # XAI Visualization\n",
        "                            if model is not None and test_loader is not None and len(test_loader.dataset) > 0:\n",
        "                                visualizer.plot_single_model_xai(model, model_name, test_loader)\n",
        "                                plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_xai.png\", dpi=150, bbox_inches='tight')\n",
        "                                plt.close('all')\n",
        "                                print(f\"XAI visualization generated for {model_name}\")\n",
        "                            else:\n",
        "                                print(f\"Skipping XAI visualization for {model_name}: model or test_loader not available\")\n",
        "\n",
        "                        except Exception as plot_error:\n",
        "                            print(f\"Visualization error for {model_name}: {plot_error}\")\n",
        "                            import traceback\n",
        "                            traceback.print_exc()\n",
        "\n",
        "\n",
        "\n",
        "                    # K-fold results plotting (load from saved files)\n",
        "                    if n_folds > 1:\n",
        "                        fold_results_loaded = []\n",
        "                        for fold in range(1, n_folds + 1):\n",
        "                            fold_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{model_name}_fold_{fold}_results.pt\"\n",
        "                            if os.path.exists(fold_result_path):\n",
        "                                try:\n",
        "                                    fold_data = torch.load(fold_result_path, map_location=Config.DEVICE, weights_only=False)\n",
        "                                    fold_results_loaded.append({\n",
        "                                        'history': {\n",
        "                                            'val_loss': fold_data['history']['val_loss'].tolist() if hasattr(fold_data['history']['val_loss'], 'tolist') else fold_data['history']['val_loss'],\n",
        "                                            'val_acc': fold_data['history']['val_acc'].tolist() if hasattr(fold_data['history']['val_acc'], 'tolist') else fold_data['history']['val_acc']\n",
        "                                        },\n",
        "                                        'result': {\n",
        "                                            'accuracy': fold_data['result']['accuracy'].cpu().item() if hasattr(fold_data['result']['accuracy'], 'cpu') else fold_data['result']['accuracy'],\n",
        "                                            'f1': fold_data['result']['f1'].cpu().item() if hasattr(fold_data['result']['f1'], 'cpu') else fold_data['result']['f1'],\n",
        "                                            'conf_matrix': fold_data['result']['conf_matrix'].cpu().numpy() if hasattr(fold_data['result']['conf_matrix'], 'cpu') else fold_data['result']['conf_matrix'],\n",
        "                                            'misclassified': fold_data['result']['misclassified']\n",
        "                                        }\n",
        "                                    })\n",
        "\n",
        "                                except Exception as e:\n",
        "                                    print(f\"Error loading fold {fold} results: {e}\")\n",
        "\n",
        "                        if fold_results_loaded:\n",
        "                            try:\n",
        "                                visualizer.plot_kfold_results(fold_results_loaded, model_name, test_loader)\n",
        "                                plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_kfold.png\", dpi=150, bbox_inches='tight')\n",
        "                                plt.close('all')\n",
        "                                print(f\"K-fold results plot generated for {model_name}\")\n",
        "                            except Exception as e:\n",
        "                                print(f\"Error plotting k-fold results for {model_name}: {e}\")\n",
        "\n",
        "\n",
        "                    # Clear visualization-related data\n",
        "                    del history_for_viz, result_for_viz\n",
        "                    if 'fold_results_loaded' in locals():\n",
        "                        del fold_results_loaded\n",
        "                    plt.close('all')\n",
        "                    torch.cuda.empty_cache()\n",
        "                    gc.collect()\n",
        "\n",
        "                    print(f\"All visualizations completed for {model_name}\")\n",
        "\n",
        "\n",
        "                    # Free visualization memory (figures, results, etc.)\n",
        "                    plt.close('all')\n",
        "                    torch.cuda.empty_cache()\n",
        "                    gc.collect()\n",
        "\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error in visualization process for {model_name}: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Step 8: Memory cleanup for this model\n",
        "            print(f\"\\n8. MEMORY CLEANUP FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Store model for ensemble\n",
        "            single_models[model_name] = model\n",
        "            model_state_dict = model.state_dict()\n",
        "            torch.save(model_state_dict, f\"{Config.OUTPUT_DIR}/models/{model_name}_for_ensemble.pt\")\n",
        "\n",
        "            # Clear all variables\n",
        "            del trainer, history, result\n",
        "            if 'fold_results' in locals():\n",
        "                del fold_results\n",
        "            del train_loader, val_loader, test_loader\n",
        "            if 'optimizer' in locals():\n",
        "                del optimizer\n",
        "            if 'fold_results_loaded' in locals():\n",
        "                del fold_results_loaded\n",
        "\n",
        "            # Clear model and data-related objects\n",
        "            del model, val_data, test_data\n",
        "            if 'model_state_dict' in locals():\n",
        "                del model_state_dict\n",
        "            # Clear dataset references in loaders\n",
        "            for loader in [train_loader, val_loader, test_loader]:\n",
        "                if loader and hasattr(loader, 'dataset'):\n",
        "                    del loader.dataset\n",
        "            # Reset CUDA state\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "            gc.collect()\n",
        "\n",
        "            # # Force garbage collection\n",
        "            # gc.collect()\n",
        "            # torch.cuda.empty_cache()\n",
        "            # torch.cuda.synchronize()\n",
        "\n",
        "            # Print memory status\n",
        "            if torch.cuda.is_available():\n",
        "                print(f\"GPU Memory after cleanup: {torch.cuda.memory_allocated()/1024**3:.2f}GB allocated\")\n",
        "                print(f\"GPU Memory cached: {torch.cuda.memory_reserved()/1024**3:.2f}GB cached\")\n",
        "\n",
        "            print(f\"Memory cleanup completed for {model_name}\")\n",
        "            print(f\"\\n‚úì {model_name} PROCESSING COMPLETED!\")\n",
        "            print(f\"{'='*70}\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {model_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "            continue\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Step 9: Ensemble processing (only if we have trained models)\n",
        "    if single_models:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"ALL MODELS PROCESSED - STARTING ENSEMBLE ANALYSIS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        try:\n",
        "            if (val_data is not None and len(val_data) == 2 and\n",
        "                len(val_data[0]) > 0 and len(val_data[1]) > 0 and\n",
        "                len(val_data[0]) == len(val_data[1])):\n",
        "\n",
        "                ensemble_manager = EnsembleManager(single_models, val_data)\n",
        "                ensemble_results, best_ensemble = ensemble_manager.test_ensemble_combinations()\n",
        "\n",
        "                # Generate visualizations for ensemble methods\n",
        "                print(\"\\nGenerating visualizations for ensemble methods...\")\n",
        "                for ensemble_name, ensemble_result in ensemble_results.items():\n",
        "                    try:\n",
        "                        if (len(ensemble_result.get('true_labels', [])) > 0 and\n",
        "                            len(ensemble_result.get('predictions', [])) > 0 and\n",
        "                            len(ensemble_result.get('true_labels', [])) == len(ensemble_result.get('predictions', []))):\n",
        "\n",
        "                            visualizer.plot_roc_curves(ensemble_result, ensemble_name)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{ensemble_name}_roc.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "\n",
        "                            visualizer.plot_confusion_matrix(ensemble_result, ensemble_name)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{ensemble_name}_confusion.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "\n",
        "                            # F1 per class visualization\n",
        "                            f1_per_class = f1_score(ensemble_result['true_labels'],\n",
        "                                                   ensemble_result['predictions'], average=None)\n",
        "                            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "                            ax.bar(range(Config.NUM_CLASSES), f1_per_class, color='lightgreen', alpha=0.8)\n",
        "                            ax.set_xticks(range(Config.NUM_CLASSES))\n",
        "                            ax.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right')\n",
        "                            ax.set_title(f'F1 Scores per Class - {ensemble_name}',\n",
        "                                       fontsize=14, fontweight='bold', pad=15)\n",
        "                            ax.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
        "                            ax.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
        "                            ax.grid(True, alpha=0.3)\n",
        "                            for i, v in enumerate(f1_per_class):\n",
        "                                ax.text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom', fontsize=10)\n",
        "                            save_path = f\"{Config.OUTPUT_DIR}/visualizations/{ensemble_name}_f1_per_class.png\"\n",
        "                            plt.savefig(save_path, dpi=300, bbox_inches='tight',\n",
        "                                      facecolor='white', edgecolor='none')\n",
        "                            plt.close()\n",
        "                            print(f\"F1 scores per class saved: {save_path}\")\n",
        "                        else:\n",
        "                            print(f\"Skipping visualizations for {ensemble_name}: invalid data\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error generating ensemble visualizations for {ensemble_name}: {e}\")\n",
        "\n",
        "                    # Clear memory\n",
        "                    if 'ensemble_result' in locals():\n",
        "                        del ensemble_result\n",
        "                    torch.cuda.empty_cache()\n",
        "                    gc.collect()\n",
        "\n",
        "                # Evaluate best ensemble on test set\n",
        "                if (best_ensemble and test_data is not None and len(test_data) == 2 and\n",
        "                    len(test_data[0]) == len(test_data[1]) and len(test_data[0]) > 0):\n",
        "\n",
        "                    print(\"Evaluating best ensemble on test set...\")\n",
        "                    test_X, test_Y = test_data\n",
        "\n",
        "                    # Create test dataset and loader for ensemble evaluation with GPU optimization\n",
        "                    test_dataset = torch.utils.data.TensorDataset(\n",
        "                        torch.stack([torch.from_numpy(x) if isinstance(x, np.ndarray) else x for x in test_X]).to(Config.DEVICE, memory_format=torch.channels_last),\n",
        "                        torch.tensor(test_Y, dtype=torch.long).to(Config.DEVICE)\n",
        "                    )\n",
        "\n",
        "                    test_loader_ensemble = DataLoader(\n",
        "                        test_dataset,\n",
        "                        batch_size=64,  # Larger batch for GPU efficiency\n",
        "                        shuffle=False,\n",
        "                        pin_memory=True,\n",
        "                        num_workers=2,\n",
        "                        prefetch_factor=2\n",
        "                    )\n",
        "\n",
        "                    # Evaluate best ensemble\n",
        "                    ensemble_test_result = ensemble_manager.evaluate_ensemble_on_test(\n",
        "                        best_ensemble, test_loader_ensemble\n",
        "                    )\n",
        "                    print(f\"Best ensemble test accuracy: {ensemble_test_result.get('accuracy', 0.0):.4f}\")\n",
        "                    print(f\"Best ensemble test F1: {ensemble_test_result.get('f1_macro', 0.0):.4f}\")\n",
        "                else:\n",
        "                    print(\"Skipping best ensemble test evaluation: invalid test data\")\n",
        "\n",
        "            else:\n",
        "                print(\"Skipping ensemble analysis: no valid validation data\")\n",
        "                print(f\"val_data validation: {val_data is not None if 'val_data' in locals() else 'val_data not defined'}\")\n",
        "                if val_data is not None:\n",
        "                    print(f\"  val_data length: {len(val_data)}\")\n",
        "                    if len(val_data) == 2:\n",
        "                        print(f\"  val_data[0] length: {len(val_data[0])}\")\n",
        "                        print(f\"  val_data[1] length: {len(val_data[1])}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in ensemble processing: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Step 10: Generate comprehensive visualizations (only if we have results)\n",
        "    if single_results:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"GENERATING COMPREHENSIVE ANALYSIS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        try:\n",
        "            # Plot overall model comparison\n",
        "            if single_results and len(single_results) > 0:\n",
        "                visualizer.plot_model_comparison(\n",
        "                    single_results,\n",
        "                    ensemble_results if 'ensemble_results' in locals() else {}\n",
        "                )\n",
        "                plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/model_comparison.png\", dpi=300, bbox_inches='tight')\n",
        "                plt.close('all')\n",
        "\n",
        "            # Generate comprehensive report\n",
        "            visualizer.generate_comprehensive_report(\n",
        "                single_results,\n",
        "                ensemble_results if 'ensemble_results' in locals() else {},\n",
        "                best_ensemble if 'best_ensemble' in locals() else None\n",
        "            )\n",
        "            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/comprehensive_report.png\", dpi=300, bbox_inches='tight')\n",
        "            plt.close('all')\n",
        "\n",
        "            # Additional visualizations\n",
        "            if test_loader is not None and len(test_loader.dataset) > 0:\n",
        "                try:\n",
        "                    visualizer.plot_comparative_xai(\n",
        "                        single_models,\n",
        "                        ensemble_results if 'ensemble_results' in locals() else {},\n",
        "                        test_loader,\n",
        "                        max_images=2\n",
        "                    )\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/comparative_xai.png\", dpi=300, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "\n",
        "                    visualizer.plot_lrp_grid(single_models, test_loader)\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/lrp_grid.png\", dpi=300, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in additional visualizations: {e}\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in comprehensive analysis: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Final cleanup\n",
        "    try:\n",
        "        if 'single_models' in locals():\n",
        "            del single_models\n",
        "        if 'test_loader' in locals():\n",
        "            del test_loader\n",
        "        if 'histories' in locals():\n",
        "            del histories\n",
        "        if 'single_results' in locals():\n",
        "            del single_results\n",
        "        if 'ensemble_results' in locals():\n",
        "            del ensemble_results\n",
        "        if 'best_ensemble' in locals():\n",
        "            del best_ensemble\n",
        "        if 'visualizer' in locals():\n",
        "            del visualizer\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "        gc.collect()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            print(f\"Final GPU memory: {torch.cuda.memory_allocated()/1024**3:.2f}GB allocated\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error in final cleanup: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PIPELINE COMPLETED!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nGenerated Files:\")\n",
        "    print(f\"- Model checkpoints: {Config.OUTPUT_DIR}/models/\")\n",
        "    print(f\"- Results: {Config.OUTPUT_DIR}/kfold_results/\")\n",
        "    print(f\"- Visualizations: {Config.OUTPUT_DIR}/visualizations/\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Multiprocessing setup for CUDA compatibility\n",
        "import torch.multiprocessing as mp\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "#     try:\n",
        "#         mp.set_start_method('spawn', force=True)\n",
        "#     except RuntimeError:\n",
        "#         pass  # Already set\n",
        "\n",
        "#     # Set environment variables for optimal GPU usage\n",
        "#     os.environ['CUDA_LAUNCH_BLOCKING'] = '0'  # Changed to 0 for better performance\n",
        "#     os.environ['OMP_NUM_THREADS'] = '2'  # Limit CPU threads\n",
        "#     os.environ['CUDA_VISIBLE_DEVICES'] = '0'  # Use first GPU only\n",
        "\n",
        "#     # Additional GPU optimizations\n",
        "#     torch.backends.cudnn.enabled = True\n",
        "#     torch.backends.cudnn.benchmark = True\n",
        "#     torch.backends.cudnn.deterministic = False\n",
        "\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "eXcdgsbTh2ED",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "084f7f54-fdc9-46cd-a7be-8bc31758df64"
      },
      "id": "eXcdgsbTh2ED",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-gradcam in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.5.0)\n",
            "Requirement already satisfied: captum in /usr/local/lib/python3.12/dist-packages (0.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from pytorch-gradcam) (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-gradcam) (1.26.4)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from captum) (3.10.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.12/dist-packages (from captum) (2.8.0+cu126)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.19.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10->captum) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10->captum) (3.0.2)\n",
            "Requirement already satisfied: captum in /usr/local/lib/python3.12/dist-packages (0.8.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from captum) (3.10.0)\n",
            "Requirement already satisfied: numpy<2.0 in /usr/local/lib/python3.12/dist-packages (from captum) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from captum) (25.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.12/dist-packages (from captum) (2.8.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from captum) (4.67.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.5)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (1.3.10)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.15.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.19.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (4.59.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10->captum) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10->captum) (3.0.2)\n",
            "Starting Fish Species Classification Pipeline...\n",
            "======================================================================\n",
            "Adjusted batch_size: 64, num_workers: 4 (GPU memory: 22.16 GB)\n",
            "Using device: cuda\n",
            "PyTorch version: 2.8.0+cu126\n",
            "Dynamic BATCH_SIZE: 64, DATALOADER_NUM_WORKERS: 4\n",
            "----------------------------------------------------------------------\n",
            "Loading and balancing data...\n",
            "Loading and preprocessing data...\n",
            "Original data shape: (8407, 3, 224, 224)\n",
            "Original class distribution: [3000 1185 2899  370  953]\n",
            "Applying SMOTE for class balancing...\n",
            "Balanced data shape: (15000, 3, 224, 224)\n",
            "Balanced class distribution: [3000 3000 3000 3000 3000]\n",
            "Total samples after balancing: 15000, Labels: 15000\n",
            "\n",
            "======================================================================\n",
            "PROCESSING MODEL: resnet50\n",
            "======================================================================\n",
            "\n",
            "1. CREATING INITIAL DATA LOADERS FOR resnet50\n",
            "--------------------------------------------------\n",
            "Train: 9000, Val: 3000, Test: 3000\n",
            "Using optimized batch size: 96\n",
            "Train loader: 9000 samples\n",
            "Val loader: 3000 samples\n",
            "Test loader: 3000 samples\n",
            "\n",
            "2. HYPERPARAMETER OPTIMIZATION FOR resnet50\n",
            "--------------------------------------------------\n",
            "Train loader size: 9000 samples, 94 batches\n",
            "Val loader size: 3000 samples, 32 batches\n",
            "Optimizing hyperparameters for resnet50...\n",
            "\n",
            "Trial 1/1 parameters for resnet50:\n",
            "  lr: 0.0000\n",
            "  weight_decay: 0.0000\n",
            "  dropout: 0.4005\n",
            "  hidden_dim_multiplier: 0.6306\n",
            "  augmentation_strength: light\n",
            "  batch_size: 32\n",
            "  optimizer_type: adamw\n",
            "  scheduler_type: cosine\n",
            "  label_smoothing: 0.0599\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 235MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Trial 1 Optuna Epoch 1 completed for Model: resnet50\n",
            "Optuna Epoch 1/1 Summary: TL: 1.698805, VL: 1.578966, TA: 0.2370, VA: 0.2573, VF1: 0.2441\n",
            "\n",
            "Validation Accuracy: 0.2573\n",
            "Validation F1 Score: 0.2441\n",
            "\n",
            "\u001b[1;31m======================================================================\u001b[0m\n",
            "\u001b[1;31mRESNET50 BEST PARAMETERS Finalized:\u001b[0m\n",
            "\u001b[1;31m  lr: 0.0000\u001b[0m\n",
            "\u001b[1;31m  batch_size: 32\u001b[0m\n",
            "\u001b[1;31m  weight_decay: 0.0000\u001b[0m\n",
            "\u001b[1;31m  dropout: 0.4005\u001b[0m\n",
            "\u001b[1;31m  hidden_dim_multiplier: 0.6306\u001b[0m\n",
            "\u001b[1;31m  augmentation_strength: light\u001b[0m\n",
            "\u001b[1;31m  optimizer_type: adamw\u001b[0m\n",
            "\u001b[1;31m  scheduler_type: cosine\u001b[0m\n",
            "\u001b[1;31m  label_smoothing: 0.0599\u001b[0m\n",
            "\u001b[1;31m======================================================================\u001b[0m\n",
            "\n",
            "3. RECREATING DATA LOADERS WITH OPTIMIZED PARAMETERS\n",
            "--------------------------------------------------\n",
            "Train: 9000, Val: 3000, Test: 3000\n",
            "Using optimized batch size: 32\n",
            "Recreated - Train: 9000, Val: 3000, Test: 3000\n",
            "Val data tuple: X=3000, Y=3000\n",
            "Test data tuple: X=3000, Y=3000\n",
            "\n",
            "4. MAIN MODEL TRAINING FOR resnet50\n",
            "--------------------------------------------------\n",
            "Training resnet50 with hyperparameters:\n",
            "  lr: 0.0000\n",
            "  batch_size: 32\n",
            "  weight_decay: 0.0000\n",
            "  dropout: 0.4005\n",
            "  hidden_dim_multiplier: 0.6306\n",
            "  augmentation_strength: light\n",
            "  optimizer_type: adamw\n",
            "  scheduler_type: cosine\n",
            "  label_smoothing: 0.0599\n",
            "\n",
            "Training main model: resnet50\n",
            "\n",
            "============================================================\n",
            "Model: RESNET50 | Epoch: 1/2\n",
            "============================================================\n",
            "train_epoch: Starting for resnet50, 282 batches, dataset size: 9000\n",
            "TRAIN |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% | Batch:  282/282 | Loss: 1.7436 | Acc: 0.3750 | ETA: 0:00:00validate_epoch: Starting for resnet50, 94 batches, dataset size: 3000\n",
            "VAL   |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% | Batch:   94/94 | Loss: 1.3605 | Acc: 0.5000 | ETA: 0:00:00\n",
            "------------------------------------------------------------\n",
            "EPOCH SUMMARY:\n",
            "  Train Loss: 1.605601 | Train Acc: 0.2960\n",
            "  Val Loss:   1.344317 | Val Acc:   0.5137\n",
            "  Val F1:     0.4795 | Epoch Time: 86.1s\n",
            "  Learning Rate: 1.81e-06\n",
            "  ‚òÖ NEW BEST MODEL! (F1: 0.4795)\n",
            "  Total Time: 0:01:26\n",
            "------------------------------------------------------------\n",
            "Epoch 1: Val F1: 0.4795, Val Acc: 0.5137\n",
            "New best model saved with Val F1: 0.4795\n",
            "\n",
            "============================================================\n",
            "Model: RESNET50 | Epoch: 2/2\n",
            "============================================================\n",
            "train_epoch: Starting for resnet50, 282 batches, dataset size: 9000\n",
            "TRAIN |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% | Batch:  282/282 | Loss: 1.4608 | Acc: 0.3750 | ETA: 0:00:00validate_epoch: Starting for resnet50, 94 batches, dataset size: 3000\n",
            "VAL   |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% | Batch:   94/94 | Loss: 1.1493 | Acc: 0.6250 | ETA: 0:00:00\n",
            "------------------------------------------------------------\n",
            "EPOCH SUMMARY:\n",
            "  Train Loss: 1.377451 | Train Acc: 0.4496\n",
            "  Val Loss:   1.182495 | Val Acc:   0.6070\n",
            "  Val F1:     0.5773 | Epoch Time: 16.0s\n",
            "  Learning Rate: 1.41e-06\n",
            "  ‚òÖ NEW BEST MODEL! (F1: 0.5773)\n",
            "  Total Time: 0:01:42\n",
            "------------------------------------------------------------\n",
            "Epoch 2: Val F1: 0.5773, Val Acc: 0.6070\n",
            "New best model saved with Val F1: 0.5773\n",
            "Evaluating For Model: resnet50...\n",
            "resnet50 Evaluation: Acc = 0.6013, F1 (Macro) = 0.5748, Loss = 1.1392\n",
            "Data shapes - Labels: (3000,), Predictions: (3000,), Probabilities: (3000, 5)\n",
            "Saved main model results to ./fish_classification_results/model_results/resnet50_main_results.pt\n",
            "Loaded results from ./fish_classification_results/model_results/resnet50_main_results.pt\n",
            "Main model training completed for resnet50\n",
            "\n",
            "5. K-FOLD CROSS-VALIDATION FOR resnet50\n",
            "--------------------------------------------------\n",
            "Performing 3-fold cross-validation...\n",
            "Computed 3 folds, train_size=9000, val_size=3000\n",
            "Total: 9000 samples, 32 batch_size, 3 folds\n",
            "Per fold: Train=6000 samples (188 batches), Val=3000 samples (94 batches)\n",
            "\n",
            "\u001b[1;31mStarting 3-fold cross-validation for resnet50\u001b[0m\n",
            "\n",
            "Fold 1/3: Train=6000 samples (188 batches), Val=3000 samples (94 batches)\n",
            "Training resnet50 with hyperparameters:\n",
            "  lr: 0.0000\n",
            "  batch_size: 32\n",
            "  weight_decay: 0.0000\n",
            "  dropout: 0.4005\n",
            "  hidden_dim_multiplier: 0.6306\n",
            "  augmentation_strength: light\n",
            "  optimizer_type: adamw\n",
            "  scheduler_type: cosine\n",
            "  label_smoothing: 0.0599\n",
            "\n",
            "Training main model: resnet50\n",
            "\n",
            "============================================================\n",
            "Model: RESNET50 | Epoch: 1/2\n",
            "============================================================\n",
            "train_epoch: Starting for resnet50, 188 batches, dataset size: 9000\n",
            "TRAIN |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà-|  99.5% | Batch:  187/188 | Loss: 1.5543 | Acc: 0.2812 | ETA: 0:00:00"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd48bb6",
      "metadata": {
        "id": "cdd48bb6"
      },
      "source": [
        "#End"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}