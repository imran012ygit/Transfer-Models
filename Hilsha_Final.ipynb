{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran012x/Transfer-Models/blob/main/Hilsha_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01bea336",
      "metadata": {
        "id": "01bea336"
      },
      "source": [
        "#Colab-connect"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "344965bc",
      "metadata": {
        "id": "344965bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3140370-9d32-4298-acd9-de9f1da303de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# # Upload a file\n",
        "# uploaded = files.upload()\n",
        "# # Get the file name\n",
        "# file_name = list(uploaded.keys())[0]\n",
        "# print(f\"Uploaded file: {file_name}\")\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# # with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_224_11k.zip', 'r') as zip_ref:\n",
        "# #     zip_ref.extractall('')\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de009928",
      "metadata": {
        "id": "de009928"
      },
      "source": [
        "#Data Preprocess and Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "6f95c03b",
      "metadata": {
        "id": "6f95c03b"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import torch\n",
        "# import numpy as np\n",
        "# from PIL import Image\n",
        "# from tqdm import tqdm\n",
        "# import random\n",
        "# import gc\n",
        "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "# import threading\n",
        "# import zipfile\n",
        "\n",
        "# # Check GPU availability\n",
        "# print(\"GPU Available:\", torch.cuda.is_available())\n",
        "# print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "# # Define fish classes and dataset paths\n",
        "# fish_classes = ['ilish', 'chandana', 'sardin', 'sardinella', 'punctatus'] #0,1,2,3,4\n",
        "# zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip').extractall('/content/.hidden_fish')\n",
        "# data_dir = '/content/.hidden_fish'\n",
        "\n",
        "# image_limits = {\n",
        "#     'ilish': 3000,\n",
        "#     'chandana': 1185,\n",
        "#     'sardin': 2899,\n",
        "#     'sardinella': 370,\n",
        "#     'punctatus': 953\n",
        "# }\n",
        "\n",
        "# # Settings\n",
        "# total_images = sum(image_limits.values())\n",
        "# batch_size = 100\n",
        "# num_threads = 4\n",
        "\n",
        "\n",
        "# # Output paths\n",
        "# output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "# labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "# xdata_file = os.path.join(output_dir, 'X_data.npy')\n",
        "\n",
        "# save_lock = threading.Lock()  # for thread-safe writes -> Prevents race conditions when multiple threads write to the same list.\n",
        "\n",
        "# # Function to gather image paths\n",
        "# def get_image_paths(class_name, max_images):\n",
        "#     path = os.path.join(data_dir, class_name)\n",
        "#     files = sorted(os.listdir(path))\n",
        "#     random.shuffle(files)\n",
        "#     return [os.path.join(path, f) for f in files[:max_images]]\n",
        "\n",
        "# # Load and preprocess batch\n",
        "# def load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     end_idx = min(start_idx + batch_size, len(image_paths))\n",
        "#     batch_paths = image_paths[start_idx:end_idx]\n",
        "#     batch_images = []\n",
        "\n",
        "#     for img_path in batch_paths:\n",
        "#         img = Image.open(img_path).resize((224, 224)).convert('RGB')\n",
        "#         img_tensor = torch.tensor(np.array(img), dtype=torch.uint8).permute(2, 0, 1)  # C x H x W\n",
        "#         batch_images.append(img_tensor)\n",
        "\n",
        "#     batch_tensor = torch.stack(batch_images)  # B x C x H x W\n",
        "#     batch_labels = np.full((len(batch_images),), class_idx, dtype=np.int32)\n",
        "#     return batch_tensor, batch_labels\n",
        "\n",
        "# # Process one batch and return tensors & labels (no file saving)\n",
        "# def process_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     return load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx)\n",
        "\n",
        "# def preprocess_and_save_all(overwrite=True):\n",
        "#     if os.path.exists(labels_file) and os.path.exists(xdata_file) and not overwrite:\n",
        "#         print(\"Preprocessed data already exists. Set overwrite=True to reprocess.\")\n",
        "#         return\n",
        "\n",
        "#     all_images = []\n",
        "#     all_labels = []\n",
        "#     processed_count = 0\n",
        "\n",
        "#     for idx, class_name in enumerate(fish_classes):\n",
        "#         print(f\"\\nProcessing class: {class_name}\")\n",
        "#         image_paths = get_image_paths(class_name, image_limits[class_name])\n",
        "#         total_batches = (len(image_paths) + batch_size - 1) // batch_size\n",
        "#         #It ensures ceiling division ‚Äî rounding up, not down.\n",
        "#         # Normal division: 103 / 20 = 5.15 ‚Üí floor division // 20 = 5 (‚ùå missing last 3 images)\n",
        "#         # This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ‚úÖ\n",
        "\n",
        "#         with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "#             futures = []\n",
        "#             for start in range(0, len(image_paths), batch_size):\n",
        "#                 futures.append(executor.submit(process_batch, image_paths, start, batch_size, idx))\n",
        "\n",
        "#             for future in tqdm(as_completed(futures), total=total_batches, desc=class_name):#taqaddum (ÿ™ŸÇÿØŸëŸÖ) ‚Äì Arabic for \"progress\".\n",
        "#                 # futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\n",
        "#                 # as_completed(futures): Yields each future as it finishes (not in order).\n",
        "\n",
        "#                 batch_tensor, batch_labels = future.result()\n",
        "#                 with save_lock: #Locks this section so that only one thread can update the shared lists safely.\n",
        "#                     all_images.append(batch_tensor)\n",
        "#                     all_labels.append(batch_labels)\n",
        "#                     processed_count += batch_tensor.size(0)\n",
        "#                     print(f\"Processed batch with {batch_tensor.size(0)} images, total processed: {processed_count}/{total_images}\")\n",
        "#                 gc.collect()\n",
        "\n",
        "#     # Combine all tensors and labels\n",
        "#     X = torch.cat(all_images, dim=0).numpy()\n",
        "#     Y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "#     # Save final arrays\n",
        "#     np.save(xdata_file, X, allow_pickle=False)#Malicious .npy -> import os;os.system(\"rm -rf /\")  # ‚Üê Dangerous command\n",
        "#     np.save(labels_file, Y, allow_pickle=False)\n",
        "\n",
        "#     print(f\"\\n‚úÖ Done! Saved {processed_count} images in {xdata_file}\")\n",
        "#     print(f\"X_data shape: {X.shape}, Y_labels shape: {Y.shape}\")\n",
        "\n",
        "#     if processed_count != total_images:\n",
        "#         raise ValueError(f\"Expected {total_images} images, but processed {processed_count}\")\n",
        "\n",
        "# # Run preprocessing and save directly to X_data.npy and Y_labels.npy\n",
        "# preprocess_and_save_all(overwrite=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0fbbeb4",
      "metadata": {
        "id": "c0fbbeb4"
      },
      "source": [
        "####DATA LOADING...."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "23d9c0c0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23d9c0c0",
        "outputId": "8c13f64b-647d-44f0-989e-1333f13ba2c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÅ X_data.npy: 1.18 GB\n",
            "üìÅ Y_labels.npy: 32.96 KB\n",
            "‚úÖ X shape: (8407, 3, 224, 224), dtype: uint8\n",
            "‚úÖ Y shape: (8407,), dtype: int32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2614331559.py:42: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:203.)\n",
            "  X = torch.from_numpy(X)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Torch tensors ready on cuda\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# Your data path\n",
        "output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "data_file = os.path.join(output_dir, 'X_data.npy')\n",
        "labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "\n",
        "# Readable size format\n",
        "def sizeof_fmt(num, suffix='B'):\n",
        "    for unit in ['', 'K', 'M', 'G', 'T']:\n",
        "        if abs(num) < 1024.0:\n",
        "            return f\"{num:3.2f} {unit}{suffix}\"\n",
        "        num /= 1024.0\n",
        "    return f\"{num:.2f} T{suffix}\"\n",
        "\n",
        "# Main loader\n",
        "def load_preprocessed_data(as_torch=True, normalize=True, to_device=None):\n",
        "    # Check file existence #cpu,cuda (CUDA stands for Compute Unified Device Architecture.)\n",
        "    for path in [data_file, labels_file]:\n",
        "        if not os.path.exists(path):\n",
        "            raise FileNotFoundError(f\"Missing: {path}\")\n",
        "\n",
        "    # Print file sizes\n",
        "    print(f\"üìÅ X_data.npy: {sizeof_fmt(os.path.getsize(data_file))}\")\n",
        "    print(f\"üìÅ Y_labels.npy: {sizeof_fmt(os.path.getsize(labels_file))}\")\n",
        "\n",
        "    # Load with mmap\n",
        "    X = np.load(data_file, mmap_mode='r')\n",
        "    Y = np.load(labels_file, mmap_mode='r')\n",
        "\n",
        "    print(f\"‚úÖ X shape: {X.shape}, dtype: {X.dtype}\")\n",
        "    print(f\"‚úÖ Y shape: {Y.shape}, dtype: {Y.dtype}\")\n",
        "\n",
        "    # Sanity check\n",
        "    if len(X) != len(Y):\n",
        "        raise ValueError(\"Mismatch between number of samples in X and Y\")\n",
        "\n",
        "    # Convert to torch\n",
        "    if as_torch:\n",
        "        X = torch.from_numpy(X)\n",
        "        Y = torch.from_numpy(Y)\n",
        "\n",
        "        if normalize and X.dtype == torch.uint8:\n",
        "            X = X.float() / 255.0\n",
        "\n",
        "        if to_device:\n",
        "            X = X.to(to_device)\n",
        "            Y = Y.to(to_device)\n",
        "\n",
        "        print(f\"üß† Torch tensors ready on {to_device or 'CPU'}\")\n",
        "\n",
        "    return X, Y\n",
        "\n",
        "# üîÅ Example call\n",
        "X, Y = load_preprocessed_data(\n",
        "    as_torch=True,\n",
        "    normalize=True,\n",
        "    to_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. IMPORTS AND INITIAL SETUP\n",
        "# =============================================================================\n",
        "# Purpose: Import all required libraries and set up warnings to suppress unnecessary messages.\n",
        "\n",
        "!pip install pytorch-gradcam optuna captum  # Uncomment if running in a new environment\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from itertools import combinations\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Deep Learning\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, f1_score,\n",
        "                             accuracy_score, precision_score, recall_score)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Augmentation\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Hyperparameter optimization\n",
        "try:\n",
        "    import optuna\n",
        "    OPTUNA_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPTUNA_AVAILABLE = False\n",
        "    print(\"Warning: Optuna not available. Using default hyperparameters.\")\n",
        "\n",
        "# XAI dependencies\n",
        "import torch.autograd as autograd\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class NpEncoder(json.JSONEncoder):\n",
        "    def default(self, obj):\n",
        "        if isinstance(obj, np.integer):\n",
        "            return int(obj)\n",
        "        if isinstance(obj, np.floating):\n",
        "            return float(obj)\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        return super(NpEncoder, self).default(obj)\n",
        "\n",
        "# ---\n",
        "# 2. CONFIGURATION\n",
        "# =============================================================================\n",
        "# Purpose: Define configuration settings and initialize the environment.\n",
        "\n",
        "class Config:\n",
        "    \"\"\"Configuration settings\"\"\"\n",
        "    # Paths - UPDATE THESE TO YOUR ACTUAL PATHS\n",
        "    DATA_FILE = '/content/drive/MyDrive/Hilsha/X_data.npy'\n",
        "    LABELS_FILE = '/content/drive/MyDrive/Hilsha/Y_labels.npy'\n",
        "    OUTPUT_DIR = './fish_classification_results'\n",
        "\n",
        "    # Dataset parameters\n",
        "    NUM_CLASSES = 5\n",
        "    CLASS_LABELS = ['Ilish', 'Chandana', 'Sardin', 'Sardinella', 'Punctatus']\n",
        "    INPUT_SIZE = 224\n",
        "\n",
        "    # Training parameters\n",
        "    BATCH_SIZE = 64\n",
        "    EPOCHS = 30\n",
        "    DATALOADER_NUM_WORKERS = 4\n",
        "    PIN_MEMORY = True\n",
        "    USE_MIXED_PRECISION = True\n",
        "    COMPILE_MODEL = True\n",
        "    PATIENCE = 10\n",
        "    LEARNING_RATE = 1e-4\n",
        "    WEIGHT_DECAY = 1e-4\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    OPTUNA_TRIALS = 10\n",
        "    OPTUNA_EPOCHS = 15\n",
        "\n",
        "    # Models to train\n",
        "    MODELS = ['resnet50', 'efficientnet_b0',\n",
        "              'mobilenet_v3_large','vgg16', 'densenet121']\n",
        "\n",
        "    # Ensemble methods\n",
        "    ENSEMBLE_METHODS = ['simple_average', 'weighted_average', 'confidence_based', 'learnable_weighted']\n",
        "\n",
        "    # Device\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    SEED = 42\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"Setup random seeds and directories\"\"\"\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "\n",
        "    directories = [\n",
        "        Config.OUTPUT_DIR,\n",
        "        f\"{Config.OUTPUT_DIR}/models\",\n",
        "        f\"{Config.OUTPUT_DIR}/visualizations\",\n",
        "        f\"{Config.OUTPUT_DIR}/reports\",\n",
        "        f\"{Config.OUTPUT_DIR}/xai_visualizations\"\n",
        "    ]\n",
        "\n",
        "    for directory in directories:\n",
        "        Path(directory).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    print(f\"Using device: {Config.DEVICE}\")\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "# ---\n",
        "# 3. TRAINING PROGRESS TRACKER\n",
        "# =============================================================================\n",
        "# Purpose: Track and display training progress with progress bars and epoch summaries.\n",
        "\n",
        "class TrainingProgressTracker:\n",
        "    \"\"\"Track and display detailed training progress\"\"\"\n",
        "\n",
        "    def __init__(self, model_name, total_epochs, total_batches_per_epoch):\n",
        "        self.model_name = model_name\n",
        "        self.total_epochs = total_epochs\n",
        "        self.total_batches_per_epoch = total_batches_per_epoch\n",
        "        self.start_time = time.time()\n",
        "        self.epoch_start_time = None\n",
        "        self.batch_times = []\n",
        "\n",
        "    def start_epoch(self, epoch):\n",
        "        \"\"\"Start tracking an epoch\"\"\"\n",
        "        self.current_epoch = epoch\n",
        "        self.epoch_start_time = time.time()\n",
        "        self.batch_times = []\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Model: {self.model_name.upper()} | Epoch: {epoch+1}/{self.total_epochs}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "    def update_batch(self, batch_idx, batch_loss, batch_acc, is_training=True):\n",
        "        \"\"\"Update progress for current batch\"\"\"\n",
        "        batch_time = time.time()\n",
        "        self.batch_times.append(batch_time)\n",
        "\n",
        "        # Calculate timing estimates\n",
        "        if len(self.batch_times) > 1:\n",
        "            avg_batch_time = np.mean(np.diff(self.batch_times[-10:]))\n",
        "        else:\n",
        "            avg_batch_time = 1.0\n",
        "\n",
        "        remaining_batches = self.total_batches_per_epoch - (batch_idx + 1)\n",
        "        eta_epoch = remaining_batches * avg_batch_time\n",
        "\n",
        "        # Progress bar\n",
        "        progress_pct = (batch_idx + 1) / self.total_batches_per_epoch * 100\n",
        "        bar_length = 30\n",
        "        filled_length = int(bar_length * (batch_idx + 1) // self.total_batches_per_epoch)\n",
        "        bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "        # Format time\n",
        "        eta_str = str(timedelta(seconds=int(eta_epoch)))\n",
        "\n",
        "        # Display progress\n",
        "        mode = \"TRAIN\" if is_training else \"VAL  \"\n",
        "        print(f\"\\r{mode} |{bar}| {progress_pct:5.1f}% | \"\n",
        "              f\"Batch: {batch_idx+1:4d}/{self.total_batches_per_epoch} | \"\n",
        "              f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
        "              f\"ETA: {eta_str}\", end='', flush=True)\n",
        "\n",
        "    def finish_epoch(self, train_loss, train_acc, val_loss, val_acc, val_f1,\n",
        "                    is_best=False, lr=None):\n",
        "        \"\"\"Finish epoch and display summary\"\"\"\n",
        "        epoch_time = time.time() - self.epoch_start_time\n",
        "        total_time = time.time() - self.start_time\n",
        "\n",
        "        print(f\"\\n{'-'*60}\")\n",
        "        print(f\"EPOCH SUMMARY:\")\n",
        "        print(f\"  Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"  Val Loss:   {val_loss:.6f} | Val Acc:   {val_acc:.4f}\")\n",
        "        print(f\"  Val F1:     {val_f1:.4f} | Epoch Time: {epoch_time:.1f}s\")\n",
        "        if lr:\n",
        "            print(f\"  Learning Rate: {lr:.2e}\")\n",
        "\n",
        "        if is_best:\n",
        "            print(f\"  ‚òÖ NEW BEST MODEL! (F1: {val_f1:.4f})\")\n",
        "\n",
        "        print(f\"  Total Time: {str(timedelta(seconds=int(total_time)))}\")\n",
        "        print(f\"{'-'*60}\")\n",
        "\n",
        "# ---\n",
        "# 4. DATA LOADING AND PREPROCESSING\n",
        "# =============================================================================\n",
        "# Purpose: Handle dataset creation, data loading, balancing with SMOTE, and data augmentation.\n",
        "\n",
        "class FishDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = self._preprocess_images(images)\n",
        "        self.labels = labels.astype(np.int64)\n",
        "        self.transform = transform\n",
        "\n",
        "    def _preprocess_images(self, images):\n",
        "        if images.max() > 1.5:\n",
        "            images = images.astype(np.float32) / 255.0\n",
        "        if len(images.shape) == 4 and images.shape[1] == 3:\n",
        "            images = np.transpose(images, (0, 2, 3, 1))\n",
        "        return images.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image=image)['image']\n",
        "        else:\n",
        "            image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "\n",
        "        return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "class DataManager:\n",
        "    @staticmethod\n",
        "    def get_transforms(is_training=True, augmentation_strength='medium'):\n",
        "        \"\"\"Get data transforms with configurable augmentation strength\"\"\"\n",
        "        if is_training:\n",
        "            if augmentation_strength == 'light':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.3),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            elif augmentation_strength == 'heavy':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.7),\n",
        "                    A.VerticalFlip(p=0.5),\n",
        "                    A.RandomRotate90(p=0.7),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, p=0.8),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.8),\n",
        "                    A.HueSaturationValue(hue_shift_limit=30, sat_shift_limit=40, val_shift_limit=30, p=0.7),\n",
        "                    A.GaussianBlur(blur_limit=(3, 9), p=0.5),\n",
        "                    A.GaussNoise(var_limit=(10.0, 80.0), p=0.4),\n",
        "                    A.CoarseDropout(max_holes=12, max_height=25, max_width=25, p=0.5),\n",
        "                    A.ElasticTransform(p=0.3),\n",
        "                    A.GridDistortion(p=0.3),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            else:  # medium\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.5),\n",
        "                    A.VerticalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.5),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.7),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
        "                    A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.6),\n",
        "                    A.GaussianBlur(blur_limit=(3, 7), p=0.4),\n",
        "                    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "                    A.CoarseDropout(max_holes=8, max_height=20, max_width=20, p=0.4),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "        else:\n",
        "            return A.Compose([\n",
        "                A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "\n",
        "    @staticmethod\n",
        "    def load_and_balance_data():\n",
        "        \"\"\"Load data and apply SMOTE\"\"\"\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "\n",
        "        X = np.load(Config.DATA_FILE)\n",
        "        Y = np.load(Config.LABELS_FILE)\n",
        "\n",
        "        print(f\"Original data shape: {X.shape}\")\n",
        "        print(f\"Original class distribution: {np.bincount(Y)}\")\n",
        "\n",
        "        print(\"Applying SMOTE for class balancing...\")\n",
        "        X_flat = X.reshape(X.shape[0], -1)\n",
        "        smote = SMOTE(random_state=Config.SEED, k_neighbors=min(5, np.bincount(Y).min()-1))\n",
        "        X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y)\n",
        "        X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "\n",
        "        print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "\n",
        "        return X_balanced, Y_balanced\n",
        "\n",
        "    @staticmethod\n",
        "    def create_data_loaders(X, Y, test_size=0.2, batch_size=None, augmentation_strength='medium'):\n",
        "        if batch_size is None:\n",
        "            if torch.cuda.is_available():\n",
        "                gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "                if gpu_memory_gb >= 24:\n",
        "                    batch_size = 128\n",
        "                elif gpu_memory_gb >= 12:\n",
        "                    batch_size = 96\n",
        "                elif gpu_memory_gb >= 8:\n",
        "                    batch_size = 64\n",
        "                else:\n",
        "                    batch_size = 48\n",
        "            else:\n",
        "                batch_size = Config.BATCH_SIZE\n",
        "\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "            X, Y, test_size=test_size, random_state=Config.SEED, stratify=Y\n",
        "        )\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=0.25, random_state=Config.SEED, stratify=y_temp\n",
        "        )\n",
        "\n",
        "        print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "        print(f\"Using optimized batch size: {batch_size}\")\n",
        "\n",
        "        train_dataset = FishDataset(X_train, y_train,\n",
        "                                  DataManager.get_transforms(True, augmentation_strength))\n",
        "        val_dataset = FishDataset(X_val, y_val, DataManager.get_transforms(False))\n",
        "        test_dataset = FishDataset(X_test, y_test, DataManager.get_transforms(False))\n",
        "\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "        sample_weights = [class_weights[y] for y in y_train]\n",
        "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            sampler=sampler,\n",
        "            num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            prefetch_factor=2,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            prefetch_factor=2,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=Config.DATALOADER_NUM_WORKERS,\n",
        "            pin_memory=Config.PIN_MEMORY,\n",
        "            prefetch_factor=2,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "        return train_loader, val_loader, test_loader, (X_val, y_val), (X_test, y_test)\n",
        "\n",
        "# ---\n",
        "# 5. MODEL FACTORY\n",
        "# =============================================================================\n",
        "# Purpose: Create different neural network models with customizable architectures.\n",
        "\n",
        "class ModelFactory:\n",
        "    @staticmethod\n",
        "    def create_model(model_name, num_classes=Config.NUM_CLASSES, dropout_rate=0.5,\n",
        "                    hidden_dim_multiplier=0.5):\n",
        "        \"\"\"Create model with configurable architecture\"\"\"\n",
        "\n",
        "        if model_name == 'resnet50':\n",
        "            model = models.resnet50(weights='IMAGENET1K_V2')\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'efficientnet_b0':\n",
        "            model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "            num_features = model.classifier[1].in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'mobilenet_v3_large':\n",
        "            model = models.mobilenet_v3_large(weights='IMAGENET1K_V2')\n",
        "            num_features = 960\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'vgg16':\n",
        "            model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "            hidden_dim = int(4096 * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Linear(512 * 7 * 7, 4096),\n",
        "                nn.ReLU(True),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(4096, hidden_dim),\n",
        "                nn.ReLU(True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'densenet121':\n",
        "            model = models.densenet121(weights='IMAGENET1K_V1')\n",
        "            num_features = model.classifier.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "        return model\n",
        "\n",
        "# ---\n",
        "# 6. LEARNABLE WEIGHTED ENSEMBLE MODEL\n",
        "# =============================================================================\n",
        "# Purpose: Define a neural network for learning optimal ensemble weights.\n",
        "\n",
        "class LearnableWeightedEnsemble(nn.Module):\n",
        "    \"\"\"Neural network for learning optimal ensemble weights\"\"\"\n",
        "    def __init__(self, num_models, num_classes, hidden_dim=64):\n",
        "        super(LearnableWeightedEnsemble, self).__init()\n",
        "        self.num_models = num_models\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        self.weight_network = nn.Sequential(\n",
        "            nn.Linear(num_models * num_classes, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(hidden_dim // 2, num_models),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "        self.prediction_head = nn.Sequential(\n",
        "            nn.Linear(num_classes, num_classes * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.2),\n",
        "            nn.Linear(num_classes * 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, model_predictions):\n",
        "        batch_size = model_predictions.shape[0]\n",
        "\n",
        "        flattened_preds = model_predictions.view(batch_size, -1)\n",
        "\n",
        "        weights = self.weight_network(flattened_preds)\n",
        "\n",
        "        weighted_avg = torch.sum(model_predictions * weights.unsqueeze(-1), dim=1)\n",
        "\n",
        "        final_predictions = self.prediction_head(weighted_avg)\n",
        "\n",
        "        return final_predictions, weights\n",
        "\n",
        "# ---\n",
        "# 7. HYPERPARAMETER OPTIMIZATION\n",
        "# =============================================================================\n",
        "# Purpose: Tune model hyperparameters using Optuna.\n",
        "\n",
        "class ExpandedHyperparameterOptimizer:\n",
        "    def __init__(self, model_name, train_loader, val_loader):\n",
        "        self.model_name = model_name\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.total_batches_per_epoch = len(train_loader)\n",
        "        self.batch_times = []\n",
        "\n",
        "        self.best_val_acc = 0.0\n",
        "        self.best_val_f1 = 0.0\n",
        "        self.best_trial = -1\n",
        "\n",
        "    def _update_progress(self, batch_idx, batch_loss, batch_acc, trial_params, is_training=True):\n",
        "        \"\"\"Display progress during hyperparameter tuning\"\"\"\n",
        "        batch_time = time.time()\n",
        "        self.batch_times.append(batch_time)\n",
        "\n",
        "        if len(self.batch_times) > 1:\n",
        "            avg_batch_time = np.mean(np.diff(self.batch_times[-10:]))\n",
        "        else:\n",
        "            avg_batch_time = 1.0\n",
        "\n",
        "        remaining_batches = self.total_batches_per_epoch - (batch_idx + 1)\n",
        "        eta_epoch = remaining_batches * avg_batch_time\n",
        "\n",
        "        progress_pct = (batch_idx + 1) / self.total_batches_per_epoch * 100\n",
        "        bar_length = 30\n",
        "        filled_length = int(bar_length * (batch_idx + 1) // self.total_batches_per_epoch)\n",
        "        bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "        eta_str = str(timedelta(seconds=int(eta_epoch)))\n",
        "\n",
        "        mode = \"TRAIN\" if is_training else \"VAL  \"\n",
        "        print(f\"\\r{mode} |{bar}| {progress_pct:5.1f}% | \"\n",
        "              f\"Batch: {batch_idx+1:4d}/{self.total_batches_per_epoch} | \"\n",
        "              f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
        "              f\"ETA: {eta_str} | Params: {self._format_params(trial_params)}\", end='', flush=True)\n",
        "\n",
        "    def _format_params(self, params):\n",
        "        \"\"\"Format hyperparameters for display\"\"\"\n",
        "        formatted = []\n",
        "        for key, value in params.items():\n",
        "            if key in ['lr', 'weight_decay']:\n",
        "                formatted.append(f\"{key}: {value:.4f}\")\n",
        "            elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                formatted.append(f\"{key}: {value:.1f}\")\n",
        "            else:\n",
        "                formatted.append(f\"{key}: {value}\")\n",
        "        return \", \".join(formatted)\n",
        "\n",
        "    def objective(self, trial):\n",
        "        \"\"\"Optuna objective function with hyperparameters\"\"\"\n",
        "        lr = trial.suggest_float('lr', 1e-5, 5e-3, log=True)\n",
        "        weight_decay = trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True)\n",
        "        dropout = trial.suggest_float('dropout', 0.2, 0.8)\n",
        "        hidden_dim_multiplier = trial.suggest_float('hidden_dim_multiplier', 0.25, 1.0)\n",
        "        augmentation_strength = trial.suggest_categorical('augmentation_strength',\n",
        "                                                        ['light', 'medium', 'heavy'])\n",
        "        batch_size = trial.suggest_categorical('batch_size', [16, 24, 32, 48, 64])\n",
        "        optimizer_type = trial.suggest_categorical('optimizer_type', ['adam', 'adamw', 'sgd'])\n",
        "        scheduler_type = trial.suggest_categorical('scheduler_type',\n",
        "                                                 ['cosine', 'step', 'exponential'])\n",
        "        label_smoothing = trial.suggest_float('label_smoothing', 0.0, 0.2)\n",
        "\n",
        "        trial_params = {\n",
        "            'lr': lr, 'weight_decay': weight_decay, 'dropout': dropout,\n",
        "            'hidden_dim_multiplier': hidden_dim_multiplier, 'augmentation_strength': augmentation_strength,\n",
        "            'batch_size': batch_size, 'optimizer_type': optimizer_type, 'scheduler_type': scheduler_type,\n",
        "            'label_smoothing': label_smoothing\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            print(f\"\\nTrial {trial.number+1}/{Config.OPTUNA_TRIALS} parameters for {self.model_name}:\")\n",
        "            for key, value in trial_params.items():\n",
        "                if key in ['lr', 'weight_decay']:\n",
        "                    print(f\"  {key}: {value:.4f}\")\n",
        "                elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                    print(f\"  {key}: {value:.1f}\")\n",
        "                else:\n",
        "                    print(f\"  {key}: {value}\")\n",
        "\n",
        "            temp_train_loader = DataLoader(\n",
        "                self.train_loader.dataset,\n",
        "                batch_size=batch_size,\n",
        "                sampler=self.train_loader.sampler\n",
        "            )\n",
        "            temp_val_loader = DataLoader(\n",
        "                self.val_loader.dataset,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=False\n",
        "            )\n",
        "\n",
        "            model = ModelFactory.create_model(\n",
        "                self.model_name,\n",
        "                dropout_rate=dropout,\n",
        "                hidden_dim_multiplier=hidden_dim_multiplier\n",
        "            )\n",
        "            model = model.to(Config.DEVICE)\n",
        "\n",
        "            if optimizer_type == 'adam':\n",
        "                optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "            elif optimizer_type == 'adamw':\n",
        "                optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "            else:\n",
        "                optimizer = optim.SGD(model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                                    momentum=0.9, nesterov=True)\n",
        "\n",
        "            criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "            if scheduler_type == 'cosine':\n",
        "                scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=Config.OPTUNA_EPOCHS)\n",
        "            elif scheduler_type == 'step':\n",
        "                scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.7)\n",
        "            else:\n",
        "                scheduler = optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
        "\n",
        "            best_val_acc = 0\n",
        "            patience_counter = 0\n",
        "\n",
        "            for epoch in range(Config.OPTUNA_EPOCHS):\n",
        "                self.batch_times = []\n",
        "                model.train()\n",
        "                train_correct = 0\n",
        "                train_total = 0\n",
        "                train_loss = 0\n",
        "\n",
        "                for batch_idx, (images, labels) in enumerate(temp_train_loader):\n",
        "                    if batch_idx > 15:\n",
        "                        break\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    optimizer.zero_grad()\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    loss.backward()\n",
        "\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                    optimizer.step()\n",
        "\n",
        "                    batch_loss = loss.item()\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    train_total += labels.size(0)\n",
        "                    train_correct += (predicted == labels).sum().item()\n",
        "                    train_loss += batch_loss\n",
        "\n",
        "                    batch_acc = train_correct / train_total\n",
        "                    self._update_progress(batch_idx, batch_loss, batch_acc, trial_params, is_training=True)\n",
        "\n",
        "                model.eval()\n",
        "                val_correct = 0\n",
        "                val_total = 0\n",
        "                val_loss = 0\n",
        "                val_predictions = []\n",
        "                val_labels = []\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    for batch_idx, (images, labels) in enumerate(temp_val_loader):\n",
        "                        if batch_idx > 8:\n",
        "                            break\n",
        "                        images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                        outputs = model(images)\n",
        "                        loss = criterion(outputs, labels)\n",
        "                        batch_loss = loss.item()\n",
        "                        val_loss += batch_loss\n",
        "                        _, predicted = torch.max(outputs.data, 1)\n",
        "                        val_total += labels.size(0)\n",
        "                        val_correct += (predicted == labels).sum().item()\n",
        "                        val_predictions.extend(predicted.cpu().numpy())\n",
        "                        val_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "                        batch_acc = val_correct / val_total\n",
        "                        self._update_progress(batch_idx, batch_loss, batch_acc, trial_params, is_training=False)\n",
        "\n",
        "                train_acc = train_correct / train_total\n",
        "                val_acc = val_correct / val_total\n",
        "                val_f1 = f1_score(val_labels, val_predictions, average='macro')\n",
        "                scheduler.step()\n",
        "\n",
        "                print(f\"\\nEpoch {epoch+1}/{Config.OPTUNA_EPOCHS} Summary: \"\n",
        "                      f\"Train Loss: {train_loss/len(temp_train_loader):.6f}, \"\n",
        "                      f\"Train Acc: {train_acc:.4f}, Val Loss: {val_loss/len(temp_val_loader):.6f}, \"\n",
        "                      f\"Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
        "\n",
        "                if val_acc > best_val_acc:\n",
        "                    best_val_acc = val_acc\n",
        "                    patience_counter = 0\n",
        "                else:\n",
        "                    patience_counter += 1\n",
        "\n",
        "                if patience_counter >= 4:\n",
        "                    print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
        "                    break\n",
        "\n",
        "                trial.report(val_acc, epoch)\n",
        "                if trial.should_prune():\n",
        "                    raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "                if val_acc > self.best_val_acc:\n",
        "                    self.best_val_acc = val_acc\n",
        "                    self.best_val_f1 = val_f1\n",
        "                    self.best_trial = trial.number\n",
        "                    print(f\"\\nTrial {trial.number+1} Epoch {epoch+1} completed:\")\n",
        "                    print(f\"New best result found!\")\n",
        "                    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "                    print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
        "                else:\n",
        "                    print(f\"\\nTrial {trial.number+1} Epoch {epoch+1} completed:\")\n",
        "                    print(f\"Validation Accuracy: {val_acc:.4f}\")\n",
        "                    print(f\"Validation F1 Score: {val_f1:.4f}\")\n",
        "                    print(f\"Previous best (Trial {self.best_trial+1}):\")\n",
        "                    print(f\"  Validation Accuracy: {self.best_val_acc:.4f}\")\n",
        "                    print(f\"  Validation F1 Score: {self.best_val_f1:.4f}\")\n",
        "\n",
        "\n",
        "            return best_val_acc\n",
        "\n",
        "        # except Exception as e:\n",
        "        #     print(f\"\\nTrial failed: {e}\")\n",
        "        #     return 0.0\n",
        "        except Exception as e:\n",
        "            print(f\"\\nTrial {trial.number+1} failed with error: {str(e)}\\n{traceback.format_exc()}\")\n",
        "            return 0.0\n",
        "\n",
        "    def optimize(self):\n",
        "        print(f\"Optimizing hyperparameters for {self.model_name}...\")\n",
        "\n",
        "        if not OPTUNA_AVAILABLE:\n",
        "            return {\n",
        "                'lr': Config.LEARNING_RATE,\n",
        "                'dropout': 0.5,\n",
        "                'weight_decay': Config.WEIGHT_DECAY,\n",
        "                'hidden_dim_multiplier': 0.5,\n",
        "                'augmentation_strength': 'medium',\n",
        "                'batch_size': Config.BATCH_SIZE,\n",
        "                'optimizer_type': 'adamw',\n",
        "                'scheduler_type': 'cosine',\n",
        "                'label_smoothing': 0.1\n",
        "            }\n",
        "\n",
        "        study = optuna.create_study(direction='maximize')\n",
        "        study.optimize(self.objective, n_trials=Config.OPTUNA_TRIALS, timeout=1200)\n",
        "\n",
        "        best_params = study.best_trial.params\n",
        "        print(f\"\\nBest params for {self.model_name}:\")\n",
        "        for key, value in best_params.items():\n",
        "            if key in ['lr', 'weight_decay']:\n",
        "                print(f\"  {key}: {value:.4f}\")\n",
        "            elif key in ['dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                print(f\"  {key}: {value:.1f}\")\n",
        "            else:\n",
        "                print(f\"  {key}: {value}\")\n",
        "        print(f\"Best validation accuracy: {study.best_trial.value:.4f}\")\n",
        "\n",
        "        return best_params\n",
        "\n",
        "# ---\n",
        "# 8. MODEL TRAINING\n",
        "# =============================================================================\n",
        "# Purpose: Train individual models with optimized hyperparameters.\n",
        "\n",
        "class EnhancedModelTrainer:\n",
        "    def __init__(self, model, model_name, hyperparameters):\n",
        "        self.model = model.to(Config.DEVICE)\n",
        "        self.model_name = model_name\n",
        "        self.hyperparameters = hyperparameters\n",
        "        self.best_val_acc = 0.0\n",
        "        self.best_val_f1 = 0.0\n",
        "        self.patience_counter = 0\n",
        "        self.history = {\n",
        "            'train_loss': [], 'train_acc': [],\n",
        "            'val_loss': [], 'val_acc': [], 'val_f1': [],\n",
        "            'learning_rates': []\n",
        "        }\n",
        "        # Create model directory\n",
        "        os.makedirs(f\"{Config.OUTPUT_DIR}/models\", exist_ok=True)\n",
        "        self._setup_training_components()\n",
        "\n",
        "    def _setup_training_components(self):\n",
        "        lr = self.hyperparameters.get('lr', Config.LEARNING_RATE)\n",
        "        weight_decay = self.hyperparameters.get('weight_decay', Config.WEIGHT_DECAY)\n",
        "        optimizer_type = self.hyperparameters.get('optimizer_type', 'adamw')\n",
        "\n",
        "        if optimizer_type == 'adam':\n",
        "            self.optimizer = optim.Adam(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        elif optimizer_type == 'adamw':\n",
        "            self.optimizer = optim.AdamW(self.model.parameters(), lr=lr, weight_decay=weight_decay)\n",
        "        else:\n",
        "            self.optimizer = optim.SGD(self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                                     momentum=0.9, nesterov=True)\n",
        "\n",
        "        label_smoothing = self.hyperparameters.get('label_smoothing', 0.1)\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "        scheduler_type = self.hyperparameters.get('scheduler_type', 'cosine')\n",
        "        if scheduler_type == 'cosine':\n",
        "            self.scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "                self.optimizer, T_0=10, T_mult=2\n",
        "            )\n",
        "        elif scheduler_type == 'step':\n",
        "            self.scheduler = optim.lr_scheduler.StepLR(self.optimizer, step_size=10, gamma=0.5)\n",
        "        else:\n",
        "            self.scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.95)\n",
        "\n",
        "    def train_epoch(self, train_loader, progress_tracker):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        batch_losses = []\n",
        "        batch_accuracies = []\n",
        "\n",
        "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "            self.optimizer.zero_grad()\n",
        "            outputs = self.model(images)\n",
        "            loss = self.criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "            self.optimizer.step()\n",
        "\n",
        "            batch_loss = loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            batch_total = labels.size(0)\n",
        "            batch_correct = (predicted == labels).sum().item()\n",
        "            batch_acc = batch_correct / batch_total\n",
        "\n",
        "            total_loss += batch_loss\n",
        "            total += batch_total\n",
        "            correct += batch_correct\n",
        "            batch_losses.append(batch_loss)\n",
        "            batch_accuracies.append(batch_acc)\n",
        "\n",
        "            progress_tracker.update_batch(batch_idx, batch_loss, batch_acc, is_training=True)\n",
        "\n",
        "        return total_loss / len(train_loader), correct / total\n",
        "\n",
        "    def validate_epoch(self, val_loader, progress_tracker):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_idx, (images, labels) in enumerate(val_loader):\n",
        "                images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                outputs = self.model(images)  # Corrected to self.model\n",
        "                loss = self.criterion(outputs, labels)\n",
        "                batch_loss = loss.item()\n",
        "                total_loss += batch_loss\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                batch_acc = (predicted == labels).float().mean().item()\n",
        "\n",
        "                all_predictions.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                progress_tracker.update_batch(batch_idx, batch_loss, batch_acc, is_training=False)\n",
        "\n",
        "        if not all_labels:\n",
        "            print(f\"Warning: No validation data processed for {self.model_name}\")\n",
        "            return float('inf'), 0.0, 0.0\n",
        "\n",
        "        accuracy = accuracy_score(all_labels, all_predictions)\n",
        "        f1 = f1_score(all_labels, all_predictions, average='macro')\n",
        "        return total_loss / len(val_loader), accuracy, f1\n",
        "\n",
        "    def train(self, train_loader, val_loader, test_loader=None, visualizer=None):\n",
        "        \"\"\"Enhanced train method with immediate plotting\"\"\"\n",
        "        print(f\"Training {self.model_name} with hyperparameters:\")\n",
        "        for key, value in self.hyperparameters.items():\n",
        "            if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                print(f\"  {key}: {value:.4f}\")\n",
        "            else:\n",
        "                print(f\"  {key}: {value}\")\n",
        "\n",
        "        progress_tracker = TrainingProgressTracker(\n",
        "            self.model_name, Config.EPOCHS, len(train_loader)\n",
        "        )\n",
        "\n",
        "        for epoch in range(Config.EPOCHS):\n",
        "            progress_tracker.start_epoch(epoch)\n",
        "            train_loss, train_acc = self.train_epoch(train_loader, progress_tracker)\n",
        "            val_loss, val_acc, val_f1 = self.validate_epoch(val_loader, progress_tracker)\n",
        "            self.scheduler.step()\n",
        "            current_lr = self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "            self.history['val_f1'].append(val_f1)\n",
        "            self.history['learning_rates'].append(current_lr)\n",
        "\n",
        "            is_best = False\n",
        "            if val_f1 > self.best_val_f1:\n",
        "                self.best_val_f1 = val_f1\n",
        "                self.best_val_acc = val_acc\n",
        "                self.patience_counter = 0\n",
        "                is_best = True\n",
        "                torch.save(self.model.state_dict(),\n",
        "                          f\"{Config.OUTPUT_DIR}/models/{self.model_name}_best.pt\")\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "\n",
        "            progress_tracker.finish_epoch(\n",
        "                train_loss, train_acc, val_loss, val_acc, val_f1,\n",
        "                is_best=is_best, lr=current_lr\n",
        "            )\n",
        "\n",
        "            if self.patience_counter >= Config.PATIENCE:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "                break\n",
        "\n",
        "        # Load best model\n",
        "        self.model.load_state_dict(\n",
        "            torch.load(f\"{Config.OUTPUT_DIR}/models/{self.model_name}_best.pt\")\n",
        "        )\n",
        "\n",
        "        # IMMEDIATE PLOTTING AFTER TRAINING\n",
        "        if visualizer:\n",
        "            # Plot training history\n",
        "            visualizer.plot_single_model_history(self.history, self.model_name)\n",
        "\n",
        "            # Evaluate and plot results\n",
        "            if test_loader:\n",
        "                evaluator = ModelEvaluator()\n",
        "                result = evaluator.evaluate_model(self.model, test_loader, self.model_name)\n",
        "\n",
        "                # Plot ROC curves, confusion matrix, and XAI\n",
        "                visualizer.plot_roc_curves(result, self.model_name)\n",
        "                visualizer.plot_confusion_matrix(result, self.model_name)\n",
        "                visualizer.plot_single_model_xai(self.model, self.model_name, test_loader)\n",
        "\n",
        "                return self.history, result\n",
        "\n",
        "        print(f\"\\n‚úì {self.model_name} training completed!\")\n",
        "        print(f\"  Best Validation F1: {self.best_val_f1:.4f}\")\n",
        "        print(f\"  Best Validation Accuracy: {self.best_val_acc:.4f}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "        return self.history, None\n",
        "\n",
        "# ---\n",
        "# 9. ENSEMBLE METHODS\n",
        "# =============================================================================\n",
        "# Purpose: Implement ensemble methods (simple, weighted, confidence-based, learnable).\n",
        "\n",
        "class EnsembleManager:\n",
        "    def __init__(self, models_dict, val_data):\n",
        "        self.models = models_dict\n",
        "        self.X_val, self.y_val = val_data\n",
        "        self.model_predictions = self._get_predictions()\n",
        "        self.histories = {}\n",
        "\n",
        "    def _get_predictions(self):\n",
        "        print(\"Getting model predictions for ensemble...\")\n",
        "        predictions = {}\n",
        "\n",
        "        val_dataset = FishDataset(self.X_val, self.y_val, DataManager.get_transforms(False))\n",
        "        val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            model.eval()\n",
        "            all_preds = []\n",
        "            all_probs = []\n",
        "            all_losses = []\n",
        "            all_labels = []\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    outputs = model(images)\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    loss = criterion(outputs, labels).item()\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    all_preds.extend(predicted.cpu().numpy())\n",
        "                    all_probs.extend(probabilities.cpu().numpy())\n",
        "                    all_losses.append(loss)\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = correct / total\n",
        "            f1 = f1_score(self.y_val, all_preds, average='macro')\n",
        "            avg_loss = np.mean(all_losses)\n",
        "\n",
        "            predictions[name] = {\n",
        "                'predictions': np.array(all_preds),\n",
        "                'probabilities': np.array(all_probs),\n",
        "                'loss': avg_loss,\n",
        "                'accuracy': accuracy,\n",
        "                'f1': f1,\n",
        "                'true_labels': np.array(all_labels)\n",
        "            }\n",
        "\n",
        "            print(f\"  {name}: F1 = {f1:.4f}, Acc = {accuracy:.4f}, Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def simple_average_ensemble(self, model_combo):\n",
        "        selected_probs = [self.model_predictions[name]['probabilities'] for name in model_combo]\n",
        "        avg_probs = np.mean(selected_probs, axis=0)\n",
        "        predictions = np.argmax(avg_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'probabilities': avg_probs,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def weighted_average_ensemble(self, model_combo):\n",
        "        weights = []\n",
        "        selected_probs = []\n",
        "\n",
        "        for name in model_combo:\n",
        "            f1 = self.model_predictions[name]['f1']\n",
        "            weights.append(f1)\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        weights = np.array(weights) / np.sum(weights)\n",
        "        weighted_probs = np.average(selected_probs, axis=0, weights=weights)\n",
        "        predictions = np.argmax(weighted_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.average([self.model_predictions[name]['loss'] for name in model_combo], weights=weights)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'weights': weights,\n",
        "            'models': model_combo,\n",
        "            'probabilities': weighted_probs,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def confidence_based_ensemble(self, model_combo):\n",
        "        final_predictions = []\n",
        "        all_probs = []\n",
        "\n",
        "        for i in range(len(self.y_val)):\n",
        "            confidences = []\n",
        "            probs = []\n",
        "\n",
        "            for name in model_combo:\n",
        "                prob = self.model_predictions[name]['probabilities'][i]\n",
        "                confidence = np.max(prob)\n",
        "                confidences.append(confidence)\n",
        "                probs.append(prob)\n",
        "\n",
        "            confidences = np.array(confidences)\n",
        "            weights = confidences / np.sum(confidences) if np.sum(confidences) > 0 else np.ones(len(confidences)) / len(confidences)\n",
        "\n",
        "            final_prob = np.average(probs, axis=0, weights=weights)\n",
        "            final_predictions.append(np.argmax(final_prob))\n",
        "            all_probs.append(final_prob)\n",
        "\n",
        "        predictions = np.array(final_predictions)\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'probabilities': np.array(all_probs),\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def learnable_weighted_ensemble(self, model_combo, epochs=30):\n",
        "        print(f\"Training learnable weighted ensemble with {len(model_combo)} models...\")\n",
        "\n",
        "        selected_probs = []\n",
        "        for name in model_combo:\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        ensemble_input = np.stack(selected_probs, axis=1)\n",
        "\n",
        "        X_ensemble = torch.FloatTensor(ensemble_input).to(Config.DEVICE)\n",
        "        y_ensemble = torch.LongTensor(self.y_val).to(Config.DEVICE)\n",
        "\n",
        "        ensemble_model = LearnableWeightedEnsemble(\n",
        "            num_models=len(model_combo),\n",
        "            num_classes=Config.NUM_CLASSES\n",
        "        ).to(Config.DEVICE)\n",
        "\n",
        "        optimizer = optim.AdamW(ensemble_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "        history = {'train_loss': [], 'train_acc': [], 'val_f1': []}\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            ensemble_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions, weights = ensemble_model(X_ensemble)\n",
        "            loss = criterion(predictions, y_ensemble)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            accuracy = accuracy_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy())\n",
        "            f1 = f1_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy(), average='macro')\n",
        "\n",
        "            history['train_loss'].append(loss.item())\n",
        "            history['train_acc'].append(accuracy)\n",
        "            history['val_f1'].append(f1)\n",
        "\n",
        "            print(f\"Ensemble Epoch {epoch+1}/{epochs}: Loss = {loss.item():.4f}, \"\n",
        "                  f\"Acc = {accuracy:.4f}, F1 = {f1:.4f}\")\n",
        "\n",
        "            if loss.item() < best_loss:\n",
        "                best_loss = loss.item()\n",
        "                torch.save(ensemble_model.state_dict(), f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\")\n",
        "\n",
        "        ensemble_model.load_state_dict(torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\"))\n",
        "        ensemble_model.eval()\n",
        "        with torch.no_grad():\n",
        "            final_predictions, learned_weights = ensemble_model(X_ensemble)\n",
        "            predictions = final_predictions.argmax(dim=1).cpu().numpy()\n",
        "            probabilities = torch.softmax(final_predictions, dim=1).cpu().numpy()\n",
        "            avg_weights = learned_weights.mean(dim=0).cpu().numpy()\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        self.histories[f\"learnable_weighted_{'+'.join(model_combo)}\"] = history\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'learned_weights': avg_weights,\n",
        "            'probabilities': probabilities,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def test_ensemble_combinations(self):\n",
        "        print(\"Testing ensemble combinations...\")\n",
        "\n",
        "        model_names = list(self.models.keys())\n",
        "        all_results = {}\n",
        "        best_result = None\n",
        "        best_score = 0\n",
        "\n",
        "        for size in range(2, min(len(model_names) + 1, 5)):\n",
        "            print(f\"Testing {size}-model combinations...\")\n",
        "\n",
        "            for combo in list(combinations(model_names, size))[:5]:\n",
        "                combo_name = f\"combo_{size}_{'+'.join(combo)}\"\n",
        "\n",
        "                for method_name in Config.ENSEMBLE_METHODS:\n",
        "                    full_name = f\"{combo_name}_{method_name}\"\n",
        "\n",
        "                    try:\n",
        "                        if method_name == 'simple_average':\n",
        "                            result = self.simple_average_ensemble(combo)\n",
        "                        elif method_name == 'weighted_average':\n",
        "                            result = self.weighted_average_ensemble(combo)\n",
        "                        elif method_name == 'confidence_based':\n",
        "                            result = self.confidence_based_ensemble(combo)\n",
        "                        elif method_name == 'learnable_weighted':\n",
        "                            result = self.learnable_weighted_ensemble(combo)\n",
        "\n",
        "                        # Verify result contains required keys\n",
        "                        required_keys = ['accuracy', 'f1', 'loss', 'predictions', 'models', 'probabilities', 'true_labels']\n",
        "                        if not all(key in result for key in required_keys):\n",
        "                            missing = [key for key in required_keys if key not in result]\n",
        "                            print(f\"  {full_name}: Missing keys {missing}\")\n",
        "                            continue\n",
        "\n",
        "                        all_results[full_name] = result\n",
        "                        print(f\"  {full_name}: F1 = {result['f1']:.4f}, Acc = {result['accuracy']:.4f}, \"\n",
        "                              f\"Loss = {result['loss']:.4f}, True Labels Shape = {result['true_labels'].shape}\")\n",
        "\n",
        "                        if result['f1'] > best_score:\n",
        "                            best_score = result['f1']\n",
        "                            best_result = (full_name, result)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"  {full_name}: FAILED - {str(e)}\")\n",
        "\n",
        "        if best_result:\n",
        "            print(f\"\\n‚úì Best ensemble: {best_result[0]} (F1: {best_result[1]['f1']:.4f})\")\n",
        "        else:\n",
        "            print(\"\\nNo valid ensemble results generated.\")\n",
        "\n",
        "        return all_results, best_result\n",
        "\n",
        "# ---\n",
        "# 10. MODEL EVALUATION\n",
        "# =============================================================================\n",
        "# Purpose: Evaluate models on test data.\n",
        "\n",
        "class ModelEvaluator:\n",
        "    def evaluate_model(self, model, test_loader, model_name):\n",
        "        print(f\"Evaluating {model_name}...\")\n",
        "        model.eval()\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "        total_loss = 0\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, labels in test_loader:\n",
        "                images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels).item()\n",
        "                probabilities = torch.softmax(outputs, dim=1)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                all_preds.extend(predicted.cpu().numpy())\n",
        "                all_labels.extend(labels.cpu().numpy())\n",
        "                all_probs.extend(probabilities.cpu().numpy())\n",
        "                total_loss += loss\n",
        "\n",
        "        if not all_labels:\n",
        "            print(f\"Warning: No test data processed for {model_name}\")\n",
        "            return {\n",
        "                'model_name': model_name,\n",
        "                'accuracy': 0.0,\n",
        "                'f1_macro': 0.0,\n",
        "                'f1_weighted': 0.0,\n",
        "                'precision_macro': 0.0,\n",
        "                'recall_macro': 0.0,\n",
        "                'f1_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "                'precision_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "                'recall_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "                'predictions': np.array([]),\n",
        "                'true_labels': np.array([]),\n",
        "                'probabilities': np.array([]),\n",
        "                'loss': float('inf')\n",
        "            }\n",
        "\n",
        "        accuracy = accuracy_score(all_labels, all_preds)\n",
        "        f1_macro = f1_score(all_labels, all_preds, average='macro')\n",
        "        f1_weighted = f1_score(all_labels, all_preds, average='weighted')\n",
        "        precision_macro = precision_score(all_labels, all_preds, average='macro')\n",
        "        recall_macro = recall_score(all_labels, all_preds, average='macro')\n",
        "        f1_per_class = f1_score(all_labels, all_preds, average=None)\n",
        "        precision_per_class = precision_score(all_labels, all_preds, average=None)\n",
        "        recall_per_class = recall_score(all_labels, all_preds, average=None)\n",
        "        avg_loss = total_loss / len(test_loader)\n",
        "\n",
        "        print(f\"{model_name} Evaluation: Acc = {accuracy:.4f}, F1 (Macro) = {f1_macro:.4f}, Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        return {\n",
        "            'model_name': model_name,\n",
        "            'accuracy': accuracy,\n",
        "            'f1_macro': f1_macro,\n",
        "            'f1_weighted': f1_weighted,\n",
        "            'precision_macro': precision_macro,\n",
        "            'recall_macro': recall_macro,\n",
        "            'f1_per_class': f1_per_class,\n",
        "            'precision_per_class': precision_per_class,\n",
        "            'recall_per_class': recall_per_class,\n",
        "            'predictions': np.array(all_preds),\n",
        "            'true_labels': np.array(all_labels),\n",
        "            'probabilities': np.array(all_probs),\n",
        "            'loss': avg_loss\n",
        "        }\n",
        "\n",
        "# ---\n",
        "# 11. ENHANCED VISUALIZATIONS\n",
        "# =============================================================================\n",
        "# Purpose: Generate visualizations for training history, ROC curves, confusion matrices, model comparisons, and XAI visualizations.\n",
        "\n",
        "class EnhancedVisualizations:\n",
        "    def __init__(self):\n",
        "        self.viz_dir = f\"{Config.OUTPUT_DIR}/visualizations\"\n",
        "        Path(self.viz_dir).mkdir(parents=True, exist_ok=True)\n",
        "        # Set better matplotlib parameters for spacing\n",
        "        plt.rcParams.update({\n",
        "            'figure.autolayout': True,\n",
        "            'axes.titlepad': 20,\n",
        "            'axes.labelpad': 10,\n",
        "            'xtick.major.pad': 8,\n",
        "            'ytick.major.pad': 8\n",
        "        })\n",
        "\n",
        "    def plot_single_model_history(self, history, model_name):\n",
        "        \"\"\"Plot training history for individual model with better spacing\"\"\"\n",
        "        if not history['train_loss']:\n",
        "            print(f\"Skipping {model_name}: No training data available\")\n",
        "            return\n",
        "\n",
        "        epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "        # Create subplot with more space\n",
        "        fig = plt.figure(figsize=(16, 10))\n",
        "        gs = fig.add_gridspec(2, 2, hspace=0.4, wspace=0.3)\n",
        "\n",
        "        # Loss plot\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        ax1.plot(epochs, history['train_loss'], 'b-', linewidth=2, label='Train Loss', marker='o', markersize=4)\n",
        "        if history.get('val_loss', []):\n",
        "            ax1.plot(epochs, history['val_loss'], 'r-', linewidth=2, label='Val Loss', marker='s', markersize=4)\n",
        "        ax1.set_title(f'{model_name} - Loss vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "        ax1.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
        "        ax1.legend(frameon=True, shadow=True, fontsize=11)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.tick_params(labelsize=10)\n",
        "\n",
        "        # Accuracy plot\n",
        "        ax2 = fig.add_subplot(gs[0, 1])\n",
        "        ax2.plot(epochs, history['train_acc'], 'g-', linewidth=2, label='Train Acc', marker='o', markersize=4)\n",
        "        if history.get('val_acc', []):\n",
        "            ax2.plot(epochs, history['val_acc'], 'm-', linewidth=2, label='Val Acc', marker='s', markersize=4)\n",
        "        ax2.set_title(f'{model_name} - Accuracy vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax2.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "        ax2.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "        ax2.legend(frameon=True, shadow=True, fontsize=11)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.tick_params(labelsize=10)\n",
        "\n",
        "        # F1 Score plot\n",
        "        ax3 = fig.add_subplot(gs[1, 0])\n",
        "        if history.get('val_f1', []):\n",
        "            ax3.plot(epochs, history['val_f1'], 'orange', linewidth=2, label='Val F1', marker='d', markersize=4)\n",
        "            ax3.set_title(f'{model_name} - F1 Score vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "            ax3.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "            ax3.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
        "            ax3.legend(frameon=True, shadow=True, fontsize=11)\n",
        "            ax3.grid(True, alpha=0.3)\n",
        "            ax3.tick_params(labelsize=10)\n",
        "\n",
        "        # Learning Rate plot\n",
        "        ax4 = fig.add_subplot(gs[1, 1])\n",
        "        if history.get('learning_rates', []):\n",
        "            ax4.plot(epochs, history['learning_rates'], 'purple', linewidth=2, label='Learning Rate', marker='x', markersize=6)\n",
        "            ax4.set_title(f'{model_name} - Learning Rate vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "            ax4.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "            ax4.set_ylabel('Learning Rate', fontsize=12, fontweight='bold')\n",
        "            ax4.legend(frameon=True, shadow=True, fontsize=11)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.tick_params(labelsize=10)\n",
        "            ax4.set_yscale('log')\n",
        "\n",
        "        plt.suptitle(f'{model_name} Training Progress', fontsize=18, fontweight='bold', y=0.98)\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_individual_training_history.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Individual training history saved: {save_path}\")\n",
        "\n",
        "    def plot_single_model_xai(self, model, model_name, test_loader, max_images=2):\n",
        "        \"\"\"Generate XAI visualizations for a single model using Grad-CAM++, Integrated Gradients, and LRP\"\"\"\n",
        "        print(f\"Generating XAI visualizations for {model_name}...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # Get sample images\n",
        "        sample_images, sample_labels = next(iter(test_loader))\n",
        "        sample_images = sample_images[:max_images].to(Config.DEVICE)\n",
        "        sample_labels = sample_labels[:max_images].numpy()\n",
        "\n",
        "        for idx, (image, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
        "            try:\n",
        "                # Create figure with larger size for clearer images\n",
        "                fig = plt.figure(figsize=(24, 8))  # Standard size for clear visualization\n",
        "                gs = fig.add_gridspec(1, 4, wspace=0.15, hspace=0.2)  # 4 columns: Original, Grad-CAM++, Integrated Gradients, LRP\n",
        "\n",
        "                # Prepare original image\n",
        "                image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                # Plot original image\n",
        "                ax_orig = fig.add_subplot(gs[0, 0])\n",
        "                ax_orig.imshow(image_np)\n",
        "                ax_orig.set_title(f'Original Image\\nTrue: {Config.CLASS_LABELS[true_label]}',\n",
        "                                 fontsize=14, fontweight='bold', pad=15)\n",
        "                ax_orig.axis('off')\n",
        "\n",
        "                # Forward pass for prediction\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(image.unsqueeze(0))\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    predicted_class = outputs.argmax(dim=1).item()\n",
        "                    confidence = probabilities[0, predicted_class].item()\n",
        "                    predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                # Generate Grad-CAM++ visualization\n",
        "                gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(model, image, predicted_class)\n",
        "                ax_gradcam = fig.add_subplot(gs[0, 1])\n",
        "                ax_gradcam.imshow(gradcam_img)\n",
        "                ax_gradcam.set_title(f'{model_name}\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                    fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_gradcam.axis('off')\n",
        "\n",
        "                # Generate Integrated Gradients visualization\n",
        "                ig_img, _ = xai_visualizer.integrated_gradients(model, image, predicted_class)\n",
        "                ax_ig = fig.add_subplot(gs[0, 2])\n",
        "                ax_ig.imshow(ig_img)\n",
        "                ax_ig.set_title(f'{model_name}\\nIntegrated Gradients', fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_ig.axis('off')\n",
        "\n",
        "                # Generate LRP visualization\n",
        "                lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, image, predicted_class)\n",
        "                ax_lrp = fig.add_subplot(gs[0, 3])\n",
        "                ax_lrp.imshow(lrp_img)\n",
        "                ax_lrp.set_title(f'{model_name}\\nLRP', fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_lrp.axis('off')\n",
        "\n",
        "                plt.suptitle(f'XAI Analysis for {model_name} - Image {idx+1}', fontsize=16, fontweight='bold', y=0.95)\n",
        "                save_path = f\"{self.viz_dir}/{model_name}_xai_image_{idx+1}.png\"\n",
        "                plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "                plt.show()\n",
        "                print(f\"XAI visualization saved: {save_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating XAI for {model_name}, image {idx+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "    def plot_confusion_matrix(self, results, model_name):\n",
        "        \"\"\"Enhanced confusion matrix with better spacing\"\"\"\n",
        "        if 'true_labels' not in results or 'predictions' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'predictions' in results for {model_name}\")\n",
        "            return\n",
        "\n",
        "        cm = confusion_matrix(results['true_labels'], results['predictions'])\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        # Create figure with better spacing\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "        # Use better color scheme and formatting\n",
        "        sns.heatmap(cm_normalized, annot=cm, fmt='d', cmap='Blues',\n",
        "                    xticklabels=Config.CLASS_LABELS, yticklabels=Config.CLASS_LABELS,\n",
        "                    cbar_kws={'label': 'Normalized Count', 'shrink': 0.8},\n",
        "                    square=True, linewidths=0.5, annot_kws={'size': 12})\n",
        "\n",
        "        ax.set_title(f'Confusion Matrix: {model_name}', fontsize=16, fontweight='bold', pad=25)\n",
        "        ax.set_xlabel('Predicted Label', fontsize=14, fontweight='bold', labelpad=15)\n",
        "        ax.set_ylabel('True Label', fontsize=14, fontweight='bold', labelpad=15)\n",
        "\n",
        "        # Rotate labels for better readability\n",
        "        plt.xticks(rotation=45, ha='right', fontsize=12)\n",
        "        plt.yticks(rotation=0, fontsize=12)\n",
        "\n",
        "        # Add performance metrics as text\n",
        "        accuracy = accuracy_score(results['true_labels'], results['predictions'])\n",
        "        f1_macro = f1_score(results['true_labels'], results['predictions'], average='macro')\n",
        "        f1_weighted = f1_score(results['true_labels'], results['predictions'], average='weighted')\n",
        "\n",
        "        metrics_text = f'Accuracy: {accuracy:.4f}\\nF1 (Macro): {f1_macro:.4f}\\nF1 (Weighted): {f1_weighted:.4f}'\n",
        "        ax.text(1.15, 0.5, metrics_text, transform=ax.transAxes, fontsize=12,\n",
        "                verticalalignment='center', bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_enhanced_confusion_matrix.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced confusion matrix saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_roc_curves(self, results, model_name):\n",
        "        \"\"\"Enhanced ROC curves with better spacing and styling for multiclass\"\"\"\n",
        "        if 'true_labels' not in results or 'probabilities' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'probabilities' in results for {model_name}\")\n",
        "            return\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, Config.NUM_CLASSES))\n",
        "\n",
        "        # Convert labels to binary format for each class (one-vs-rest)\n",
        "        for i, color in zip(range(Config.NUM_CLASSES), colors):\n",
        "            # Binarize the labels for the current class\n",
        "            y_true_bin = (np.array(results['true_labels']) == i).astype(int)\n",
        "            y_score = results['probabilities'][:, i]\n",
        "\n",
        "            # Compute ROC curve and AUC\n",
        "            fpr, tpr, _ = roc_curve(y_true_bin, y_score)\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            ax.plot(fpr, tpr, color=color, linewidth=3,\n",
        "                    label=f'{Config.CLASS_LABELS[i]} (AUC = {roc_auc:.3f})')\n",
        "\n",
        "        # Diagonal line\n",
        "        ax.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.6, label='Random Classifier')\n",
        "\n",
        "        ax.set_title(f'{model_name} - ROC Curves', fontsize=16, fontweight='bold', pad=20)\n",
        "        ax.set_xlabel('False Positive Rate', fontsize=14, fontweight='bold', labelpad=10)\n",
        "        ax.set_ylabel('True Positive Rate', fontsize=14, fontweight='bold', labelpad=10)\n",
        "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', frameon=True, shadow=True, fontsize=11)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_xlim([0.0, 1.0])\n",
        "        ax.set_ylim([0.0, 1.05])\n",
        "\n",
        "        # Compute micro-average ROC curve\n",
        "        y_true_bin = label_binarize(results['true_labels'], classes=range(Config.NUM_CLASSES))\n",
        "        fpr_micro, tpr_micro, _ = roc_curve(y_true_bin.ravel(), results['probabilities'].ravel())\n",
        "        roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
        "        ax.plot(fpr_micro, tpr_micro, 'deeppink', linestyle=':', linewidth=4,\n",
        "                label=f'Micro-average (AUC = {roc_auc_micro:.3f})')\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_enhanced_roc_curves.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced ROC curves saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def generate_comprehensive_report(self, single_results, ensemble_results, best_ensemble):\n",
        "        \"\"\"Generate a comprehensive visual report\"\"\"\n",
        "        fig = plt.figure(figsize=(24, 16))\n",
        "        gs = fig.add_gridspec(3, 4, hspace=0.4, wspace=0.3, top=0.92, bottom=0.08, left=0.05, right=0.95)\n",
        "\n",
        "        # Title\n",
        "        fig.suptitle('Fish Species Classification - Comprehensive Analysis Report',\n",
        "                    fontsize=24, fontweight='bold', y=0.96)\n",
        "\n",
        "        # 1. Model Performance Comparison\n",
        "        ax1 = fig.add_subplot(gs[0, :2])\n",
        "        model_names = list(single_results.keys())\n",
        "        accuracies = [single_results[name]['accuracy'] for name in model_names]\n",
        "        f1_scores = [single_results[name]['f1_macro'] for name in model_names]\n",
        "\n",
        "        x = np.arange(len(model_names))\n",
        "        width = 0.35\n",
        "\n",
        "        bars1 = ax1.bar(x - width/2, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "        bars2 = ax1.bar(x + width/2, f1_scores, width, label='F1 Score', alpha=0.8, color='lightcoral')\n",
        "\n",
        "        ax1.set_xlabel('Models', fontweight='bold', fontsize=12)\n",
        "        ax1.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "        ax1.set_title('Individual Model Performance', fontweight='bold', fontsize=14, pad=15)\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "        ax1.legend(fontsize=11)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, 1.1)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar in bars1 + bars2:\n",
        "            height = bar.get_height()\n",
        "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                    f'{height:.3f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        # 2. Best vs Worst Model Comparison\n",
        "        ax2 = fig.add_subplot(gs[0, 2:])\n",
        "        if ensemble_results and best_ensemble:\n",
        "            best_single_f1 = max(f1_scores)\n",
        "            worst_single_f1 = min(f1_scores)\n",
        "            best_ensemble_f1 = best_ensemble[1]['f1']\n",
        "\n",
        "            categories = ['Worst Single', 'Best Single', 'Best Ensemble']\n",
        "            values = [worst_single_f1, best_single_f1, best_ensemble_f1]\n",
        "            colors = ['lightcoral', 'lightblue', 'gold']\n",
        "\n",
        "            bars = ax2.bar(categories, values, color=colors, alpha=0.8)\n",
        "            ax2.set_ylabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax2.set_title('Performance Comparison', fontweight='bold', fontsize=14, pad=15)\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.set_ylim(0, max(values) * 1.1)\n",
        "\n",
        "            for bar, value in zip(bars, values):\n",
        "                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                        f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "        # 3. Per-class Performance Heatmap\n",
        "        ax3 = fig.add_subplot(gs[1, :2])\n",
        "        per_class_f1 = []\n",
        "        for model_name in model_names:\n",
        "            per_class_f1.append(single_results[model_name]['f1_per_class'])\n",
        "\n",
        "        per_class_f1 = np.array(per_class_f1)\n",
        "        im = ax3.imshow(per_class_f1, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "        ax3.set_xticks(range(len(Config.CLASS_LABELS)))\n",
        "        ax3.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right')\n",
        "        ax3.set_yticks(range(len(model_names)))\n",
        "        ax3.set_yticklabels(model_names)\n",
        "        ax3.set_title('Per-Class F1 Scores Heatmap', fontweight='bold', fontsize=14, pad=15)\n",
        "\n",
        "        # Add colorbar\n",
        "        cbar = plt.colorbar(im, ax=ax3, shrink=0.8)\n",
        "        cbar.set_label('F1 Score', rotation=270, labelpad=15)\n",
        "\n",
        "        # Add text annotations\n",
        "        for i in range(len(model_names)):\n",
        "            for j in range(len(Config.CLASS_LABELS)):\n",
        "                text_color = 'white' if per_class_f1[i, j] < 0.5 else 'black'\n",
        "                ax3.text(j, i, f'{per_class_f1[i, j]:.2f}',\n",
        "                        ha=\"center\", va=\"center\", color=text_color, fontsize=8, fontweight='bold')\n",
        "\n",
        "        # 4. Ensemble Methods Performance\n",
        "        ax4 = fig.add_subplot(gs[1, 2:])\n",
        "        if ensemble_results:\n",
        "            ensemble_items = list(ensemble_results.items())\n",
        "            ensemble_items.sort(key=lambda x: x[1]['f1'], reverse=True)\n",
        "            top_ensembles = ensemble_items[:8]\n",
        "\n",
        "            ensemble_names = [name.split('_')[-1] for name, _ in top_ensembles]\n",
        "            ensemble_f1s = [result['f1'] for _, result in top_ensembles]\n",
        "\n",
        "            bars = ax4.barh(range(len(ensemble_names)), ensemble_f1s, alpha=0.8, color='lightgreen')\n",
        "            ax4.set_yticks(range(len(ensemble_names)))\n",
        "            ax4.set_yticklabels(ensemble_names)\n",
        "            ax4.set_xlabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax4.set_title('Top Ensemble Methods', fontweight='bold', fontsize=14, pad=15)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "\n",
        "            for bar, value in zip(bars, ensemble_f1s):\n",
        "                ax4.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,\n",
        "                        f'{value:.4f}', ha='left', va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "        # 5. Summary Statistics Table\n",
        "        ax5 = fig.add_subplot(gs[2, :])\n",
        "        ax5.axis('off')\n",
        "\n",
        "        # Create summary data\n",
        "        summary_data = []\n",
        "        for model_name in model_names:\n",
        "            result = single_results[model_name]\n",
        "            summary_data.append([\n",
        "                model_name,\n",
        "                f\"{result['accuracy']:.4f}\",\n",
        "                f\"{result['f1_macro']:.4f}\",\n",
        "                f\"{result['f1_weighted']:.4f}\",\n",
        "                f\"{result['precision_macro']:.4f}\",\n",
        "                f\"{result['recall_macro']:.4f}\"\n",
        "            ])\n",
        "\n",
        "        if ensemble_results and best_ensemble:\n",
        "            best_result = best_ensemble[1]\n",
        "            summary_data.append([\n",
        "                f\"Best Ensemble\\n({best_ensemble[0]})\",\n",
        "                f\"{best_result['accuracy']:.4f}\",\n",
        "                f\"{best_result['f1']:.4f}\",\n",
        "                \"N/A\",\n",
        "                \"N/A\",\n",
        "                \"N/A\"\n",
        "            ])\n",
        "\n",
        "        columns = ['Model', 'Accuracy', 'F1 (Macro)', 'F1 (Weighted)', 'Precision', 'Recall']\n",
        "\n",
        "        table = ax5.table(cellText=summary_data, colLabels=columns, loc='center', cellLoc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1.2, 2)\n",
        "\n",
        "        # Style the table\n",
        "        for i in range(len(columns)):\n",
        "            table[(0, i)].set_facecolor('#4CAF50')\n",
        "            table[(0, i)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "        for i in range(1, len(summary_data) + 1):\n",
        "            for j in range(len(columns)):\n",
        "                if i % 2 == 0:\n",
        "                    table[(i, j)].set_facecolor('#f0f0f0')\n",
        "                else:\n",
        "                    table[(i, j)].set_facecolor('white')\n",
        "\n",
        "        ax5.set_title('Model Performance Summary', fontweight='bold', fontsize=16, pad=20)\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/comprehensive_report.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Comprehensive report saved: {save_path}\")\n",
        "        return save_path\n",
        "\n",
        "    def plot_model_comparison(self, single_results, ensemble_results):\n",
        "        \"\"\"Enhanced model comparison with better spacing\"\"\"\n",
        "        fig = plt.figure(figsize=(20, 16))\n",
        "        gs = fig.add_gridspec(2, 2, hspace=0.4, wspace=0.3, top=0.92, bottom=0.08)\n",
        "\n",
        "        model_names = list(single_results.keys())\n",
        "        accuracies = [single_results[name]['accuracy'] for name in model_names]\n",
        "        f1_scores = [single_results[name]['f1_macro'] for name in model_names]\n",
        "        f1_weighted = [single_results[name]['f1_weighted'] for name in model_names]\n",
        "        losses = [single_results[name]['loss'] for name in model_names]\n",
        "\n",
        "        x = np.arange(len(model_names))\n",
        "        width = 0.2\n",
        "\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        bars1 = ax1.bar(x - width*1.5, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "        bars2 = ax1.bar(x - width/2, f1_scores, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "        bars3 = ax1.bar(x + width/2, f1_weighted, width, label='F1 (Weighted)', alpha=0.8, color='lightgreen')\n",
        "        bars4 = ax1.bar(x + width*1.5, losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "        ax1.set_xlabel('Models', fontweight='bold', fontsize=12)\n",
        "        ax1.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "        ax1.set_title('Individual Model Performance', fontweight='bold', fontsize=14, pad=20)\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(model_names, rotation=45, ha='right', fontsize=10)\n",
        "        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, max(max(accuracies), max(f1_scores), max(f1_weighted), max(losses)) * 1.1)\n",
        "\n",
        "        if ensemble_results:\n",
        "            ensemble_items = list(ensemble_results.items())\n",
        "            ensemble_items.sort(key=lambda x: x[1]['f1'], reverse=True)\n",
        "            top_ensembles = ensemble_items[:10]\n",
        "\n",
        "            ensemble_names = [name.split('_')[-1] for name, _ in top_ensembles]\n",
        "            ensemble_f1s = [result['f1'] for _, result in top_ensembles]\n",
        "            ensemble_accs = [result['accuracy'] for _, result in top_ensembles]\n",
        "            ensemble_losses = [result['loss'] for _, result in top_ensembles]\n",
        "\n",
        "            x = np.arange(len(ensemble_names))\n",
        "            ax2 = fig.add_subplot(gs[0, 1])\n",
        "            ax2.bar(x - width, ensemble_accs, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "            ax2.bar(x, ensemble_f1s, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "            ax2.bar(x + width, ensemble_losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "            ax2.set_xticks(x)\n",
        "            ax2.set_xticklabels([f\"{name}\" for name in ensemble_names], rotation=45, ha='right', fontsize=10)\n",
        "            ax2.set_xlabel('Ensemble Methods', fontweight='bold', fontsize=12)\n",
        "            ax2.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "            ax2.set_title('Top Ensemble Methods', fontweight='bold', fontsize=14, pad=20)\n",
        "            ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.set_ylim(0, max(max(ensemble_accs), max(ensemble_f1s), max(ensemble_losses)) * 1.1)\n",
        "\n",
        "        if single_results:\n",
        "            per_class_f1 = []\n",
        "            for model_name in model_names:\n",
        "                per_class_f1.append(single_results[model_name]['f1_per_class'])\n",
        "\n",
        "            per_class_f1 = np.array(per_class_f1)\n",
        "            ax3 = fig.add_subplot(gs[1, 0])\n",
        "            im = ax3.imshow(per_class_f1, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "            ax3.set_xticks(range(len(Config.CLASS_LABELS)))\n",
        "            ax3.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right', fontsize=10)\n",
        "            ax3.set_yticks(range(len(model_names)))\n",
        "            ax3.set_yticklabels(model_names, fontsize=10)\n",
        "            ax3.set_title('Per-Class F1 Scores', fontweight='bold', fontsize=14, pad=20)\n",
        "\n",
        "            cbar = plt.colorbar(im, ax=ax3, shrink=0.8)\n",
        "            cbar.set_label('F1 Score', rotation=270, labelpad=15)\n",
        "\n",
        "            for i in range(len(model_names)):\n",
        "                for j in range(len(Config.CLASS_LABELS)):\n",
        "                    text_color = 'white' if per_class_f1[i, j] < 0.5 else 'black'\n",
        "                    ax3.text(j, i, f'{per_class_f1[i, j]:.2f}',\n",
        "                            ha=\"center\", va=\"center\", color=text_color, fontsize=8)\n",
        "\n",
        "        if ensemble_results:\n",
        "            best_single_f1 = max(f1_scores)\n",
        "            best_single_name = model_names[f1_scores.index(best_single_f1)]\n",
        "            best_ensemble_f1 = max([result['f1'] for result in ensemble_results.values()])\n",
        "            best_ensemble_name = max(ensemble_results.items(), key=lambda x: x[1]['f1'])[0]\n",
        "\n",
        "            ax4 = fig.add_subplot(gs[1, 1])\n",
        "            categories = ['Best Single\\nModel', 'Best Ensemble']\n",
        "            values = [best_single_f1, best_ensemble_f1]\n",
        "            colors = ['lightblue', 'gold']\n",
        "\n",
        "            bars = ax4.bar(categories, values, color=colors, alpha=0.8, width=0.6)\n",
        "            ax4.set_ylabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax4.set_title('Single vs Ensemble Comparison', fontweight='bold', fontsize=14, pad=20)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.set_ylim(0, 1)\n",
        "\n",
        "            for bar, value in zip(bars, values):\n",
        "                ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "                        f'{value:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
        "\n",
        "            improvement = ((best_ensemble_f1 - best_single_f1) / best_single_f1) * 100\n",
        "            ax4.text(0.5, 0.5, f'Improvement:\\n{improvement:.2f}%',\n",
        "                    transform=ax4.transAxes, ha='center', va='center',\n",
        "                    fontsize=14, fontweight='bold',\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"yellow\", alpha=0.8))\n",
        "\n",
        "        plt.suptitle('Fish Species Classification - Model Comparison Analysis',\n",
        "                    fontsize=18, fontweight='bold', y=0.96)\n",
        "        save_path = f\"{self.viz_dir}/enhanced_model_comparison.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced model comparison saved: {save_path}\")\n",
        "        return save_path\n",
        "\n",
        "\n",
        "    def plot_comparative_xai(self, single_models, ensemble_results, test_loader, max_images=2):\n",
        "        \"\"\"Generate comparative XAI visualizations with Grad-CAM++ vs Integrated Gradients and Grad-CAM++ vs LRP\"\"\"\n",
        "        print(f\"Generating comparative XAI visualizations for {max_images} images...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # Get sample images\n",
        "        sample_images, sample_labels = next(iter(test_loader))\n",
        "        sample_images = sample_images[:max_images].to(Config.DEVICE)\n",
        "        sample_labels = sample_labels[:max_images].numpy()\n",
        "\n",
        "        # Get best ensemble if available\n",
        "        best_ensemble_name = max(ensemble_results.items(), key=lambda x: x[1]['f1'])[0] if ensemble_results else None\n",
        "        best_ensemble = ensemble_results.get(best_ensemble_name, None) if best_ensemble_name else None\n",
        "\n",
        "        for idx, (image, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
        "            try:\n",
        "                # Larger figure size for standard, clearer images\n",
        "                num_rows = len(single_models) + (1 if best_ensemble else 0)\n",
        "                fig = plt.figure(figsize=(32, 10 * num_rows))  # Wider and taller for standard image size\n",
        "                gs = fig.add_gridspec(num_rows, 4, wspace=0.15, hspace=0.25)  # 4 columns: Original, Grad-CAM++, Integrated Gradients, LRP\n",
        "\n",
        "                # Prepare original image\n",
        "                image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                # Plot original image spanning all rows in first column\n",
        "                ax_orig = fig.add_subplot(gs[:, 0])\n",
        "                ax_orig.imshow(image_np)\n",
        "                ax_orig.set_title(f'Original Image\\nTrue: {Config.CLASS_LABELS[true_label]}',\n",
        "                                 fontsize=16, fontweight='bold', pad=20)\n",
        "                ax_orig.axis('off')\n",
        "\n",
        "                # Plot XAI for single models\n",
        "                for row, (model_name, model) in enumerate(single_models.items()):\n",
        "                    model.eval()\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(image.unsqueeze(0))\n",
        "                        probabilities = torch.softmax(outputs, dim=1)\n",
        "                        predicted_class = outputs.argmax(dim=1).item()\n",
        "                        confidence = probabilities[0, predicted_class].item()\n",
        "                        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                    # Generate Grad-CAM++ visualization\n",
        "                    gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(model, image, predicted_class)\n",
        "\n",
        "                    # Plot Grad-CAM++ in second column\n",
        "                    ax_gradcam = fig.add_subplot(gs[row, 1])\n",
        "                    ax_gradcam.imshow(gradcam_img)\n",
        "                    ax_gradcam.set_title(f'{model_name}\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                        fontsize=14, fontweight='bold', pad=15)\n",
        "                    ax_gradcam.axis('off')\n",
        "\n",
        "                    # Generate Integrated Gradients visualization\n",
        "                    ig_img, _ = xai_visualizer.integrated_gradients(model, image, predicted_class)\n",
        "\n",
        "                    # Plot Integrated Gradients in third column\n",
        "                    ax_ig = fig.add_subplot(gs[row, 2])\n",
        "                    ax_ig.imshow(ig_img)\n",
        "                    ax_ig.set_title(f'{model_name}\\nIntegrated Gradients', fontsize=14, fontweight='bold', pad=15)\n",
        "                    ax_ig.axis('off')\n",
        "\n",
        "                    # Generate LRP visualization\n",
        "                    lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, image, predicted_class)\n",
        "\n",
        "                    # Plot LRP in fourth column\n",
        "                    ax_lrp = fig.add_subplot(gs[row, 3])\n",
        "                    ax_lrp.imshow(lrp_img)\n",
        "                    ax_lrp.set_title(f'{model_name}\\nLRP', fontsize=14, fontweight='bold', pad=15)\n",
        "                    ax_lrp.axis('off')\n",
        "\n",
        "                # Plot XAI for best ensemble (if available)\n",
        "                if best_ensemble:\n",
        "                    ensemble_models = best_ensemble['models']\n",
        "                    with torch.no_grad():\n",
        "                        model_probs = []\n",
        "                        for model_name in ensemble_models:\n",
        "                            model = single_models[model_name]\n",
        "                            outputs = model(image.unsqueeze(0))\n",
        "                            probs = torch.softmax(outputs, dim=1)\n",
        "                            model_probs.append(probs)\n",
        "                        model_probs = torch.stack(model_probs, dim=1)\n",
        "\n",
        "                        # Load learnable ensemble model if applicable\n",
        "                        if 'learnable_weighted' in best_ensemble_name:\n",
        "                            ensemble_model = LearnableWeightedEnsemble(\n",
        "                                num_models=len(ensemble_models),\n",
        "                                num_classes=Config.NUM_CLASSES\n",
        "                            ).to(Config.DEVICE)\n",
        "                            ensemble_model.load_state_dict(\n",
        "                                torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(ensemble_models)}.pt\")\n",
        "                            )\n",
        "                            ensemble_model.eval()\n",
        "                            outputs, _ = ensemble_model(model_probs)\n",
        "                        else:\n",
        "                            weights = best_ensemble.get('weights', np.ones(len(ensemble_models)) / len(ensemble_models))\n",
        "                            outputs = torch.sum(model_probs * torch.tensor(weights, device=Config.DEVICE).view(1, -1, 1), dim=1)\n",
        "\n",
        "                        predicted_class = outputs.argmax(dim=1).item()\n",
        "                        confidence = torch.softmax(outputs, dim=1)[0, predicted_class].item()\n",
        "                        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                    # Approximate ensemble Grad-CAM++ by averaging\n",
        "                    gradcam_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(single_models[model_name], image, predicted_class)\n",
        "                        gradcam_imgs.append(gradcam_img)\n",
        "                    ensemble_gradcam = np.mean(gradcam_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble Grad-CAM++ in second column\n",
        "                    ax_gradcam = fig.add_subplot(gs[num_rows-1, 1])\n",
        "                    ax_gradcam.imshow(ensemble_gradcam)\n",
        "                    ax_gradcam.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                        fontsize=14, fontweight='bold', pad=15)\n",
        "                    ax_gradcam.axis('off')\n",
        "\n",
        "                    # Approximate ensemble Integrated Gradients by averaging\n",
        "                    ig_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        ig_img, _ = xai_visualizer.integrated_gradients(single_models[model_name], image, predicted_class)\n",
        "                        ig_imgs.append(ig_img)\n",
        "                    ensemble_ig = np.mean(ig_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble Integrated Gradients in third column\n",
        "                    ax_ig = fig.add_subplot(gs[num_rows-1, 2])\n",
        "                    ax_ig.imshow(ensemble_ig)\n",
        "                    ax_ig.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nIntegrated Gradients', fontsize=14, fontweight='bold', pad=15)\n",
        "                    ax_ig.axis('off')\n",
        "\n",
        "                    # Approximate ensemble LRP by averaging\n",
        "                    lrp_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(single_models[model_name], image, predicted_class)\n",
        "                        lrp_imgs.append(lrp_img)\n",
        "                    ensemble_lrp = np.mean(lrp_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble LRP in fourth column\n",
        "                    ax_lrp = fig.add_subplot(gs[num_rows-1, 3])\n",
        "                    ax_lrp.imshow(ensemble_lrp)\n",
        "                    ax_lrp.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nLRP', fontsize=14, fontweight='bold', pad=15)\n",
        "                    ax_lrp.axis('off')\n",
        "\n",
        "                plt.suptitle(f'Comparative XAI Analysis - Image {idx+1}', fontsize=18, fontweight='bold', y=0.92)\n",
        "                save_path = f\"{self.viz_dir}/comparative_xai_image_{idx+1}.png\"\n",
        "                plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "                plt.show()\n",
        "                print(f\"Comparative XAI visualization saved: {save_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating comparative XAI for image {idx+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "# ---\n",
        "# 12. FULLY FIXED XAI VISUALIZATIONS\n",
        "# =============================================================================\n",
        "# Purpose: Implement corrected Grad-CAM++ and LRP with proper tensor handling.\n",
        "\n",
        "class XAIVisualizer:\n",
        "    @staticmethod\n",
        "    def grad_cam_plus_plus(model, image, target_class):\n",
        "        \"\"\"Implement Grad-CAM++ for visualizing important image regions.\"\"\"\n",
        "        model.eval()\n",
        "\n",
        "        # Find the last convolutional layer\n",
        "        target_layer = None\n",
        "        for name, module in reversed(list(model.named_modules())):\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                target_layer = module\n",
        "                break\n",
        "\n",
        "        if target_layer is None:\n",
        "            raise ValueError(\"No convolutional layer found in the model\")\n",
        "\n",
        "        # Hook to capture gradients and activations\n",
        "        gradients = []\n",
        "        activations = []\n",
        "\n",
        "        def forward_hook(module, input, output):\n",
        "            activations.append(output.detach())  # Detach to avoid grad issues\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            gradients.append(grad_output[0].detach())  # Detach to avoid grad issues\n",
        "\n",
        "        # Register hooks\n",
        "        forward_handle = target_layer.register_forward_hook(forward_hook)\n",
        "        backward_handle = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "        try:\n",
        "            # Forward pass\n",
        "            image_tensor = image.unsqueeze(0).requires_grad_(True)\n",
        "            output = model(image_tensor)\n",
        "\n",
        "            # Backward pass\n",
        "            model.zero_grad()\n",
        "            score = output[0, target_class]\n",
        "            score.backward()\n",
        "\n",
        "            # Get gradients and activations\n",
        "            if not gradients or not activations:\n",
        "                raise ValueError(\"No gradients or activations captured\")\n",
        "\n",
        "            grad = gradients[0]  # Shape: (1, C, H, W)\n",
        "            act = activations[0]  # Shape: (1, C, H, W)\n",
        "\n",
        "            # Grad-CAM++ calculations\n",
        "            alpha_num = grad.pow(2)\n",
        "            alpha_denom = 2.0 * grad.pow(2) + (act * grad.pow(3)).sum(dim=(2, 3), keepdim=True)\n",
        "            alpha_denom = torch.where(alpha_denom != 0, alpha_denom, torch.ones_like(alpha_denom))\n",
        "            alpha = alpha_num / alpha_denom\n",
        "\n",
        "            weights = (alpha * F.relu(grad)).sum(dim=(2, 3))  # Shape: (1, C)\n",
        "            cam = (weights.unsqueeze(-1).unsqueeze(-1) * act).sum(dim=1, keepdim=True)  # Shape: (1, 1, H, W)\n",
        "            cam = F.relu(cam)\n",
        "\n",
        "            # Normalize\n",
        "            cam = cam - cam.min()\n",
        "            cam = cam / (cam.max() + 1e-8)\n",
        "\n",
        "            # Resize to input image size\n",
        "            cam = F.interpolate(cam, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "            cam = cam.squeeze().detach().cpu().numpy()  # Properly detach before numpy conversion\n",
        "\n",
        "            # Apply colormap\n",
        "            cam = (cam * 255).astype(np.uint8)\n",
        "            heatmap = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
        "\n",
        "            # Convert original image for visualization\n",
        "            image_np = image.detach().permute(1, 2, 0).cpu().numpy()  # Detach here too\n",
        "            image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "            image_np = np.clip(image_np, 0, 1)\n",
        "            image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "            # Superimpose heatmap\n",
        "            superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "        finally:\n",
        "            # Remove hooks\n",
        "            forward_handle.remove()\n",
        "            backward_handle.remove()\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "    @staticmethod\n",
        "    def integrated_gradients(model, image, target_class):\n",
        "        \"\"\"Integrated Gradients implementation (previously misnamed as LRP).\"\"\"\n",
        "        model.eval()\n",
        "\n",
        "        # Detach the image first to avoid gradient issues\n",
        "        image_detached = image.detach()\n",
        "\n",
        "        # Create baseline (black image)\n",
        "        baseline = torch.zeros_like(image_detached)\n",
        "\n",
        "        # Generate path from baseline to image\n",
        "        num_steps = 30  # Reduced for efficiency\n",
        "        alphas = torch.linspace(0, 1, num_steps).to(image_detached.device)\n",
        "\n",
        "        gradients = []\n",
        "        for alpha in alphas:\n",
        "            interpolated = baseline + alpha * (image_detached - baseline)\n",
        "            interpolated = interpolated.requires_grad_(True)\n",
        "\n",
        "            output = model(interpolated.unsqueeze(0))\n",
        "            score = output[0, target_class]\n",
        "\n",
        "            # Clear gradients\n",
        "            model.zero_grad()\n",
        "            if interpolated.grad is not None:\n",
        "                interpolated.grad.zero_()\n",
        "\n",
        "            score.backward()\n",
        "\n",
        "            # Detach gradient before storing\n",
        "            if interpolated.grad is not None:\n",
        "                gradients.append(interpolated.grad.detach().clone())\n",
        "\n",
        "            # Clear the gradient to free memory\n",
        "            interpolated.grad = None\n",
        "\n",
        "        if not gradients:\n",
        "            # Fallback: simple gradient\n",
        "            image_grad = image_detached.requires_grad_(True)\n",
        "            output = model(image_grad.unsqueeze(0))\n",
        "            score = output[0, target_class]\n",
        "            model.zero_grad()\n",
        "            score.backward()\n",
        "            gradients = [image_grad.grad.detach().clone()]\n",
        "\n",
        "        # Average gradients\n",
        "        avg_gradients = torch.stack(gradients).mean(dim=0)\n",
        "\n",
        "        # Compute integrated gradients\n",
        "        integrated_gradients = (image_detached - baseline) * avg_gradients\n",
        "\n",
        "        # Sum across color channels\n",
        "        relevance = integrated_gradients.abs().sum(dim=0).cpu().numpy()\n",
        "\n",
        "        # Normalize\n",
        "        relevance = relevance / (relevance.max() + 1e-8)\n",
        "\n",
        "        # Apply colormap\n",
        "        relevance = (relevance * 255).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(relevance, cv2.COLORMAP_JET)\n",
        "\n",
        "        # Convert original image for visualization\n",
        "        image_np = image_detached.permute(1, 2, 0).cpu().numpy()\n",
        "        image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "        # Superimpose heatmap\n",
        "        superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "    @staticmethod\n",
        "    def layer_wise_relevance_propagation(model, image, target_class, epsilon=1e-6):\n",
        "        \"\"\"Layer-wise Relevance Propagation (LRP) using epsilon-rule for CNNs.\"\"\"\n",
        "        model.eval()\n",
        "\n",
        "        # Forward pass to collect activations\n",
        "        activations = []\n",
        "        input_activations = []\n",
        "        def hook_fn(module, input, output):\n",
        "            input_activations.append(input[0])\n",
        "            activations.append(output)\n",
        "\n",
        "        hooks = []\n",
        "        for module in model.modules():\n",
        "            if isinstance(module, (nn.Conv2d, nn.Linear, nn.BatchNorm2d)):\n",
        "                hooks.append(module.register_forward_hook(hook_fn))\n",
        "            elif 'Bottleneck' in str(type(module)):\n",
        "                hooks.append(module.register_forward_hook(hook_fn))\n",
        "\n",
        "        image_tensor = image.unsqueeze(0).requires_grad_(True)\n",
        "        output = model(image_tensor)\n",
        "        predicted_class = output.argmax(dim=1).item() if target_class is None else target_class\n",
        "\n",
        "        # Initialize relevance at output\n",
        "        relevance = torch.zeros_like(output)\n",
        "        relevance[0, predicted_class] = output[0, predicted_class]\n",
        "\n",
        "        # Get layers in reverse order\n",
        "        layers = list(model.modules())[::-1]\n",
        "        activation_index = len(activations) - 1\n",
        "        input_activation_index = len(input_activations) - 1\n",
        "\n",
        "        # Backward propagation of relevance\n",
        "        current_relevance = relevance\n",
        "        successful_layers = 0\n",
        "        for layer in layers:\n",
        "            if activation_index < 0 or input_activation_index < 0:\n",
        "                break\n",
        "            act = activations[activation_index]\n",
        "            input_act = input_activations[input_activation_index]\n",
        "            activation_index -= 1\n",
        "            input_activation_index -= 1\n",
        "\n",
        "            try:\n",
        "                if isinstance(layer, nn.Conv2d):\n",
        "                    weight = layer.weight\n",
        "                    if input_act.size(1) != weight.size(1):\n",
        "                        continue\n",
        "                    z = nn.functional.conv2d(input_act, weight, stride=layer.stride, padding=layer.padding, groups=layer.groups) + epsilon\n",
        "                    s = current_relevance / (z + 1e-8)\n",
        "                    c = torch.autograd.grad(z, input_act, grad_outputs=s, retain_graph=True)[0]\n",
        "                    current_relevance = input_act * c\n",
        "                    successful_layers += 1\n",
        "                elif isinstance(layer, nn.Linear):\n",
        "                    weight = layer.weight\n",
        "                    input_act_flat = input_act.view(input_act.size(0), -1)\n",
        "                    if input_act_flat.size(1) != weight.size(1):\n",
        "                        continue\n",
        "                    z = torch.matmul(input_act_flat, weight.t()) + epsilon\n",
        "                    s = current_relevance / (z + 1e-8)\n",
        "                    c = torch.matmul(s, weight)\n",
        "                    current_relevance = (input_act_flat * c).view_as(input_act)\n",
        "                    successful_layers += 1\n",
        "                elif isinstance(layer, nn.BatchNorm2d):\n",
        "                    current_relevance = current_relevance * layer.weight.view(1, -1, 1, 1) / (layer.running_var.view(1, -1, 1, 1) + epsilon)\n",
        "                    successful_layers += 1\n",
        "                elif 'Bottleneck' in str(type(layer)):\n",
        "                    if len(input_act) == 2:\n",
        "                        main_act, skip_act = input_act\n",
        "                        main_norm = main_act.norm()\n",
        "                        skip_norm = skip_act.norm()\n",
        "                        total_norm = main_norm + skip_norm\n",
        "                        current_relevance = current_relevance * (main_norm / total_norm) + current_relevance * (skip_norm / total_norm)\n",
        "                    successful_layers += 1\n",
        "            except:\n",
        "                continue\n",
        "\n",
        "        # Clean up hooks\n",
        "        for h in hooks:\n",
        "            h.remove()\n",
        "\n",
        "        # Handle relevance map\n",
        "        current_relevance = current_relevance.detach()\n",
        "        if current_relevance.dim() == 4:\n",
        "            relevance_map = current_relevance.abs().sum(dim=1).squeeze().cpu().numpy()\n",
        "        else:\n",
        "            relevance_map = current_relevance.abs().squeeze().cpu().numpy()\n",
        "            size = int(np.sqrt(relevance_map.size))\n",
        "            if size * size == relevance_map.size:\n",
        "                relevance_map = relevance_map.reshape(size, size)\n",
        "            else:\n",
        "                relevance_map = np.zeros((Config.INPUT_SIZE, Config.INPUT_SIZE))\n",
        "\n",
        "        relevance_map = cv2.resize(relevance_map, (Config.INPUT_SIZE, Config.INPUT_SIZE))\n",
        "        relevance_map = relevance_map / (relevance_map.max() + 1e-8)\n",
        "        relevance_map = np.clip(relevance_map, 0, 1)\n",
        "        relevance_map = (relevance_map * 255).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(relevance_map, cv2.COLORMAP_JET)\n",
        "\n",
        "        image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "        image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "        superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "# ---\n",
        "# 13. MAIN EXECUTION\n",
        "# =============================================================================\n",
        "# Purpose: Orchestrate the entire pipeline: data loading, model training, ensemble creation, evaluation, and visualization.\n",
        "\n",
        "def main():\n",
        "    print(\"Starting Fish Species Classification Pipeline...\")\n",
        "    print(\"=\"*70)\n",
        "    setup_environment()\n",
        "\n",
        "    # Load and balance data\n",
        "    X, Y = DataManager.load_and_balance_data()\n",
        "    train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(X, Y)\n",
        "\n",
        "    # Initialize components\n",
        "    single_models = {}\n",
        "    single_results = {}\n",
        "    histories = {}\n",
        "    visualizer = EnhancedVisualizations()\n",
        "\n",
        "    # Train individual models with immediate plotting\n",
        "    for model_name in Config.MODELS:\n",
        "        print(f\"\\nTraining {model_name}...\")\n",
        "        print(\"-\"*50)\n",
        "\n",
        "        # Optimize hyperparameters\n",
        "        optimizer = ExpandedHyperparameterOptimizer(model_name, train_loader, val_loader)\n",
        "        best_params = optimizer.optimize()\n",
        "\n",
        "        # Create and train model with immediate visualization\n",
        "        model = ModelFactory.create_model(\n",
        "            model_name,\n",
        "            dropout_rate=best_params.get('dropout', 0.5),\n",
        "            hidden_dim_multiplier=best_params.get('hidden_dim_multiplier', 0.5)\n",
        "        )\n",
        "        trainer = EnhancedModelTrainer(model, model_name, best_params)\n",
        "\n",
        "        # Train with immediate plotting (includes training history, ROC, confusion matrix, XAI)\n",
        "        history, result = trainer.train(train_loader, val_loader, test_loader, visualizer)\n",
        "\n",
        "        histories[model_name] = history\n",
        "        single_models[model_name] = model\n",
        "        if result:\n",
        "            single_results[model_name] = result\n",
        "\n",
        "    # If some models didn't get evaluated during training, evaluate them now\n",
        "    evaluator = ModelEvaluator()\n",
        "    for model_name, model in single_models.items():\n",
        "        if model_name not in single_results:\n",
        "            result = evaluator.evaluate_model(model, test_loader, model_name)\n",
        "            single_results[model_name] = result\n",
        "\n",
        "    # Create and evaluate ensembles\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"ENSEMBLE ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    ensemble_manager = EnsembleManager(single_models, val_data)\n",
        "    ensemble_results, best_ensemble = ensemble_manager.test_ensemble_combinations()\n",
        "\n",
        "    # Evaluate best ensemble on test set\n",
        "    if best_ensemble:\n",
        "        ensemble_name, ensemble_result = best_ensemble\n",
        "        ensemble_models = ensemble_result['models']\n",
        "        ensemble_method = ensemble_name.split('_')[-1]\n",
        "        print(f\"\\nEvaluating best ensemble ({ensemble_name}) on test set...\")\n",
        "\n",
        "        test_dataset = FishDataset(test_data[0], test_data[1], DataManager.get_transforms(False))\n",
        "        test_loader_ensemble = DataLoader(test_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        if ensemble_method == 'learnable_weighted':\n",
        "            ensemble_model = LearnableWeightedEnsemble(\n",
        "                num_models=len(ensemble_models),\n",
        "                num_classes=Config.NUM_CLASSES\n",
        "            ).to(Config.DEVICE)\n",
        "            ensemble_model.load_state_dict(\n",
        "                torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(ensemble_models)}.pt\")\n",
        "            )\n",
        "            ensemble_model.eval()\n",
        "\n",
        "            all_preds = []\n",
        "            all_probs = []\n",
        "            all_labels = []\n",
        "            total_loss = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in test_loader_ensemble:\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    model_probs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        model = single_models[model_name]\n",
        "                        outputs = model(images)\n",
        "                        probs = torch.softmax(outputs, dim=1)\n",
        "                        model_probs.append(probs)\n",
        "                    model_probs = torch.stack(model_probs, dim=1)\n",
        "                    outputs, _ = ensemble_model(model_probs)\n",
        "                    loss = criterion(outputs, labels).item()\n",
        "                    total_loss += loss\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    all_preds.extend(predicted.cpu().numpy())\n",
        "                    all_probs.extend(torch.softmax(outputs, dim=1).cpu().numpy())\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = accuracy_score(all_labels, all_preds)\n",
        "            f1 = f1_score(all_labels, all_preds, average='macro')\n",
        "            avg_loss = total_loss / len(test_loader_ensemble)\n",
        "\n",
        "            ensemble_results[ensemble_name]['test_accuracy'] = accuracy\n",
        "            ensemble_results[ensemble_name]['test_f1'] = f1\n",
        "            ensemble_results[ensemble_name]['test_loss'] = avg_loss\n",
        "            ensemble_results[ensemble_name]['test_predictions'] = np.array(all_preds)\n",
        "            ensemble_results[ensemble_name]['test_probabilities'] = np.array(all_probs)\n",
        "            ensemble_results[ensemble_name]['test_true_labels'] = np.array(all_labels)\n",
        "\n",
        "            print(f\"Best Ensemble ({ensemble_name}) Test Results:\")\n",
        "            print(f\"  Accuracy: {accuracy:.4f}\")\n",
        "            print(f\"  F1 Score (Macro): {f1:.4f}\")\n",
        "            print(f\"  Loss: {avg_loss:.4f}\")\n",
        "\n",
        "            # Plot best ensemble results\n",
        "            visualizer.plot_roc_curves(ensemble_results[ensemble_name], ensemble_name)\n",
        "            visualizer.plot_confusion_matrix(ensemble_results[ensemble_name], ensemble_name)\n",
        "\n",
        "    # Generate comprehensive visualizations\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"GENERATING COMPREHENSIVE ANALYSIS\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Plot overall model comparison\n",
        "    visualizer.plot_model_comparison(single_results, ensemble_results)\n",
        "\n",
        "    # Generate comprehensive report\n",
        "    visualizer.generate_comprehensive_report(single_results, ensemble_results, best_ensemble)\n",
        "\n",
        "    # Generate comparative XAI visualizations\n",
        "    visualizer.plot_comparative_xai(single_models, ensemble_results, test_loader, max_images=2)\n",
        "\n",
        "    # Save results\n",
        "    results = {\n",
        "        'single_results': {k: {kk: vv.tolist() if isinstance(vv, np.ndarray) else vv\n",
        "                              for kk, vv in v.items()} for k, v in single_results.items()},\n",
        "        'ensemble_results': {k: {kk: vv.tolist() if isinstance(vv, np.ndarray) else vv\n",
        "                                for kk, vv in v.items() if not kk.startswith('test_')}\n",
        "                            for k, v in ensemble_results.items()},\n",
        "        'best_ensemble': best_ensemble[0] if best_ensemble else None,\n",
        "        'best_ensemble_f1': best_ensemble[1]['f1'] if best_ensemble else None\n",
        "    }\n",
        "\n",
        "    with open(f\"{Config.OUTPUT_DIR}/results.json\", 'w') as f:\n",
        "        json.dump(results, f, indent=4, cls=NpEncoder)\n",
        "\n",
        "    print(f\"Results saved to {Config.OUTPUT_DIR}/results.json\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"PIPELINE COMPLETED SUCCESSFULLY!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nGenerated Files:\")\n",
        "    print(f\"- Individual model training histories: {Config.OUTPUT_DIR}/visualizations/*_individual_training_history.png\")\n",
        "    print(f\"- Individual model XAI visualizations: {Config.OUTPUT_DIR}/visualizations/*_xai_image_*.png\")\n",
        "    print(f\"- Enhanced confusion matrices: {Config.OUTPUT_DIR}/visualizations/*_enhanced_confusion_matrix.png\")\n",
        "    print(f\"- Enhanced ROC curves: {Config.OUTPUT_DIR}/visualizations/*_enhanced_roc_curves.png\")\n",
        "    print(f\"- Model comparison analysis: {Config.OUTPUT_DIR}/visualizations/enhanced_model_comparison.png\")\n",
        "    print(f\"- Comprehensive report: {Config.OUTPUT_DIR}/visualizations/comprehensive_report.png\")\n",
        "    print(f\"- Comparative XAI: {Config.OUTPUT_DIR}/visualizations/comparative_xai_image_*.png\")\n",
        "\n",
        "    # # REAL-WORLD TESTING (Commented out as requested)\n",
        "    # # =============================================================================\n",
        "    # # Purpose: Test the model on new, unseen images from a real-world dataset.\n",
        "    # print(\"\\nReal-World Testing (Commented Out)\")\n",
        "    # print(\"-\"*50)\n",
        "    # # real_world_images = load_real_world_data()  # Placeholder for loading real-world data\n",
        "    # # real_world_predictions = []\n",
        "    # # for image in real_world_images:\n",
        "    # #     processed_image = preprocess_real_world_image(image)\n",
        "    # #     with torch.no_grad():\n",
        "    # #         output = best_model(processed_image.to(Config.DEVICE))\n",
        "    # #         prediction = torch.argmax(output, dim=1).cpu().numpy()\n",
        "    # #         real_world_predictions.append(prediction)\n",
        "    # # save_real_world_results(real_world_predictions)\n",
        "\n",
        "    # # Real-world data testing part\n",
        "    # # Uncomment to use\n",
        "    # # from google.colab import files\n",
        "    # # uploaded = files.upload()\n",
        "    # # for fn in uploaded.keys():\n",
        "    # #     # Load and preprocess the uploaded image\n",
        "    # #     image = Image.open(fn)\n",
        "    # #     transform = transforms.Compose([\n",
        "    # #         transforms.Resize((224, 224)),\n",
        "    # #         transforms.ToTensor(),\n",
        "    # #         transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    # #     ])\n",
        "    # #     image_tensor = transform(image).unsqueeze(0).to(Config.DEVICE)\n",
        "    # #     # Predict using the best saved model\n",
        "    # #     best_model.eval()\n",
        "    # #     with torch.no_grad():\n",
        "    # #         output = best_model(image_tensor)\n",
        "    # #         predicted_class = output.argmax(dim=1).item()\n",
        "    # #     print(f\"Predicted class for {fn}: {Config.CLASS_LABELS[predicted_class]}\")\n",
        "    # #     # Show XAI explanation\n",
        "    # #     xai_visualizer = XAIVisualizer()\n",
        "    # #     gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(best_model, image_tensor.squeeze(), predicted_class)\n",
        "    # #     plt.imshow(gradcam_img)\n",
        "    # #     plt.show()\n",
        "\n",
        "    # # Save the best model as .keras file\n",
        "    # # Note: Converting Torch to Keras requires additional steps (e.g., ONNX or manual conversion)\n",
        "    # # For simplicity, saving as .pt file instead\n",
        "    # torch.save(self.model.state_dict(), f\"{Config.OUTPUT_DIR}/models/best_model.pt\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PP9oUaRCq5f1",
        "outputId": "1704acde-7613-4635-9fa2-c318d93f94fe"
      },
      "id": "PP9oUaRCq5f1",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch-gradcam in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.12/dist-packages (4.5.0)\n",
            "Requirement already satisfied: captum in /usr/local/lib/python3.12/dist-packages (0.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from pytorch-gradcam) (4.11.0.86)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch-gradcam) (1.26.4)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (1.16.4)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.12/dist-packages (from optuna) (6.9.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from optuna) (25.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from optuna) (2.0.43)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from optuna) (6.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from captum) (3.10.0)\n",
            "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.12/dist-packages (from captum) (2.8.0+cu126)\n",
            "Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n",
            "Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.12/dist-packages (from alembic>=1.5.0->optuna) (4.14.1)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.19.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.10->captum) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (4.59.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->captum) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.10->captum) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.10->captum) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdd48bb6",
      "metadata": {
        "id": "cdd48bb6"
      },
      "source": [
        "#End"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "history_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}