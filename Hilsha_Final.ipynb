{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran012x/Transfer-Models/blob/main/Hilsha_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 1: Colab-Setup\n"
      ],
      "metadata": {
        "id": "k1SaijPsU_az"
      },
      "id": "k1SaijPsU_az"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "drive_path = '/content/drive'\n",
        "\n",
        "if os.path.exists(drive_path) and os.path.ismount(drive_path):\n",
        "    print(\"Google Drive is already connected ‚úÖ\")\n",
        "else:\n",
        "    drive.mount(drive_path)\n",
        "    print(\"Google Drive connection done ‚úÖ\")\n",
        "\n",
        "\n",
        "# # Upload a file\n",
        "# uploaded = files.upload()\n",
        "# # Get the file name\n",
        "# file_name = list(uploaded.keys())[0]\n",
        "# print(f\"Uploaded file: {file_name}\")\n",
        "\n",
        "\n",
        "# import zipfile\n",
        "# import os\n",
        "# # with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_224_11k.zip', 'r') as zip_ref:\n",
        "# #     zip_ref.extractall('')\n",
        "# with zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bo8MKzRhJHqC",
        "outputId": "603590bf-f894-443c-f32f-fb3b8a8db30f"
      },
      "id": "Bo8MKzRhJHqC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Drive is already connected ‚úÖ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 2: Import & Config & Env Setup"
      ],
      "metadata": {
        "id": "HiFbgREXbGzn"
      },
      "id": "HiFbgREXbGzn"
    },
    {
      "cell_type": "code",
      "source": [
        "#1. IMPORTS AND INITIAL SETUP\n",
        "# ================================================================================================================================\n",
        "# Purpose: Import all required libraries and set up warnings to suppress unnecessary messages.\n",
        "\n",
        "\n",
        "\n",
        "!pip install pytorch-gradcam optuna captum -q  # Uncomment if running in a new environment\n",
        "\n",
        "\n",
        "import sys\n",
        "import numpy\n",
        "import pandas\n",
        "import seaborn as sns\n",
        "\n",
        "print(f\"python_version: {sys.version.split()[0]}\")\n",
        "print(f\"numpy_version: {numpy.__version__}\")\n",
        "print(f\"pandas_version: {pandas.__version__}\")\n",
        "print(f\"seaborn_version: {sns.__version__}\\n\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Standard Library\n",
        "# ============================================================\n",
        "import os\n",
        "import sys\n",
        "import gc\n",
        "import time\n",
        "import json\n",
        "import zipfile\n",
        "import logging\n",
        "import random\n",
        "import warnings\n",
        "import traceback\n",
        "import logging\n",
        "import subprocess\n",
        "import threading\n",
        "import traceback\n",
        "from pathlib import Path\n",
        "from threading import Lock\n",
        "import multiprocessing as mp\n",
        "from itertools import combinations\n",
        "from datetime import datetime, timedelta\n",
        "from collections import Counter, defaultdict\n",
        "from typing import Tuple, Dict, Any, Optional\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "# ============================================================\n",
        "# Data Handling & Utilities\n",
        "# ============================================================\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ============================================================\n",
        "# Visualization\n",
        "# ============================================================\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "# ============================================================\n",
        "# System & Resource Monitoring\n",
        "# ============================================================\n",
        "import psutil\n",
        "import pynvml\n",
        "\n",
        "# ============================================================\n",
        "# Machine Learning\n",
        "# ============================================================\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import (\n",
        "    confusion_matrix, classification_report, f1_score, accuracy_score,\n",
        "    precision_score, recall_score, roc_curve, auc\n",
        ")\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# Imbalanced data handling\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# ============================================================\n",
        "# Deep Learning - PyTorch\n",
        "# ============================================================\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, SubsetRandomSampler\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# ============================================================\n",
        "# Augmentation\n",
        "# ============================================================\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Explainable AI (XAI)\n",
        "# ============================================================\n",
        "\n",
        "import torch.autograd as autograd\n",
        "from captum.attr import LRP\n",
        "\n",
        "# Optuna\n",
        "import optuna\n",
        "import optuna.logging\n",
        "\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# Hyperparameter Optimization\n",
        "# ============================================================\n",
        "try:\n",
        "    OPTUNA_AVAILABLE = True\n",
        "except ImportError:\n",
        "    OPTUNA_AVAILABLE = False\n",
        "    print(\"Warning: Optuna not available. Using default hyperparameters.\")\n",
        "\n",
        "\n",
        "\n",
        "#For DeprecationWarning / FutureWarning specifically:\n",
        "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
        "warnings.simplefilter(\"ignore\", category=FutureWarning)\n",
        "\n",
        "# Hide all pip warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
        "\n",
        "\n",
        "# ---\n",
        "# 2. CONFIGURATION\n",
        "# ================================================================================================================================\n",
        "# Purpose: Define configuration settings and initialize the environment.\n",
        "\n",
        "class Config:\n",
        "\n",
        "\n",
        "    OUTPUT_DIR = './fish_classification_results'\n",
        "\n",
        "    # Dataset parameters\n",
        "    NUM_CLASSES = 5\n",
        "    CLASS_LABELS = ['Ilish', 'Chandana', 'Sardin', 'Sardinella', 'Punctatus']\n",
        "    INPUT_SIZE = 224\n",
        "\n",
        "    # Training parameters\n",
        "    BATCH_SIZE = 32 #Will Change Dynamically\n",
        "    DATALOADER_NUM_WORKERS = 1 #Will Change Dynamically\n",
        "    # Dynamically adjust batch size and workers\n",
        "    EPOCHS = 25\n",
        "    PIN_MEMORY = True\n",
        "    USE_MIXED_PRECISION = True #True\n",
        "    COMPILE_MODEL = True\n",
        "    PATIENCE = 4\n",
        "    LEARNING_RATE = 1e-5\n",
        "    WEIGHT_DECAY = 1e-4\n",
        "\n",
        "    # Hyperparameter tuning\n",
        "    OPTUNA_TRIALS = 40\n",
        "    OPTUNA_EPOCHS = 10\n",
        "\n",
        "    # Models to train\n",
        "    # MODELS = ['resnet50','efficientnet_b0','mobilenet_v3_large','vgg16', 'densenet121']\n",
        "    MODELS = [\n",
        "        'resnet50',\n",
        "        'efficientnet_b0',\n",
        "        'mobilenet_v3_large',\n",
        "        'vgg16',\n",
        "        'densenet121',\n",
        "        'inception_v3',\n",
        "        # 'vit_b_16',\n",
        "        # 'convnext_base',\n",
        "        # 'regnet_y_32gf'\n",
        "    ]\n",
        "\n",
        "\n",
        "    # Ensemble methods\n",
        "    ENSEMBLE_METHODS = ['simple_average', 'weighted_average', 'confidence_based', 'learnable_weighted']\n",
        "\n",
        "    # Device\n",
        "    DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "    SEED = 42\n",
        "\n",
        "\n",
        "\n",
        "# def get_available_cpu_memory():\n",
        "#     \"\"\"Get available CPU memory in GB.\"\"\"\n",
        "#     mem = psutil.virtual_memory()\n",
        "#     return mem.available / 1024**3  # Convert bytes to GB\n",
        "\n",
        "# def get_available_gpu_memory():\n",
        "#     \"\"\"Get available GPU memory in GB.\"\"\"\n",
        "#     pynvml.nvmlInit()\n",
        "#     handle = pynvml.nvmlDeviceGetHandleByIndex(0)\n",
        "#     mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
        "#     return mem_info.free / 1024**3  # Convert bytes to GB\n",
        "\n",
        "# def adjust_batch_size_and_workers(base_batch_size, base_num_workers):\n",
        "#     gpu_memory = get_available_gpu_memory()\n",
        "#     print(f\"GPU memory available: {gpu_memory:.2f} GB\")\n",
        "\n",
        "#     # Prioritize GPU memory for batch size\n",
        "#     if gpu_memory > 24:  # High-end GPU\n",
        "#         batch_size = base_batch_size * 4\n",
        "#         num_workers = min(8, psutil.cpu_count())  # Use more workers for high GPU memory\n",
        "#     elif gpu_memory > 12:  # Mid-range GPU\n",
        "#         batch_size = base_batch_size * 2\n",
        "#         num_workers = min(4, psutil.cpu_count())  # Moderate workers\n",
        "#     elif gpu_memory > 6:  # Lower-end GPU\n",
        "#         batch_size = base_batch_size\n",
        "#         num_workers = min(2, psutil.cpu_count())  # Minimal workers\n",
        "#     else:  # Very low GPU memory\n",
        "#         batch_size = max(8, base_batch_size // 2)\n",
        "#         num_workers = 0  # Disable workers to minimize CPU load\n",
        "\n",
        "    # if batch_size is None:\n",
        "    # if torch.cuda.is_available():\n",
        "    #     gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
        "    #     if gpu_memory_gb >= 24:\n",
        "    #         batch_size = 128\n",
        "    #     elif gpu_memory_gb >= 12:\n",
        "    #         batch_size = 96\n",
        "    #     elif gpu_memory_gb >= 8:\n",
        "    #         batch_size = 64\n",
        "    #     else:\n",
        "    #         batch_size = 48\n",
        "    # else:\n",
        "    #     batch_size = Config.BATCH_SIZE\n",
        "\n",
        "\n",
        "    # print(f\"Adjusted batch_size: {batch_size}, num_workers: {num_workers} And GPU memory: {gpu_memory:.2f} GB)\")\n",
        "    # return batch_size, num_workers\n",
        "\n",
        "\n",
        "def setup_environment():\n",
        "    \"\"\"Setup random seeds, directories, and dynamically adjust batch size and workers\"\"\"\n",
        "\n",
        "    os.environ['PYTHONHASHSEED'] = str(Config.SEED)  # For hash seed reproducibility\n",
        "    random.seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    torch.cuda.manual_seed_all(Config.SEED)  # For multi-GPU if applicable\n",
        "    #Guard for GPU determinism (optional, but helpful if you want exact reproducibility across runs):\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "    torch.manual_seed(Config.SEED)\n",
        "    np.random.seed(Config.SEED)\n",
        "\n",
        "    directories = [\n",
        "        Config.OUTPUT_DIR,\n",
        "        f\"{Config.OUTPUT_DIR}/models\",\n",
        "        f\"{Config.OUTPUT_DIR}/visualizations\",\n",
        "        f\"{Config.OUTPUT_DIR}/reports\",\n",
        "        f\"{Config.OUTPUT_DIR}/xai_visualizations\"\n",
        "    ]\n",
        "\n",
        "    for directory in directories:\n",
        "        Path(directory).mkdir(parents=True, exist_ok=True)#With exist_ok=True:Python will not raise an error if already exists.Or else raise a FileExistsError\n",
        "        #& parents=True ‚Üí creates all missing parent directories in the path.\n",
        "\n",
        "    # Ensure all output directories exist\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/best_model\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/model_results\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/kfold_results\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/visualizations\", exist_ok=True)\n",
        "\n",
        "    print(f\"Using device: {Config.DEVICE}\")\n",
        "    print(f\"PyTorch version: {torch.__version__}\")\n",
        "    print(f\"Dynamic BATCH_SIZE: {Config.BATCH_SIZE}, DATALOADER_NUM_WORKERS: {Config.DATALOADER_NUM_WORKERS}\")\n",
        "    print(\"-\" * 70)\n",
        "\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    seed = Config.SEED + worker_id\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "\n",
        "# class NpEncoder(json.JSONEncoder):\n",
        "#     def default(self, obj):\n",
        "#         if isinstance(obj, torch.Tensor):\n",
        "#             return obj.cpu().detach().numpy().tolist()  # Convert tensor to NumPy array, then to list\n",
        "#         if isinstance(obj, np.integer):\n",
        "#             return int(obj)\n",
        "#         if isinstance(obj, np.floating):\n",
        "#             return float(obj)\n",
        "#         if isinstance(obj, np.ndarray):\n",
        "#             return obj.tolist()\n",
        "#         return super(NpEncoder, self).default(obj)\n",
        "\n",
        "# Config.BATCH_SIZE, Config.DATALOADER_NUM_WORKERS = adjust_batch_size_and_workers(Config.BATCH_SIZE, Config.DATALOADER_NUM_WORKERS)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ================================================================================================================================\n",
        "# Purpose: Track and display training progress with progress bars and epoch summaries.\n",
        "\n",
        "class TrainingProgressTracker:\n",
        "    \"\"\"Track and display detailed training progress\"\"\"\n",
        "\n",
        "    def __init__(self, model_name, total_epochs, total_batches_per_epoch):\n",
        "        self.model_name = model_name\n",
        "        self.total_epochs = total_epochs\n",
        "        self.total_batches_per_epoch = total_batches_per_epoch\n",
        "\n",
        "        self.current_epoch = 0\n",
        "        self.start_time = time.time()\n",
        "        self.epoch_start_time = None\n",
        "        self.batch_times = []\n",
        "\n",
        "\n",
        "\n",
        "    def start_epoch(self, epoch):\n",
        "        \"\"\"Start tracking an epoch\"\"\"\n",
        "        self.current_epoch = epoch\n",
        "        self.epoch_start_time = time.time()\n",
        "        self.batch_times = []\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"Model: {self.model_name.upper()} | Epoch: {epoch+1}/{self.total_epochs}\")\n",
        "        print(f\"{'='*60}\")\n",
        "\n",
        "\n",
        "\n",
        "    def update_batch(self, batch_idx, batch_loss, batch_acc, is_training=True,total_batches=None):\n",
        "        \"\"\"Update progress for current batch\"\"\"\n",
        "        batch_time = time.time()\n",
        "        self.batch_times.append(batch_time)\n",
        "\n",
        "\n",
        "        # Calculate timing estimates\n",
        "        if len(self.batch_times) > 1:\n",
        "            avg_batch_time = np.mean(np.diff(self.batch_times[-10:]))\n",
        "        else:\n",
        "            avg_batch_time = 1.0\n",
        "\n",
        "        total_batches = total_batches if total_batches is not None else self.total_batches_per_epoch\n",
        "        remaining_batches = total_batches - (batch_idx + 1)\n",
        "\n",
        "\n",
        "        # remaining_batches = self.total_batches_per_epoch - (batch_idx + 1)\n",
        "        eta_epoch = remaining_batches * avg_batch_time\n",
        "\n",
        "        # Progress bar\n",
        "        # progress_pct = (batch_idx + 1) / self.total_batches_per_epoch * 100\n",
        "        progress_pct = (batch_idx + 1) / total_batches * 100\n",
        "        bar_length = 30\n",
        "\n",
        "        # filled_length = int(bar_length * (batch_idx + 1) // self.total_batches_per_epoch)\n",
        "        filled_length = int(bar_length * (batch_idx + 1) // total_batches)\n",
        "        bar = '‚ñà' * filled_length + '-' * (bar_length - filled_length)\n",
        "\n",
        "        # Format time\n",
        "        eta_str = str(timedelta(seconds=int(eta_epoch)))\n",
        "\n",
        "        # Display progress\n",
        "        mode = \"TRAIN\" if is_training else \"VAL  \"\n",
        "\n",
        "        print(f\"\\r{mode} |{bar}| {progress_pct:5.1f}% | \"\n",
        "              f\"Batch: {batch_idx+1:4d}/{total_batches} | \"\n",
        "              f\"Loss: {batch_loss:.4f} | Acc: {batch_acc:.4f} | \"\n",
        "              f\"ETA: {eta_str}\", end='', flush=True)\n",
        "\n",
        "\n",
        "    def finish_epoch(self, train_loss, train_acc, val_loss, val_acc, val_f1, is_best=False, lr=None):\n",
        "        \"\"\"Finish epoch and display summary\"\"\"\n",
        "        epoch_time = time.time() - self.epoch_start_time\n",
        "        total_time = time.time() - self.start_time\n",
        "\n",
        "        print(f\"\\n{'-'*60}\")\n",
        "        print(f\"EPOCH SUMMARY:\")\n",
        "        print(f\"  Train Loss: {train_loss:.6f} | Train Acc: {train_acc:.4f}\")\n",
        "        print(f\"  Val Loss:   {val_loss:.6f} | Val Acc:   {val_acc:.4f}\")\n",
        "        print(f\"  Val F1:     {val_f1:.4f} | Epoch Time: {epoch_time:.1f}s\")\n",
        "        if lr:\n",
        "            print(f\"  Learning Rate: {lr:.2e}\")\n",
        "\n",
        "        if is_best:\n",
        "            print(f\"  ‚òÖ NEW BEST MODEL! (F1: {val_f1:.4f})\")\n",
        "\n",
        "        print(f\"  Total Time: {str(timedelta(seconds=int(total_time)))}\")\n",
        "        print(f\"{'-'*60}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5tVhsrE2bL5w",
        "outputId": "315b5881-c5af-4a1f-e654-1dea4c1ff575"
      },
      "id": "5tVhsrE2bL5w",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python_version: 3.12.11\n",
            "numpy_version: 1.26.4\n",
            "pandas_version: 2.2.2\n",
            "seaborn_version: 0.13.2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 3: Pre-processing & Save"
      ],
      "metadata": {
        "id": "M9g_LvnMZ1Rs"
      },
      "id": "M9g_LvnMZ1Rs"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # Check GPU availability\n",
        "# print(\"GPU Available:\", torch.cuda.is_available())\n",
        "# print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "\n",
        "# # Define fish classes and dataset paths\n",
        "# fish_classes = ['ilish', 'chandana', 'sardin', 'sardinella', 'punctatus'] #0,1,2,3,4\n",
        "# zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip').extractall('/content/.hidden_fish')\n",
        "# data_dir = '/content/.hidden_fish'\n",
        "\n",
        "# image_limits = {\n",
        "#     'ilish': 3000,\n",
        "#     'chandana': 1185,\n",
        "#     'sardin': 2899,\n",
        "#     'sardinella': 370,\n",
        "#     'punctatus': 953\n",
        "# }\n",
        "\n",
        "# # Settings\n",
        "# total_images = sum(image_limits.values())\n",
        "# batch_size = 100\n",
        "# num_threads = 4\n",
        "\n",
        "\n",
        "# # Output paths\n",
        "# output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "# os.makedirs(output_dir, exist_ok=True)\n",
        "# labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "# xdata_file = os.path.join(output_dir, 'X_data.npy')\n",
        "\n",
        "# save_lock = threading.Lock()  # for thread-safe writes -> Prevents race conditions when multiple threads write to the same list.\n",
        "\n",
        "# # Function to gather image paths\n",
        "# def get_image_paths(class_name, max_images):\n",
        "#     path = os.path.join(data_dir, class_name)\n",
        "#     files = sorted(os.listdir(path))\n",
        "#     random.shuffle(files)\n",
        "#     return [os.path.join(path, f) for f in files[:max_images]]\n",
        "\n",
        "# # Load and preprocess batch\n",
        "# def load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     end_idx = min(start_idx + batch_size, len(image_paths))\n",
        "#     batch_paths = image_paths[start_idx:end_idx]\n",
        "#     batch_images = []\n",
        "\n",
        "#     for img_path in batch_paths:\n",
        "#         img = Image.open(img_path).resize((224, 224)).convert('RGB')\n",
        "#         img_tensor = torch.tensor(np.array(img), dtype=torch.uint8).permute(2, 0, 1)  # C x H x W\n",
        "#         batch_images.append(img_tensor)\n",
        "\n",
        "#     batch_tensor = torch.stack(batch_images)  # B x C x H x W\n",
        "#     batch_labels = np.full((len(batch_images),), class_idx, dtype=np.int32)\n",
        "#     return batch_tensor, batch_labels\n",
        "\n",
        "# # Process one batch and return tensors & labels (no file saving)\n",
        "# def process_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "#     return load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx)\n",
        "\n",
        "# def preprocess_and_save_all(overwrite=True):\n",
        "#     if os.path.exists(labels_file) and os.path.exists(xdata_file) and not overwrite:\n",
        "#         print(\"Preprocessed data already exists. Set overwrite=True to reprocess.\")\n",
        "#         return\n",
        "\n",
        "#     all_images = []\n",
        "#     all_labels = []\n",
        "#     processed_count = 0\n",
        "\n",
        "#     for idx, class_name in enumerate(fish_classes):\n",
        "#         print(f\"\\nProcessing class: {class_name}\")\n",
        "#         image_paths = get_image_paths(class_name, image_limits[class_name])\n",
        "#         total_batches = (len(image_paths) + batch_size - 1) // batch_size\n",
        "#         #It ensures ceiling division ‚Äî rounding up, not down.\n",
        "#         # Normal division: 103 / 20 = 5.15 ‚Üí floor division // 20 = 5 (‚ùå missing last 3 images)\n",
        "#         # This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ‚úÖ\n",
        "\n",
        "#         with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "#             futures = []\n",
        "#             for start in range(0, len(image_paths), batch_size):\n",
        "#                 futures.append(executor.submit(process_batch, image_paths, start, batch_size, idx))\n",
        "\n",
        "#             for future in tqdm(as_completed(futures), total=total_batches, desc=class_name):#taqaddum (ÿ™ŸÇÿØŸëŸÖ) ‚Äì Arabic for \"progress\".\n",
        "#                 # futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\n",
        "#                 # as_completed(futures): Yields each future as it finishes (not in order).\n",
        "\n",
        "#                 batch_tensor, batch_labels = future.result()\n",
        "#                 with save_lock: #Locks this section so that only one thread can update the shared lists safely.\n",
        "#                     all_images.append(batch_tensor)\n",
        "#                     all_labels.append(batch_labels)\n",
        "#                     processed_count += batch_tensor.size(0)\n",
        "#                     print(f\"Processed batch with {batch_tensor.size(0)} images, total processed: {processed_count}/{total_images}\")\n",
        "#                 gc.collect()\n",
        "\n",
        "#     # Combine all tensors and labels\n",
        "#     X = torch.cat(all_images, dim=0).numpy()\n",
        "#     Y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "#     # Save final arrays\n",
        "#     np.save(xdata_file, X, allow_pickle=False)#Malicious .npy -> import os;os.system(\"rm -rf /\")  # ‚Üê Dangerous command\n",
        "#     np.save(labels_file, Y, allow_pickle=False)\n",
        "\n",
        "#     print(f\"\\n‚úÖ Done! Saved {processed_count} images in {xdata_file}\")\n",
        "#     print(f\"X_data shape: {X.shape}, Y_labels shape: {Y.shape}\")\n",
        "\n",
        "#     if processed_count != total_images:\n",
        "#         raise ValueError(f\"Expected {total_images} images, but processed {processed_count}\")\n",
        "\n",
        "# # Run preprocessing and save directly to X_data.npy and Y_labels.npy\n",
        "# preprocess_and_save_all(overwrite=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class FishDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "\n",
        "        self.images = self._preprocess_images(images)\n",
        "        self.labels = labels.astype(np.int64)\n",
        "        self.transform = transform #Here means: Medium,Heavy or Any\n",
        "\n",
        "    def _preprocess_images(self, images):\n",
        "        \"\"\"Preprocess images to ensure proper format and normalization\"\"\"\n",
        "        if images.max() > 1.5: #üëâ The threshold 1.5 is just a safe cutoff to distinguish between the two cases.\n",
        "            #Because some normalized images can have values slightly above 1.0 (e.g., after augmentations, rounding, or scaling bugs).\n",
        "            images = images.astype(np.float32) / 255.0\n",
        "\n",
        "        if len(images.shape) == 4 and images.shape[1] == 3: #If input is (batch, channels, height, width) ‚Üí convert to (batch, height, width, channels) (common for TensorFlow).\n",
        "            images = np.transpose(images, (0, 2, 3, 1))\n",
        "        return images.astype(np.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Return the total number of samples in the dataset\"\"\"\n",
        "        return len(self.images)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "\n",
        "        if self.transform:  #Applies an Albumentations transform pipeline (it returns a dict, so you take ['image']).\n",
        "            image = self.transform(image=image)['image'] #\n",
        "        else:\n",
        "            image = torch.from_numpy(image).permute(2, 0, 1)\n",
        "        #With transform ‚Üí advanced augmentations.\n",
        "        #Without transform ‚Üí just convert to PyTorch format.\n",
        "\n",
        "\n",
        "        # Convert label to plain Python int to avoid CUDA tensor creation in workers.That wastes memory and slows down training.\n",
        "        if isinstance(label, np.ndarray):\n",
        "            label = int(label.item())\n",
        "        elif hasattr(label, 'item'):\n",
        "            label = int(label.item())\n",
        "        else:\n",
        "            label = int(label)\n",
        "\n",
        "\n",
        "        return image, label  # Plain Python int, not torch.tensor\n",
        "        # return image, torch.tensor(int(label), dtype=torch.long)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # def __getitem__(self, idx):\n",
        "    #     image = self.images[idx]  # H x W x C\n",
        "    #     label = self.labels[idx]\n",
        "\n",
        "    #     # Ensure image has 3 channels\n",
        "    #     if image.ndim == 2:  # grayscale H x W\n",
        "    #         image = np.stack([image]*3, axis=-1)\n",
        "    #     elif image.shape[-1] == 4:  # RGBA\n",
        "    #         image = image[:, :, :3]\n",
        "\n",
        "    #     # Apply Albumentations transform if any\n",
        "    #     if self.transform:\n",
        "    #         image = self.transform(image=image)['image']  # may already be tensor\n",
        "\n",
        "    #     # Convert to PyTorch tensor C x H x W if it's a numpy array\n",
        "    #     if isinstance(image, np.ndarray):\n",
        "    #         image = torch.from_numpy(image).permute(2, 0, 1).float()\n",
        "    #     elif isinstance(image, torch.Tensor) and image.ndim == 3 and image.shape[0] != 3:\n",
        "    #         # If transform returns H x W x C tensor, permute to C x H x W\n",
        "    #         image = image.permute(2, 0, 1).float()\n",
        "    #     # else assume it's already C x H x W\n",
        "\n",
        "    #     # Convert label to tensor\n",
        "    #     label = int(label) if not isinstance(label, torch.Tensor) else label.long()\n",
        "\n",
        "    #     return image, torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # class MyClass:\n",
        "        #     def greet(self):\n",
        "        #         print(\"Hello!\")\n",
        "        # obj = MyClass()\n",
        "        # print(hasattr(obj, 'greet'))   # True, because obj has a method greet\n",
        "        # print(hasattr(obj, 'name'))    # False, no attribute called name\n",
        "        # # Using hasattr with .item()\n",
        "        # import torch\n",
        "        # x = torch.tensor(5)  # scalar tensor\n",
        "        # print(hasattr(x, 'item'))      # True\n",
        "        # print(x.item())                # 5\n",
        "\n",
        "        # return image, torch.tensor(label, dtype=torch.long)  # <-- ensure label is tensor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DataManager:\n",
        "    @staticmethod  #In Python, @staticmethod is used to define a method that belongs to a class but doesn‚Äôt access self or cls.\n",
        "\n",
        "    # class DataManager:\n",
        "    # staticmethod\n",
        "    # def greet(name):\n",
        "    #     return f\"Hello, {name}!\"\n",
        "    # # Call without creating an instance\n",
        "    # print(DataManager.greet(\"Imran\"))  # Output: Hello, Imran!\n",
        "    # # Call with an instance\n",
        "    # dm = DataManager()\n",
        "    # print(dm.greet(\"Imran\"))           # Output: Hello, Imran!\n",
        "\n",
        "    # class MyClass:\n",
        "    #     count = 0\n",
        "\n",
        "    #     staticmethod\n",
        "    #     def greet(name):\n",
        "    #         return f\"Hello, {name}!\"\n",
        "\n",
        "    #     classmethod\n",
        "    #     def increment_count(cls):\n",
        "    #         cls.count += 1\n",
        "    #         return cls.count\n",
        "\n",
        "    # # Static method\n",
        "    # print(MyClass.greet(\"Imran\"))      # Hello, Imran!\n",
        "    # # Class method\n",
        "    # print(MyClass.increment_count())   # 1\n",
        "    # print(MyClass.increment_count())   # 2\n",
        "    #Static method ‚Üí independent of class/instance.\n",
        "    #Class method ‚Üí works with the class itself (cls), can modify class variables.\n",
        "\n",
        "\n",
        "    def get_transforms(is_training=True, augmentation_strength='medium'):\n",
        "        \"\"\"Get data transforms with configurable augmentation strength\"\"\"\n",
        "        if is_training:\n",
        "            if augmentation_strength == 'light':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.3),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            elif augmentation_strength == 'heavy':\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.7),\n",
        "                    A.VerticalFlip(p=0.5),\n",
        "                    A.RandomRotate90(p=0.7),\n",
        "                    # A.ShiftScaleRotate(shift_limit=0.3, scale_limit=0.3, rotate_limit=45, p=0.8),\n",
        "                    # A.RandomBrightnessContrast(brightness_limit=0.4, contrast_limit=0.4, p=0.8),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
        "                    # A.HueSaturationValue(hue_shift_limit=30, sat_shift_limit=40, val_shift_limit=30, p=0.7),\n",
        "                    A.GaussianBlur(blur_limit=(3, 9), p=0.5),\n",
        "                    A.GaussNoise(var_limit=(10.0, 80.0), p=0.4),\n",
        "                    A.CoarseDropout(max_holes=12, max_height=25, max_width=25, p=0.5),\n",
        "                    A.ElasticTransform(p=0.3),\n",
        "                    A.GridDistortion(p=0.3),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "\n",
        "                    A.RandomFog(fog_coef_lower=0.1, fog_coef_upper=0.3, p=0.3),\n",
        "                    A.RandomRain(blur_value=3, p=0.2),\n",
        "                    A.ColorJitter(hue=0.1, p=0.5),\n",
        "\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "            else:  # medium\n",
        "                return A.Compose([\n",
        "                    A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                    A.HorizontalFlip(p=0.5),\n",
        "                    A.VerticalFlip(p=0.3),\n",
        "                    A.RandomRotate90(p=0.5),\n",
        "                    # A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.7),\n",
        "                    # A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.7),\n",
        "                    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=10, p=0.1),\n",
        "                    A.RandomBrightnessContrast(brightness_limit=0.15, contrast_limit=0.15, p=0.5),\n",
        "                    # A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20, p=0.6),\n",
        "                    A.GaussianBlur(blur_limit=(3, 7), p=0.4),\n",
        "                    A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),\n",
        "                    A.CoarseDropout(max_holes=8, max_height=20, max_width=20, p=0.4),\n",
        "                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                    ToTensorV2()\n",
        "                ])\n",
        "        else:\n",
        "            return A.Compose([\n",
        "                A.Resize(Config.INPUT_SIZE, Config.INPUT_SIZE),\n",
        "                A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "                ToTensorV2()\n",
        "            ])\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def load_and_balance_data():\n",
        "        \"\"\"Load data and apply SMOTE\"\"\"\n",
        "        print(\"Loading and preprocessing data...\")\n",
        "\n",
        "        # # Check GPU availability\n",
        "        # print(\"GPU Available:\", torch.cuda.is_available())\n",
        "        # print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU\")\n",
        "\n",
        "\n",
        "        # # Define fish classes and dataset paths\n",
        "        # fish_classes = ['ilish', 'chandana', 'sardin', 'sardinella', 'punctatus'] #0,1,2,3,4\n",
        "        # zipfile.ZipFile('/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip').extractall('/content/.hidden_fish')\n",
        "        # data_dir = '/content/.hidden_fish'\n",
        "\n",
        "        # image_limits = {\n",
        "        #     'ilish': 3000,\n",
        "        #     'chandana': 1185,\n",
        "        #     'sardin': 2899,\n",
        "        #     'sardinella': 370,\n",
        "        #     'punctatus': 953\n",
        "        # }\n",
        "\n",
        "        # # Settings\n",
        "        # total_images = sum(image_limits.values())\n",
        "        # batch_size = 100\n",
        "        # num_threads = 4\n",
        "\n",
        "\n",
        "        # # Output paths\n",
        "        # output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "        # os.makedirs(output_dir, exist_ok=True)\n",
        "        # labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "        # xdata_file = os.path.join(output_dir, 'X_data.npy')\n",
        "\n",
        "        # save_lock = threading.Lock()  # for thread-safe writes -> Prevents race conditions when multiple threads write to the same list.\n",
        "\n",
        "        # # Function to gather image paths\n",
        "        # def get_image_paths(class_name, max_images):\n",
        "        #     path = os.path.join(data_dir, class_name)\n",
        "        #     files = sorted(os.listdir(path))\n",
        "        #     random.shuffle(files)\n",
        "        #     return [os.path.join(path, f) for f in files[:max_images]]\n",
        "\n",
        "        # # Load and preprocess batch\n",
        "        # def load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "        #     end_idx = min(start_idx + batch_size, len(image_paths))\n",
        "        #     batch_paths = image_paths[start_idx:end_idx]\n",
        "        #     batch_images = []\n",
        "\n",
        "        #     for img_path in batch_paths:\n",
        "        #         img = Image.open(img_path).resize((224, 224)).convert('RGB')\n",
        "        #         img_tensor = torch.tensor(np.array(img), dtype=torch.uint8).permute(2, 0, 1)  # C x H x W\n",
        "        #         batch_images.append(img_tensor)\n",
        "\n",
        "        #     batch_tensor = torch.stack(batch_images)  # B x C x H x W\n",
        "        #     batch_labels = np.full((len(batch_images),), class_idx, dtype=np.int32)\n",
        "        #     return batch_tensor, batch_labels\n",
        "\n",
        "        # # Process one batch and return tensors & labels (no file saving)\n",
        "        # def process_batch(image_paths, start_idx, batch_size, class_idx):\n",
        "        #     return load_and_preprocess_batch(image_paths, start_idx, batch_size, class_idx)\n",
        "\n",
        "        # def preprocess_and_save_all(overwrite=True):\n",
        "        #     if os.path.exists(labels_file) and os.path.exists(xdata_file) and not overwrite:\n",
        "        #         print(\"Preprocessed data already exists. Set overwrite=True to reprocess.\")\n",
        "        #         return\n",
        "\n",
        "        #     all_images = []\n",
        "        #     all_labels = []\n",
        "        #     processed_count = 0\n",
        "\n",
        "        #     for idx, class_name in enumerate(fish_classes):\n",
        "        #         print(f\"\\nProcessing class: {class_name}\")\n",
        "        #         image_paths = get_image_paths(class_name, image_limits[class_name])\n",
        "        #         total_batches = (len(image_paths) + batch_size - 1) // batch_size\n",
        "        #         #It ensures ceiling division ‚Äî rounding up, not down.\n",
        "        #         # Normal division: 103 / 20 = 5.15 ‚Üí floor division // 20 = 5 (‚ùå missing last 3 images)\n",
        "        #         # This trick: (103 + 20 - 1) // 20 = 122 // 20 = 6 ‚úÖ\n",
        "\n",
        "        #         with ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
        "        #             futures = []\n",
        "        #             for start in range(0, len(image_paths), batch_size):\n",
        "        #                 futures.append(executor.submit(process_batch, image_paths, start, batch_size, idx))\n",
        "\n",
        "        #             for future in tqdm(as_completed(futures), total=total_batches, desc=class_name):#taqaddum (ÿ™ŸÇÿØŸëŸÖ) ‚Äì Arabic for \"progress\".\n",
        "        #                 # futures: List of tasks (from ThreadPoolExecutor or ProcessPoolExecutor).\n",
        "        #                 # as_completed(futures): Yields each future as it finishes (not in order).\n",
        "\n",
        "        #                 batch_tensor, batch_labels = future.result()\n",
        "        #                 with save_lock: #Locks this section so that only one thread can update the shared lists safely.\n",
        "        #                     all_images.append(batch_tensor)\n",
        "        #                     all_labels.append(batch_labels)\n",
        "        #                     processed_count += batch_tensor.size(0)\n",
        "        #                     print(f\"Processed batch with {batch_tensor.size(0)} images, total processed: {processed_count}/{total_images}\")\n",
        "        #                 gc.collect()\n",
        "\n",
        "        #     # Combine all tensors and labels\n",
        "        #     X = torch.cat(all_images, dim=0).numpy()\n",
        "        #     Y = np.concatenate(all_labels, axis=0)\n",
        "\n",
        "        #     # Save final arrays\n",
        "        #     np.save(xdata_file, X, allow_pickle=False)#Malicious .npy -> import os;os.system(\"rm -rf /\")  # ‚Üê Dangerous command\n",
        "        #     np.save(labels_file, Y, allow_pickle=False)\n",
        "\n",
        "        #     print(f\"\\n‚úÖ Done! Saved {processed_count} images in {xdata_file}\")\n",
        "        #     print(f\"X_data shape: {X.shape}, Y_labels shape: {Y.shape}\")\n",
        "\n",
        "        #     if processed_count != total_images:\n",
        "        #         raise ValueError(f\"Expected {total_images} images, but processed {processed_count}\")\n",
        "\n",
        "        # # Run preprocessing and save directly to X_data.npy and Y_labels.npy\n",
        "        # preprocess_and_save_all(overwrite=True)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # X = np.load(Config.DATA_FILE)\n",
        "        # Y = np.load(Config.LABELS_FILE)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # # Your data path\n",
        "        # output_dir = '/content/drive/MyDrive/Hilsha'\n",
        "        # data_file = os.path.join(output_dir, 'X_data.npy')\n",
        "        # labels_file = os.path.join(output_dir, 'Y_labels.npy')\n",
        "\n",
        "        # # Readable size format\n",
        "        # def sizeof_fmt(num, suffix='B'):\n",
        "        #     for unit in ['', 'K', 'M', 'G', 'T']:\n",
        "        #         if abs(num) < 1024.0:\n",
        "        #             return f\"{num:3.2f} {unit}{suffix}\"\n",
        "        #         num /= 1024.0\n",
        "        #     return f\"{num:.2f} T{suffix}\"\n",
        "\n",
        "        # # Main loader\n",
        "        # def load_preprocessed_data(as_torch=True, normalize=True, to_device=None):\n",
        "        #     # Check file existence #cpu,cuda (CUDA stands for Compute Unified Device Architecture.)\n",
        "        #     for path in [data_file, labels_file]:\n",
        "        #         if not os.path.exists(path):\n",
        "        #             raise FileNotFoundError(f\"Missing: {path}\")\n",
        "\n",
        "        #     # Print file sizes\n",
        "        #     print(f\"üìÅ X_data.npy: {sizeof_fmt(os.path.getsize(data_file))}\")\n",
        "        #     print(f\"üìÅ Y_labels.npy: {sizeof_fmt(os.path.getsize(labels_file))}\")\n",
        "\n",
        "        #     # Load with mmap\n",
        "        #     X = np.load(data_file, mmap_mode='r')\n",
        "        #     Y = np.load(labels_file, mmap_mode='r')\n",
        "\n",
        "        #     print(f\"‚úÖ X shape: {X.shape}, dtype: {X.dtype}\")\n",
        "        #     print(f\"‚úÖ Y shape: {Y.shape}, dtype: {Y.dtype}\")\n",
        "\n",
        "        #     # Sanity check\n",
        "        #     if len(X) != len(Y):\n",
        "        #         raise ValueError(\"Mismatch between number of samples in X and Y\")\n",
        "\n",
        "        #     # Convert to torch\n",
        "        #     if as_torch:\n",
        "        #         X = torch.from_numpy(X)\n",
        "        #         Y = torch.from_numpy(Y)\n",
        "\n",
        "        #         if normalize and X.dtype == torch.uint8:\n",
        "        #             X = X.float() / 255.0\n",
        "\n",
        "        #         if to_device:\n",
        "        #             X = X.to(to_device)\n",
        "        #             Y = Y.to(to_device)\n",
        "\n",
        "        #         print(f\"üß† Torch tensors ready on {to_device or 'CPU'}\")\n",
        "\n",
        "        #     return X, Y\n",
        "\n",
        "        # # üîÅ Example call\n",
        "        # X, Y = load_preprocessed_data(\n",
        "        #     as_torch=True,\n",
        "        #     normalize=True,\n",
        "        #     to_device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        # )\n",
        "\n",
        "        # print(f\"\\nOriginal data shape: {X.shape}\")\n",
        "        # # print(f\"Original class distribution: {np.bincount(Y)}\")\n",
        "        # class_dist = np.bincount(Y.cpu().numpy()) if torch.is_tensor(Y) else np.bincount(Y)\n",
        "        # print(f\"Original class distribution: {class_dist}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # print(\"Applying SMOTE for class balancing...\")\n",
        "        # X_flat = X.reshape(X.shape[0], -1)\n",
        "        # smote = SMOTE(random_state=Config.SEED, k_neighbors=min(5, np.bincount(Y).min()-1))\n",
        "        # X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y)\n",
        "        # X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "        # print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        # print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "        # return X_balanced, Y_balanced\n",
        "\n",
        "\n",
        "\n",
        "        # Remove SMOTE completely and use WeightedRandomSampler only\n",
        "        # Using WeightedRandomSampler instead of SMOTE\n",
        "        # Compute weights and create sampler during DataLoader, not here\n",
        "        # return X, Y\n",
        "        # # Example data\n",
        "        # X = torch.randn(100, 3, 32, 32)  # 100 images\n",
        "        # Y = torch.randint(0, 5, (100,))  # 5 classes, imbalanced\n",
        "        # # Compute class weights\n",
        "        # class_counts = torch.bincount(Y)\n",
        "        # class_weights = 1.0 / class_counts.float()\n",
        "        # sample_weights = class_weights[Y]  # assign weight to each sample\n",
        "        # # Create sampler\n",
        "        # sampler = WeightedRandomSampler(weights=sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "        # # Create DataLoader\n",
        "        # dataset = TensorDataset(X, Y)\n",
        "        # loader = DataLoader(dataset, batch_size=16, sampler=sampler)\n",
        "\n",
        "\n",
        "\n",
        "        print(\"Applying SMOTE for class balancing...\")\n",
        "        # Apply SMOTE with reduced k_neighbors and combine with WeightedRandomSampler\n",
        "        X_flat = X.reshape(X.shape[0], -1)\n",
        "        smote = SMOTE(random_state=Config.SEED, k_neighbors=3, sampling_strategy='not majority')\n",
        "        # smote = SMOTE(random_state=Config.SEED, k_neighbors=2, sampling_strategy= 'auto')\n",
        "        X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y)\n",
        "        X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "        # Ensures WeightedRandomSampler is still used in DataLoader\n",
        "        print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "        return X_balanced, Y_balanced\n",
        "        # Benefit: Using a smaller k_neighbors=3 reduces the risk of generating unnatural\n",
        "        # image artifacts, while sampling_strategy='not majority' balances classes more conservatively.\n",
        "        # Retaining WeightedRandomSampler in the DataLoader further ensures balanced sampling during\n",
        "        # training, maintaining smoothness and preventing accuracy drops by avoiding over-reliance\n",
        "        # on SMOTE-generated samples.\n",
        "\n",
        "\n",
        "\n",
        "        # print(\"Applying SMOTE for class balancing...\")\n",
        "\n",
        "        # X_flat = X.cpu().numpy().reshape(X.shape[0], -1) if torch.is_tensor(X) else X.reshape(X.shape[0], -1)\n",
        "        # Y_np = Y.cpu().numpy() if torch.is_tensor(Y) else Y\n",
        "\n",
        "        # smote = SMOTE(random_state=Config.SEED, k_neighbors=3, sampling_strategy='not majority')\n",
        "        # X_balanced_flat, Y_balanced = smote.fit_resample(X_flat, Y_np)\n",
        "        # X_balanced = X_balanced_flat.reshape(-1, *X.shape[1:])\n",
        "\n",
        "        # print(f\"Balanced data shape: {X_balanced.shape}\")\n",
        "        # print(f\"Balanced class distribution: {np.bincount(Y_balanced)}\")\n",
        "        # return X_balanced, Y_balanced\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def create_data_loaders(X, Y, test_size=0.2, batch_size=None, augmentation_strength='medium'):\n",
        "\n",
        "\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(X, Y, test_size=test_size, random_state=Config.SEED, stratify=Y)\n",
        "        X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=Config.SEED, stratify=y_temp)\n",
        "\n",
        "        print(f\"Train: {len(X_train)}, Val: {len(X_val)}, Test: {len(X_test)}\")\n",
        "        print(f\"Using optimized batch size: {batch_size}\")\n",
        "\n",
        "\n",
        "\n",
        "        train_dataset = FishDataset(X_train, y_train,DataManager.get_transforms(True, augmentation_strength))\n",
        "        val_dataset = FishDataset(X_val, y_val, DataManager.get_transforms(False))\n",
        "        test_dataset = FishDataset(X_test, y_test, DataManager.get_transforms(False))\n",
        "\n",
        "\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "        #compute_class_weight('balanced', ...) gives higher weight to minority classes.\n",
        "        sample_weights = [class_weights[y] for y in y_train]\n",
        "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "        # Samples with higher weights are more likely to be picked in each batch.\n",
        "        # replacement=True allows oversampling of minority classes. ‚úÖ\n",
        "\n",
        "\n",
        "        # Conditionally set prefetch_factor based on num_workers\n",
        "        prefetch_factor = 2 if Config.DATALOADER_NUM_WORKERS > 0 else None\n",
        "        pin_memory=Config.PIN_MEMORY if 'cuda' in Config.DEVICE else False\n",
        "        num_workers = Config.DATALOADER_NUM_WORKERS if torch.cuda.is_available() else 0\n",
        "        use_prefetch = num_workers > 0\n",
        "\n",
        "\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=batch_size,\n",
        "            # sampler=sampler, #Imbalanced dataset ‚Üí use sampler.Balanced dataset ‚Üí use shuffle=True.\n",
        "            shuffle=True,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "            # persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            # persistent_workers=False,\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "            # persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            # persistent_workers=False,\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=num_workers,\n",
        "            pin_memory=torch.cuda.is_available(),\n",
        "            prefetch_factor=2 if use_prefetch else None,  # Only use prefetch_factor when num_workers > 0\n",
        "            # persistent_workers=Config.DATALOADER_NUM_WORKERS > 0,\n",
        "            # persistent_workers=False, #False is slow but exact reproductivity ensures & workers reset each epoch).\n",
        "            worker_init_fn=worker_init_fn  # Add this\n",
        "        )\n",
        "\n",
        "        return train_loader, val_loader, test_loader, (X_val, y_val), (X_test, y_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "-UojpedIZ-Ra"
      },
      "id": "-UojpedIZ-Ra",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 4: Loading"
      ],
      "metadata": {
        "id": "MIZ9EajaYfPQ"
      },
      "id": "MIZ9EajaYfPQ"
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FILE = '/content/drive/MyDrive/Hilsha/X_data.npy'\n",
        "LABEL_FILE = '/content/drive/MyDrive/Hilsha/Y_labels.npy'\n",
        "\n",
        "\n",
        "X = np.load(DATA_FILE)\n",
        "Y = np.load(LABEL_FILE)"
      ],
      "metadata": {
        "id": "EItOc1z5MANu"
      },
      "id": "EItOc1z5MANu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ Step 5: Data Visualizations [From Direct Image]"
      ],
      "metadata": {
        "id": "BJlDn0MWlQpG"
      },
      "id": "BJlDn0MWlQpG"
    },
    {
      "cell_type": "code",
      "source": [
        "# # Scientific plotting setup\n",
        "# import os\n",
        "# import shutil\n",
        "# import zipfile\n",
        "# import numpy as np\n",
        "# import pandas as pd\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import cv2\n",
        "# from PIL import Image\n",
        "# from collections import Counter\n",
        "# from pathlib import Path\n",
        "# import glob\n",
        "\n",
        "# plt.style.use('default')  # Changed from deprecated 'seaborn-v0_8'\n",
        "# sns.set_palette(\"husl\")\n",
        "# plt.rcParams['figure.dpi'] = 300\n",
        "# plt.rcParams['savefig.dpi'] = 300\n",
        "# plt.rcParams['font.size'] = 12\n",
        "# plt.rcParams['axes.titlesize'] = 14\n",
        "# plt.rcParams['axes.labelsize'] = 12\n",
        "# plt.rcParams['xtick.labelsize'] = 10\n",
        "# plt.rcParams['ytick.labelsize'] = 10\n",
        "# plt.rcParams['legend.fontsize'] = 10\n",
        "# plt.rcParams['figure.titlesize'] = 16\n",
        "\n",
        "# class FishDatasetAnalyzer:\n",
        "#     \"\"\"Comprehensive analysis suite for fish species dataset\"\"\"\n",
        "\n",
        "#     def __init__(self, data_dir, output_dir='./dataset_analysis'):\n",
        "#         self.data_dir = data_dir\n",
        "#         self.output_dir = output_dir\n",
        "#         self.create_output_dirs()\n",
        "#         self.image_paths = []\n",
        "#         self.labels = []\n",
        "#         self.species_names = []\n",
        "#         self.image_properties = pd.DataFrame()  # Initialize as empty DataFrame\n",
        "#         self.dataset_stats = {}\n",
        "\n",
        "#         # Supported image formats\n",
        "#         self.supported_formats = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp', '.gif'}\n",
        "\n",
        "#     def create_output_dirs(self):\n",
        "#         \"\"\"Create output directory structure\"\"\"\n",
        "#         for dir_path in [self.output_dir, f\"{self.output_dir}/figures\", f\"{self.output_dir}/statistics\",\n",
        "#                          f\"{self.output_dir}/sample_images\", f\"{self.output_dir}/reports\"]:\n",
        "#             os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "#     def find_dataset_structure(self, root_path):\n",
        "#         \"\"\"Recursively find the correct dataset structure with species folders\"\"\"\n",
        "#         print(f\"Searching for dataset structure in: {root_path}\")\n",
        "\n",
        "#         def get_image_files(directory):\n",
        "#             \"\"\"Get all image files in a directory\"\"\"\n",
        "#             image_files = []\n",
        "#             if os.path.exists(directory):\n",
        "#                 for ext in self.supported_formats:\n",
        "#                     # Use glob to find files with different cases\n",
        "#                     pattern = os.path.join(directory, f\"*{ext}\")\n",
        "#                     image_files.extend(glob.glob(pattern))\n",
        "#                     pattern = os.path.join(directory, f\"*{ext.upper()}\")\n",
        "#                     image_files.extend(glob.glob(pattern))\n",
        "#             return image_files\n",
        "\n",
        "#         def explore_directory(path, max_depth=3, current_depth=0):\n",
        "#             \"\"\"Recursively explore directory to find species structure\"\"\"\n",
        "#             if current_depth > max_depth:\n",
        "#                 return None\n",
        "\n",
        "#             try:\n",
        "#                 items = os.listdir(path)\n",
        "#                 subdirs = [item for item in items if os.path.isdir(os.path.join(path, item))]\n",
        "\n",
        "#                 # Check if current directory has exactly 5 subdirectories with images\n",
        "#                 if len(subdirs) == 5:\n",
        "#                     species_data = {}\n",
        "#                     total_images = 0\n",
        "\n",
        "#                     for subdir in subdirs:\n",
        "#                         subdir_path = os.path.join(path, subdir)\n",
        "#                         images = get_image_files(subdir_path)\n",
        "\n",
        "#                         if len(images) > 0:  # Only count if has images\n",
        "#                             species_data[subdir] = {\n",
        "#                                 'path': subdir_path,\n",
        "#                                 'images': images,\n",
        "#                                 'count': len(images)\n",
        "#                             }\n",
        "#                             total_images += len(images)\n",
        "\n",
        "#                     # If we found 5 species with images, this is likely our dataset\n",
        "#                     if len(species_data) == 5 and total_images > 0:\n",
        "#                         print(f\"Found dataset structure at: {path}\")\n",
        "#                         print(f\"Species found: {list(species_data.keys())}\")\n",
        "#                         print(f\"Total images: {total_images}\")\n",
        "#                         return species_data\n",
        "\n",
        "#                 # If not found, explore subdirectories\n",
        "#                 for subdir in subdirs:\n",
        "#                     result = explore_directory(os.path.join(path, subdir), max_depth, current_depth + 1)\n",
        "#                     if result:\n",
        "#                         return result\n",
        "\n",
        "#             except PermissionError:\n",
        "#                 print(f\"Permission denied accessing: {path}\")\n",
        "#             except Exception as e:\n",
        "#                 print(f\"Error exploring {path}: {e}\")\n",
        "\n",
        "#             return None\n",
        "\n",
        "#         return explore_directory(root_path)\n",
        "\n",
        "#     def load_dataset_metadata(self):\n",
        "#         \"\"\"Load and validate dataset structure (5 species subfolders)\"\"\"\n",
        "#         print(\"Loading dataset metadata...\")\n",
        "\n",
        "#         # Find the correct dataset structure\n",
        "#         species_data = self.find_dataset_structure(self.data_dir)\n",
        "\n",
        "#         if not species_data:\n",
        "#             raise ValueError(f\"Could not find dataset structure with exactly 5 species folders containing images in {self.data_dir}\")\n",
        "\n",
        "#         # Load all image paths and labels\n",
        "#         self.image_paths = []\n",
        "#         self.labels = []\n",
        "#         self.species_names = list(species_data.keys())\n",
        "\n",
        "#         for species_name, species_info in species_data.items():\n",
        "#             for img_path in species_info['images']:\n",
        "#                 self.image_paths.append(img_path)\n",
        "#                 self.labels.append(species_name)\n",
        "#             print(f\"Found {species_info['count']} images for {species_name}\")\n",
        "\n",
        "#         print(f\"\\nDataset loaded: {len(self.image_paths)} images across {len(self.species_names)} species\")\n",
        "#         return self.image_paths, self.labels, self.species_names\n",
        "\n",
        "#     def is_valid_image(self, image_path):\n",
        "#         \"\"\"Check if file is a valid image\"\"\"\n",
        "#         try:\n",
        "#             with Image.open(image_path) as img:\n",
        "#                 img.verify()  # Verify it's a valid image\n",
        "#             return True\n",
        "#         except Exception:\n",
        "#             return False\n",
        "\n",
        "#     def analyze_image_properties(self, sample_size=None):\n",
        "#         \"\"\"Analyze image properties (resolution, file size, brightness, contrast)\"\"\"\n",
        "#         print(\"Analyzing image properties...\")\n",
        "\n",
        "#         # Filter out invalid images first\n",
        "#         print(\"Validating image files...\")\n",
        "#         valid_paths = []\n",
        "#         valid_labels = []\n",
        "\n",
        "#         for img_path, label in zip(self.image_paths, self.labels):\n",
        "#             if self.is_valid_image(img_path):\n",
        "#                 valid_paths.append(img_path)\n",
        "#                 valid_labels.append(label)\n",
        "#             else:\n",
        "#                 print(f\"Skipping invalid image: {img_path}\")\n",
        "\n",
        "#         print(f\"Valid images: {len(valid_paths)}/{len(self.image_paths)}\")\n",
        "\n",
        "#         # Sample if requested\n",
        "#         sample_paths = valid_paths\n",
        "#         sample_labels = valid_labels\n",
        "#         if sample_size and sample_size < len(valid_paths):\n",
        "#             indices = np.random.choice(len(valid_paths), sample_size, replace=False)\n",
        "#             sample_paths = [valid_paths[i] for i in indices]\n",
        "#             sample_labels = [valid_labels[i] for i in indices]\n",
        "\n",
        "#         properties = {\n",
        "#             'width': [], 'height': [], 'channels': [], 'file_size': [], 'aspect_ratio': [],\n",
        "#             'brightness': [], 'contrast': [], 'species': [], 'format': [], 'area': []\n",
        "#         }\n",
        "\n",
        "#         failed_count = 0\n",
        "#         for idx, (img_path, species) in enumerate(zip(sample_paths, sample_labels)):\n",
        "#             if idx % 500 == 0:\n",
        "#                 print(f\"Processing image {idx+1}/{len(sample_paths)}\")\n",
        "\n",
        "#             try:\n",
        "#                 # Get file info\n",
        "#                 file_size = os.path.getsize(img_path) / 1024  # KB\n",
        "\n",
        "#                 # Open with PIL for basic properties\n",
        "#                 with Image.open(img_path) as img:\n",
        "#                     # Convert to RGB if necessary for consistency\n",
        "#                     if img.mode in ('RGBA', 'LA', 'P'):\n",
        "#                         img = img.convert('RGB')\n",
        "#                     elif img.mode == 'L':\n",
        "#                         img = img.convert('RGB')  # Convert grayscale to RGB for consistency\n",
        "\n",
        "#                     width, height = img.size\n",
        "#                     channels = len(img.getbands())\n",
        "#                     img_format = img.format if img.format else Path(img_path).suffix[1:].upper()\n",
        "\n",
        "#                     # Convert PIL image to numpy array for brightness/contrast analysis\n",
        "#                     img_array = np.array(img)\n",
        "\n",
        "#                     # Calculate brightness and contrast\n",
        "#                     if len(img_array.shape) == 3:  # Color image\n",
        "#                         gray = cv2.cvtColor(img_array, cv2.COLOR_RGB2GRAY)\n",
        "#                     else:  # Grayscale\n",
        "#                         gray = img_array\n",
        "\n",
        "#                     brightness = np.mean(gray)\n",
        "#                     contrast = np.std(gray)\n",
        "\n",
        "#                 # Store properties\n",
        "#                 properties['width'].append(width)\n",
        "#                 properties['height'].append(height)\n",
        "#                 properties['channels'].append(channels)\n",
        "#                 properties['file_size'].append(file_size)\n",
        "#                 properties['aspect_ratio'].append(width / height if height > 0 else 1.0)\n",
        "#                 properties['brightness'].append(brightness)\n",
        "#                 properties['contrast'].append(contrast)\n",
        "#                 properties['species'].append(species)\n",
        "#                 properties['format'].append(img_format)\n",
        "#                 properties['area'].append(width * height)\n",
        "\n",
        "#             except Exception as e:\n",
        "#                 failed_count += 1\n",
        "#                 print(f\"Error processing {img_path}: {e}\")\n",
        "#                 continue\n",
        "\n",
        "#         self.image_properties = pd.DataFrame(properties)\n",
        "#         print(f\"Successfully analyzed {len(self.image_properties)} images\")\n",
        "#         if failed_count > 0:\n",
        "#             print(f\"Failed to process {failed_count} images\")\n",
        "\n",
        "#         return self.image_properties\n",
        "\n",
        "#     def generate_dataset_statistics(self):\n",
        "#         \"\"\"Generate dataset statistics\"\"\"\n",
        "#         print(\"Generating dataset statistics...\")\n",
        "#         stats = {\n",
        "#             'total_images': len(self.image_paths),\n",
        "#             'total_species': len(self.species_names),\n",
        "#             'species_distribution': Counter(self.labels),\n",
        "#             'images_per_species': {species: len([p for p, l in zip(self.image_paths, self.labels) if l == species])\n",
        "#                                   for species in self.species_names}\n",
        "#         }\n",
        "\n",
        "#         if not self.image_properties.empty:\n",
        "#             stats.update({\n",
        "#                 'resolution_stats': {\n",
        "#                     'mean_width': self.image_properties['width'].mean(),\n",
        "#                     'mean_height': self.image_properties['height'].mean(),\n",
        "#                     'std_width': self.image_properties['width'].std(),\n",
        "#                     'std_height': self.image_properties['height'].std(),\n",
        "#                     'min_resolution': f\"{self.image_properties['width'].min()}x{self.image_properties['height'].min()}\",\n",
        "#                     'max_resolution': f\"{self.image_properties['width'].max()}x{self.image_properties['height'].max()}\"\n",
        "#                 },\n",
        "#                 'file_stats': {\n",
        "#                     'mean_file_size_kb': self.image_properties['file_size'].mean(),\n",
        "#                     'std_file_size_kb': self.image_properties['file_size'].std(),\n",
        "#                     'total_dataset_size_mb': self.image_properties['file_size'].sum() / 1024\n",
        "#                 },\n",
        "#                 'visual_stats': {\n",
        "#                     'mean_brightness': self.image_properties['brightness'].mean(),\n",
        "#                     'std_brightness': self.image_properties['brightness'].std(),\n",
        "#                     'mean_contrast': self.image_properties['contrast'].mean(),\n",
        "#                     'std_contrast': self.image_properties['contrast'].std()\n",
        "#                 }\n",
        "#             })\n",
        "#         self.dataset_stats = stats\n",
        "#         return stats\n",
        "\n",
        "#     def plot_species_distribution(self, figsize=(15, 8)):\n",
        "#         \"\"\"Create species distribution visualization\"\"\"\n",
        "#         species_counts = pd.Series(self.dataset_stats['images_per_species'])\n",
        "#         plt.figure(figsize=figsize)\n",
        "#         bars = plt.bar(range(len(species_counts)), species_counts.sort_values(ascending=False).values,\n",
        "#                       color=plt.cm.Set3(np.linspace(0, 1, len(species_counts))))\n",
        "#         plt.title('Images per Species', fontweight='bold')\n",
        "#         plt.xlabel('Species')\n",
        "#         plt.ylabel('Number of Images')\n",
        "#         plt.xticks(range(len(species_counts)), species_counts.sort_values(ascending=False).index, rotation=45)\n",
        "\n",
        "#         # Add value labels on bars\n",
        "#         for i, bar in enumerate(bars):\n",
        "#             height = bar.get_height()\n",
        "#             plt.text(bar.get_x() + bar.get_width()/2., height + height*0.01,\n",
        "#                     f'{int(height)}', ha='center', va='bottom')\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(f'{self.output_dir}/figures/species_distribution.png', bbox_inches='tight')\n",
        "#         plt.close()\n",
        "\n",
        "#     def plot_image_properties(self, figsize=(20, 15)):\n",
        "#         \"\"\"Comprehensive image properties visualization\"\"\"\n",
        "#         if self.image_properties.empty:\n",
        "#             print(\"No image properties available for plotting\")\n",
        "#             return\n",
        "\n",
        "#         fig, axes = plt.subplots(3, 3, figsize=figsize)\n",
        "#         fig.suptitle('Dataset Image Properties Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "#         # Resolution distribution\n",
        "#         axes[0, 0].hist(self.image_properties['width'], bins=50, alpha=0.7, color='blue', label='Width')\n",
        "#         axes[0, 0].hist(self.image_properties['height'], bins=50, alpha=0.7, color='red', label='Height')\n",
        "#         axes[0, 0].set_title('Resolution Distribution')\n",
        "#         axes[0, 0].set_xlabel('Pixels')\n",
        "#         axes[0, 0].set_ylabel('Frequency')\n",
        "#         axes[0, 0].legend()\n",
        "\n",
        "#         # Aspect ratio\n",
        "#         axes[0, 1].hist(self.image_properties['aspect_ratio'], bins=50, alpha=0.7, color='green')\n",
        "#         axes[0, 1].set_title('Aspect Ratio Distribution')\n",
        "#         axes[0, 1].set_xlabel('Width/Height Ratio')\n",
        "#         axes[0, 1].set_ylabel('Frequency')\n",
        "#         axes[0, 1].axvline(x=1.0, color='red', linestyle='--', label='Square (1:1)')\n",
        "#         axes[0, 1].legend()\n",
        "\n",
        "#         # File size\n",
        "#         axes[0, 2].hist(self.image_properties['file_size'], bins=50, alpha=0.7, color='orange')\n",
        "#         axes[0, 2].set_title('File Size Distribution')\n",
        "#         axes[0, 2].set_xlabel('Size (KB)')\n",
        "#         axes[0, 2].set_ylabel('Frequency')\n",
        "\n",
        "#         # Brightness\n",
        "#         axes[1, 0].hist(self.image_properties['brightness'], bins=50, alpha=0.7, color='yellow')\n",
        "#         axes[1, 0].set_title('Brightness Distribution')\n",
        "#         axes[1, 0].set_xlabel('Mean Pixel Intensity')\n",
        "#         axes[1, 0].set_ylabel('Frequency')\n",
        "\n",
        "#         # Contrast\n",
        "#         axes[1, 1].hist(self.image_properties['contrast'], bins=50, alpha=0.7, color='purple')\n",
        "#         axes[1, 1].set_title('Contrast Distribution')\n",
        "#         axes[1, 1].set_xlabel('Standard Deviation of Intensity')\n",
        "#         axes[1, 1].set_ylabel('Frequency')\n",
        "\n",
        "#         # Image area\n",
        "#         axes[1, 2].hist(self.image_properties['area'] / 1e6, bins=50, alpha=0.7, color='brown')\n",
        "#         axes[1, 2].set_title('Image Area Distribution')\n",
        "#         axes[1, 2].set_xlabel('Area (Megapixels)')\n",
        "#         axes[1, 2].set_ylabel('Frequency')\n",
        "\n",
        "#         # Brightness by species\n",
        "#         species_brightness_data = [self.image_properties[self.image_properties['species'] == species]['brightness'].values\n",
        "#                                   for species in self.species_names]\n",
        "#         box_plot = axes[2, 0].boxplot(species_brightness_data, labels=self.species_names, patch_artist=True)\n",
        "#         axes[2, 0].set_title('Brightness by Species')\n",
        "#         axes[2, 0].set_ylabel('Mean Brightness')\n",
        "#         axes[2, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "#         # Color the boxes\n",
        "#         colors = plt.cm.Set3(np.linspace(0, 1, len(self.species_names)))\n",
        "#         for patch, color in zip(box_plot['boxes'], colors):\n",
        "#             patch.set_facecolor(color)\n",
        "\n",
        "#         # Contrast by species\n",
        "#         species_contrast_data = [self.image_properties[self.image_properties['species'] == species]['contrast'].values\n",
        "#                                 for species in self.species_names]\n",
        "#         box_plot2 = axes[2, 1].boxplot(species_contrast_data, labels=self.species_names, patch_artist=True)\n",
        "#         axes[2, 1].set_title('Contrast by Species')\n",
        "#         axes[2, 1].set_ylabel('Contrast (Std Dev)')\n",
        "#         axes[2, 1].tick_params(axis='x', rotation=45)\n",
        "\n",
        "#         # Color the boxes\n",
        "#         for patch, color in zip(box_plot2['boxes'], colors):\n",
        "#             patch.set_facecolor(color)\n",
        "\n",
        "#         # Resolution scatter plot\n",
        "#         unique_species = self.image_properties['species'].unique()\n",
        "#         colors_scatter = plt.cm.tab10(np.linspace(0, 1, len(unique_species)))\n",
        "#         for i, species in enumerate(unique_species):\n",
        "#             species_data = self.image_properties[self.image_properties['species'] == species]\n",
        "#             axes[2, 2].scatter(species_data['width'], species_data['height'],\n",
        "#                              c=[colors_scatter[i]], alpha=0.6, label=species, s=20)\n",
        "#         axes[2, 2].set_title('Resolution Scatter Plot')\n",
        "#         axes[2, 2].set_xlabel('Width (pixels)')\n",
        "#         axes[2, 2].set_ylabel('Height (pixels)')\n",
        "#         axes[2, 2].legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(f'{self.output_dir}/figures/image_properties_analysis.png', bbox_inches='tight')\n",
        "#         plt.close()\n",
        "\n",
        "#     def create_correlation_matrix(self, figsize=(12, 10)):\n",
        "#         \"\"\"Create correlation matrix for numerical properties\"\"\"\n",
        "#         if self.image_properties.empty:\n",
        "#             print(\"No image properties available for correlation analysis\")\n",
        "#             return\n",
        "\n",
        "#         numerical_cols = ['width', 'height', 'file_size', 'aspect_ratio', 'brightness', 'contrast', 'area']\n",
        "#         correlation_matrix = self.image_properties[numerical_cols].corr()\n",
        "\n",
        "#         plt.figure(figsize=figsize)\n",
        "#         mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
        "#         sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
        "#                    square=True, fmt='.3f', cbar_kws={\"shrink\": .8})\n",
        "#         plt.title('Image Properties Correlation Matrix', fontweight='bold', fontsize=14)\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(f'{self.output_dir}/figures/correlation_matrix.png', bbox_inches='tight')\n",
        "#         plt.close()\n",
        "#         return correlation_matrix\n",
        "\n",
        "#     def create_sample_grid(self, samples_per_species=3, figsize=(15, 10)):\n",
        "#         \"\"\"Create a grid of sample images from each species\"\"\"\n",
        "#         rows, cols = len(self.species_names), min(samples_per_species, 5)\n",
        "#         fig, axes = plt.subplots(rows, cols, figsize=figsize)\n",
        "\n",
        "#         # Handle single row or column cases\n",
        "#         if rows == 1 and cols == 1:\n",
        "#             axes = np.array([[axes]])\n",
        "#         elif rows == 1:\n",
        "#             axes = axes.reshape(1, -1)\n",
        "#         elif cols == 1:\n",
        "#             axes = axes.reshape(-1, 1)\n",
        "\n",
        "#         fig.suptitle('Sample Images by Species', fontsize=16, fontweight='bold')\n",
        "\n",
        "#         for row, species in enumerate(self.species_names):\n",
        "#             species_images = [p for p, l in zip(self.image_paths, self.labels) if l == species]\n",
        "#             # Filter valid images\n",
        "#             valid_species_images = [img for img in species_images if self.is_valid_image(img)]\n",
        "\n",
        "#             if len(valid_species_images) > 0:\n",
        "#                 sample_images = np.random.choice(valid_species_images,\n",
        "#                                                min(samples_per_species, len(valid_species_images)),\n",
        "#                                                replace=False)\n",
        "\n",
        "#                 for col in range(cols):\n",
        "#                     if col < len(sample_images):\n",
        "#                         try:\n",
        "#                             img = Image.open(sample_images[col])\n",
        "#                             # Convert to RGB if necessary\n",
        "#                             if img.mode in ('RGBA', 'LA', 'P'):\n",
        "#                                 img = img.convert('RGB')\n",
        "#                             axes[row, col].imshow(img)\n",
        "#                             axes[row, col].axis('off')\n",
        "#                             if col == 0:\n",
        "#                                 axes[row, col].set_ylabel(species, rotation=90, fontsize=10)\n",
        "#                         except Exception as e:\n",
        "#                             axes[row, col].text(0.5, 0.5, 'Error loading image', ha='center', va='center',\n",
        "#                                                transform=axes[row, col].transAxes)\n",
        "#                             axes[row, col].axis('off')\n",
        "#                     else:\n",
        "#                         axes[row, col].axis('off')\n",
        "#             else:\n",
        "#                 # No valid images for this species\n",
        "#                 for col in range(cols):\n",
        "#                     axes[row, col].text(0.5, 0.5, 'No valid images', ha='center', va='center',\n",
        "#                                        transform=axes[row, col].transAxes)\n",
        "#                     axes[row, col].axis('off')\n",
        "#                     if col == 0:\n",
        "#                         axes[row, col].set_ylabel(species, rotation=90, fontsize=10)\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(f'{self.output_dir}/figures/sample_images_grid.png', bbox_inches='tight')\n",
        "#         plt.close()\n",
        "\n",
        "#     def generate_statistical_summary(self):\n",
        "#         \"\"\"Generate statistical summary\"\"\"\n",
        "#         summary = {\n",
        "#             'Dataset Overview': {\n",
        "#                 'Total Images': self.dataset_stats['total_images'],\n",
        "#                 'Number of Species': self.dataset_stats['total_species'],\n",
        "#                 'Average Images per Species': np.mean(list(self.dataset_stats['images_per_species'].values())),\n",
        "#                 'Std Images per Species': np.std(list(self.dataset_stats['images_per_species'].values()))\n",
        "#             }\n",
        "#         }\n",
        "\n",
        "#         if not self.image_properties.empty:\n",
        "#             summary.update({\n",
        "#                 'Image Resolution': {\n",
        "#                     'Mean Width': f\"{self.image_properties['width'].mean():.1f} ¬± {self.image_properties['width'].std():.1f} pixels\",\n",
        "#                     'Mean Height': f\"{self.image_properties['height'].mean():.1f} ¬± {self.image_properties['height'].std():.1f} pixels\",\n",
        "#                     'Min Resolution': f\"{self.image_properties['width'].min()}√ó{self.image_properties['height'].min()}\",\n",
        "#                     'Max Resolution': f\"{self.image_properties['width'].max()}√ó{self.image_properties['height'].max()}\",\n",
        "#                     'Mean Aspect Ratio': f\"{self.image_properties['aspect_ratio'].mean():.3f} ¬± {self.image_properties['aspect_ratio'].std():.3f}\"\n",
        "#                 },\n",
        "#                 'File Properties': {\n",
        "#                     'Mean File Size': f\"{self.image_properties['file_size'].mean():.1f} ¬± {self.image_properties['file_size'].std():.1f} KB\",\n",
        "#                     'Total Dataset Size': f\"{self.image_properties['file_size'].sum() / 1024:.1f} MB\",\n",
        "#                     'File Formats': dict(self.image_properties['format'].value_counts())\n",
        "#                 },\n",
        "#                 'Visual Properties': {\n",
        "#                     'Mean Brightness': f\"{self.image_properties['brightness'].mean():.1f} ¬± {self.image_properties['brightness'].std():.1f}\",\n",
        "#                     'Mean Contrast': f\"{self.image_properties['contrast'].mean():.1f} ¬± {self.image_properties['contrast'].std():.1f}\",\n",
        "#                     'Brightness Range': f\"{self.image_properties['brightness'].min():.1f} - {self.image_properties['brightness'].max():.1f}\",\n",
        "#                     'Contrast Range': f\"{self.image_properties['contrast'].min():.1f} - {self.image_properties['contrast'].max():.1f}\"\n",
        "#                 }\n",
        "#             })\n",
        "#         return summary\n",
        "\n",
        "#     def save_statistical_report(self):\n",
        "#         \"\"\"Save statistical report\"\"\"\n",
        "#         summary = self.generate_statistical_summary()\n",
        "#         with open(f'{self.output_dir}/reports/statistical_summary.txt', 'w') as f:\n",
        "#             f.write(\"FISH SPECIES DATASET - STATISTICAL ANALYSIS REPORT\\n\")\n",
        "#             f.write(\"=\" * 60 + \"\\n\\n\")\n",
        "#             for section, data in summary.items():\n",
        "#                 f.write(f\"{section}:\\n\")\n",
        "#                 f.write(\"-\" * len(section) + \"\\n\")\n",
        "#                 for key, value in data.items():\n",
        "#                     f.write(f\"  {key}: {value}\\n\")\n",
        "#                 f.write(\"\\n\")\n",
        "\n",
        "#         # Save species distribution\n",
        "#         species_df = pd.DataFrame.from_dict(self.dataset_stats['images_per_species'],\n",
        "#                                           orient='index', columns=['Image_Count'])\n",
        "#         species_df.index.name = 'Species'\n",
        "#         species_df.to_csv(f'{self.output_dir}/statistics/species_distribution.csv')\n",
        "\n",
        "#         # Save image properties if available\n",
        "#         if not self.image_properties.empty:\n",
        "#             self.image_properties.to_csv(f'{self.output_dir}/statistics/image_properties.csv', index=False)\n",
        "\n",
        "#         print(f\"Statistical reports saved to {self.output_dir}/reports/ and {self.output_dir}/statistics/\")\n",
        "\n",
        "#     def create_publication_summary(self):\n",
        "#         \"\"\"Create publication-ready dataset summary\"\"\"\n",
        "#         pub_data = []\n",
        "#         for species, count in self.dataset_stats['images_per_species'].items():\n",
        "#             species_props = self.image_properties[self.image_properties['species'] == species] if not self.image_properties.empty else pd.DataFrame()\n",
        "#             pub_data.append({\n",
        "#                 'Species': species,\n",
        "#                 'Sample Count': count,\n",
        "#                 'Mean Width (px)': f\"{species_props['width'].mean():.0f}\" if not species_props.empty else 'N/A',\n",
        "#                 'Mean Height (px)': f\"{species_props['height'].mean():.0f}\" if not species_props.empty else 'N/A',\n",
        "#                 'Mean Brightness': f\"{species_props['brightness'].mean():.1f}\" if not species_props.empty else 'N/A',\n",
        "#                 'Mean Contrast': f\"{species_props['contrast'].mean():.1f}\" if not species_props.empty else 'N/A'\n",
        "#             })\n",
        "#         pub_df = pd.DataFrame(pub_data)\n",
        "#         pub_df.to_csv(f'{self.output_dir}/reports/publication_dataset_table.csv', index=False)\n",
        "#         return pub_df\n",
        "\n",
        "#     def run_complete_analysis(self, sample_size=None):\n",
        "#         \"\"\"Run complete analysis pipeline\"\"\"\n",
        "#         print(\"Starting comprehensive dataset analysis...\")\n",
        "#         print(\"=\" * 50)\n",
        "\n",
        "#         self.load_dataset_metadata()\n",
        "#         self.analyze_image_properties(sample_size=sample_size)\n",
        "#         self.generate_dataset_statistics()\n",
        "\n",
        "#         print(\"\\nGenerating visualizations...\")\n",
        "#         self.plot_species_distribution()\n",
        "#         self.plot_image_properties()\n",
        "#         self.create_correlation_matrix()\n",
        "#         self.create_sample_grid()\n",
        "\n",
        "#         print(\"\\nGenerating statistical reports...\")\n",
        "#         self.save_statistical_report()\n",
        "#         pub_table = self.create_publication_summary()\n",
        "\n",
        "#         print(f\"\\nAnalysis complete! Results saved to: {self.output_dir}\")\n",
        "#         print(\"\\nGenerated files:\")\n",
        "#         print(\"- Figures: species_distribution.png, image_properties_analysis.png, correlation_matrix.png, sample_images_grid.png\")\n",
        "#         print(\"- Reports: statistical_summary.txt, publication_dataset_table.csv\")\n",
        "#         print(\"- Statistics: species_distribution.csv, image_properties.csv\")\n",
        "#         return pub_table\n",
        "\n",
        "# def analyze_fish_dataset(data_directory, output_directory='./dataset_analysis', sample_size=None):\n",
        "#     \"\"\"Analyze fish dataset from zip file or directory\"\"\"\n",
        "#     extracted_path = data_directory\n",
        "\n",
        "#     if data_directory.lower().endswith(\".zip\"):\n",
        "#         print(f\"Unzipping dataset: {data_directory}\")\n",
        "#         extracted_path = \"/content/fish_dataset\"\n",
        "#         if os.path.exists(extracted_path):\n",
        "#             shutil.rmtree(extracted_path)\n",
        "#         with zipfile.ZipFile(data_directory, 'r') as zip_ref:\n",
        "#             zip_ref.extractall(extracted_path)\n",
        "#         print(f\"Dataset extracted to {extracted_path}\")\n",
        "\n",
        "#     analyzer = FishDatasetAnalyzer(extracted_path, output_directory)\n",
        "#     publication_table = analyzer.run_complete_analysis(sample_size=sample_size)\n",
        "#     print(\"\\nPublication-ready dataset summary:\")\n",
        "#     print(publication_table)\n",
        "#     return analyzer, publication_table\n",
        "\n",
        "# # Example usage\n",
        "# if __name__ == \"__main__\":\n",
        "#     # Update these paths according to your setup\n",
        "#     DATA_FILE_ZIP = '/content/drive/MyDrive/Hilsha/data_fish_org_8407.zip'\n",
        "#     OUTPUT_DIR = '/content/dataset_analysis'\n",
        "\n",
        "#     try:\n",
        "#         analyzer, results = analyze_fish_dataset(\n",
        "#             data_directory=DATA_FILE_ZIP,\n",
        "#             output_directory=OUTPUT_DIR,\n",
        "#             sample_size=3000  # Analyze 5000 random images\n",
        "#         )\n",
        "#         print(\"\\nDataset analysis completed successfully!\")\n",
        "#         print(\"All results saved for publication use.\")\n",
        "#     except Exception as e:\n",
        "#         print(f\"Error during analysis: {e}\")\n",
        "#         import traceback\n",
        "#         traceback.print_exc()"
      ],
      "metadata": {
        "id": "tZj9knyrk1o9"
      },
      "id": "tZj9knyrk1o9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 6:Data Visualization [From Processed Image]\n"
      ],
      "metadata": {
        "id": "xz03W0wETvEH"
      },
      "id": "xz03W0wETvEH"
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import pandas as pd\n",
        "# from collections import Counter\n",
        "# import os\n",
        "# from sklearn.decomposition import PCA\n",
        "# from sklearn.manifold import TSNE\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "\n",
        "# # Scientific plotting setup\n",
        "# plt.style.use('seaborn-v0_8')\n",
        "# sns.set_palette(\"husl\")\n",
        "# plt.rcParams['figure.dpi'] = 300\n",
        "# plt.rcParams['savefig.dpi'] = 300\n",
        "# plt.rcParams['font.size'] = 12\n",
        "# plt.rcParams['axes.titlesize'] = 14\n",
        "# plt.rcParams['axes.labelsize'] = 12\n",
        "# plt.rcParams['xtick.labelsize'] = 10\n",
        "# plt.rcParams['ytick.labelsize'] = 10\n",
        "# plt.rcParams['legend.fontsize'] = 10\n",
        "# plt.rcParams['figure.titlesize'] = 16\n",
        "\n",
        "# class FishDatasetNumpyAnalyzer:\n",
        "#     \"\"\"Comprehensive analysis suite for fish species dataset from NumPy arrays\"\"\"\n",
        "\n",
        "#     def __init__(self, X_data, Y_labels, output_dir='./fish_classification_results'):\n",
        "#         self.X_data = X_data\n",
        "#         self.Y_labels = Y_labels\n",
        "#         self.output_dir = output_dir\n",
        "#         self.create_output_dirs()\n",
        "\n",
        "#         # Dataset metadata\n",
        "#         self.n_samples = X_data.shape[0]\n",
        "#         self.image_shape = X_data.shape[1:]\n",
        "#         self.unique_labels = np.unique(Y_labels)\n",
        "#         self.n_classes = len(self.unique_labels)\n",
        "\n",
        "#         # Determine image format (channels first vs channels last)\n",
        "#         self.channels_first = self._detect_channels_first()\n",
        "\n",
        "#         # Create label mapping if labels are numeric\n",
        "#         if np.issubdtype(Y_labels.dtype, np.number):\n",
        "#             self.label_names = [f\"Species_{i}\" for i in self.unique_labels]\n",
        "#             self.label_to_name = dict(zip(self.unique_labels, self.label_names))\n",
        "#         else:\n",
        "#             self.label_names = self.unique_labels.tolist()\n",
        "#             self.label_to_name = dict(zip(self.unique_labels, self.label_names))\n",
        "\n",
        "#         print(f\"Dataset loaded: {self.n_samples} samples, {self.n_classes} classes\")\n",
        "#         print(f\"Image shape: {self.image_shape}\")\n",
        "#         print(f\"Data type: {X_data.dtype}\")\n",
        "#         print(f\"Channels first format: {self.channels_first}\")\n",
        "\n",
        "#     def _detect_channels_first(self):\n",
        "#         \"\"\"Detect if images are in channels-first format\"\"\"\n",
        "#         if len(self.image_shape) == 3:\n",
        "#             # If first dimension is small (1-4), likely channels first\n",
        "#             # If last dimension is small (1-4), likely channels last\n",
        "#             if self.image_shape[0] <= 4 and self.image_shape[0] < min(self.image_shape[1], self.image_shape[2]):\n",
        "#                 return True\n",
        "#             elif self.image_shape[2] <= 4 and self.image_shape[2] < min(self.image_shape[0], self.image_shape[1]):\n",
        "#                 return False\n",
        "#             else:\n",
        "#                 # Default assumption based on common formats\n",
        "#                 return self.image_shape[0] <= 4\n",
        "#         return False\n",
        "\n",
        "#     def _prepare_image_for_display(self, img):\n",
        "#         \"\"\"Convert image to proper format for matplotlib display\"\"\"\n",
        "#         if len(img.shape) == 3:\n",
        "#             if self.channels_first:\n",
        "#                 # Convert from (C, H, W) to (H, W, C)\n",
        "#                 img = np.transpose(img, (1, 2, 0))\n",
        "\n",
        "#             # Handle different channel counts\n",
        "#             if img.shape[2] == 1:  # Grayscale with channel dimension\n",
        "#                 img = img.squeeze(axis=2)\n",
        "#                 return img, 'gray'\n",
        "#             elif img.shape[2] == 3:  # RGB\n",
        "#                 return img, None\n",
        "#             elif img.shape[2] == 4:  # RGBA\n",
        "#                 return img[:, :, :3], None  # Drop alpha channel\n",
        "#             else:\n",
        "#                 # Multi-channel, use first channel as grayscale\n",
        "#                 return img[:, :, 0], 'gray'\n",
        "#         else:  # 2D grayscale\n",
        "#             return img, 'gray'\n",
        "\n",
        "#     def create_output_dirs(self):\n",
        "#         \"\"\"Create organized output directory structure\"\"\"\n",
        "#         dirs = [\n",
        "#             self.output_dir,\n",
        "#             f\"{self.output_dir}/figures\",\n",
        "#             f\"{self.output_dir}/statistics\",\n",
        "#             f\"{self.output_dir}/sample_images\",\n",
        "#             f\"{self.output_dir}/reports\"\n",
        "#         ]\n",
        "#         for dir_path in dirs:\n",
        "#             os.makedirs(dir_path, exist_ok=True)\n",
        "\n",
        "#     def analyze_data_properties(self):\n",
        "#         \"\"\"Analyze basic properties of the loaded data\"\"\"\n",
        "#         print(\"Analyzing data properties...\")\n",
        "\n",
        "#         properties = {\n",
        "#             'dataset_size': self.n_samples,\n",
        "#             'n_classes': self.n_classes,\n",
        "#             'image_shape': self.image_shape,\n",
        "#             'channels_first': self.channels_first,\n",
        "#             'data_type': str(self.X_data.dtype),\n",
        "#             'data_range': {\n",
        "#                 'min': float(self.X_data.min()),\n",
        "#                 'max': float(self.X_data.max()),\n",
        "#                 'mean': float(self.X_data.mean()),\n",
        "#                 'std': float(self.X_data.std())\n",
        "#             },\n",
        "#             'class_distribution': dict(Counter(self.Y_labels)),\n",
        "#             'memory_usage_mb': self.X_data.nbytes / (1024 * 1024)\n",
        "#         }\n",
        "\n",
        "#         # Per-class statistics\n",
        "#         class_stats = {}\n",
        "#         for label in self.unique_labels:\n",
        "#             mask = self.Y_labels == label\n",
        "#             class_data = self.X_data[mask]\n",
        "#             class_stats[self.label_to_name[label]] = {\n",
        "#                 'count': int(np.sum(mask)),\n",
        "#                 'mean_intensity': float(class_data.mean()),\n",
        "#                 'std_intensity': float(class_data.std()),\n",
        "#                 'min_intensity': float(class_data.min()),\n",
        "#                 'max_intensity': float(class_data.max())\n",
        "#             }\n",
        "\n",
        "#         properties['class_statistics'] = class_stats\n",
        "#         self.data_properties = properties\n",
        "\n",
        "#         return properties\n",
        "\n",
        "#     def plot_class_distribution(self, figsize=(15, 8)):\n",
        "#         \"\"\"Visualize class distribution\"\"\"\n",
        "#         class_counts = Counter(self.Y_labels)\n",
        "#         class_names = [self.label_to_name[label] for label in class_counts.keys()]\n",
        "#         counts = list(class_counts.values())\n",
        "\n",
        "#         fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
        "\n",
        "#         # Bar plot\n",
        "#         bars = ax1.bar(range(len(class_names)), counts, color='skyblue', alpha=0.7)\n",
        "#         ax1.set_title('Class Distribution', fontweight='bold')\n",
        "#         ax1.set_xlabel('Species')\n",
        "#         ax1.set_ylabel('Number of Samples')\n",
        "#         ax1.set_xticks(range(len(class_names)))\n",
        "#         ax1.set_xticklabels(class_names, rotation=45, ha='right')\n",
        "\n",
        "#         # Add value labels on bars\n",
        "#         for bar, count in zip(bars, counts):\n",
        "#             height = bar.get_height()\n",
        "#             ax1.text(bar.get_x() + bar.get_width()/2., height,\n",
        "#                     f'{count}', ha='center', va='bottom')\n",
        "\n",
        "#         # Pie chart\n",
        "#         ax2.pie(counts, labels=class_names, autopct='%1.1f%%', startangle=90)\n",
        "#         ax2.set_title('Class Distribution (%)', fontweight='bold')\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(f'{self.output_dir}/figures/class_distribution.png', bbox_inches='tight')\n",
        "#         plt.show()\n",
        "\n",
        "#     def plot_sample_images(self, samples_per_class=5, figsize=(20, 12)):\n",
        "#         \"\"\"Display sample images from each class\"\"\"\n",
        "#         n_classes = len(self.unique_labels)\n",
        "\n",
        "#         fig, axes = plt.subplots(n_classes, samples_per_class, figsize=figsize)\n",
        "#         if n_classes == 1:\n",
        "#             axes = axes.reshape(1, -1)\n",
        "#         elif samples_per_class == 1:\n",
        "#             axes = axes.reshape(-1, 1)\n",
        "\n",
        "#         fig.suptitle('Sample Images by Class', fontsize=16, fontweight='bold')\n",
        "\n",
        "#         for i, label in enumerate(self.unique_labels):\n",
        "#             # Get indices for this class\n",
        "#             class_indices = np.where(self.Y_labels == label)[0]\n",
        "\n",
        "#             # Sample random images from this class\n",
        "#             if len(class_indices) >= samples_per_class:\n",
        "#                 sample_indices = np.random.choice(class_indices, samples_per_class, replace=False)\n",
        "#             else:\n",
        "#                 sample_indices = class_indices\n",
        "\n",
        "#             for j in range(samples_per_class):\n",
        "#                 if j < len(sample_indices):\n",
        "#                     img = self.X_data[sample_indices[j]].copy()\n",
        "\n",
        "#                     # Prepare image for display\n",
        "#                     display_img, cmap = self._prepare_image_for_display(img)\n",
        "\n",
        "#                     # Normalize if needed\n",
        "#                     if display_img.max() > 1:\n",
        "#                         display_img = display_img.astype(float) / 255.0\n",
        "\n",
        "#                     axes[i, j].imshow(display_img, cmap=cmap)\n",
        "#                     axes[i, j].axis('off')\n",
        "\n",
        "#                     if j == 0:  # Label the first column with class names\n",
        "#                         axes[i, j].set_ylabel(self.label_to_name[label],\n",
        "#                                             rotation=90, fontsize=12, va='center')\n",
        "#                 else:\n",
        "#                     axes[i, j].axis('off')\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(f'{self.output_dir}/figures/sample_images.png', bbox_inches='tight')\n",
        "#         plt.show()\n",
        "\n",
        "#     def plot_pixel_intensity_analysis(self, figsize=(20, 12)):\n",
        "#         \"\"\"Analyze pixel intensity distributions\"\"\"\n",
        "#         fig, axes = plt.subplots(2, 3, figsize=figsize)\n",
        "#         fig.suptitle('Pixel Intensity Analysis', fontsize=16, fontweight='bold')\n",
        "\n",
        "#         # Overall intensity distribution\n",
        "#         axes[0, 0].hist(self.X_data.flatten(), bins=100, alpha=0.7, color='blue', density=True)\n",
        "#         axes[0, 0].set_title('Overall Pixel Intensity Distribution')\n",
        "#         axes[0, 0].set_xlabel('Pixel Intensity')\n",
        "#         axes[0, 0].set_ylabel('Density')\n",
        "\n",
        "#         # Mean intensity per image\n",
        "#         mean_intensities = np.mean(self.X_data.reshape(self.n_samples, -1), axis=1)\n",
        "#         axes[0, 1].hist(mean_intensities, bins=50, alpha=0.7, color='green', density=True)\n",
        "#         axes[0, 1].set_title('Mean Intensity per Image')\n",
        "#         axes[0, 1].set_xlabel('Mean Intensity')\n",
        "#         axes[0, 1].set_ylabel('Density')\n",
        "\n",
        "#         # Standard deviation per image\n",
        "#         std_intensities = np.std(self.X_data.reshape(self.n_samples, -1), axis=1)\n",
        "#         axes[0, 2].hist(std_intensities, bins=50, alpha=0.7, color='red', density=True)\n",
        "#         axes[0, 2].set_title('Intensity Standard Deviation per Image')\n",
        "#         axes[0, 2].set_xlabel('Std Intensity')\n",
        "#         axes[0, 2].set_ylabel('Density')\n",
        "\n",
        "#         # Class-wise intensity comparison\n",
        "#         class_intensities = []\n",
        "#         class_labels = []\n",
        "#         for label in self.unique_labels:\n",
        "#             mask = self.Y_labels == label\n",
        "#             class_data = self.X_data[mask]\n",
        "#             class_mean_intensities = np.mean(class_data.reshape(np.sum(mask), -1), axis=1)\n",
        "#             class_intensities.extend(class_mean_intensities)\n",
        "#             class_labels.extend([self.label_to_name[label]] * len(class_mean_intensities))\n",
        "\n",
        "#         intensity_df = pd.DataFrame({\n",
        "#             'intensity': class_intensities,\n",
        "#             'class': class_labels\n",
        "#         })\n",
        "\n",
        "#         # Create boxplot data\n",
        "#         box_data = [intensity_df[intensity_df['class'] == name]['intensity'].values\n",
        "#                    for name in self.label_names]\n",
        "\n",
        "#         axes[1, 0].boxplot(box_data, labels=self.label_names)\n",
        "#         axes[1, 0].set_title('Mean Intensity by Class')\n",
        "#         axes[1, 0].set_ylabel('Mean Intensity')\n",
        "#         axes[1, 0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "#         # Average image intensity heatmap by class\n",
        "#         avg_images = np.zeros((len(self.unique_labels), *self.image_shape))\n",
        "#         for i, label in enumerate(self.unique_labels):\n",
        "#             mask = self.Y_labels == label\n",
        "#             avg_images[i] = np.mean(self.X_data[mask], axis=0)\n",
        "\n",
        "#         # Calculate average intensity across spatial dimensions\n",
        "#         if len(self.image_shape) == 3:\n",
        "#             if self.channels_first:\n",
        "#                 # Average across height and width for each channel\n",
        "#                 avg_intensities = np.mean(avg_images, axis=(2, 3))  # Shape: (n_classes, n_channels)\n",
        "#             else:\n",
        "#                 # Average across height and width for each channel\n",
        "#                 avg_intensities = np.mean(avg_images, axis=(1, 2))  # Shape: (n_classes, n_channels)\n",
        "#         else:\n",
        "#             # Grayscale images - average across spatial dimensions\n",
        "#             avg_intensities = np.mean(avg_images, axis=(1, 2))  # Shape: (n_classes,)\n",
        "#             avg_intensities = avg_intensities.reshape(-1, 1)  # Make it 2D for heatmap\n",
        "\n",
        "#         im = axes[1, 1].imshow(avg_intensities, cmap='viridis', aspect='auto')\n",
        "#         axes[1, 1].set_title('Average Intensity by Class')\n",
        "#         axes[1, 1].set_ylabel('Class Index')\n",
        "#         axes[1, 1].set_yticks(range(len(self.unique_labels)))\n",
        "#         axes[1, 1].set_yticklabels([self.label_to_name[label] for label in self.unique_labels])\n",
        "\n",
        "#         if len(self.image_shape) == 3:\n",
        "#             if self.channels_first:\n",
        "#                 n_channels = self.image_shape[0]\n",
        "#             else:\n",
        "#                 n_channels = self.image_shape[2]\n",
        "\n",
        "#             if n_channels > 1:\n",
        "#                 axes[1, 1].set_xlabel('Channel')\n",
        "#                 axes[1, 1].set_xticks(range(n_channels))\n",
        "#                 if n_channels == 3:\n",
        "#                     axes[1, 1].set_xticklabels(['R', 'G', 'B'])\n",
        "#                 else:\n",
        "#                     axes[1, 1].set_xticklabels([f'Ch{i}' for i in range(n_channels)])\n",
        "#         else:\n",
        "#             axes[1, 1].set_xlabel('Intensity')\n",
        "\n",
        "#         plt.colorbar(im, ax=axes[1, 1])\n",
        "\n",
        "#         # Channel analysis for color images\n",
        "#         if len(self.image_shape) == 3:\n",
        "#             if self.channels_first:\n",
        "#                 n_channels = self.image_shape[0]\n",
        "#                 channel_means = np.mean(self.X_data, axis=(0, 2, 3))  # Average over batch, height, width\n",
        "#             else:\n",
        "#                 n_channels = self.image_shape[2]\n",
        "#                 channel_means = np.mean(self.X_data, axis=(0, 1, 2))  # Average over batch, height, width\n",
        "\n",
        "#             if n_channels > 1:\n",
        "#                 colors = ['red', 'green', 'blue'] if n_channels == 3 else ['gray'] * n_channels\n",
        "#                 axes[1, 2].bar(range(n_channels), channel_means, color=colors)\n",
        "#                 axes[1, 2].set_title('Mean Intensity by Channel')\n",
        "#                 axes[1, 2].set_xlabel('Channel')\n",
        "#                 axes[1, 2].set_ylabel('Mean Intensity')\n",
        "#                 if n_channels == 3:\n",
        "#                     axes[1, 2].set_xticks(range(3))\n",
        "#                     axes[1, 2].set_xticklabels(['Red', 'Green', 'Blue'])\n",
        "#                 else:\n",
        "#                     axes[1, 2].set_xticks(range(n_channels))\n",
        "#                     axes[1, 2].set_xticklabels([f'Ch{i}' for i in range(n_channels)])\n",
        "#             else:\n",
        "#                 axes[1, 2].text(0.5, 0.5, 'Single Channel\\n(Grayscale)',\n",
        "#                                ha='center', va='center', transform=axes[1, 2].transAxes)\n",
        "#                 axes[1, 2].set_title('Channel Information')\n",
        "#         else:\n",
        "#             axes[1, 2].text(0.5, 0.5, 'Single Channel\\n(Grayscale)',\n",
        "#                            ha='center', va='center', transform=axes[1, 2].transAxes)\n",
        "#             axes[1, 2].set_title('Channel Information')\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(f'{self.output_dir}/figures/pixel_intensity_analysis.png', bbox_inches='tight')\n",
        "#         plt.show()\n",
        "\n",
        "#     def perform_dimensionality_reduction(self, n_components=2, sample_size=5000):\n",
        "#         \"\"\"Perform PCA and t-SNE for visualization\"\"\"\n",
        "#         print(\"Performing dimensionality reduction...\")\n",
        "\n",
        "#         # Sample data if too large\n",
        "#         if self.n_samples > sample_size:\n",
        "#             indices = np.random.choice(self.n_samples, sample_size, replace=False)\n",
        "#             X_sample = self.X_data[indices]\n",
        "#             Y_sample = self.Y_labels[indices]\n",
        "#         else:\n",
        "#             X_sample = self.X_data\n",
        "#             Y_sample = self.Y_labels\n",
        "\n",
        "#         # Flatten images\n",
        "#         X_flat = X_sample.reshape(len(X_sample), -1)\n",
        "\n",
        "#         # Normalize data\n",
        "#         X_normalized = (X_flat - X_flat.mean()) / (X_flat.std() + 1e-8)\n",
        "\n",
        "#         # PCA\n",
        "#         print(\"Computing PCA...\")\n",
        "#         pca = PCA(n_components=n_components)\n",
        "#         X_pca = pca.fit_transform(X_normalized)\n",
        "\n",
        "#         # t-SNE\n",
        "#         print(\"Computing t-SNE...\")\n",
        "#         tsne = TSNE(n_components=n_components, random_state=42, perplexity=30)\n",
        "#         X_tsne = tsne.fit_transform(X_normalized)\n",
        "\n",
        "#         # Plot results\n",
        "#         fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
        "\n",
        "#         # PCA plot\n",
        "#         scatter1 = ax1.scatter(X_pca[:, 0], X_pca[:, 1],\n",
        "#                               c=Y_sample, cmap='tab10', alpha=0.6)\n",
        "#         ax1.set_title(f'PCA Visualization\\nExplained Variance: {pca.explained_variance_ratio_.sum():.3f}')\n",
        "#         ax1.set_xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.3f})')\n",
        "#         ax1.set_ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.3f})')\n",
        "\n",
        "#         # Add colorbar for PCA\n",
        "#         cbar1 = plt.colorbar(scatter1, ax=ax1)\n",
        "#         cbar1.set_label('Class')\n",
        "\n",
        "#         # t-SNE plot\n",
        "#         scatter2 = ax2.scatter(X_tsne[:, 0], X_tsne[:, 1],\n",
        "#                               c=Y_sample, cmap='tab10', alpha=0.6)\n",
        "#         ax2.set_title('t-SNE Visualization')\n",
        "#         ax2.set_xlabel('t-SNE 1')\n",
        "#         ax2.set_ylabel('t-SNE 2')\n",
        "\n",
        "#         # Add colorbar for t-SNE\n",
        "#         cbar2 = plt.colorbar(scatter2, ax=ax2)\n",
        "#         cbar2.set_label('Class')\n",
        "\n",
        "#         plt.tight_layout()\n",
        "#         plt.savefig(f'{self.output_dir}/figures/dimensionality_reduction.png', bbox_inches='tight')\n",
        "#         plt.show()\n",
        "\n",
        "#         return pca, X_pca, X_tsne\n",
        "\n",
        "#     def create_data_summary_report(self):\n",
        "#         \"\"\"Create comprehensive data summary\"\"\"\n",
        "#         if not hasattr(self, 'data_properties'):\n",
        "#             self.analyze_data_properties()\n",
        "\n",
        "#         summary = f\"\"\"\n",
        "# FISH SPECIES DATASET - DATA ANALYSIS REPORT\n",
        "# {'='*60}\n",
        "\n",
        "# Dataset Overview:\n",
        "# - Total samples: {self.data_properties['dataset_size']:,}\n",
        "# - Number of classes: {self.data_properties['n_classes']}\n",
        "# - Image dimensions: {self.data_properties['image_shape']}\n",
        "# - Channels first format: {self.data_properties['channels_first']}\n",
        "# - Data type: {self.data_properties['data_type']}\n",
        "# - Memory usage: {self.data_properties['memory_usage_mb']:.1f} MB\n",
        "\n",
        "# Data Range:\n",
        "# - Minimum value: {self.data_properties['data_range']['min']:.3f}\n",
        "# - Maximum value: {self.data_properties['data_range']['max']:.3f}\n",
        "# - Mean value: {self.data_properties['data_range']['mean']:.3f}\n",
        "# - Standard deviation: {self.data_properties['data_range']['std']:.3f}\n",
        "\n",
        "# Class Distribution:\n",
        "# \"\"\"\n",
        "\n",
        "#         for class_name, stats in self.data_properties['class_statistics'].items():\n",
        "#             summary += f\"\\n{class_name}:\\n\"\n",
        "#             summary += f\"  - Sample count: {stats['count']:,}\\n\"\n",
        "#             summary += f\"  - Mean intensity: {stats['mean_intensity']:.3f}\\n\"\n",
        "#             summary += f\"  - Std intensity: {stats['std_intensity']:.3f}\\n\"\n",
        "#             summary += f\"  - Intensity range: {stats['min_intensity']:.3f} - {stats['max_intensity']:.3f}\\n\"\n",
        "\n",
        "#         # Save report\n",
        "#         with open(f'{self.output_dir}/reports/data_summary.txt', 'w') as f:\n",
        "#             f.write(summary)\n",
        "\n",
        "#         print(summary)\n",
        "#         return summary\n",
        "\n",
        "#     def run_complete_analysis(self, sample_size_dr=5000):\n",
        "#         \"\"\"Run complete analysis pipeline\"\"\"\n",
        "#         print(\"Starting comprehensive NumPy dataset analysis...\")\n",
        "#         print(\"=\" * 60)\n",
        "\n",
        "#         # Step 1: Analyze data properties\n",
        "#         self.analyze_data_properties()\n",
        "\n",
        "#         # Step 2: Create visualizations\n",
        "#         print(\"\\nGenerating visualizations...\")\n",
        "#         self.plot_class_distribution()\n",
        "#         self.plot_sample_images()\n",
        "#         self.plot_pixel_intensity_analysis()\n",
        "\n",
        "#         # Step 3: Dimensionality reduction\n",
        "#         pca, X_pca, X_tsne = self.perform_dimensionality_reduction(sample_size=sample_size_dr)\n",
        "\n",
        "#         # Step 4: Generate report\n",
        "#         print(\"\\nGenerating comprehensive report...\")\n",
        "#         self.create_data_summary_report()\n",
        "\n",
        "#         print(f\"\\nAnalysis complete! Results saved to: {self.output_dir}\")\n",
        "#         print(\"\\nGenerated files:\")\n",
        "#         print(\"- Figures: class_distribution.png, sample_images.png, pixel_intensity_analysis.png, dimensionality_reduction.png\")\n",
        "#         print(\"- Reports: data_summary.txt\")\n",
        "\n",
        "#         return pca, X_pca, X_tsne\n",
        "\n",
        "\n",
        "# # Usage example:\n",
        "# analyzer = FishDatasetNumpyAnalyzer(X_Loaded, Y_Loaded, output_dir='./fish_classification_results')\n",
        "# pca_model, X_pca_result, X_tsne_result = analyzer.run_complete_analysis(sample_size_dr=3000)\n",
        "# print(\"\\nDataset analysis completed successfully!\")\n",
        "# print(\"All visualizations and reports have been generated.\")"
      ],
      "metadata": {
        "id": "3GW4mxs4UgSQ"
      },
      "id": "3GW4mxs4UgSQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 7: Model Architecture"
      ],
      "metadata": {
        "id": "EJcWrfAbXyhI"
      },
      "id": "EJcWrfAbXyhI"
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelFactory:\n",
        "    @staticmethod\n",
        "    # def create_model(model_name, num_classes=Config.NUM_CLASSES, dropout_rate=0.5, hidden_dim_multiplier=0.5):\n",
        "    def create_model(model_name, params=None, num_classes=Config.NUM_CLASSES):\n",
        "        #Create model with configurable architecture\n",
        "        if params is None:\n",
        "            params = {}\n",
        "        dropout_rate = params.get('dropout', 0.5)\n",
        "        hidden_dim_multiplier = params.get('hidden_dim_multiplier', 0.5)\n",
        "\n",
        "        if model_name == 'resnet50':\n",
        "            model = models.resnet50(weights='IMAGENET1K_V2')\n",
        "            # Partial unfreeze for better accuracy: unfreeze layer4 and fc\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                # if \"layer4\" in name or \"fc\" in name:\n",
        "                if \"layer3\" in name or \"layer4\" in name or \"fc\" in name:\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'efficientnet_b0':\n",
        "            model = models.efficientnet_b0(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: last blocks\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"_blocks.15\" in name or \"_blocks.16\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = model.classifier[1].in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'mobilenet_v3_large':\n",
        "            model = models.mobilenet_v3_large(weights='IMAGENET1K_V2')\n",
        "            # Partial unfreeze: last features\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"features.12\" in name or \"features.13\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = 960\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'vgg16':\n",
        "            model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: classifier and last features\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"classifier\" in name or \"features.28\" in name:\n",
        "                    param.requires_grad = True\n",
        "            hidden_dim = int(4096 * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Linear(512 * 7 * 7, 4096),\n",
        "                nn.ReLU(True),\n",
        "                nn.Dropout(),\n",
        "                nn.Linear(4096, hidden_dim),\n",
        "                nn.ReLU(True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'densenet121':\n",
        "            model = models.densenet121(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: denseblock4 and classifier\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"denseblock4\" in name or \"classifier\" in name:\n",
        "                    param.requires_grad = True\n",
        "            num_features = model.classifier.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'inception_v3':\n",
        "            model = models.inception_v3(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: Mixed_7a, Mixed_7b, Mixed_7c and classifiers\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if any(layer in name for layer in [\"Mixed_7a\", \"Mixed_7b\", \"Mixed_7c\", \"fc\", \"AuxLogits\"]):\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "\n",
        "            # Main classifier\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "            # Auxiliary classifier (if exists)\n",
        "            if hasattr(model, 'AuxLogits') and model.AuxLogits is not None:\n",
        "                aux_features = model.AuxLogits.fc.in_features\n",
        "                aux_hidden = int(aux_features * hidden_dim_multiplier)\n",
        "                model.AuxLogits.fc = nn.Sequential(\n",
        "                    nn.Dropout(dropout_rate),\n",
        "                    nn.Linear(aux_features, aux_hidden),\n",
        "                    nn.ReLU(inplace=True),\n",
        "                    nn.BatchNorm1d(aux_hidden),\n",
        "                    nn.Dropout(dropout_rate / 2),\n",
        "                    nn.Linear(aux_hidden, num_classes)\n",
        "                )\n",
        "\n",
        "        elif model_name == 'vit_b_16':\n",
        "            model = models.vit_b_16(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: last encoder layers and head\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if any(layer in name for layer in [\"encoder.layers.10\", \"encoder.layers.11\", \"heads\"]):\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.heads.head.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.heads.head = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'convnext_base':\n",
        "            model = models.convnext_base(weights='IMAGENET1K_V1')\n",
        "            # Partial unfreeze: last stages and classifier\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if any(layer in name for layer in [\"features.7\", \"classifier\"]):\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.classifier[2].in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.classifier = nn.Sequential(\n",
        "                model.classifier[0],  # Keep the LayerNorm\n",
        "                model.classifier[1],  # Keep the Flatten\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'regnet_y_32gf':\n",
        "            model = models.regnet_y_32gf(weights='IMAGENET1K_V2')\n",
        "            # Partial unfreeze: last trunk stage and fc\n",
        "            for name, param in model.named_parameters():\n",
        "                param.requires_grad = False\n",
        "                if \"trunk_output\" in name or \"fc\" in name:\n",
        "                    param.requires_grad = True\n",
        "\n",
        "            num_features = model.fc.in_features\n",
        "            hidden_dim = int(num_features * hidden_dim_multiplier)\n",
        "            model.fc = nn.Sequential(\n",
        "                nn.Dropout(dropout_rate),\n",
        "                nn.Linear(num_features, hidden_dim),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.BatchNorm1d(hidden_dim),\n",
        "                nn.Dropout(dropout_rate / 2),\n",
        "                nn.Linear(hidden_dim, num_classes)\n",
        "            )\n",
        "\n",
        "        elif model_name == 'cnn':\n",
        "            # class SimpleCNN(nn.Module):\n",
        "\n",
        "            class SimpleCNN(nn.Module):\n",
        "                def __init__(self, num_classes=5, dropout_rate=0.3, hidden_dim_multiplier=0.3):\n",
        "                    super(SimpleCNN, self).__init__()\n",
        "\n",
        "                    # More conservative feature extractor to prevent overfitting\n",
        "                    self.features = nn.Sequential(\n",
        "                        # Block 1 - Start small\n",
        "                        nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(32),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.1),  # Spatial dropout in conv layers\n",
        "                        nn.MaxPool2d(2, 2),  # 224 -> 112\n",
        "\n",
        "                        # Block 2\n",
        "                        nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(64),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.15),\n",
        "                        nn.MaxPool2d(2, 2),  # 112 -> 56\n",
        "\n",
        "                        # Block 3\n",
        "                        nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.2),\n",
        "                        nn.MaxPool2d(2, 2),  # 56 -> 28\n",
        "\n",
        "                        # Block 4 - Add one more conv before pooling\n",
        "                        nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(128),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.25),\n",
        "                        nn.MaxPool2d(2, 2),  # 28 -> 14\n",
        "\n",
        "                        # Block 5 - Final feature extraction\n",
        "                        nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "                        nn.BatchNorm2d(256),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.Dropout2d(0.3),\n",
        "                        nn.AdaptiveAvgPool2d((7, 7))  # Fixed spatial size\n",
        "                    )\n",
        "\n",
        "                    # Calculate features after adaptive pooling\n",
        "                    conv_output_size = 256 * 7 * 7  # 12544\n",
        "\n",
        "                    # Much smaller hidden dimension to prevent overfitting\n",
        "                    hidden_dim = int(conv_output_size * hidden_dim_multiplier)\n",
        "                    hidden_dim = max(64, min(hidden_dim, 512))  # Smaller range\n",
        "\n",
        "                    # Simple but effective classifier\n",
        "                    self.classifier = nn.Sequential(\n",
        "                        nn.Dropout(dropout_rate),\n",
        "                        nn.Linear(conv_output_size, hidden_dim),\n",
        "                        nn.ReLU(inplace=True),\n",
        "                        nn.BatchNorm1d(hidden_dim),\n",
        "                        nn.Dropout(dropout_rate * 0.5),\n",
        "                        nn.Linear(hidden_dim, num_classes)\n",
        "                    )\n",
        "\n",
        "                    # Initialize weights properly\n",
        "                    self._initialize_weights()\n",
        "\n",
        "                def _initialize_weights(self):\n",
        "                    for m in self.modules():\n",
        "                        if isinstance(m, nn.Conv2d):\n",
        "                            # Use smaller initialization for better gradient flow\n",
        "                            nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "                        elif isinstance(m, nn.Linear):\n",
        "                            # Smaller initialization for linear layers\n",
        "                            nn.init.xavier_uniform_(m.weight, gain=0.5)\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "                        elif isinstance(m, (nn.BatchNorm2d, nn.BatchNorm1d)):\n",
        "                            if m.weight is not None:\n",
        "                                nn.init.ones_(m.weight)\n",
        "                            if m.bias is not None:\n",
        "                                nn.init.zeros_(m.bias)\n",
        "\n",
        "                def forward(self, x):\n",
        "                    # Feature extraction\n",
        "                    x = self.features(x)\n",
        "\n",
        "                    # Flatten\n",
        "                    x = torch.flatten(x, 1)\n",
        "\n",
        "                    # Classification with gradient clipping\n",
        "                    x = self.classifier(x)\n",
        "\n",
        "                    # Clip outputs to prevent extreme values\n",
        "                    x = torch.clamp(x, min=-10, max=10)\n",
        "\n",
        "                    return x\n",
        "\n",
        "            # # Example usage\n",
        "            # model = SimpleCNN(num_classes=num_classes, dropout_rate=dropout_rate, hidden_dim_multiplier=hidden_dim_multiplier)\n",
        "            # model = model.to(Config.DEVICE)  # Move to device right after creation\n",
        "            model = SimpleCNN(num_classes=num_classes, dropout_rate=dropout_rate, hidden_dim_multiplier=hidden_dim_multiplier)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "\n",
        "        return model"
      ],
      "metadata": {
        "id": "Pxu1Cn5CXx-B"
      },
      "id": "Pxu1Cn5CXx-B",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 8: Ensamble Model Architecture"
      ],
      "metadata": {
        "id": "HMjRUeNFW-m_"
      },
      "id": "HMjRUeNFW-m_"
    },
    {
      "cell_type": "code",
      "source": [
        "# ---\n",
        "# 6. ENSEMBLE METHODS\n",
        "# ================================================================================================================================\n",
        "# Purpose: Implement ensemble methods (simple, weighted, confidence-based, learnable).\n",
        "\n",
        "class EnsembleManager:\n",
        "    def __init__(self, models_dict, val_data):\n",
        "        self.models = models_dict\n",
        "        self.X_val, self.y_val = val_data\n",
        "        self.model_predictions = self._get_predictions()\n",
        "        self.histories = {}\n",
        "\n",
        "    def _get_predictions(self):\n",
        "        print(\"Getting model predictions for ensemble...\")\n",
        "        predictions = {}\n",
        "\n",
        "        val_dataset = FishDataset(self.X_val, self.y_val, DataManager.get_transforms(False))\n",
        "        val_loader = DataLoader(val_dataset, batch_size=Config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "        for name, model in self.models.items():\n",
        "            model.eval()\n",
        "            all_preds = []\n",
        "            all_probs = []\n",
        "            all_losses = []\n",
        "            all_labels = []\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for images, labels in val_loader:\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    outputs = model(images)\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    loss = criterion(outputs, labels).item()\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    all_preds.extend(predicted.cpu().numpy())\n",
        "                    all_probs.extend(probabilities.cpu().numpy())\n",
        "                    all_losses.append(loss)\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "            accuracy = correct / total\n",
        "            f1 = f1_score(self.y_val, all_preds, average='macro')\n",
        "            avg_loss = np.mean(all_losses)\n",
        "\n",
        "            predictions[name] = {\n",
        "                'predictions': np.array(all_preds),\n",
        "                'probabilities': np.array(all_probs),\n",
        "                'loss': avg_loss,\n",
        "                'accuracy': accuracy,\n",
        "                'f1': f1,\n",
        "                'true_labels': np.array(all_labels)\n",
        "            }\n",
        "\n",
        "            print(f\"  {name}: F1 = {f1:.4f}, Acc = {accuracy:.4f}, Loss = {avg_loss:.4f}\")\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def simple_average_ensemble(self, model_combo):\n",
        "        selected_probs = [self.model_predictions[name]['probabilities'] for name in model_combo]\n",
        "        avg_probs = np.mean(selected_probs, axis=0)\n",
        "        predictions = np.argmax(avg_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        avg_probs = np.mean(selected_probs, axis=0) if selected_probs else np.zeros((len(self.y_val), Config.NUM_CLASSES))\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            # 'probabilities': avg_probs,\n",
        "            'probabilities': avg_probs if avg_probs.ndim == 2 else np.zeros((0, Config.NUM_CLASSES)),\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def weighted_average_ensemble(self, model_combo):\n",
        "        weights = []\n",
        "        selected_probs = []\n",
        "\n",
        "        for name in model_combo:\n",
        "            f1 = self.model_predictions[name]['f1']\n",
        "            weights.append(f1)\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        weights = np.array(weights) / np.sum(weights)\n",
        "        weighted_probs = np.average(selected_probs, axis=0, weights=weights)\n",
        "        predictions = np.argmax(weighted_probs, axis=1)\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.average([self.model_predictions[name]['loss'] for name in model_combo], weights=weights)\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'weights': weights,\n",
        "            'models': model_combo,\n",
        "            'probabilities': weighted_probs,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def confidence_based_ensemble(self, model_combo):\n",
        "        final_predictions = []\n",
        "        all_probs = []\n",
        "\n",
        "        for i in range(len(self.y_val)):\n",
        "            confidences = []\n",
        "            probs = []\n",
        "\n",
        "            for name in model_combo:\n",
        "                prob = self.model_predictions[name]['probabilities'][i]\n",
        "                confidence = np.max(prob)\n",
        "                confidences.append(confidence)\n",
        "                probs.append(prob)\n",
        "\n",
        "            confidences = np.array(confidences)\n",
        "            weights = confidences / np.sum(confidences) if np.sum(confidences) > 0 else np.ones(len(confidences)) / len(confidences)\n",
        "\n",
        "            final_prob = np.average(probs, axis=0, weights=weights)\n",
        "            final_predictions.append(np.argmax(final_prob))\n",
        "            all_probs.append(final_prob)\n",
        "\n",
        "        predictions = np.array(final_predictions)\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'probabilities': np.array(all_probs),\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def learnable_weighted_ensemble(self, model_combo, epochs=30):\n",
        "        print(f\"Training learnable weighted ensemble with {len(model_combo)} models...\")\n",
        "\n",
        "        selected_probs = []\n",
        "        for name in model_combo:\n",
        "            selected_probs.append(self.model_predictions[name]['probabilities'])\n",
        "\n",
        "        ensemble_input = np.stack(selected_probs, axis=1)\n",
        "\n",
        "        X_ensemble = torch.FloatTensor(ensemble_input).to(Config.DEVICE)\n",
        "        y_ensemble = torch.LongTensor(self.y_val).to(Config.DEVICE)\n",
        "\n",
        "        ensemble_model = LearnableWeightedEnsemble(\n",
        "            num_models=len(model_combo),\n",
        "            num_classes=Config.NUM_CLASSES\n",
        "        ).to(Config.DEVICE)\n",
        "\n",
        "        optimizer = optim.AdamW(ensemble_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "\n",
        "        history = {'train_loss': [], 'train_acc': [], 'val_f1': []}\n",
        "        best_loss = float('inf')\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            ensemble_model.train()\n",
        "            optimizer.zero_grad()\n",
        "            predictions, weights = ensemble_model(X_ensemble)\n",
        "            loss = criterion(predictions, y_ensemble)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            accuracy = accuracy_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy())\n",
        "            f1 = f1_score(y_ensemble.cpu().numpy(), predictions.argmax(dim=1).cpu().numpy(), average='macro')\n",
        "\n",
        "            history['train_loss'].append(loss.item())\n",
        "            history['train_acc'].append(accuracy)\n",
        "            history['val_f1'].append(f1)\n",
        "\n",
        "            print(f\"Ensemble Epoch {epoch+1}/{epochs}: Loss = {loss.item():.4f}, \"\n",
        "                  f\"Acc = {accuracy:.4f}, F1 = {f1:.4f}\")\n",
        "\n",
        "            if loss.item() < best_loss:\n",
        "                best_loss = loss.item()\n",
        "                torch.save(ensemble_model.state_dict(), f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\")\n",
        "\n",
        "        ensemble_model.load_state_dict(torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(model_combo)}.pt\"))\n",
        "        ensemble_model.eval()\n",
        "        with torch.no_grad():\n",
        "            final_predictions, learned_weights = ensemble_model(X_ensemble)\n",
        "            predictions = final_predictions.argmax(dim=1).cpu().numpy()\n",
        "            probabilities = torch.softmax(final_predictions, dim=1).cpu().numpy()\n",
        "            avg_weights = learned_weights.mean(dim=0).cpu().numpy()\n",
        "\n",
        "        accuracy = accuracy_score(self.y_val, predictions)\n",
        "        f1 = f1_score(self.y_val, predictions, average='macro')\n",
        "        loss = np.mean([self.model_predictions[name]['loss'] for name in model_combo])\n",
        "\n",
        "        self.histories[f\"learnable_weighted_{'+'.join(model_combo)}\"] = history\n",
        "\n",
        "        return {\n",
        "            'accuracy': accuracy,\n",
        "            'f1': f1,\n",
        "            'loss': loss,\n",
        "            'predictions': predictions,\n",
        "            'models': model_combo,\n",
        "            'learned_weights': avg_weights,\n",
        "            'probabilities': probabilities,\n",
        "            'true_labels': self.y_val\n",
        "        }\n",
        "\n",
        "    def test_ensemble_combinations(self):\n",
        "        print(\"Testing ensemble combinations...\")\n",
        "\n",
        "        model_names = list(self.models.keys())\n",
        "        all_results = {}\n",
        "        best_result = None\n",
        "        best_score = 0\n",
        "\n",
        "        for size in range(2, min(len(model_names) + 1, 5)):\n",
        "            print(f\"Testing {size}-model combinations...\")\n",
        "\n",
        "            for combo in list(combinations(model_names, size))[:5]:\n",
        "                combo_name = f\"combo_{size}_{'+'.join(combo)}\"\n",
        "\n",
        "                for method_name in Config.ENSEMBLE_METHODS:\n",
        "                    full_name = f\"{combo_name}_{method_name}\"\n",
        "\n",
        "                    try:\n",
        "                        if method_name == 'simple_average':\n",
        "                            result = self.simple_average_ensemble(combo)\n",
        "                        elif method_name == 'weighted_average':\n",
        "                            result = self.weighted_average_ensemble(combo)\n",
        "                        elif method_name == 'confidence_based':\n",
        "                            result = self.confidence_based_ensemble(combo)\n",
        "                        elif method_name == 'learnable_weighted':\n",
        "                            result = self.learnable_weighted_ensemble(combo)\n",
        "\n",
        "                        # Verify result contains required keys\n",
        "                        required_keys = ['accuracy', 'f1', 'loss', 'predictions', 'models', 'probabilities', 'true_labels']\n",
        "                        if not all(key in result for key in required_keys):\n",
        "                            missing = [key for key in required_keys if key not in result]\n",
        "                            print(f\"  {full_name}: Missing keys {missing}\")\n",
        "                            continue\n",
        "                        # Ensure probabilities is 2D\n",
        "                        if 'probabilities' in result and (result['probabilities'].ndim != 2 or result['probabilities'].shape[1] != Config.NUM_CLASSES):\n",
        "                            result['probabilities'] = np.zeros((len(result['true_labels']), Config.NUM_CLASSES))\n",
        "\n",
        "                        all_results[full_name] = result\n",
        "                        print(f\"  {full_name}: F1 = {result['f1']:.4f}, Acc = {result['accuracy']:.4f}, \"\n",
        "                              f\"Loss = {result['loss']:.4f}, True Labels Shape = {result['true_labels'].shape}\")\n",
        "\n",
        "                        if result['f1'] > best_score:\n",
        "                            best_score = result['f1']\n",
        "                            best_result = (full_name, result)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"  {full_name}: FAILED - {str(e)}\")\n",
        "\n",
        "        if best_result:\n",
        "            print(f\"\\n‚úì Best ensemble: {best_result[0]} (F1: {best_result[1]['f1']:.4f})\")\n",
        "        else:\n",
        "            print(\"\\nNo valid ensemble results generated.\")\n",
        "\n",
        "        return all_results, best_result\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# LEARNABLE WEIGHTED ENSEMBLE MODEL\n",
        "# ===============================================================================================================================\n",
        "# Purpose: Define a neural network for learning optimal ensemble weights.\n",
        "\n",
        "class LearnableWeightedEnsemble(nn.Module):\n",
        "    \"\"\"Ensemble model with per-class adaptive weights and attention\"\"\"\n",
        "    def __init__(self, num_models, num_classes, hidden_dim=128, num_heads=4):\n",
        "        super(LearnableWeightedEnsemble, self).__init__()\n",
        "        self.num_models = num_models\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "        # Attention mechanism to learn relations between model predictions\n",
        "        self.attention = nn.MultiheadAttention(embed_dim=num_classes, num_heads=num_heads, batch_first=True)\n",
        "\n",
        "        # Weight network outputs per-class weights for each model\n",
        "        self.weight_network = nn.Sequential(\n",
        "            nn.Linear(num_classes, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes),\n",
        "            nn.Sigmoid()  # Per-class weight scaling\n",
        "        )\n",
        "\n",
        "        # Prediction head: combines weighted predictions + raw predictions\n",
        "        self.prediction_head = nn.Sequential(\n",
        "            nn.Linear(num_classes * (num_models + 1), hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Linear(hidden_dim, num_classes * 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(num_classes * 2, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, model_predictions):\n",
        "        \"\"\"\n",
        "        model_predictions: (batch, num_models, num_classes)\n",
        "        Returns:\n",
        "            final_predictions: logits for classification\n",
        "            weights: learned per-class weights for each model\n",
        "        \"\"\"\n",
        "        batch_size = model_predictions.size(0)\n",
        "\n",
        "        # --- Step 1: Attention over model predictions --- #The model looks at how predictions of different models relate to each other.\n",
        "        attn_output, _ = self.attention(model_predictions, model_predictions, model_predictions)\n",
        "        # shape: (batch, num_models, num_classes)\n",
        "\n",
        "\n",
        "        # --- Step 2: Per-class weights for each model ---\n",
        "        #Learns a weight for each model for each class.\n",
        "        #softmax ensures weights across models sum to 1 for each class.\n",
        "        #Basically: ‚ÄúFor class 0, I trust model 2 more; for class 1, I trust model 0 more.‚Äù\n",
        "        weights = self.weight_network(attn_output)  # (batch, num_models, num_classes)\n",
        "        weights = F.softmax(weights, dim=1)  # normalize over models\n",
        "\n",
        "\n",
        "        # --- Step 3: Weighted average across models ---\n",
        "        #Combines the models‚Äô predictions using the learned weights ‚Üí smarter than a plain average.\n",
        "        weighted_avg = torch.sum(model_predictions * weights, dim=1)  # (batch, num_classes)\n",
        "\n",
        "\n",
        "        # --- Step 4: Residual connection with raw predictions ---\n",
        "        #Combines the weighted average and all raw predictions.Gives the network more info to refine the final prediction.\n",
        "        flat_preds = model_predictions.view(batch_size, -1)  # (batch, num_models * num_classes)\n",
        "        final_input = torch.cat([weighted_avg, flat_preds], dim=1)  # (batch, num_classes + num_models*num_classes)\n",
        "\n",
        "\n",
        "        # --- Step 5: Final refined prediction ---\n",
        "        #A small feed-forward network refines the predictions.Output: (batch_size, num_classes) ‚Üí logits for each class.\n",
        "        final_predictions = self.prediction_head(final_input)  # (batch, num_classes)\n",
        "\n",
        "        return final_predictions, weights\n",
        "        #It learns which model is best for each class, combines their predictions smartly using attention, and produces a refined final prediction.\n",
        "\n",
        "    # def entropy_regularization(self, weights):\n",
        "    #     \"\"\"Encourage diverse weight usage (optional loss term).\"\"\"\n",
        "    #     # weights: (batch, num_models, num_classes)\n",
        "    #     entropy = -torch.sum(weights * torch.log(weights + 1e-8), dim=1)  # (batch, num_classes)\n",
        "    #     return torch.mean(entropy)\n"
      ],
      "metadata": {
        "id": "pWZlr59kXHue"
      },
      "id": "pWZlr59kXHue",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 9: Evaluation"
      ],
      "metadata": {
        "id": "myBECpTNXJEC"
      },
      "id": "myBECpTNXJEC"
    },
    {
      "cell_type": "code",
      "source": [
        "class ModelEvaluator:\n",
        "    @staticmethod\n",
        "    def evaluate_model(model, test_loader, model_name):\n",
        "        try:\n",
        "            print(f\"\\nEvaluating For Model: {model_name}...\")\n",
        "            model.eval()\n",
        "\n",
        "            all_preds = []\n",
        "            all_labels = []\n",
        "            misclassified = []\n",
        "            total_loss = 0\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "            all_probs = []\n",
        "\n",
        "            if test_loader is None or len(test_loader.dataset) == 0:\n",
        "                print(f\"Warning: No test data available for {model_name}\")\n",
        "                return ModelEvaluator._create_empty_result(model_name)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for batch_idx, (images, labels) in enumerate(test_loader):\n",
        "                    # CPU version\n",
        "                    # images, labels = images.cpu(), labels.cpu()\n",
        "                    #GPU version\n",
        "                    # Keep everything on the same device as the model\n",
        "                    images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "\n",
        "\n",
        "\n",
        "                    outputs = model(images)\n",
        "                    loss = criterion(outputs, labels)\n",
        "                    total_loss += loss.item()\n",
        "\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "\n",
        "                    # all_preds.extend(predicted.numpy())\n",
        "                    # all_labels.extend(labels.numpy())\n",
        "                    # To this:\n",
        "                    all_preds.extend(predicted.cpu().numpy())\n",
        "                    all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "                    # Convert logits to probabilities\n",
        "                    prob = torch.softmax(outputs, dim=1)\n",
        "                    # Store probabilities\n",
        "                    all_probs.append(prob.detach().cpu().numpy())\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    # Identify misclassified\n",
        "                    incorrect_mask = predicted != labels\n",
        "                    if incorrect_mask.any():\n",
        "                        incorrect_images = images[incorrect_mask]\n",
        "                        incorrect_labels = labels[incorrect_mask]\n",
        "                        incorrect_preds = predicted[incorrect_mask]\n",
        "                        for img, true_label, pred_label in zip(incorrect_images, incorrect_labels, incorrect_preds):\n",
        "                            misclassified.append({\n",
        "                                'image': img,\n",
        "                                'true_label': int(true_label),\n",
        "                                'pred_label': int(pred_label)\n",
        "                            })\n",
        "                    del images, labels, outputs, loss, predicted\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                    # ---------------- GPU VERSION (commented) ----------------\n",
        "                    # images, labels = images.to(Config.DEVICE), labels.to(Config.DEVICE)\n",
        "                    # outputs = model(images)\n",
        "                    # loss = criterion(outputs, labels)\n",
        "                    # _, predicted = torch.max(outputs.data, 1)\n",
        "                    # all_preds.append(predicted)\n",
        "                    # all_labels.append(labels)\n",
        "                    # --------------------------------------------------------\n",
        "\n",
        "\n",
        "\n",
        "            # CPU metrics\n",
        "            # Convert to single array\n",
        "            all_probs = np.concatenate(all_probs, axis=0)  # shape: (num_samples, num_classes)\n",
        "            # all_probs = [\n",
        "            #     (32, 5),   # batch 1: 32 samples √ó 5 classes\n",
        "            #     (32, 5),   # batch 2: 32 samples √ó 5 classes\n",
        "            #     (16, 5)    # batch 3: 16 samples √ó 5 classes\n",
        "            # ]\n",
        "            # result shape = (32 + 32 + 16, 5) = (80, 5)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            all_preds = np.array(all_preds)\n",
        "            all_labels = np.array(all_labels)\n",
        "            avg_loss = total_loss / len(test_loader)\n",
        "            accuracy = accuracy_score(all_labels, all_preds)\n",
        "            f1_macro = f1_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "            f1_weighted = f1_score(all_labels, all_preds, average='weighted', zero_division=0)\n",
        "            precision_macro = precision_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "            recall_macro = recall_score(all_labels, all_preds, average='macro', zero_division=0)\n",
        "            f1_per_class = f1_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "            precision_per_class = precision_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "            recall_per_class = recall_score(all_labels, all_preds, average=None, zero_division=0)\n",
        "            conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "\n",
        "            print(f\"{model_name} Evaluation: Acc = {accuracy:.4f}, F1 (Macro) = {f1_macro:.4f}, Loss = {avg_loss:.4f}\")\n",
        "            print(f\"Data shapes - Labels: {all_labels.shape}, Predictions: {all_preds.shape}\")\n",
        "\n",
        "            return {\n",
        "                'all_preds': all_preds,\n",
        "                'all_labels': all_labels,\n",
        "                'all_probs': all_probs,\n",
        "\n",
        "\n",
        "                'model_name': model_name,\n",
        "                'accuracy': accuracy,\n",
        "                'f1_macro': f1_macro,\n",
        "                'f1_weighted': f1_weighted,\n",
        "                'precision_macro': precision_macro,\n",
        "                'recall_macro': recall_macro,\n",
        "                'f1_per_class': f1_per_class,\n",
        "                'precision_per_class': precision_per_class,\n",
        "                'recall_per_class': recall_per_class,\n",
        "                'predictions': all_preds,\n",
        "                'true_labels': all_labels,\n",
        "                # 'probabilities': None,  # CPU version\n",
        "                'probabilities': all_probs,  # correctly collected probabilities\n",
        "                'conf_matrix': conf_matrix,\n",
        "                'loss': avg_loss,\n",
        "                'misclassified': misclassified\n",
        "            }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Evaluation error for {model_name}: {e}\")\n",
        "            return ModelEvaluator._create_empty_result(model_name)\n",
        "\n",
        "    @staticmethod\n",
        "    def _create_empty_result(model_name):\n",
        "        return {\n",
        "            'model_name': model_name,\n",
        "            'accuracy': 0.0,\n",
        "            'f1_macro': 0.0,\n",
        "            'f1_weighted': 0.0,\n",
        "            'precision_macro': 0.0,\n",
        "            'recall_macro': 0.0,\n",
        "            'f1_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "            'precision_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "            'recall_per_class': np.zeros(Config.NUM_CLASSES),\n",
        "            'predictions': np.array([]),\n",
        "            'true_labels': np.array([]),\n",
        "            'probabilities': np.array([]),\n",
        "            'conf_matrix': np.zeros((Config.NUM_CLASSES, Config.NUM_CLASSES)),\n",
        "            'loss': 0.0,\n",
        "            'misclassified': []\n",
        "        }"
      ],
      "metadata": {
        "id": "55h_10sUcaTo"
      },
      "id": "55h_10sUcaTo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 10: Plot Visualizations"
      ],
      "metadata": {
        "id": "zEYGh3Ykcbcz"
      },
      "id": "zEYGh3Ykcbcz"
    },
    {
      "cell_type": "code",
      "source": [
        "# visualizations for training history, ROC curves, confusion matrices, model comparisons, and XAI visualizations.\n",
        "\n",
        "class EnhancedVisualizations:\n",
        "    def __init__(self):\n",
        "        self.viz_dir = f\"{Config.OUTPUT_DIR}/visualizations\"\n",
        "        Path(self.viz_dir).mkdir(parents=True, exist_ok=True)\n",
        "        # Set better matplotlib parameters for spacing\n",
        "        plt.rcParams.update({\n",
        "            'figure.autolayout': True,\n",
        "            'axes.titlepad': 20,\n",
        "            'axes.labelpad': 10,\n",
        "            'xtick.major.pad': 8,\n",
        "            'ytick.major.pad': 8\n",
        "        })\n",
        "\n",
        "\n",
        "    def plot_single_model_history(self, history, model_name, alpha=0.2):  # (range: 0.1‚Äì0.3; lower = smoother, higher = more responsive)\n",
        "        \"\"\"Plot training history for individual model with better spacing\"\"\"\n",
        "        if not history['train_loss']:\n",
        "            print(f\"Skipping {model_name}: No training data available\")\n",
        "            return\n",
        "\n",
        "        # def smooth_ema(values, alpha):\n",
        "        #     \"\"\"Apply exponential moving average (EMA) smoothing to a list of values.\"\"\"\n",
        "        #     if not values:\n",
        "        #         return values\n",
        "        #     smoothed = [values[0]]\n",
        "        #     for val in values[1:]:\n",
        "        #         smoothed.append(alpha * val + (1 - alpha) * smoothed[-1])\n",
        "        #     return smoothed\n",
        "        def smooth_ema(values, alpha=0.1):\n",
        "            \"\"\"\n",
        "            Apply exponential moving average smoothing to a list or tensor of values.\n",
        "\n",
        "            Args:\n",
        "                values: List, NumPy array, or PyTorch tensor of numerical values\n",
        "                alpha: Smoothing factor (default: 0.1)\n",
        "\n",
        "            Returns:\n",
        "                List of smoothed values\n",
        "            \"\"\"\n",
        "            # Convert tensor to list if necessary\n",
        "            if torch.is_tensor(values):\n",
        "                values = values.cpu().numpy().tolist()\n",
        "            elif isinstance(values, np.ndarray):\n",
        "                values = values.tolist()\n",
        "\n",
        "            if not values:  # Check if the list is empty\n",
        "                return []\n",
        "\n",
        "            smoothed = [values[0]]\n",
        "            for i in range(1, len(values)):\n",
        "                smoothed.append(alpha * values[i] + (1 - alpha) * smoothed[-1])\n",
        "\n",
        "            return smoothed\n",
        "\n",
        "\n",
        "\n",
        "        epochs = range(1, len(history['train_loss']) + 1)\n",
        "\n",
        "        # Create subplot with more space\n",
        "        fig = plt.figure(figsize=(16, 10))\n",
        "        gs = fig.add_gridspec(2, 2, hspace=0.4, wspace=0.3)\n",
        "\n",
        "        # Loss plot\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        smoothed_train_loss = smooth_ema(history['train_loss'], alpha)\n",
        "        smoothed_val_loss = smooth_ema(history.get('val_loss', []), alpha)\n",
        "        ax1.plot(epochs, smoothed_train_loss, 'b-', linewidth=2, label='Train Loss', marker='o', markersize=4)\n",
        "        if smoothed_val_loss:\n",
        "            ax1.plot(epochs, smoothed_val_loss, 'r-', linewidth=2, label='Val Loss', marker='s', markersize=4)\n",
        "        ax1.set_title(f'{model_name} - Loss vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "        ax1.set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
        "        ax1.legend(frameon=True, shadow=True, fontsize=11)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.tick_params(labelsize=10)\n",
        "\n",
        "        # Accuracy plot\n",
        "        ax2 = fig.add_subplot(gs[0, 1])\n",
        "        ax2.plot(epochs, history['train_acc'], 'g-', linewidth=2, label='Train Acc', marker='o', markersize=4)\n",
        "        if history.get('val_acc', []):\n",
        "            ax2.plot(epochs, history['val_acc'], 'm-', linewidth=2, label='Val Acc', marker='s', markersize=4)\n",
        "        ax2.set_title(f'{model_name} - Accuracy vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "        ax2.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "        ax2.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "        ax2.legend(frameon=True, shadow=True, fontsize=11)\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "        ax2.tick_params(labelsize=10)\n",
        "\n",
        "        # F1 Score plot\n",
        "        ax3 = fig.add_subplot(gs[1, 0])\n",
        "        smoothed_val_f1 = smooth_ema(history.get('val_f1', []), alpha)\n",
        "        if smoothed_val_f1:\n",
        "            ax3.plot(epochs, smoothed_val_f1, 'orange', linewidth=2, label='Val F1', marker='d', markersize=4)\n",
        "            ax3.set_title(f'{model_name} - F1 Score vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "            ax3.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "            ax3.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
        "            ax3.legend(frameon=True, shadow=True, fontsize=11)\n",
        "            ax3.grid(True, alpha=0.3)\n",
        "            ax3.tick_params(labelsize=10)\n",
        "\n",
        "        # Learning Rate plot\n",
        "        ax4 = fig.add_subplot(gs[1, 1])\n",
        "        smoothed_lr = smooth_ema(history.get('learning_rates', []), alpha)\n",
        "        if smoothed_lr:\n",
        "            ax4.plot(epochs, smoothed_lr, 'purple', linewidth=2, label='Learning Rate', marker='x', markersize=6)\n",
        "            ax4.set_title(f'{model_name} - Learning Rate vs Epoch', fontsize=14, fontweight='bold', pad=20)\n",
        "            ax4.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "            ax4.set_ylabel('Learning Rate', fontsize=12, fontweight='bold')\n",
        "            ax4.legend(frameon=True, shadow=True, fontsize=11)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.tick_params(labelsize=10)\n",
        "            ax4.set_yscale('log')\n",
        "\n",
        "        plt.suptitle(f'{model_name} Training Progress', fontsize=18, fontweight='bold', y=0.98)\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_individual_training_history.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Individual training history saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "    def plot_single_model_xai(self, model, model_name, test_loader, max_images=5):\n",
        "        \"\"\"Generate XAI visualizations for a single model using Grad-CAM++, Integrated Gradients, and LRP\"\"\"\n",
        "        print(f\"Generating XAI visualizations for {model_name}...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # # Get sample images\n",
        "        # sample_images, sample_labels = next(iter(test_loader))\n",
        "        # sample_images = sample_images[:max_images].to(Config.DEVICE)\n",
        "        # sample_labels = sample_labels[:max_images].numpy()\n",
        "\n",
        "        # Get sample images\n",
        "        sample_images = []\n",
        "        sample_labels = []\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            class_mask = np.where(test_loader.dataset.labels == i)[0]\n",
        "            if len(class_mask) > 0:\n",
        "                idx = np.random.choice(class_mask)\n",
        "                image, label = test_loader.dataset[idx]\n",
        "                if image.dim() == 4:\n",
        "                    image = image.squeeze(0)\n",
        "                sample_images.append(image.to(Config.DEVICE))\n",
        "                sample_labels.append(label)\n",
        "\n",
        "\n",
        "        for idx, (image, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
        "            try:\n",
        "                # Create figure with larger size for clearer images\n",
        "                fig = plt.figure(figsize=(24, 8))  # Standard size for clear visualization\n",
        "                gs = fig.add_gridspec(1, 4, wspace=0.15, hspace=0.2)  # 4 columns: Original, Grad-CAM++, Integrated Gradients, LRP\n",
        "\n",
        "                # Prepare original image\n",
        "                image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                # Plot original image\n",
        "                ax_orig = fig.add_subplot(gs[0, 0])\n",
        "                ax_orig.imshow(image_np)\n",
        "                ax_orig.set_title(f'Original Image\\nTrue: {Config.CLASS_LABELS[true_label]}',\n",
        "                                 fontsize=14, fontweight='bold', pad=15)\n",
        "                ax_orig.axis('off')\n",
        "\n",
        "                # Forward pass for prediction\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(image.unsqueeze(0))\n",
        "                    probabilities = torch.softmax(outputs, dim=1)\n",
        "                    predicted_class = outputs.argmax(dim=1).item()\n",
        "                    confidence = probabilities[0, predicted_class].item()\n",
        "                    predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                # Generate Grad-CAM++ visualization\n",
        "                gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(model, image, predicted_class)\n",
        "                ax_gradcam = fig.add_subplot(gs[0, 1])\n",
        "                ax_gradcam.imshow(gradcam_img)\n",
        "                ax_gradcam.set_title(f'{model_name}\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                    fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_gradcam.axis('off')\n",
        "\n",
        "                # Generate Integrated Gradients visualization\n",
        "                ig_img, _ = xai_visualizer.integrated_gradients(model, image, predicted_class)\n",
        "                ax_ig = fig.add_subplot(gs[0, 2])\n",
        "                ax_ig.imshow(ig_img)\n",
        "                ax_ig.set_title(f'{model_name}\\nIntegrated Gradients', fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_ig.axis('off')\n",
        "\n",
        "                # Generate LRP visualization\n",
        "                lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, image, predicted_class)\n",
        "                ax_lrp = fig.add_subplot(gs[0, 3])\n",
        "                # ax_lrp.imshow(lrp_img)\n",
        "                ax_lrp.imshow(cv2.cvtColor(lrp_img, cv2.COLOR_BGR2RGB))\n",
        "                ax_lrp.set_title(f'{model_name}\\nLRP', fontsize=12, fontweight='bold', pad=10)\n",
        "                ax_lrp.axis('off')\n",
        "\n",
        "                plt.suptitle(f'XAI Analysis for {model_name} - Image {idx+1}', fontsize=16, fontweight='bold', y=0.95)\n",
        "                save_path = f\"{self.viz_dir}/{model_name}_xai_image_{idx+1}.png\"\n",
        "                plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "                plt.show()\n",
        "                print(f\"XAI visualization saved: {save_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating XAI for {model_name}, image {idx+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "    def plot_confusion_matrix(self, results, model_name):\n",
        "        \"\"\"Enhanced confusion matrix with better spacing\"\"\"\n",
        "        if 'true_labels' not in results or 'predictions' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'predictions' in results for {model_name}\")\n",
        "            return\n",
        "\n",
        "        cm = confusion_matrix(results['true_labels'], results['predictions'])\n",
        "        cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "        # Create figure with better spacing\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "        # Use better color scheme and formatting\n",
        "        sns.heatmap(cm_normalized, annot=cm, fmt='d', cmap='Blues',\n",
        "                    xticklabels=Config.CLASS_LABELS, yticklabels=Config.CLASS_LABELS,\n",
        "                    cbar_kws={'label': 'Normalized Count', 'shrink': 0.8},\n",
        "                    square=True, linewidths=0.5, annot_kws={'size': 12})\n",
        "\n",
        "        # === Move colorbar label to the top ===\n",
        "        cbar = ax.collections[0].colorbar\n",
        "        cbar.ax.yaxis.set_label_position('left')   # keep label aligned left of bar\n",
        "        cbar.set_label(\"Normalized Count\", rotation=0, labelpad=15)\n",
        "        cbar.ax.yaxis.set_label_coords(-1.2, 1.02)  # fine-tune position (x, y)\n",
        "\n",
        "        ax.set_title(f'Confusion Matrix: {model_name}', fontsize=16, fontweight='bold', pad=25)\n",
        "        ax.set_xlabel('Predicted Label', fontsize=14, fontweight='bold', labelpad=15)\n",
        "        ax.set_ylabel('True Label', fontsize=14, fontweight='bold', labelpad=15)\n",
        "\n",
        "        # Rotate labels for better readability\n",
        "        plt.xticks(rotation=45, ha='right', fontsize=12)\n",
        "        plt.yticks(rotation=0, fontsize=12)\n",
        "\n",
        "        # Add performance metrics as text\n",
        "        accuracy = accuracy_score(results['true_labels'], results['predictions'])\n",
        "        f1_macro = f1_score(results['true_labels'], results['predictions'], average='macro')\n",
        "        f1_weighted = f1_score(results['true_labels'], results['predictions'], average='weighted')\n",
        "\n",
        "        metrics_text = f'Accuracy: {accuracy:.4f}\\nF1 (Macro): {f1_macro:.4f}\\nF1 (Weighted): {f1_weighted:.4f}'\n",
        "        ax.text(1.15, 0.5, metrics_text, transform=ax.transAxes, fontsize=12,\n",
        "                verticalalignment='center', bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgray\", alpha=0.8))\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_enhanced_confusion_matrix.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced confusion matrix saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_roc_curves(self, results, model_name):\n",
        "        \"\"\"Plot ROC curves for multi-class classification.\"\"\"\n",
        "        import numpy as np\n",
        "        \"\"\"Enhanced ROC curves with better spacing and styling for multiclass\"\"\"\n",
        "        if 'true_labels' not in results or 'probabilities' not in results:\n",
        "            print(f\"Error: Missing 'true_labels' or 'probabilities' in results for {model_name}\")\n",
        "            return\n",
        "\n",
        "        fig, ax = plt.subplots(figsize=(12, 10))\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, Config.NUM_CLASSES))\n",
        "        probabilities = np.array(results['probabilities'])\n",
        "        if len(results['true_labels']) == 0 or probabilities.size == 0 or probabilities.ndim != 2 or probabilities.shape[1] != Config.NUM_CLASSES:\n",
        "            print(f\"Warning: Invalid or empty probabilities shape {probabilities.shape} for {model_name}. Skipping ROC plot.\")\n",
        "            ax.text(0.5, 0.5, 'No data available for ROC', horizontalalignment='center', verticalalignment='center', fontsize=12)\n",
        "            return\n",
        "        colors = plt.cm.Set3(np.linspace(0, 1, Config.NUM_CLASSES))\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            y_true_bin = (np.array(results['true_labels']) == i).astype(int)\n",
        "            y_score = probabilities[:, i]\n",
        "\n",
        "            fpr, tpr, _ = roc_curve(y_true_bin, y_score)\n",
        "            roc_auc = auc(fpr, tpr)\n",
        "            ax.plot(fpr, tpr, color=colors[i], linewidth=2,\n",
        "                    label=f'{Config.CLASS_LABELS[i]} (AUC = {roc_auc:.4f})')\n",
        "\n",
        "        # Diagonal line\n",
        "        ax.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.6, label='Random Classifier')\n",
        "\n",
        "        ax.set_title(f'{model_name} - ROC Curves', fontsize=16, fontweight='bold', pad=20)\n",
        "        ax.set_xlabel('False Positive Rate', fontsize=14, fontweight='bold', labelpad=10)\n",
        "        ax.set_ylabel('True Positive Rate', fontsize=14, fontweight='bold', labelpad=10)\n",
        "        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', frameon=True, shadow=True, fontsize=11)\n",
        "        ax.grid(True, alpha=0.3)\n",
        "        ax.set_xlim([0.0, 1.0])\n",
        "        ax.set_ylim([0.0, 1.05])\n",
        "\n",
        "        # Compute micro-average ROC curve\n",
        "        y_true_bin = label_binarize(results['true_labels'], classes=range(Config.NUM_CLASSES))\n",
        "        fpr_micro, tpr_micro, _ = roc_curve(y_true_bin.ravel(), results['probabilities'].ravel())\n",
        "        roc_auc_micro = auc(fpr_micro, tpr_micro)\n",
        "        ax.plot(fpr_micro, tpr_micro, 'deeppink', linestyle=':', linewidth=4,\n",
        "                label=f'Micro-average (AUC = {roc_auc_micro:.4f})')\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/{model_name}_enhanced_roc_curves.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced ROC curves saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_misclassified_images(self, misclassified, model_name):\n",
        "        \"\"\"Plot up to 4 misclassified images in a 2x2 grid with improved visibility.\"\"\"\n",
        "        import matplotlib.pyplot as plt\n",
        "        import numpy as np\n",
        "\n",
        "        if not misclassified:\n",
        "            print(f\"No misclassified images for {model_name}\")\n",
        "            return\n",
        "\n",
        "        # Select up to 4 misclassified images\n",
        "        misclassified = misclassified[:4]\n",
        "        fig, axes = plt.subplots(2, 2, figsize=(10, 10))  # Slightly smaller size\n",
        "        axes = axes.flatten()\n",
        "\n",
        "        for idx, item in enumerate(misclassified):\n",
        "            # image = item['image'].permute(1, 2, 0).cpu().numpy()  # Convert CHW -> HWC\n",
        "            image = item['image']\n",
        "            if isinstance(image, torch.Tensor):\n",
        "                image = image.permute(1, 2, 0).cpu().numpy()  # CHW -> HWC\n",
        "            elif isinstance(image, np.ndarray):\n",
        "                if image.shape[0] in [1, 3]:  # If channel-first\n",
        "                    image = np.transpose(image, (1, 2, 0))  # CHW -> HWC\n",
        "\n",
        "\n",
        "            # Normalize for display\n",
        "            if image.max() > 1.0:\n",
        "                image = image / 255.0\n",
        "            else:\n",
        "                image = (image - image.min()) / (image.max() - image.min() + 1e-8)\n",
        "            image = np.clip(image, 0, 1)\n",
        "\n",
        "            # Grayscale vs RGB\n",
        "            if image.shape[2] == 1:\n",
        "                image = image.squeeze()\n",
        "                axes[idx].imshow(image, cmap='gray')\n",
        "            else:\n",
        "                axes[idx].imshow(image)\n",
        "\n",
        "            # Titles with color\n",
        "            true_label = Config.CLASS_LABELS[item['true_label']]\n",
        "            pred_label = Config.CLASS_LABELS[item['pred_label']]\n",
        "            axes[idx].set_title(\n",
        "                f\"True: {true_label}\\nPred: {pred_label}\",\n",
        "                fontsize=9,\n",
        "                fontweight=\"bold\",\n",
        "                pad=10,\n",
        "                color=\"black\" #if true_label != pred_label else \"darkgreen\"\n",
        "            )\n",
        "\n",
        "            axes[idx].axis(\"off\")\n",
        "            # Add white border around each image\n",
        "            for spine in axes[idx].spines.values():\n",
        "                spine.set_edgecolor(\"lightgray\")\n",
        "                spine.set_linewidth(3)\n",
        "\n",
        "        # Hide unused subplots (if <4 images)\n",
        "        for idx in range(len(misclassified), 4):\n",
        "            axes[idx].axis(\"off\")\n",
        "\n",
        "        plt.suptitle(\n",
        "            f\"Misclassified Images for {model_name}\",\n",
        "            fontsize=12,\n",
        "            fontweight=\"bold\",\n",
        "            y=0.99,\n",
        "            color=\"black\"\n",
        "        )\n",
        "        plt.subplots_adjust(wspace=0.3, hspace=0.4)  # Increase padding between plots\n",
        "        save_path = f\"{self.viz_dir}/misclassified_{model_name}.png\"\n",
        "        plt.savefig(save_path, bbox_inches=\"tight\", dpi=300, facecolor=\"white\")\n",
        "        plt.show()\n",
        "        plt.close()\n",
        "        print(f\"Saved misclassified images plot for {model_name} at {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_kfold_results(self, fold_results, model_name, test_loader):\n",
        "        \"\"\"Plot k-fold results: 2x2 grid per fold and 1x2 comparison across folds.\"\"\"\n",
        "        n_folds = len(fold_results)\n",
        "        plt.style.use('seaborn-v0_8')  # Use modern Seaborn style\n",
        "\n",
        "        # 2x2 Grid Plot for Each Fold\n",
        "        for fold in range(n_folds):\n",
        "            fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "            fig.suptitle(f'{model_name} - Fold {fold+1} Metrics', fontsize=16)\n",
        "            history = fold_results[fold]['history']\n",
        "\n",
        "            # Plot Validation Accuracy\n",
        "            axes[0, 0].plot(history['val_acc'], label='Validation Accuracy', marker='s')\n",
        "            axes[0, 0].set_title('Validation Accuracy')\n",
        "            axes[0, 0].set_xlabel('Epoch')\n",
        "            axes[0, 0].set_ylabel('Accuracy')\n",
        "            axes[0, 0].legend()\n",
        "            axes[0, 0].grid(True)\n",
        "\n",
        "            # Plot Validation Loss\n",
        "            axes[0, 1].plot(history['val_loss'], label='Validation Loss', marker='s')\n",
        "            axes[0, 1].set_title('Validation Loss')\n",
        "            axes[0, 1].set_xlabel('Epoch')\n",
        "            axes[0, 1].set_ylabel('Loss')\n",
        "            axes[0, 1].legend()\n",
        "            axes[0, 1].grid(True)\n",
        "\n",
        "            # Hide unused subplots\n",
        "            axes[1, 0].set_visible(False)\n",
        "            axes[1, 1].set_visible(False)\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()\n",
        "\n",
        "        # 1x2 Comparison Plot Across Folds\n",
        "        fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
        "        fig.suptitle(f'{model_name} - Cross-Fold Comparison', fontsize=16)\n",
        "\n",
        "        # Plot Validation Accuracy Across Folds\n",
        "        for fold in range(n_folds):\n",
        "            history = fold_results[fold]['history']\n",
        "            axes[0].plot(history['val_acc'], label=f'Fold {fold+1}', marker='s')\n",
        "        axes[0].set_title('Validation Accuracy Across Folds')\n",
        "        axes[0].set_xlabel('Epoch')\n",
        "        axes[0].set_ylabel('Accuracy')\n",
        "        axes[0].legend()\n",
        "        axes[0].grid(True)\n",
        "\n",
        "        # Plot Validation Loss Across Folds\n",
        "        for fold in range(n_folds):\n",
        "            history = fold_results[fold]['history']\n",
        "            axes[1].plot(history['val_loss'], label=f'Fold {fold+1}', marker='s')\n",
        "        axes[1].set_title('Validation Loss Across Folds')\n",
        "        axes[1].set_xlabel('Epoch')\n",
        "        axes[1].set_ylabel('Loss')\n",
        "        axes[1].legend()\n",
        "        axes[1].grid(True)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def plot_model_results(self, model_name, fold_results, test_loader):\n",
        "        \"\"\"Plot model results: ROC curves, confusion matrix, misclassified images, XAI, and k-fold results.\"\"\"\n",
        "        print(f\"Generating plots for {model_name}\")\n",
        "\n",
        "        # Plot single-model results using first fold's result\n",
        "        first_result = fold_results[0]['result']\n",
        "        self.plot_roc_curves(first_result, model_name)\n",
        "        self.plot_confusion_matrix(first_result, model_name)\n",
        "        self.plot_misclassified_images(first_result['misclassified'], model_name)\n",
        "\n",
        "        # Recreate model for XAI plotting\n",
        "        model = ModelFactory.create_model(\n",
        "            model_name,\n",
        "            num_classes=Config.NUM_CLASSES,\n",
        "            dropout_rate=0.5,  # Use default or pass from hyperparameters\n",
        "            hidden_dim_multiplier=0.5\n",
        "        ).to(Config.DEVICE)\n",
        "        self.plot_single_model_xai(model, model_name, test_loader)\n",
        "\n",
        "        # Plot k-fold results\n",
        "        self.plot_kfold_results(fold_results, model_name, test_loader)\n",
        "\n",
        "        print(\"Completed plotting k-fold results\")\n",
        "\n",
        "        # Clean up\n",
        "        del model, fold_results, first_result\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.cuda.synchronize()\n",
        "        gc.collect()\n",
        "        # print(f\"Plotting memory cleared: {torch.cuda.memory_summary()}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def generate_comprehensive_report(self, single_results, ensemble_results, best_ensemble):\n",
        "        \"\"\"Generate a comprehensive visual report\"\"\"\n",
        "        # fig = plt.figure(figsize=(24, 16))\n",
        "        fig = plt.figure(figsize=(30, 20))\n",
        "        gs = fig.add_gridspec(3, 4, hspace=0.4, wspace=0.3, top=0.92, bottom=0.08, left=0.05, right=0.95)\n",
        "\n",
        "        # Title\n",
        "        fig.suptitle('Fish Species Classification - Comprehensive Analysis Report',\n",
        "                    fontsize=24, fontweight='bold', y=0.96)\n",
        "\n",
        "        # 1. Model Performance Comparison\n",
        "        ax1 = fig.add_subplot(gs[0, :2])\n",
        "        model_names = list(single_results.keys())\n",
        "        accuracies = [single_results[name]['accuracy'] for name in model_names]\n",
        "        f1_scores = [single_results[name]['f1_macro'] for name in model_names]\n",
        "\n",
        "        x = np.arange(len(model_names))\n",
        "        width = 0.35\n",
        "\n",
        "        bars1 = ax1.bar(x - width/2, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "        bars2 = ax1.bar(x + width/2, f1_scores, width, label='F1 Score', alpha=0.8, color='lightcoral')\n",
        "\n",
        "        ax1.set_xlabel('Models', fontweight='bold', fontsize=12)\n",
        "        ax1.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "        ax1.set_title('Individual Model Performance', fontweight='bold', fontsize=14, pad=15)\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "        ax1.legend(fontsize=11)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, 1.1)\n",
        "\n",
        "        # Add value labels on bars\n",
        "        for bar in bars1 + bars2:\n",
        "            height = bar.get_height()\n",
        "            ax1.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "                    f'{height:.4f}', ha='center', va='bottom', fontsize=9)\n",
        "\n",
        "        # 2. Best vs Worst Model Comparison\n",
        "        ax2 = fig.add_subplot(gs[0, 2:])\n",
        "        if ensemble_results and best_ensemble:\n",
        "            best_single_f1 = max(f1_scores)\n",
        "            worst_single_f1 = min(f1_scores)\n",
        "            best_ensemble_f1 = best_ensemble[1]['f1']\n",
        "\n",
        "            categories = ['Worst Single', 'Best Single', 'Best Ensemble']\n",
        "            values = [worst_single_f1, best_single_f1, best_ensemble_f1]\n",
        "            colors = ['lightcoral', 'lightblue', 'gold']\n",
        "\n",
        "            bars = ax2.bar(categories, values, color=colors, alpha=0.8)\n",
        "            ax2.set_ylabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax2.set_title('Performance Comparison', fontweight='bold', fontsize=14, pad=15)\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.set_ylim(0, max(values) * 1.1)\n",
        "\n",
        "            for bar, value in zip(bars, values):\n",
        "                ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
        "                        f'{value:.4f}', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "        # 3. Per-class Performance Heatmap\n",
        "        ax3 = fig.add_subplot(gs[1, :2])\n",
        "        per_class_f1 = []\n",
        "        for model_name in model_names:\n",
        "            per_class_f1.append(single_results[model_name]['f1_per_class'])\n",
        "\n",
        "        per_class_f1 = np.array(per_class_f1)\n",
        "        im = ax3.imshow(per_class_f1, cmap='RdYlGn', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "        ax3.set_xticks(range(len(Config.CLASS_LABELS)))\n",
        "        ax3.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right')\n",
        "        ax3.set_yticks(range(len(model_names)))\n",
        "        ax3.set_yticklabels(model_names)\n",
        "        ax3.set_title('Per-Class F1 Scores Heatmap', fontweight='bold', fontsize=14, pad=15)\n",
        "\n",
        "        # Add colorbar\n",
        "        cbar = plt.colorbar(im, ax=ax3, shrink=0.8)\n",
        "        cbar.set_label('F1 Score', rotation=270, labelpad=15)\n",
        "\n",
        "        # Add text annotations\n",
        "        for i in range(len(model_names)):\n",
        "            for j in range(len(Config.CLASS_LABELS)):\n",
        "                text_color = 'white' if per_class_f1[i, j] < 0.5 else 'black'\n",
        "                ax3.text(j, i, f'{per_class_f1[i, j]:.2f}',\n",
        "                        ha=\"center\", va=\"center\", color=text_color, fontsize=8, fontweight='bold')\n",
        "\n",
        "        # 4. Ensemble Methods Performance\n",
        "        ax4 = fig.add_subplot(gs[1, 2:])\n",
        "        if ensemble_results:\n",
        "            ensemble_items = list(ensemble_results.items())\n",
        "            ensemble_items.sort(key=lambda x: x[1]['f1'], reverse=True)\n",
        "            top_ensembles = ensemble_items[:8]\n",
        "\n",
        "            ensemble_names = [name.split('_')[-1] for name, _ in top_ensembles]\n",
        "            ensemble_f1s = [result['f1'] for _, result in top_ensembles]\n",
        "\n",
        "            bars = ax4.barh(range(len(ensemble_names)), ensemble_f1s, alpha=0.8, color='lightgreen')\n",
        "            ax4.set_yticks(range(len(ensemble_names)))\n",
        "            ax4.set_yticklabels(ensemble_names)\n",
        "            ax4.set_xlabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax4.set_title('Top Ensemble Methods', fontweight='bold', fontsize=14, pad=15)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "\n",
        "            for bar, value in zip(bars, ensemble_f1s):\n",
        "                ax4.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2,\n",
        "                        f'{value:.4f}', ha='left', va='center', fontsize=9, fontweight='bold')\n",
        "\n",
        "        # 5. Summary Statistics Table\n",
        "        ax5 = fig.add_subplot(gs[2, :])\n",
        "        ax5.axis('off')\n",
        "\n",
        "        # Create summary data\n",
        "        summary_data = []\n",
        "        for model_name in model_names:\n",
        "            result = single_results[model_name]\n",
        "            summary_data.append([\n",
        "                model_name,\n",
        "                f\"{result['accuracy']:.4f}\",\n",
        "                f\"{result['f1_macro']:.4f}\",\n",
        "                f\"{result['f1_weighted']:.4f}\",\n",
        "                f\"{result['precision_macro']:.4f}\",\n",
        "                f\"{result['recall_macro']:.4f}\"\n",
        "            ])\n",
        "\n",
        "        if ensemble_results and best_ensemble:\n",
        "            best_result = best_ensemble[1]\n",
        "            summary_data.append([\n",
        "                f\"Best Ensemble\\n({best_ensemble[0]})\",\n",
        "                f\"{best_result['accuracy']:.4f}\",\n",
        "                f\"{best_result['f1']:.4f}\",\n",
        "                \"N/A\",\n",
        "                \"N/A\",\n",
        "                \"N/A\"\n",
        "            ])\n",
        "\n",
        "        columns = ['Model', 'Accuracy', 'F1 (Macro)', 'F1 (Weighted)', 'Precision', 'Recall']\n",
        "\n",
        "        table = ax5.table(cellText=summary_data, colLabels=columns, loc='center', cellLoc='center')\n",
        "        table.auto_set_font_size(False)\n",
        "        table.set_fontsize(10)\n",
        "        table.scale(1.2, 2)\n",
        "\n",
        "        # Style the table\n",
        "        for i in range(len(columns)):\n",
        "            table[(0, i)].set_facecolor('#4CAF50')\n",
        "            table[(0, i)].set_text_props(weight='bold', color='white')\n",
        "\n",
        "        for i in range(1, len(summary_data) + 1):\n",
        "            for j in range(len(columns)):\n",
        "                if i % 2 == 0:\n",
        "                    table[(i, j)].set_facecolor('#f0f0f0')\n",
        "                else:\n",
        "                    table[(i, j)].set_facecolor('white')\n",
        "\n",
        "        ax5.set_title('Model Performance Summary', fontweight='bold', fontsize=16, pad=20)\n",
        "\n",
        "        save_path = f\"{self.viz_dir}/comprehensive_report.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Comprehensive report saved: {save_path}\")\n",
        "        return save_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_model_comparison(self, single_results, ensemble_results):\n",
        "        \"\"\"Enhanced model comparison with better spacing\"\"\"\n",
        "        # fig = plt.figure(figsize=(20, 16))\n",
        "        fig = plt.figure(figsize=(30, 20))\n",
        "        gs = fig.add_gridspec(2, 2, hspace=0.4, wspace=0.3, top=0.92, bottom=0.08)\n",
        "\n",
        "        model_names = list(single_results.keys())\n",
        "        accuracies = [single_results[name]['accuracy'] for name in model_names]\n",
        "        f1_scores = [single_results[name]['f1_macro'] for name in model_names]\n",
        "        f1_weighted = [single_results[name]['f1_weighted'] for name in model_names]\n",
        "        # losses = [single_results[name]['loss'] for name in model_names]\n",
        "        # Use f1_macro as substitute since loss is not available in single_results\n",
        "        losses = [1 - single_results[name]['f1_macro'] for name in model_names]  # Convert F1 to loss-like metric\n",
        "\n",
        "        x = np.arange(len(model_names))\n",
        "        width = 0.2\n",
        "\n",
        "        ax1 = fig.add_subplot(gs[0, 0])\n",
        "        bars1 = ax1.bar(x - width*1.5, accuracies, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "        bars2 = ax1.bar(x - width/2, f1_scores, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "        bars3 = ax1.bar(x + width/2, f1_weighted, width, label='F1 (Weighted)', alpha=0.8, color='lightgreen')\n",
        "        bars4 = ax1.bar(x + width*1.5, losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "        ax1.set_xlabel('Models', fontweight='bold', fontsize=12)\n",
        "        ax1.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "        ax1.set_title('Individual Model Performance', fontweight='bold', fontsize=14, pad=20)\n",
        "        ax1.set_xticks(x)\n",
        "        ax1.set_xticklabels(model_names, rotation=45, ha='right', fontsize=10)\n",
        "        ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "        ax1.set_ylim(0, max(max(accuracies), max(f1_scores), max(f1_weighted), max(losses)) * 1.1)\n",
        "\n",
        "        if ensemble_results:\n",
        "            ensemble_items = list(ensemble_results.items())\n",
        "            ensemble_items.sort(key=lambda x: x[1]['f1'], reverse=True)\n",
        "            top_ensembles = ensemble_items[:10]\n",
        "\n",
        "            ensemble_names = [name.split('_')[-1] for name, _ in top_ensembles]\n",
        "            ensemble_f1s = [result['f1'] for _, result in top_ensembles]\n",
        "            ensemble_accs = [result['accuracy'] for _, result in top_ensembles]\n",
        "            ensemble_losses = [result['loss'] for _, result in top_ensembles]\n",
        "\n",
        "            x = np.arange(len(ensemble_names))\n",
        "            ax2 = fig.add_subplot(gs[0, 1])\n",
        "            ax2.bar(x - width, ensemble_accs, width, label='Accuracy', alpha=0.8, color='skyblue')\n",
        "            ax2.bar(x, ensemble_f1s, width, label='F1 (Macro)', alpha=0.8, color='lightcoral')\n",
        "            ax2.bar(x + width, ensemble_losses, width, label='Loss', alpha=0.8, color='salmon')\n",
        "\n",
        "            ax2.set_xticks(x)\n",
        "            ax2.set_xticklabels([f\"{name}\" for name in ensemble_names], rotation=45, ha='right', fontsize=10)\n",
        "            ax2.set_xlabel('Ensemble Methods', fontweight='bold', fontsize=12)\n",
        "            ax2.set_ylabel('Score', fontweight='bold', fontsize=12)\n",
        "            ax2.set_title('Top Ensemble Methods', fontweight='bold', fontsize=14, pad=20)\n",
        "            ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=10)\n",
        "            ax2.grid(True, alpha=0.3)\n",
        "            ax2.set_ylim(0, max(max(ensemble_accs), max(ensemble_f1s), max(ensemble_losses)) * 1.1)\n",
        "\n",
        "        if single_results:\n",
        "            per_class_f1 = []\n",
        "            for model_name in model_names:\n",
        "                per_class_f1.append(single_results[model_name]['f1_per_class'])\n",
        "\n",
        "            per_class_f1 = np.array(per_class_f1)\n",
        "            ax3 = fig.add_subplot(gs[1, 0])\n",
        "            im = ax3.imshow(per_class_f1, cmap='RdYlBu_r', aspect='auto', vmin=0, vmax=1)\n",
        "\n",
        "            ax3.set_xticks(range(len(Config.CLASS_LABELS)))\n",
        "            ax3.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right', fontsize=10)\n",
        "            ax3.set_yticks(range(len(model_names)))\n",
        "            ax3.set_yticklabels(model_names, fontsize=10)\n",
        "            ax3.set_title('Per-Class F1 Scores', fontweight='bold', fontsize=14, pad=20)\n",
        "\n",
        "            cbar = plt.colorbar(im, ax=ax3, shrink=0.8)\n",
        "            cbar.set_label('F1 Score', rotation=270, labelpad=15)\n",
        "\n",
        "            for i in range(len(model_names)):\n",
        "                for j in range(len(Config.CLASS_LABELS)):\n",
        "                    text_color = 'white' if per_class_f1[i, j] < 0.5 else 'black'\n",
        "                    ax3.text(j, i, f'{per_class_f1[i, j]:.2f}',\n",
        "                            ha=\"center\", va=\"center\", color=text_color, fontsize=8)\n",
        "\n",
        "        if ensemble_results:\n",
        "            best_single_f1 = max(f1_scores)\n",
        "            best_single_name = model_names[f1_scores.index(best_single_f1)]\n",
        "            best_ensemble_f1 = max([result['f1'] for result in ensemble_results.values()])\n",
        "            best_ensemble_name = max(ensemble_results.items(), key=lambda x: x[1]['f1'])[0]\n",
        "\n",
        "            ax4 = fig.add_subplot(gs[1, 1])\n",
        "            categories = ['Best Single\\nModel', 'Best Ensemble']\n",
        "            values = [best_single_f1, best_ensemble_f1]\n",
        "            colors = ['lightblue', 'gold']\n",
        "\n",
        "            bars = ax4.bar(categories, values, color=colors, alpha=0.8, width=0.6)\n",
        "            ax4.set_ylabel('F1 Score', fontweight='bold', fontsize=12)\n",
        "            ax4.set_title('Single vs Ensemble Comparison', fontweight='bold', fontsize=14, pad=20)\n",
        "            ax4.grid(True, alpha=0.3)\n",
        "            ax4.set_ylim(0, 1)\n",
        "\n",
        "            for bar, value in zip(bars, values):\n",
        "                ax4.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.02,\n",
        "                        f'{value:.4f}', ha='center', va='bottom', fontweight='bold', fontsize=12)\n",
        "\n",
        "            improvement = ((best_ensemble_f1 - best_single_f1) / best_single_f1) * 100\n",
        "            ax4.text(0.5, 0.5, f'Improvement:\\n{improvement:.2f}%',\n",
        "                    transform=ax4.transAxes, ha='center', va='center',\n",
        "                    fontsize=14, fontweight='bold',\n",
        "                    bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"yellow\", alpha=0.8))\n",
        "\n",
        "        plt.suptitle('Fish Species Classification - Model Comparison Analysis',\n",
        "                    fontsize=18, fontweight='bold', y=0.96)\n",
        "        save_path = f\"{self.viz_dir}/enhanced_model_comparison.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"Enhanced model comparison saved: {save_path}\")\n",
        "        return save_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_lrp_grid(self, single_models, test_loader):\n",
        "        print(\"Generating LRP grid visualization for TP, TN, FP, FN...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # Compute predictions and confusion matrix\n",
        "        model = list(single_models.values())[0]\n",
        "        model.eval()\n",
        "        true_labels = []\n",
        "        pred_labels = []\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                # images, labels = batch['image'].to(Config.DEVICE), batch['label'].to(Config.DEVICE)\n",
        "                # images, labels = batch[0].to(Config.DEVICE), batch[1].to(Config.DEVICE)  # Access tuple elements\n",
        "                # Make it consistent with your data loader format:\n",
        "                if isinstance(batch, dict):\n",
        "                    images, labels = batch['image'].to(Config.DEVICE), batch['label'].to(Config.DEVICE)\n",
        "                elif isinstance(batch, (list, tuple)) and len(batch) == 2:\n",
        "                    images, labels = batch[0].to(Config.DEVICE), batch[1].to(Config.DEVICE)\n",
        "                else:\n",
        "                    raise ValueError(f\"Unexpected batch format: {type(batch)}\")\n",
        "\n",
        "                outputs = model(images)\n",
        "                preds = outputs.argmax(dim=1) if outputs.dim() > 1 else (outputs > 0.5).float()\n",
        "                true_labels.extend(labels.cpu().numpy())\n",
        "                pred_labels.extend(preds.cpu().numpy())\n",
        "\n",
        "        cm = confusion_matrix(true_labels, pred_labels)\n",
        "        classes = Config.CLASS_LABELS\n",
        "        tp = np.diag(cm)\n",
        "        fp = cm.sum(axis=0) - tp\n",
        "        fn = cm.sum(axis=1) - tp\n",
        "        tn = cm.sum() - (fp + fn + tp)\n",
        "        metrics = [tp, tn, fp, fn]\n",
        "\n",
        "        # Collect one image per class per category (TP, TN, FP, FN)\n",
        "        sample_images = {cls: {\"TP\": None, \"TN\": None, \"FP\": None, \"FN\": None} for cls in range(5)}\n",
        "        with torch.no_grad():\n",
        "            for batch in test_loader:\n",
        "                # images, labels = batch['image'].to(Config.DEVICE), batch['label'].to(Config.DEVICE)\n",
        "                # images, labels = batch[0].to(Config.DEVICE), batch[1].to(Config.DEVICE)  # Access tuple elements\n",
        "                # Make it consistent with your data loader format:\n",
        "                if isinstance(batch, dict):\n",
        "                    images, labels = batch['image'].to(Config.DEVICE), batch['label'].to(Config.DEVICE)\n",
        "                elif isinstance(batch, (list, tuple)) and len(batch) == 2:\n",
        "                    images, labels = batch[0].to(Config.DEVICE), batch[1].to(Config.DEVICE)\n",
        "                else:\n",
        "                    raise ValueError(f\"Unexpected batch format: {type(batch)}\")\n",
        "\n",
        "\n",
        "\n",
        "                outputs = model(images)\n",
        "                preds = outputs.argmax(dim=1) if outputs.dim() > 1 else (outputs > 0.5).float()\n",
        "                for img, true, pred in zip(images, labels, preds):\n",
        "                    cls = int(true.item())\n",
        "                    pred_cls = int(pred.item())\n",
        "                    for i in range(5):  # Check for each class\n",
        "                        category = {\n",
        "                            (1, 1): \"TP\",  # Predicted class i, true class i\n",
        "                            (0, 0): \"TN\",  # Predicted not i, true not i\n",
        "                            (1, 0): \"FP\",  # Predicted i, true not i\n",
        "                            (0, 1): \"FN\"   # Predicted not i, true i\n",
        "                        }[(1 if pred_cls == i else 0, 1 if cls == i else 0)]\n",
        "                        if sample_images[cls][category] is None:\n",
        "                            sample_images[cls][category] = (img, true)\n",
        "                    if all(sample_images[c][cat] is not None for c in range(5) for cat in [\"TP\", \"TN\", \"FP\", \"FN\"]):\n",
        "                        break\n",
        "                if all(sample_images[c][cat] is not None for c in range(5) for cat in [\"TP\", \"TN\", \"FP\", \"FN\"]):\n",
        "                    break\n",
        "\n",
        "        # Visualization\n",
        "        fig, axes = plt.subplots(5, 4, figsize=(30, 35))  # Large figure for clarity\n",
        "        for i in range(5):  # Classes\n",
        "            for j, category in enumerate([\"TP\", \"TN\", \"FP\", \"FN\"]):\n",
        "                ax = axes[i, j]\n",
        "                if sample_images[i][category] is not None:\n",
        "                    img, true = sample_images[i][category]\n",
        "                    img = img.squeeze().cpu()\n",
        "                    lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, img, i)\n",
        "                    img = img.permute(1, 2, 0).numpy()\n",
        "                    img = np.clip(img, 0, 1)\n",
        "                    img = img[..., [2, 1, 0]] if img.shape[2] == 3 else img  # Convert BGR to RGB\n",
        "                    img = (img * 255).astype(np.uint8)\n",
        "                    ax.imshow(img)\n",
        "                    lrp_img = (lrp_img - lrp_img.min()) / (lrp_img.max() - lrp_img.min() + 1e-8)  # Normalize heatmap\n",
        "                    ax.imshow(lrp_img, cmap='jet', alpha=0.4, vmin=0, vmax=np.percentile(lrp_img, 95))\n",
        "                    ax.set_title(f'{classes[i]} - {category}: {metrics[j][i]}', fontsize=16, fontweight='bold', pad=10)\n",
        "                ax.axis('off')\n",
        "\n",
        "        plt.tight_layout()\n",
        "        save_path = f\"{self.viz_dir}/lrp_fish_metrics_grid.png\"\n",
        "        plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "        plt.show()\n",
        "        print(f\"LRP grid visualization saved: {save_path}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def plot_comparative_xai(self, single_models, ensemble_results, test_loader, max_images=5):\n",
        "        \"\"\"Generate comparative XAI visualizations with Grad-CAM++, Integrated Gradients, and LRP in the same row\"\"\"\n",
        "        print(f\"Generating comparative XAI visualizations for {max_images} images...\")\n",
        "        xai_visualizer = XAIVisualizer()\n",
        "\n",
        "        # Get sample images\n",
        "        # sample_images, sample_labels = next(iter(test_loader))\n",
        "        # sample_images = sample_images[:max_images].to(Config.DEVICE)\n",
        "        # sample_labels = sample_labels[:max_images].numpy()\n",
        "        sample_images = []\n",
        "        sample_labels = []\n",
        "        for i in range(Config.NUM_CLASSES):\n",
        "            class_mask = np.where(test_loader.dataset.labels == i)[0]\n",
        "            if len(class_mask) > 0:\n",
        "                idx = np.random.choice(class_mask)\n",
        "                image, label = test_loader.dataset[idx]\n",
        "                if image.dim() == 4:\n",
        "                    image = image.squeeze(0)\n",
        "                sample_images.append(image.to(Config.DEVICE))\n",
        "                sample_labels.append(label)\n",
        "        sample_images = sample_images[:max_images]\n",
        "        sample_labels = sample_labels[:max_images]\n",
        "\n",
        "        # Get best ensemble if available\n",
        "        best_ensemble_name = max(ensemble_results.items(), key=lambda x: x[1]['f1'])[0] if ensemble_results else None\n",
        "        best_ensemble = ensemble_results.get(best_ensemble_name, None) if best_ensemble_name else None\n",
        "\n",
        "        for idx, (image, true_label) in enumerate(zip(sample_images, sample_labels)):\n",
        "            try:\n",
        "                # Adjusted figure size with more height per row to prevent text cropping\n",
        "                num_rows = len(single_models) + (1 if best_ensemble else 0)\n",
        "                fig = plt.figure(figsize=(36, 14 * num_rows))  # Increased width and height per row\n",
        "                gs = fig.add_gridspec(num_rows, 4, wspace=0.3, hspace=0.5)  # Increased wspace and hspace for better spacing\n",
        "\n",
        "                # Prepare original image\n",
        "                image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "                # Plot original image spanning all rows in first column\n",
        "                ax_orig = fig.add_subplot(gs[:, 0])\n",
        "                ax_orig.imshow(image_np)\n",
        "                ax_orig.set_title(f'Original Image\\nTrue: {Config.CLASS_LABELS[true_label]}',\n",
        "                                fontsize=16, fontweight='bold', pad=30)  # Increased pad for title\n",
        "                ax_orig.axis('off')\n",
        "\n",
        "                # Plot XAI for single models\n",
        "                for row, (model_name, model) in enumerate(single_models.items()):\n",
        "                    model.eval()\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(image.unsqueeze(0))\n",
        "                        probabilities = torch.softmax(outputs, dim=1)\n",
        "                        predicted_class = outputs.argmax(dim=1).item()\n",
        "                        confidence = probabilities[0, predicted_class].item()\n",
        "                        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                    # Generate Grad-CAM++ visualization\n",
        "                    gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(model, image, predicted_class)\n",
        "\n",
        "                    # Plot Grad-CAM++ in second column\n",
        "                    ax_gradcam = fig.add_subplot(gs[row, 1])\n",
        "                    ax_gradcam.imshow(gradcam_img)\n",
        "                    ax_gradcam.set_title(f'{model_name}\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                        fontsize=14, fontweight='bold', pad=30)  # Increased pad\n",
        "                    ax_gradcam.axis('off')\n",
        "\n",
        "                    # Generate Integrated Gradients visualization\n",
        "                    ig_img, _ = xai_visualizer.integrated_gradients(model, image, predicted_class)\n",
        "\n",
        "                    # Plot Integrated Gradients in third column\n",
        "                    ax_ig = fig.add_subplot(gs[row, 2])\n",
        "                    ax_ig.imshow(ig_img)\n",
        "                    ax_ig.set_title(f'{model_name}\\nIntegrated Gradients', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_ig.axis('off')\n",
        "\n",
        "                    # Generate LRP visualization\n",
        "                    lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(model, image, predicted_class)\n",
        "\n",
        "                    # Plot LRP in fourth column\n",
        "                    ax_lrp = fig.add_subplot(gs[row, 3])\n",
        "                    # ax_lrp.imshow(lrp_img)\n",
        "                    ax_lrp.imshow(cv2.cvtColor(lrp_img, cv2.COLOR_BGR2RGB))\n",
        "                    ax_lrp.set_title(f'{model_name}\\nLRP', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_lrp.axis('off')\n",
        "\n",
        "                # Plot XAI for best ensemble (if available)\n",
        "                if best_ensemble:\n",
        "                    ensemble_models = best_ensemble['models']\n",
        "                    with torch.no_grad():\n",
        "                        model_probs = []\n",
        "                        for model_name in ensemble_models:\n",
        "                            model = single_models[model_name]\n",
        "                            outputs = model(image.unsqueeze(0))\n",
        "                            probs = torch.softmax(outputs, dim=1)\n",
        "                            model_probs.append(probs)\n",
        "                        model_probs = torch.stack(model_probs, dim=1)\n",
        "\n",
        "                        # Load learnable ensemble model if applicable\n",
        "                        if 'learnable_weighted' in best_ensemble_name:\n",
        "                            ensemble_model = LearnableWeightedEnsemble(\n",
        "                                num_models=len(ensemble_models),\n",
        "                                num_classes=Config.NUM_CLASSES\n",
        "                            ).to(Config.DEVICE)\n",
        "                            # ensemble_model.load_state_dict(\n",
        "                            #     torch.load(f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(ensemble_models)}.pt\")\n",
        "                            # )\n",
        "                            # PROBLEM: This line tries to load a model that may not exist\n",
        "                            # FIX: Add error handling and fallback\n",
        "                            try:\n",
        "                                model_path = f\"{Config.OUTPUT_DIR}/models/learnable_ensemble_{'+'.join(ensemble_models)}.pt\"\n",
        "                                if os.path.exists(model_path):\n",
        "                                    ensemble_model.load_state_dict(torch.load(model_path, map_location=Config.DEVICE))\n",
        "                                else:\n",
        "                                    # Fallback to simple weighted average if no saved learnable model\n",
        "                                    weights = best_ensemble.get('weights', np.ones(len(ensemble_models)) / len(ensemble_models))\n",
        "                                    outputs = torch.sum(model_probs * torch.tensor(weights, device=Config.DEVICE).view(1, -1, 1), dim=1)\n",
        "                                    predicted_class = outputs.argmax(dim=1).item()\n",
        "                                    confidence = torch.softmax(outputs, dim=1)[0, predicted_class].item()\n",
        "                            except Exception as e:\n",
        "                                print(f\"Error loading learnable ensemble model: {e}, using simple averaging\")\n",
        "                                weights = best_ensemble.get('weights', np.ones(len(ensemble_models)) / len(ensemble_models))\n",
        "                                outputs = torch.sum(model_probs * torch.tensor(weights, device=Config.DEVICE).view(1, -1, 1), dim=1)\n",
        "                                predicted_class = outputs.argmax(dim=1).item()\n",
        "                                confidence = torch.softmax(outputs, dim=1)[0, predicted_class].item()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "                            ensemble_model.eval()\n",
        "                            # outputs, _ = ensemble_model(model_probs)\n",
        "                            # TO THIS (ensure correct input format):\n",
        "                            if model_probs.dim() == 3:  # Already correct format\n",
        "                                outputs, learned_weights = ensemble_model(model_probs)\n",
        "                            else:  # Need to reshape\n",
        "                                model_probs_reshaped = model_probs.view(1, len(ensemble_models), Config.NUM_CLASSES)\n",
        "                                outputs, learned_weights = ensemble_model(model_probs_reshaped)\n",
        "\n",
        "                        else:\n",
        "                            weights = best_ensemble.get('weights', np.ones(len(ensemble_models)) / len(ensemble_models))\n",
        "                            outputs = torch.sum(model_probs * torch.tensor(weights, device=Config.DEVICE).view(1, -1, 1), dim=1)\n",
        "\n",
        "                        predicted_class = outputs.argmax(dim=1).item()\n",
        "                        confidence = torch.softmax(outputs, dim=1)[0, predicted_class].item()\n",
        "                        predicted_label = Config.CLASS_LABELS[predicted_class]\n",
        "\n",
        "                    # Approximate ensemble Grad-CAM++ by averaging\n",
        "                    gradcam_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        gradcam_img, _ = xai_visualizer.grad_cam_plus_plus(single_models[model_name], image, predicted_class)\n",
        "                        gradcam_imgs.append(gradcam_img)\n",
        "                    ensemble_gradcam = np.mean(gradcam_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble Grad-CAM++ in second column\n",
        "                    ax_gradcam = fig.add_subplot(gs[num_rows-1, 1])\n",
        "                    ax_gradcam.imshow(ensemble_gradcam)\n",
        "                    ax_gradcam.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nGrad-CAM++\\nPred: {predicted_label}\\nConf: {confidence:.2%}',\n",
        "                                        fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_gradcam.axis('off')\n",
        "\n",
        "                    # Approximate ensemble Integrated Gradients by averaging\n",
        "                    ig_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        ig_img, _ = xai_visualizer.integrated_gradients(single_models[model_name], image, predicted_class)\n",
        "                        ig_imgs.append(ig_img)\n",
        "                    ensemble_ig = np.mean(ig_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble Integrated Gradients in third column\n",
        "                    ax_ig = fig.add_subplot(gs[num_rows-1, 2])\n",
        "                    ax_ig.imshow(ensemble_ig)\n",
        "                    ax_ig.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nIntegrated Gradients', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_ig.axis('off')\n",
        "\n",
        "                    # Approximate ensemble LRP by averaging\n",
        "                    lrp_imgs = []\n",
        "                    for model_name in ensemble_models:\n",
        "                        lrp_img, _ = xai_visualizer.layer_wise_relevance_propagation(single_models[model_name], image, predicted_class)\n",
        "                        lrp_imgs.append(lrp_img)\n",
        "                    ensemble_lrp = np.mean(lrp_imgs, axis=0).astype(np.uint8)\n",
        "\n",
        "                    # Plot ensemble LRP in fourth column\n",
        "                    ax_lrp = fig.add_subplot(gs[num_rows-1, 3])\n",
        "                    ax_lrp.imshow(ensemble_lrp)\n",
        "                    ax_lrp.set_title(f'Best Ensemble ({best_ensemble_name.split(\"_\")[-1]})\\nLRP', fontsize=14, fontweight='bold', pad=30)\n",
        "                    ax_lrp.axis('off')\n",
        "\n",
        "                # Adjusted suptitle with increased padding\n",
        "                plt.suptitle(f'Comparative XAI Analysis - Image {idx+1}', fontsize=18, fontweight='bold', y=0.97)\n",
        "                plt.tight_layout(rect=[0, 0, 1, 0.95])  # Added rect to ensure suptitle is not cropped\n",
        "                save_path = f\"{self.viz_dir}/comparative_xai_image_{idx+1}.png\"\n",
        "                plt.savefig(save_path, dpi=300, bbox_inches='tight', facecolor='white', edgecolor='none')\n",
        "                plt.show()\n",
        "                print(f\"Comparative XAI visualization saved: {save_path}\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error generating comparative XAI for image {idx+1}: {e}\")\n",
        "                continue\n",
        "\n",
        "\n",
        "\n",
        "# Purpose: Implement corrected Grad-CAM++ and Gradiant_Base & LRP with proper tensor handling.\n",
        "\n",
        "class XAIVisualizer:\n",
        "    @staticmethod\n",
        "    def grad_cam_plus_plus(model, image, target_class):\n",
        "        \"\"\"Implement Grad-CAM++ for visualizing important image regions.\"\"\"\n",
        "        if image.dim() == 4:\n",
        "            image = image.squeeze(0)  # Normalize to (C, H, W)\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Find the last convolutional layer\n",
        "        target_layer = None\n",
        "        for name, module in model.named_modules():  # Corrected: removed redundant reversed\n",
        "            if isinstance(module, nn.Conv2d):\n",
        "                target_layer = module\n",
        "\n",
        "        if target_layer is None:\n",
        "            raise ValueError(\"No convolutional layer found in the model\")\n",
        "\n",
        "        # Hook to capture gradients and activations\n",
        "        gradients = []\n",
        "        activations = []\n",
        "\n",
        "        def forward_hook(module, input, output):\n",
        "            activations.append(output.detach())\n",
        "\n",
        "        def backward_hook(module, grad_input, grad_output):\n",
        "            gradients.append(grad_output[0].detach())\n",
        "\n",
        "        # Register hooks\n",
        "        forward_handle = target_layer.register_forward_hook(forward_hook)\n",
        "        backward_handle = target_layer.register_backward_hook(backward_hook)\n",
        "\n",
        "        try:\n",
        "            # Forward pass\n",
        "            image_tensor = image.unsqueeze(0).requires_grad_(True)\n",
        "            output = model(image_tensor)\n",
        "\n",
        "            # Backward pass\n",
        "            model.zero_grad()\n",
        "            score = output[0, target_class]\n",
        "            score.backward()\n",
        "\n",
        "            # Get gradients and activations\n",
        "            if not gradients or not activations:\n",
        "                raise ValueError(\"No gradients or activations captured\")\n",
        "\n",
        "            grad = gradients[0]  # Shape: (1, C, H, W)\n",
        "            act = activations[0]  # Shape: (1, C, H, W)\n",
        "\n",
        "            # Grad-CAM++ calculations\n",
        "            alpha_num = grad.pow(2)\n",
        "            alpha_denom = 2.0 * grad.pow(2) + (act * grad.pow(3)).sum(dim=(2, 3), keepdim=True)\n",
        "            alpha_denom = torch.where(alpha_denom != 0, alpha_denom, torch.ones_like(alpha_denom))\n",
        "            alpha = alpha_num / alpha_denom\n",
        "\n",
        "            weights = (alpha * F.relu(grad)).sum(dim=(2, 3))  # Shape: (1, C)\n",
        "            cam = (weights.unsqueeze(-1).unsqueeze(-1) * act).sum(dim=1, keepdim=True)  # Shape: (1, 1, H, W)\n",
        "            cam = F.relu(cam)\n",
        "\n",
        "            # Normalize\n",
        "            cam = cam - cam.min()\n",
        "            cam = cam / (cam.max() + 1e-8)\n",
        "\n",
        "            # Resize to input image size\n",
        "            cam = F.interpolate(cam, size=(224, 224), mode='bilinear', align_corners=False)\n",
        "            cam = cam.squeeze().detach().cpu().numpy()\n",
        "\n",
        "            # Apply colormap\n",
        "            cam = (cam * 255).astype(np.uint8)\n",
        "            heatmap = cv2.applyColorMap(cam, cv2.COLORMAP_JET)\n",
        "\n",
        "            # Convert original image for visualization\n",
        "            image_np = image.detach().permute(1, 2, 0).cpu().numpy()\n",
        "            image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "            image_np = np.clip(image_np, 0, 1)\n",
        "            image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "            # Superimpose heatmap\n",
        "            superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "            # superimposed_img = cv2.addWeighted(image_np[:, :, ::-1], 0.6, heatmap, 0.4, 0)  # Convert image_np to BGR for cv2\n",
        "            # superimposed_img = superimposed_img[:, :, ::-1]  # Back to RGB for display\n",
        "\n",
        "        finally:\n",
        "            # Remove hooks\n",
        "            forward_handle.remove()\n",
        "            backward_handle.remove()\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def integrated_gradients(model, image, target_class):\n",
        "        \"\"\"Integrated Gradients implementation.\"\"\"\n",
        "        if image.dim() == 4:\n",
        "            image = image.squeeze(0)  # Normalize to (C, H, W)\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        # Detach the image first to avoid gradient issues\n",
        "        image_detached = image.detach()\n",
        "\n",
        "        # Create baseline (black image)\n",
        "        baseline = torch.zeros_like(image_detached)\n",
        "\n",
        "        # Generate path from baseline to image\n",
        "        num_steps = 30\n",
        "        alphas = torch.linspace(0, 1, num_steps).to(image_detached.device)\n",
        "\n",
        "        gradients = []\n",
        "        for alpha in alphas:\n",
        "            interpolated = baseline + alpha * (image_detached - baseline)\n",
        "            interpolated = interpolated.requires_grad_(True)\n",
        "\n",
        "            output = model(interpolated.unsqueeze(0))\n",
        "            score = output[0, target_class]\n",
        "\n",
        "            # Clear gradients\n",
        "            model.zero_grad()\n",
        "            if interpolated.grad is not None:\n",
        "                interpolated.grad.zero_()\n",
        "\n",
        "            score.backward()\n",
        "\n",
        "            # Detach gradient before storing\n",
        "            if interpolated.grad is not None:\n",
        "                gradients.append(interpolated.grad.detach().clone())\n",
        "\n",
        "            # Clear the gradient to free memory\n",
        "            interpolated.grad = None\n",
        "\n",
        "        if not gradients:\n",
        "            # Fallback: simple gradient\n",
        "            image_grad = image_detached.requires_grad_(True)\n",
        "            output = model(image_grad.unsqueeze(0))\n",
        "            score = output[0, target_class]\n",
        "            model.zero_grad()\n",
        "            score.backward()\n",
        "            gradients = [image_grad.grad.detach().clone()]\n",
        "\n",
        "        # Average gradients\n",
        "        avg_gradients = torch.stack(gradients).mean(dim=0)\n",
        "\n",
        "        # Compute integrated gradients\n",
        "        integrated_gradients = (image_detached - baseline) * avg_gradients\n",
        "\n",
        "        # Sum across color channels\n",
        "        relevance = integrated_gradients.abs().sum(dim=0).cpu().numpy()\n",
        "\n",
        "        # Normalize\n",
        "        relevance = relevance / (relevance.max() + 1e-8)\n",
        "\n",
        "        # Apply colormap\n",
        "        relevance = (relevance * 255).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(relevance, cv2.COLORMAP_JET)\n",
        "\n",
        "        # Convert original image for visualization\n",
        "        image_np = image_detached.permute(1, 2, 0).cpu().numpy()\n",
        "        image_np = image_np * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "        # Superimpose heatmap\n",
        "        superimposed_img = cv2.addWeighted(image_np, 0.6, heatmap, 0.4, 0)\n",
        "\n",
        "        return superimposed_img, heatmap\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def layer_wise_relevance_propagation(\n",
        "        model,\n",
        "        image,\n",
        "        target_class=None,\n",
        "        device=\"cuda\",\n",
        "        input_size=None,\n",
        "        epsilon=1e-6,\n",
        "        imagenet_norm=True\n",
        "    ):\n",
        "\n",
        "\n",
        "        model.eval()\n",
        "        model.to(device)\n",
        "\n",
        "        # Ensure correct input shape\n",
        "        if image.dim() == 4:\n",
        "            image = image.squeeze(0)\n",
        "        if image.dim() != 3:\n",
        "            raise ValueError(f\"Expected 3D image tensor (C,H,W), got {image.shape}\")\n",
        "\n",
        "        image_tensor = image.unsqueeze(0).to(device).requires_grad_(True)\n",
        "\n",
        "        # Determine target class\n",
        "        if target_class is None:\n",
        "            with torch.no_grad():\n",
        "                output = model(image_tensor)\n",
        "                target_class = output.argmax(dim=1).item()\n",
        "\n",
        "        try:\n",
        "            from captum.attr import LRP\n",
        "\n",
        "            lrp = LRP(model)\n",
        "            attributions = lrp.attribute(image_tensor, target=target_class)\n",
        "            if attributions is None:\n",
        "                raise ValueError(\"LRP attribution returned None\")\n",
        "\n",
        "            relevance = attributions.detach().cpu().squeeze(0)  # (C,H,W)\n",
        "            if relevance.dim() == 3:\n",
        "                relevance = relevance.sum(dim=0)  # (H,W)\n",
        "\n",
        "        except Exception as e:\n",
        "            # Fallback: Gradient-based relevance\n",
        "            try:\n",
        "                model.zero_grad()\n",
        "                image_tensor = image_tensor.detach().requires_grad_(True)\n",
        "                output = model(image_tensor)\n",
        "\n",
        "                target_score = output[0, target_class]\n",
        "                target_score.backward()\n",
        "\n",
        "                if image_tensor.grad is None:\n",
        "                    raise ValueError(\"Gradients are None in fallback.\")\n",
        "\n",
        "                relevance = image_tensor.grad.detach().cpu().squeeze(0)\n",
        "                if relevance.dim() == 3:\n",
        "                    relevance = relevance.clamp(min=0).sum(dim=0)\n",
        "\n",
        "            except Exception as fallback_e:\n",
        "                print(f\"LRP + fallback failed: {fallback_e}\")\n",
        "                # Return original image and blank heatmap\n",
        "                image_np = image.permute(1, 2, 0).cpu().numpy()\n",
        "                image_np = np.clip(image_np, 0, 1)\n",
        "                image_np = (image_np * 255).astype(np.uint8)\n",
        "                heatmap = np.zeros_like(image_np, dtype=np.uint8)\n",
        "                return image_np, heatmap\n",
        "\n",
        "        # Normalize relevance\n",
        "        relevance = relevance.clamp(min=0)\n",
        "        if relevance.max() > 0:\n",
        "            relevance = relevance / (relevance.max() + epsilon)\n",
        "\n",
        "        relevance_map = relevance.numpy()\n",
        "        if input_size is not None and relevance_map.shape != (input_size, input_size):\n",
        "            relevance_map = cv2.resize(relevance_map, (input_size, input_size))\n",
        "\n",
        "        relevance_map = (relevance_map * 255).astype(np.uint8)\n",
        "        heatmap = cv2.applyColorMap(relevance_map, cv2.COLORMAP_JET)\n",
        "\n",
        "        # Prepare original image\n",
        "        image_np = image_tensor.detach().squeeze(0).permute(1, 2, 0).cpu().numpy()\n",
        "\n",
        "        if imagenet_norm:\n",
        "            mean = np.array([0.485, 0.456, 0.406])\n",
        "            std = np.array([0.229, 0.224, 0.225])\n",
        "            image_np = image_np * std + mean\n",
        "\n",
        "        image_np = np.clip(image_np, 0, 1)\n",
        "        image_np = (image_np * 255).astype(np.uint8)\n",
        "\n",
        "        # Superimpose heatmap\n",
        "        superimposed_img = cv2.addWeighted(image_np, 0.7, heatmap, 0.3, 0.0)\n",
        "\n",
        "        return superimposed_img, heatmap\n"
      ],
      "metadata": {
        "id": "eXcdgsbTh2ED"
      },
      "id": "eXcdgsbTh2ED",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 11: üìä Optuna Trials [Hyper-parameter Tuning]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DgnPYu28n6Db"
      },
      "id": "DgnPYu28n6Db"
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimized for maximum GPU utilization and enhanced user experience\n",
        "from threading import Lock\n",
        "from termcolor import colored, cprint\n",
        "\n",
        "import warnings\n",
        "from optuna.exceptions import ExperimentalWarning\n",
        "# Suppress only ExperimentalWarning\n",
        "warnings.filterwarnings(\"ignore\", category=ExperimentalWarning)\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "\n",
        "# # Configure logging\n",
        "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "# logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "\n",
        "def worker_init_fn(worker_id):\n",
        "    #Initialize worker with different random seed\n",
        "    np.random.seed(torch.initial_seed() % 2**32 + worker_id)\n",
        "\n",
        "class Optuna_DataManager:\n",
        "\n",
        "    @staticmethod\n",
        "    def create_data_loaders(X, Y, train_batch_size=64, val_batch_size=128,\n",
        "                                    test_size=0.2, augmentation_strength='medium',\n",
        "                                    num_workers=8, pin_memory=True, persistent_workers=True):\n",
        "\n",
        "        # Split data strategically\n",
        "        X_temp, X_test, y_temp, y_test = train_test_split(\n",
        "            X, Y, test_size=test_size, random_state=42, stratify=Y\n",
        "        )\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
        "        )\n",
        "\n",
        "        cprint(f\"üìä Data Distribution:\", 'cyan', attrs=['bold'])\n",
        "        print(f\"   Train: {len(X_train):,} samples\")\n",
        "        print(f\"   Val:   {len(X_val):,} samples\")\n",
        "        print(f\"   Test:  {len(X_test):,} samples\")\n",
        "        print(f\"   Batch: Train={train_batch_size}, Val={val_batch_size}\")\n",
        "\n",
        "        # Create datasets with transforms (assuming these classes exist)\n",
        "        # You need to define these or import them\n",
        "        try:\n",
        "            # from your_data_module import FishDataset, DataManager  # Replace with actual imports\n",
        "            train_dataset = FishDataset(X_train, y_train, DataManager.get_transforms(True, augmentation_strength))\n",
        "            val_dataset = FishDataset(X_val, y_val, DataManager.get_transforms(False))\n",
        "            test_dataset = FishDataset(X_test, y_test, DataManager.get_transforms(False))\n",
        "        except ImportError:\n",
        "            raise ImportError(\"FishDataset and DataManager classes not found. Please ensure they are imported.\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error creating datasets: {e}\")\n",
        "\n",
        "        # Calculate class weights for balanced training\n",
        "        class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "        sample_weights = [class_weights[y] for y in y_train]\n",
        "        sampler = WeightedRandomSampler(sample_weights, len(sample_weights), replacement=True)\n",
        "\n",
        "        # GPU-optimized data loading parameters\n",
        "        actual_num_workers = min(num_workers, os.cpu_count()) if torch.cuda.is_available() else 4\n",
        "        prefetch_factor = min(8, 2)  # Fixed: prevent excessive prefetch factor\n",
        "\n",
        "        # Create GPU-optimized data loaders\n",
        "        train_loader = DataLoader(\n",
        "            train_dataset,\n",
        "            batch_size=train_batch_size,\n",
        "            sampler=sampler,\n",
        "            num_workers=actual_num_workers,\n",
        "            pin_memory=pin_memory and torch.cuda.is_available(),\n",
        "            prefetch_factor=prefetch_factor,\n",
        "            persistent_workers=persistent_workers and actual_num_workers > 0,\n",
        "            worker_init_fn=worker_init_fn,\n",
        "            drop_last=True\n",
        "        )\n",
        "\n",
        "        val_loader = DataLoader(\n",
        "            val_dataset,\n",
        "            batch_size=val_batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=actual_num_workers,\n",
        "            pin_memory=pin_memory and torch.cuda.is_available(),\n",
        "            prefetch_factor=prefetch_factor,\n",
        "            persistent_workers=persistent_workers and actual_num_workers > 0,\n",
        "            worker_init_fn=worker_init_fn\n",
        "        )\n",
        "\n",
        "        test_loader = DataLoader(\n",
        "            test_dataset,\n",
        "            batch_size=val_batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=actual_num_workers,\n",
        "            pin_memory=pin_memory and torch.cuda.is_available(),\n",
        "            prefetch_factor=prefetch_factor,\n",
        "            persistent_workers=persistent_workers and actual_num_workers > 0,\n",
        "            worker_init_fn=worker_init_fn\n",
        "        )\n",
        "\n",
        "        return train_loader, val_loader, test_loader, (X_val, y_val), (X_test, y_test)\n",
        "\n",
        "\n",
        "def setup_maximum_gpu_utilization() -> Tuple[int, float, float]:\n",
        "    \"\"\"Setup GPU optimizations with proper error handling\"\"\"\n",
        "    print(\"\\n\" + \"=\"*80)\n",
        "    cprint(\"üöÄ SETTING UP MAXIMUM GPU UTILIZATION\", 'red', attrs=['bold'])\n",
        "    print(\"=\"*80)\n",
        "\n",
        "    gpu_memory_gb = 0.0\n",
        "    if torch.cuda.is_available():\n",
        "        # Aggressive GPU optimizations\n",
        "        torch.cuda.empty_cache()\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.backends.cudnn.enabled = True\n",
        "\n",
        "        # Maximum performance settings\n",
        "        if hasattr(torch.backends.cuda.matmul, 'allow_tf32'):\n",
        "            torch.backends.cuda.matmul.allow_tf32 = True\n",
        "        if hasattr(torch.backends.cudnn, 'allow_tf32'):\n",
        "            torch.backends.cudnn.allow_tf32 = True\n",
        "\n",
        "        # Fixed: Proper Flash Attention setup\n",
        "        if hasattr(torch.backends.cuda, 'enable_flash_sdp'):\n",
        "            torch.backends.cuda.enable_flash_sdp(True)\n",
        "\n",
        "        # Use maximum GPU memory (reduced from 98% to prevent OOM)\n",
        "        torch.cuda.set_per_process_memory_fraction(0.90)\n",
        "\n",
        "        # Get GPU specifications\n",
        "        for i in range(torch.cuda.device_count()):\n",
        "            gpu_props = torch.cuda.get_device_properties(i)\n",
        "            gpu_memory_gb = gpu_props.total_memory / 1e9\n",
        "\n",
        "            cprint(f\"üéÆ GPU {i}: {gpu_props.name}\", 'green', attrs=['bold'])\n",
        "            print(f\"   Memory: {gpu_memory_gb:.1f}GB\")\n",
        "            print(f\"   Compute: {gpu_props.major}.{gpu_props.minor}\")\n",
        "            print(f\"   Cores: {gpu_props.multi_processor_count}\")\n",
        "\n",
        "        # Set multi-GPU if available\n",
        "        if torch.cuda.device_count() > 1:\n",
        "            cprint(f\"üî• Using {torch.cuda.device_count()} GPUs!\", 'red', attrs=['bold'])\n",
        "    else:\n",
        "        cprint(\"‚ö†Ô∏è  No GPU available - using CPU only\", 'yellow', attrs=['bold'])\n",
        "\n",
        "    # CPU optimizations for data loading\n",
        "    cpu_count = os.cpu_count()\n",
        "    optimal_threads = min(cpu_count, 16)  # Limit threads to prevent overhead\n",
        "\n",
        "    torch.set_num_threads(optimal_threads)\n",
        "    os.environ['OMP_NUM_THREADS'] = str(optimal_threads)\n",
        "    os.environ['MKL_NUM_THREADS'] = str(optimal_threads)\n",
        "    os.environ['NUMEXPR_NUM_THREADS'] = str(optimal_threads)\n",
        "\n",
        "    # Memory information\n",
        "    memory_info = psutil.virtual_memory()\n",
        "    available_ram = memory_info.available / (1024**3)\n",
        "    total_ram = memory_info.total / (1024**3)\n",
        "\n",
        "    cprint(f\"üíª CPU: {cpu_count} cores (using {optimal_threads})\", 'blue', attrs=['bold'])\n",
        "    cprint(f\"üß† RAM: {total_ram:.1f}GB total, {available_ram:.1f}GB available\", 'blue', attrs=['bold'])\n",
        "\n",
        "    return optimal_threads, available_ram, gpu_memory_gb\n",
        "\n",
        "\n",
        "\n",
        "def get_maximum_batch_sizes(model_name: str, available_ram_gb: float, gpu_memory_gb: float) -> Tuple[int, int]:\n",
        "    \"\"\"Calculate maximum batch sizes for full GPU utilization\"\"\"\n",
        "\n",
        "    # Conservative batch sizes to prevent OOM\n",
        "    base_batch_sizes = {\n",
        "        'resnet50': {'train': 64, 'val': 128},\n",
        "        'efficientnet_b0': {'train': 96, 'val': 192},\n",
        "        'mobilenet_v3_large': {'train': 128, 'val': 256},\n",
        "        'vgg16': {'train': 32, 'val': 64},\n",
        "        'densenet121': {'train': 48, 'val': 96},\n",
        "        'inception_v3': {'train': 40, 'val': 80},\n",
        "        'vit_b_16': {'train': 32, 'val': 64},\n",
        "        'convnext_base': {'train': 36, 'val': 72},\n",
        "        'regnet_y_32gf': {'train': 24, 'val': 48}\n",
        "    }\n",
        "\n",
        "    # Conservative scaling based on GPU memory\n",
        "    if gpu_memory_gb >= 24:  # High-end GPU\n",
        "        gpu_multiplier = 1.8\n",
        "    elif gpu_memory_gb >= 16:  # Mid-range GPU\n",
        "        gpu_multiplier = 1.5\n",
        "    elif gpu_memory_gb >= 8:   # Entry-level GPU\n",
        "        gpu_multiplier = 1.2\n",
        "    else:\n",
        "        gpu_multiplier = 1.0\n",
        "\n",
        "    # RAM scaling\n",
        "    ram_multiplier = min(2.0, available_ram_gb / 16)\n",
        "    total_multiplier = min(gpu_multiplier, ram_multiplier)\n",
        "\n",
        "    model_key = model_name.lower()\n",
        "    if model_key not in base_batch_sizes:\n",
        "        model_key = 'resnet50'\n",
        "\n",
        "    base_train = base_batch_sizes[model_key]['train']\n",
        "    base_val = base_batch_sizes[model_key]['val']\n",
        "\n",
        "    train_batch = int(base_train * total_multiplier)\n",
        "    val_batch = int(base_val * total_multiplier)\n",
        "\n",
        "    # Ensure minimum viable sizes\n",
        "    train_batch = max(16, train_batch)\n",
        "    val_batch = max(32, val_batch)\n",
        "\n",
        "    return train_batch, val_batch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# class EarlyStoppingCallback:\n",
        "#     def __init__(self, target_accuracy=99.8, optimizer_instance=None):\n",
        "#         self.target_accuracy = target_accuracy\n",
        "#         self.optimizer = optimizer_instance\n",
        "\n",
        "#     def __call__(self, study, trial):\n",
        "#         if self.optimizer and self.optimizer.best_accuracy >= self.target_accuracy:\n",
        "#             study.stop()\n",
        "#             cprint(f\"\\nüéØ EARLY STOPPING: Target accuracy {self.target_accuracy}% achieved!\", 'red', attrs=['bold'])\n",
        "\n",
        "\n",
        "\n",
        "class HyperparameterOptimizer:\n",
        "    \"\"\"Enhanced hyperparameter optimizer with proper error handling\"\"\"\n",
        "\n",
        "    def __init__(self, model_name: str, train_loader, val_loader, n_trials: int = 100):\n",
        "        self.model_name = model_name\n",
        "        self.train_loader = train_loader\n",
        "        self.val_loader = val_loader\n",
        "        self.n_trials = n_trials\n",
        "\n",
        "        # Set Google Drive path\n",
        "        self.drive_path = '/content/drive/MyDrive/Fish_Parameters'\n",
        "        os.makedirs(self.drive_path, exist_ok=True)\n",
        "\n",
        "        # Use all available GPUs\n",
        "        if torch.cuda.is_available():\n",
        "            self.device = torch.device('cuda:0')\n",
        "            self.use_multi_gpu = torch.cuda.device_count() > 1\n",
        "        else:\n",
        "            self.device = torch.device('cpu')\n",
        "            self.use_multi_gpu = False\n",
        "\n",
        "        self.lock = Lock()\n",
        "        self.best_accuracy = 0.0\n",
        "        self.current_trial = 0\n",
        "\n",
        "        # Track best trial information\n",
        "        self.best_trial_info = {\n",
        "            'trial_number': 0,\n",
        "            'accuracy': 0.0,\n",
        "            'train_loss': 0.0,\n",
        "            'val_loss': 0.0,\n",
        "            'train_acc': 0.0,\n",
        "            'val_acc': 0.0,\n",
        "            'train_f1': 0.0,\n",
        "            'val_f1': 0.0,\n",
        "            'hyperparameters': {}\n",
        "        }\n",
        "\n",
        "    def suggest_hyperparameters(self, trial) -> Dict[str, Any]:\n",
        "        \"\"\"Suggest hyperparameters - you need to implement this\"\"\"\n",
        "        # This is a placeholder - implement your hyperparameter suggestions\n",
        "        return {\n",
        "            'lr': trial.suggest_float('lr', 1e-5, 1e-2, log=True),\n",
        "            'weight_decay': trial.suggest_float('weight_decay', 1e-6, 1e-2, log=True),\n",
        "            'optimizer': trial.suggest_categorical('optimizer', ['adamw', 'adam', 'sgd']),\n",
        "            'scheduler': trial.suggest_categorical('scheduler', ['cosine', 'step', 'plateau']),\n",
        "            'label_smoothing': trial.suggest_float('label_smoothing', 0.0, 0.2),\n",
        "            'gradient_clip': trial.suggest_float('gradient_clip', 0.5, 2.0),\n",
        "            'warmup_epochs': trial.suggest_int('warmup_epochs', 0, 3),\n",
        "            'dropout': trial.suggest_float('dropout', 0.1, 0.5)\n",
        "        }\n",
        "\n",
        "    def create_model_with_params(self, params: Dict[str, Any]):\n",
        "        \"\"\"Create model with parameters - you need to implement this\"\"\"\n",
        "        # This is a placeholder - implement your model creation logic\n",
        "        try:\n",
        "            # from your_model_module import ModelFactory  # Replace with actual import\n",
        "            model = ModelFactory.create_model(self.model_name, params)\n",
        "            if self.use_multi_gpu:\n",
        "                model = nn.DataParallel(model)\n",
        "            return model.to(self.device)\n",
        "        except ImportError:\n",
        "            raise ImportError(\"ModelFactory not found. Please ensure it is imported.\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error creating model: {e}\")\n",
        "\n",
        "\n",
        "    def display_hyperparameters(self, trial_num: int, params: Dict[str, Any]):\n",
        "        \"\"\"Display hyperparameters in a formatted way\"\"\"\n",
        "        print(\"\\n\" + \"üîß\" * 80)\n",
        "        cprint(f\"üìã TRIAL {trial_num} HYPERPARAMETERS - {self.model_name.upper()}\", 'cyan', attrs=['bold'])\n",
        "        print(\"üîß\" * 80)\n",
        "\n",
        "        # Display all parameters\n",
        "        cprint(\"  üéØ HYPERPARAMETERS:\", 'yellow', attrs=['bold'])\n",
        "        for key, value in params.items():\n",
        "            if isinstance(value, float):\n",
        "                print(f\"    üîπ {key:<20}: {value:.8f}\")\n",
        "            else:\n",
        "                print(f\"    üîπ {key:<20}: {value}\")\n",
        "\n",
        "        print(\"üîß\" * 80)\n",
        "\n",
        "\n",
        "    def display_best_trial_status(self):\n",
        "        \"\"\"Display current best trial information\"\"\"\n",
        "        # print(\"\\n\" + \"üèÜ\" * 80)\n",
        "        cprint(f\"üëë CURRENT BEST TRIAL STATUS - {self.model_name.upper()}\", 'red', attrs=['bold'])\n",
        "        print(\"üèÜ\" * 80)\n",
        "\n",
        "        if self.best_trial_info['trial_number'] > 0:\n",
        "            cprint(f\"  ü•á Best Trial : #{self.best_trial_info['trial_number']}\", 'yellow', attrs=['bold'])\n",
        "            cprint(f\"  üéØ Best Accuracy: {self.best_trial_info['accuracy']:.4f}%\", 'green', attrs=['bold'])\n",
        "\n",
        "            # Display metrics\n",
        "            print(f\"  üìä METRICS:\")\n",
        "            print(f\"    üî∏ Train Loss:     {self.best_trial_info['train_loss']:.6f}\")\n",
        "            print(f\"    üî∏ Val Loss:       {self.best_trial_info['val_loss']:.6f}\")\n",
        "            print(f\"    üî∏ Train Accuracy: {self.best_trial_info['train_acc']:.4f}%\")\n",
        "            print(f\"    üî∏ Val Accuracy:   {self.best_trial_info['val_acc']:.4f}%\")\n",
        "            print(f\"    üî∏ Train F1:       {self.best_trial_info['train_f1']:.4f}%\")\n",
        "            print(f\"    üî∏ Val F1:         {self.best_trial_info['val_f1']:.4f}%\")\n",
        "        else:\n",
        "            cprint(\"  üîÑ No trials completed yet\", 'yellow')\n",
        "\n",
        "        # print(\"üèÜ\" * 80)\n",
        "\n",
        "    def create_optimizer_and_scheduler(self, model, params: Dict[str, Any], steps_per_epoch: int):\n",
        "        \"\"\"Create optimizer and scheduler with GPU optimizations\"\"\"\n",
        "\n",
        "        # Create optimizer\n",
        "        if params['optimizer'] == 'adamw':\n",
        "            optimizer = torch.optim.AdamW(\n",
        "                model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'],\n",
        "                betas=(0.9, 0.999), eps=1e-8\n",
        "            )\n",
        "        elif params['optimizer'] == 'adam':\n",
        "            optimizer = torch.optim.Adam(\n",
        "                model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'],\n",
        "                betas=(0.9, 0.999), eps=1e-8\n",
        "            )\n",
        "        elif params['optimizer'] == 'sgd':\n",
        "            optimizer = torch.optim.SGD(\n",
        "                model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'],\n",
        "                momentum=0.9, nesterov=True\n",
        "            )\n",
        "        else:  # rmsprop\n",
        "            optimizer = torch.optim.RMSprop(\n",
        "                model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'],\n",
        "                momentum=0.9, alpha=0.99\n",
        "            )\n",
        "\n",
        "        # Create scheduler\n",
        "        if params['scheduler'] == 'cosine':\n",
        "            scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=8)\n",
        "        elif params['scheduler'] == 'cosine_warm':\n",
        "            scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=3, T_mult=2)\n",
        "        elif params['scheduler'] == 'step':\n",
        "            scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.7)\n",
        "        else:  # plateau\n",
        "            scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                optimizer, mode='max', patience=2, factor=0.5\n",
        "            )\n",
        "\n",
        "        return optimizer, scheduler\n",
        "\n",
        "\n",
        "    # def train_and_validate(self, model, params: Dict[str, Any], epochs: int = 8) -> Tuple[float, Dict]:\n",
        "    def train_and_validate(self, model, params: Dict[str, Any], epochs: int=None , trial=None) -> Tuple[float, Dict]: #epochs: int = 8\n",
        "        #Enhanced training with comprehensive metrics and GPU utilization\n",
        "        if epochs is None:\n",
        "            epochs = Config.OPTUNA_EPOCHS\n",
        "\n",
        "        steps_per_epoch = len(self.train_loader)\n",
        "        optimizer, scheduler = self.create_optimizer_and_scheduler(model, params, steps_per_epoch)\n",
        "        criterion = nn.CrossEntropyLoss(label_smoothing=params.get('label_smoothing', 0.0))\n",
        "        scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
        "\n",
        "        best_val_acc = 0.0\n",
        "        metrics_history = []\n",
        "        patience = 0  # ‡¶≤‡ßÅ‡¶™‡ßá‡¶∞ ‡¶¨‡¶æ‡¶á‡¶∞‡ßá initialize\n",
        "        epoch_best_f1 = 0.0\n",
        "\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            # Training phase\n",
        "            model.train()\n",
        "            train_loss = 0.0\n",
        "            train_correct = 0\n",
        "            train_total = 0\n",
        "            train_preds = []\n",
        "            train_targets = []\n",
        "\n",
        "            train_pbar = tqdm(\n",
        "                self.train_loader,\n",
        "                desc=f\"  üèÉ Epoch {epoch+1:2d} Train\",\n",
        "                leave=False,\n",
        "                ncols=100\n",
        "            )\n",
        "\n",
        "            for batch_idx, (data, targets) in enumerate(train_pbar):\n",
        "                data, targets = data.to(self.device, non_blocking=True), targets.to(self.device, non_blocking=True)\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                if scaler and torch.cuda.is_available():\n",
        "                    with torch.cuda.amp.autocast():\n",
        "                        outputs = model(data)\n",
        "                        loss = criterion(outputs, targets)\n",
        "\n",
        "                    scaler.scale(loss).backward()\n",
        "                    scaler.unscale_(optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), params.get('gradient_clip', 1.0))\n",
        "                    scaler.step(optimizer)\n",
        "                    scaler.update()\n",
        "                else:\n",
        "                    outputs = model(data)\n",
        "                    loss = criterion(outputs, targets)\n",
        "                    loss.backward()\n",
        "                    torch.nn.utils.clip_grad_norm_(model.parameters(), params.get('gradient_clip', 1.0))\n",
        "                    optimizer.step()\n",
        "\n",
        "                # Metrics calculation\n",
        "                train_loss += loss.item() * data.size(0)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                train_total += targets.size(0)\n",
        "                train_correct += (predicted == targets).sum().item()\n",
        "\n",
        "                train_preds.extend(predicted.cpu().numpy())\n",
        "                train_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "                # Update progress bar\n",
        "                current_acc = 100 * train_correct / train_total\n",
        "                train_pbar.set_postfix({\n",
        "                    'Loss': f'{loss.item():.4f}',\n",
        "                    'Acc': f'{current_acc:.2f}%'\n",
        "                })\n",
        "\n",
        "            # Validation phase\n",
        "            model.eval()\n",
        "            val_loss = 0.0\n",
        "            val_correct = 0\n",
        "            val_total = 0\n",
        "            val_preds = []\n",
        "            val_targets = []\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                for data, targets in self.val_loader:\n",
        "                    data, targets = data.to(self.device, non_blocking=True), targets.to(self.device, non_blocking=True)\n",
        "\n",
        "                    if scaler and torch.cuda.is_available():\n",
        "                        with torch.cuda.amp.autocast():\n",
        "                            outputs = model(data)\n",
        "                            loss = criterion(outputs, targets)\n",
        "                    else:\n",
        "                        outputs = model(data)\n",
        "                        loss = criterion(outputs, targets)\n",
        "\n",
        "                    val_loss += loss.item() * data.size(0)\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    val_total += targets.size(0)\n",
        "                    val_correct += (predicted == targets).sum().item()\n",
        "\n",
        "                    val_preds.extend(predicted.cpu().numpy())\n",
        "                    val_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "            # Calculate metrics\n",
        "            train_accuracy = 100 * train_correct / train_total\n",
        "            val_accuracy = 100 * val_correct / val_total\n",
        "            avg_train_loss = train_loss / train_total\n",
        "            avg_val_loss = val_loss / val_total\n",
        "\n",
        "            train_f1 = f1_score(train_targets, train_preds, average='weighted') * 100\n",
        "            val_f1 = f1_score(val_targets, val_preds, average='weighted') * 100\n",
        "\n",
        "            val_wrong = val_total - val_correct\n",
        "\n",
        "            # Print epoch results\n",
        "            print(f\"    üìä TL:{avg_train_loss:.4f} VL:{avg_val_loss:.4f} | \" +\n",
        "                  f\"TA:{train_accuracy:.2f}% VA:{val_accuracy:.2f}% | \" +\n",
        "                  f\"TF1:{train_f1:.2f}% VF1:{val_f1:.2f}% | \" +\n",
        "                  f\"WP:{val_wrong}\")\n",
        "\n",
        "            # Store metrics\n",
        "            epoch_metrics = {\n",
        "                'epoch': epoch + 1,\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_loss': avg_val_loss,\n",
        "                'train_acc': train_accuracy,\n",
        "                'val_acc': val_accuracy,\n",
        "                'train_f1': train_f1,\n",
        "                'val_f1': val_f1,\n",
        "                'wrong_predictions': val_wrong\n",
        "            }\n",
        "            metrics_history.append(epoch_metrics)\n",
        "\n",
        "            # Update best accuracy\n",
        "            if val_accuracy > best_val_acc:\n",
        "                best_val_acc = val_accuracy\n",
        "\n",
        "            # Update scheduler\n",
        "            if params['scheduler'] == 'plateau':\n",
        "                scheduler.step(val_accuracy)\n",
        "            else:\n",
        "                scheduler.step()\n",
        "\n",
        "\n",
        "\n",
        "            # Early stopping for optimization speed\n",
        "            if epoch+1 >= 5 and val_accuracy < 80.0:\n",
        "                print(f\"‚ö†Ô∏è Early stopping cause epoch {epoch+1} but still not satisfactory accuracy obtain.\")\n",
        "                break\n",
        "\n",
        "\n",
        "            # Early stopping for not improvement\n",
        "            if val_f1 > epoch_best_f1 * 1.001:  # improvement condition (0.1% increment)\n",
        "                epoch_best_f1 = val_f1\n",
        "                patience = 0  # reset patience, ‡¶ï‡¶æ‡¶∞‡¶£ improvement ‡¶π‡ßü‡ßá‡¶õ‡ßá\n",
        "            else:\n",
        "                patience += 1  # no improvement, patience ‡¶¨‡¶æ‡ßú‡¶æ‡¶ì\n",
        "            if patience > Config.PATIENCE:\n",
        "                print(f\"‚ö†Ô∏è Early stopping: No improvement for {Config.PATIENCE} consecutive epochs\")\n",
        "                break\n",
        "\n",
        "\n",
        "            #Early stopping for trial level pruning\n",
        "            # Report intermediate value for pruning\n",
        "            if trial is not None:\n",
        "                trial.report(val_accuracy, epoch)\n",
        "                # Check if trial should be pruned\n",
        "                if trial.should_prune():\n",
        "                    print(f\"    ‚ö†Ô∏è Early stopping at epoch {epoch+1}: Low accuracy probability detected\")\n",
        "                    print(f\"    üîÑ Pruning trial - proceeding to next hyperparameter combination\")\n",
        "                    raise optuna.exceptions.TrialPruned()\n",
        "\n",
        "        return best_val_acc, {'history': metrics_history, 'best_epoch_metrics': max(metrics_history, key=lambda x: x['val_acc'])}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def objective(self, trial) -> float:\n",
        "      \"\"\"Enhanced objective function with detailed progress tracking\"\"\"\n",
        "      self.current_trial += 1\n",
        "\n",
        "\n",
        "      print(\"\\n\" + \"‚ñà\" * 100)\n",
        "      cprint(f\"üî• TRIAL {self.current_trial:3d}/{self.n_trials} STARTING - {self.model_name.upper()}\", 'red', attrs=['bold'])\n",
        "      print(\"‚ñà\" * 100)\n",
        "\n",
        "      try:\n",
        "          with self.lock:\n",
        "              if torch.cuda.is_available():\n",
        "                  torch.cuda.empty_cache()\n",
        "                  for i in range(torch.cuda.device_count()):\n",
        "                      memory_used = torch.cuda.memory_allocated(i) / 1e9\n",
        "                      memory_total = torch.cuda.get_device_properties(i).total_memory / 1e9\n",
        "                      print(f\"  üéÆ GPU {i}: {memory_used:.1f}/{memory_total:.1f}GB ({memory_used/memory_total*100:.1f}%)\")\n",
        "              gc.collect()\n",
        "\n",
        "          # Get hyperparameters\n",
        "          params = self.suggest_hyperparameters(trial)\n",
        "          self.display_hyperparameters(self.current_trial, params)\n",
        "\n",
        "          # Create and train model\n",
        "          model = self.create_model_with_params(params)\n",
        "          best_acc, detailed_metrics = self.train_and_validate(model, params, trial=trial)\n",
        "\n",
        "          # SUCCESS HANDLING - Move this BEFORE the except blocks\n",
        "          best_epoch_metrics = detailed_metrics['best_epoch_metrics']\n",
        "\n",
        "          # Trial completion summary\n",
        "          print(\"  \" + \"‚îÄ\" * 80)\n",
        "          cprint(f\"  ‚úÖ TRIAL {self.current_trial} COMPLETED\", 'green', attrs=['bold'])\n",
        "          cprint(f\"  üéØ Highest Validation Accuracy for this Trial: {best_acc:.4f}%\", 'yellow', attrs=['bold'])\n",
        "\n",
        "          # Update best trial info if this is better\n",
        "          if best_acc > self.best_accuracy:\n",
        "              self.best_accuracy = best_acc\n",
        "              self.best_trial_info = {\n",
        "                  'trial_number': self.current_trial,\n",
        "                  'accuracy': best_acc,\n",
        "                  'train_loss': best_epoch_metrics['train_loss'],\n",
        "                  'val_loss': best_epoch_metrics['val_loss'],\n",
        "                  'train_acc': best_epoch_metrics['train_acc'],\n",
        "                  'val_acc': best_epoch_metrics['val_acc'],\n",
        "                  'train_f1': best_epoch_metrics['train_f1'],\n",
        "                  'val_f1': best_epoch_metrics['val_f1'],\n",
        "                  'hyperparameters': params.copy()\n",
        "              }\n",
        "              cprint(f\"  üèÜ NEW BEST ACCURACY: {best_acc:.4f}%\", 'red', attrs=['bold'])\n",
        "              # Save immediately\n",
        "              self.save_best_params_immediately(getattr(self, 'output_dir', './output'))\n",
        "\n",
        "\n",
        "\n",
        "          self.display_best_trial_status()\n",
        "\n",
        "\n",
        "\n",
        "          # Cleanup\n",
        "          del model\n",
        "          if torch.cuda.is_available():\n",
        "              torch.cuda.empty_cache()\n",
        "          gc.collect()\n",
        "\n",
        "          return best_acc\n",
        "\n",
        "      except optuna.exceptions.TrialPruned:\n",
        "          cprint(f\"  ‚úÇÔ∏è TRIAL {self.current_trial} PRUNED: Low accuracy probability detected\", 'yellow', attrs=['bold'])\n",
        "          cprint(f\"  üîÑ Skipping to next hyperparameter combination for efficiency\", 'cyan')\n",
        "          # Cleanup\n",
        "          if 'model' in locals():\n",
        "              del model\n",
        "          if torch.cuda.is_available():\n",
        "              torch.cuda.empty_cache()\n",
        "          gc.collect()\n",
        "          raise  # Re-raise the TrialPruned exception\n",
        "\n",
        "      except Exception as e:\n",
        "          cprint(f\"  ‚ùå TRIAL {self.current_trial} FAILED: {e}\", 'red', attrs=['bold'])\n",
        "          cprint(f\"  üìã Error Details: {traceback.format_exc()}\", 'yellow')\n",
        "          # Cleanup\n",
        "          if 'model' in locals():\n",
        "              del model\n",
        "          if torch.cuda.is_available():\n",
        "              torch.cuda.empty_cache()\n",
        "          gc.collect()\n",
        "          return 0.0\n",
        "\n",
        "\n",
        "    def optimize(self) -> Dict[str, Any]:\n",
        "        \"\"\"Run optimization with enhanced progress tracking\"\"\"\n",
        "\n",
        "        # print(\"\\n\" + \"üöÄ\" * 40)\n",
        "        cprint(f\"STARTING HYPERPARAMETER OPTIMIZATION FOR {self.model_name.upper()}\", 'red', attrs=['bold'])\n",
        "        print(\"üöÄ\" * 40)\n",
        "\n",
        "        # Create study\n",
        "        study = optuna.create_study(\n",
        "            direction='maximize',\n",
        "            sampler=optuna.samplers.TPESampler(\n",
        "                # n_startup_trials=max(15, self.n_trials // 8),\n",
        "                n_startup_trials = max(15, self.n_trials // 6),\n",
        "                # Example: If you set n_startup_trials=10, the first 10 trials will be random, then trial 11 onwards will use TPE-guided sampling.\n",
        "                n_ei_candidates=32,\n",
        "                constant_liar=True,\n",
        "                multivariate=True\n",
        "            ),\n",
        "            # Sampler‚Äôs n_startup_trials ‚Üí when TPE optimization begins.\n",
        "            # Pruner‚Äôs n_startup_trials ‚Üí how many full trials to finish before pruning starts.\n",
        "            # Pruner‚Äôs n_warmup_steps ‚Üí how many epochs per trial to protect before pruning checks.\n",
        "            pruner=optuna.pruners.MedianPruner(\n",
        "                # n_startup_trials=max(6, self.n_trials // 15),\n",
        "                n_startup_trials = max(10, self.n_trials //8),\n",
        "                n_warmup_steps=3,\n",
        "                interval_steps=1\n",
        "            )\n",
        "        )\n",
        "\n",
        "        # Run optimization\n",
        "        cprint(f\"üéØ Target: {self.n_trials} trials\", 'cyan', attrs=['bold'])\n",
        "        # study.optimize(\n",
        "        #     self.objective,\n",
        "        #     n_trials=self.n_trials,\n",
        "        #     timeout=10800,\n",
        "        #     n_jobs=1\n",
        "        # )\n",
        "        # Run optimization with early stopping check\n",
        "        for trial_num in range(self.n_trials):\n",
        "            try:\n",
        "                study.optimize(self.objective, timeout=None, n_jobs=1, n_trials=1)\n",
        "\n",
        "                # Check for early stopping after each trial\n",
        "                if self.best_accuracy >= 99.5:\n",
        "                    cprint(f\"\\nüéØ TARGET ACCURACY ACHIEVED!\", 'red', attrs=['bold'])\n",
        "                    cprint(f\"üèÜ Best Accuracy: {self.best_accuracy:.4f}% >= 99.5%\", 'green', attrs=['bold'])\n",
        "                    cprint(f\"‚ö° Stopping optimization early after {self.current_trial} trials\", 'yellow', attrs=['bold'])\n",
        "                    cprint(f\"üöÄ Moving to next model for maximum efficiency!\", 'cyan', attrs=['bold'])\n",
        "                    break\n",
        "\n",
        "            except KeyboardInterrupt:\n",
        "                cprint(f\"\\n‚ö†Ô∏è Optimization interrupted by user\", 'yellow', attrs=['bold'])\n",
        "                break\n",
        "            except Exception as e:\n",
        "                cprint(f\"‚ö†Ô∏è Trial failed: {e}\", 'red')\n",
        "                continue\n",
        "\n",
        "\n",
        "        # # Create early stopping callback\n",
        "        # early_stop_callback = EarlyStoppingCallback(target_accuracy=99.8, optimizer_instance=self)\n",
        "\n",
        "        # # Run optimization with callback\n",
        "        # cprint(f\"üéØ Target: {self.n_trials} trials (will stop early if 99.8% accuracy achieved)\", 'cyan', attrs=['bold'])\n",
        "        # study.optimize(\n",
        "        #     self.objective,\n",
        "        #     n_trials=self.n_trials,\n",
        "        #     timeout=10800,\n",
        "        #     n_jobs=1,\n",
        "        #     callbacks=[early_stop_callback]\n",
        "        # )\n",
        "\n",
        "\n",
        "\n",
        "        # Final results\n",
        "        print(\"\\n\" + \"üèÅ\" * 40)\n",
        "        # cprint(f\"OPTIMIZATION COMPLETED FOR {self.model_name.upper()}\", 'green', attrs=['bold'])\n",
        "        if self.best_accuracy >= 99.5:\n",
        "            cprint(f\"üéØ OPTIMIZATION COMPLETED - TARGET ACHIEVED!\", 'green', attrs=['bold'])\n",
        "            cprint(f\"‚ö° Completed in {self.current_trial} trials (saved {self.n_trials - self.current_trial} trials)\", 'yellow', attrs=['bold'])\n",
        "        else:\n",
        "            cprint(f\"OPTIMIZATION COMPLETED FOR {self.model_name.upper()}\", 'green', attrs=['bold'])\n",
        "\n",
        "        cprint(f\"üèÜ OPTIMIZATION BEST ACCURACY: {self.best_accuracy:.4f}%\", 'red', attrs=['bold'])\n",
        "        print(\"üèÅ\" * 40)\n",
        "\n",
        "        return study.best_params if study.best_params else {}\n",
        "\n",
        "\n",
        "\n",
        "    def save_best_params_immediately(self, output_dir: str = './output') -> None:\n",
        "        if self.best_trial_info['trial_number'] == 0:\n",
        "            return\n",
        "\n",
        "        # Local save\n",
        "        os.makedirs(f\"{output_dir}/hyperparameters/immediate\", exist_ok=True)\n",
        "        local_file = f\"{output_dir}/hyperparameters/immediate/{self.model_name}_best_params_trial_{self.best_trial_info['trial_number']}.json\"\n",
        "\n",
        "        # Google Drive save\n",
        "        drive_file = f\"{self.drive_path}/{self.model_name}_best_params_trial_{self.best_trial_info['trial_number']}.json\"\n",
        "\n",
        "        results_with_meta = {\n",
        "            'model_name': self.model_name,\n",
        "            'trial_number': self.best_trial_info['trial_number'],\n",
        "            'accuracy': self.best_trial_info['accuracy'],\n",
        "            'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "            'metrics': {\n",
        "                'train_loss': self.best_trial_info['train_loss'],\n",
        "                'val_loss': self.best_trial_info['val_loss'],\n",
        "                'train_acc': self.best_trial_info['train_acc'],\n",
        "                'val_acc': self.best_trial_info['val_acc'],\n",
        "                'train_f1': self.best_trial_info['train_f1'],\n",
        "                'val_f1': self.best_trial_info['val_f1']\n",
        "            },\n",
        "            'hyperparameters': self.best_trial_info['hyperparameters']\n",
        "        }\n",
        "\n",
        "        # Save to both locations\n",
        "        with open(local_file, 'w') as f:\n",
        "            json.dump(results_with_meta, f, indent=4, sort_keys=True)\n",
        "\n",
        "        with open(drive_file, 'w') as f:\n",
        "            json.dump(results_with_meta, f, indent=4, sort_keys=True)\n",
        "\n",
        "        cprint(f\"  üíæ Best params saved locally: {local_file}\", 'green')\n",
        "        cprint(f\"  ‚òÅÔ∏è Best params saved to Drive: {drive_file}\", 'green')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# def optimize_single_model(model_name: str, config: Dict[str, Any]) -> Dict[str, Any]:\n",
        "def optimize_single_model(model_name: str, config: Dict[str, Any], output_dir: str = './output') -> Dict[str, Any]:\n",
        "    \"\"\"Optimize single model with maximum GPU utilization\"\"\"\n",
        "\n",
        "    print(\"\\n\" + \"‚ö°\" * 50)\n",
        "    cprint(f\"OPTIMIZING {model_name.upper()}\", 'red', attrs=['bold'])\n",
        "    print(\"‚ö°\" * 50)\n",
        "\n",
        "    try:\n",
        "        # Setup environment\n",
        "        optimal_threads, available_ram, gpu_memory_gb = setup_maximum_gpu_utilization()\n",
        "\n",
        "        # Get maximum batch sizes\n",
        "        train_batch_size, val_batch_size = get_maximum_batch_sizes(\n",
        "            model_name, available_ram, gpu_memory_gb\n",
        "        )\n",
        "\n",
        "        cprint(f\"üéØ Maximum Batch Sizes - Train: {train_batch_size}, Val: {val_batch_size}\", 'green', attrs=['bold'])\n",
        "\n",
        "        # Create data loaders\n",
        "        train_loader, val_loader, test_loader, val_data, test_data = Optuna_DataManager.create_data_loaders(\n",
        "            config['X'], config['Y'],\n",
        "            train_batch_size=train_batch_size,\n",
        "            val_batch_size=val_batch_size,\n",
        "            num_workers=optimal_threads,\n",
        "            pin_memory=True,\n",
        "            persistent_workers=True\n",
        "        )\n",
        "\n",
        "        # Run optimization\n",
        "        optimizer = HyperparameterOptimizer(\n",
        "            model_name, train_loader, val_loader,\n",
        "            n_trials=Config.OPTUNA_TRIALS  # Reduced for testing\n",
        "        )\n",
        "\n",
        "        # Store output_dir for immediate saving\n",
        "        optimizer.output_dir = output_dir\n",
        "\n",
        "\n",
        "\n",
        "        best_params = optimizer.optimize()\n",
        "\n",
        "        # Cleanup\n",
        "        del optimizer, train_loader, val_loader, test_loader\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "        gc.collect()\n",
        "\n",
        "        return best_params\n",
        "\n",
        "    except Exception as e:\n",
        "        cprint(f\"‚ùå OPTIMIZATION FAILED FOR {model_name}: {e}\", 'red', attrs=['bold'])\n",
        "        cprint(f\"üìã Error: {traceback.format_exc()}\", 'yellow')\n",
        "        return {}\n",
        "\n",
        "\n",
        "\n",
        "# def parallel_hyperparameter_optimization(model_configs: Dict[str, Any], max_workers: int = 1) -> Dict[str, Any]:\n",
        "def parallel_hyperparameter_optimization(model_configs: Dict[str, Any], max_workers: int = 1, output_dir: str = './output') -> Dict[str, Any]:\n",
        "    # Run optimization with sequential processing for maximum GPU utilization\n",
        "\n",
        "    results = {}\n",
        "\n",
        "    # print(\"\\n\" + \"üé™\" * 50)\n",
        "    cprint(\"STARTING PARALLEL HYPERPARAMETER OPTIMIZATION\", 'red', attrs=['bold'])\n",
        "    # print(\"üé™\" * 50)\n",
        "\n",
        "    # Sequential processing for maximum GPU utilization per model\n",
        "    for i, (model_name, config) in enumerate(model_configs.items(), 1):\n",
        "        cprint(f\"\\nüìç MODEL {i}/{len(model_configs)}: {model_name.upper()}\", 'cyan', attrs=['bold'])\n",
        "\n",
        "        try:\n",
        "            # best_params = optimize_single_model(model_name, config)\n",
        "            best_params = optimize_single_model(model_name, config, './output')\n",
        "            results[model_name] = best_params\n",
        "\n",
        "            if best_params:\n",
        "                cprint(f\"‚úÖ {model_name.upper()} OPTIMIZATION COMPLETED!\", 'green', attrs=['bold'])\n",
        "            else:\n",
        "                cprint(f\"‚ùå {model_name.upper()} OPTIMIZATION FAILED!\", 'red', attrs=['bold'])\n",
        "\n",
        "        except Exception as e:\n",
        "            cprint(f\"‚ùå {model_name.upper()} CRASHED: {e}\", 'red', attrs=['bold'])\n",
        "            results[model_name] = {}\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "\n",
        "def save_optimization_results(results: Dict[str, Any], output_dir: str) -> None:\n",
        "    \"\"\"Save optimization results with enhanced formatting\"\"\"\n",
        "\n",
        "    os.makedirs(f\"{output_dir}/hyperparameters\", exist_ok=True)\n",
        "\n",
        "    print(\"\\n\" + \"üíæ\" * 50)\n",
        "    cprint(\"SAVING OPTIMIZATION RESULTS\", 'cyan', attrs=['bold'])\n",
        "    print(\"üíæ\" * 50)\n",
        "\n",
        "    # Save individual model results\n",
        "    successful_models = 0\n",
        "    for model_name, best_params in results.items():\n",
        "        if best_params:\n",
        "            params_file = f\"{output_dir}/hyperparameters/{model_name}_best_params.json\"\n",
        "\n",
        "            # Enhanced metadata\n",
        "            results_with_meta = {\n",
        "                'model_name': model_name,\n",
        "                'timestamp': time.strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                'gpu_optimized': True,\n",
        "                'hyperparameters': best_params,\n",
        "                'optimization_config': {\n",
        "                    'framework': 'optuna',\n",
        "                    'sampler': 'TPE_Multivariate',\n",
        "                    'pruner': 'Median',\n",
        "                    'trials': 40,\n",
        "                    'gpu_acceleration': torch.cuda.is_available(),\n",
        "                    'multi_gpu': torch.cuda.device_count() > 1 if torch.cuda.is_available() else False\n",
        "                }\n",
        "            }\n",
        "\n",
        "            with open(params_file, 'w') as f:\n",
        "                json.dump(results_with_meta, f, indent=4, sort_keys=True)\n",
        "\n",
        "            cprint(f\"‚úÖ {model_name.upper()} parameters saved!\", 'green')\n",
        "\n",
        "            # Display best parameters\n",
        "            print(f\"  üìã {model_name.upper()} BEST PARAMETERS:\")\n",
        "            for key, value in best_params.items():\n",
        "                if isinstance(value, float):\n",
        "                    print(f\"    üîπ {key:<20}: {value:.6f}\")\n",
        "                else:\n",
        "                    print(f\"    üîπ {key:<20}: {value}\")\n",
        "            print()\n",
        "\n",
        "            successful_models += 1\n",
        "\n",
        "    # Save master results file\n",
        "    master_file = f\"{output_dir}/hyperparameters/all_best_params.json\"\n",
        "\n",
        "    # GPU information\n",
        "    gpu_info = {}\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_info = {\n",
        "            'gpu_count': torch.cuda.device_count(),\n",
        "            'gpu_names': [torch.cuda.get_device_properties(i).name for i in range(torch.cuda.device_count())],\n",
        "            'total_gpu_memory_gb': sum(torch.cuda.get_device_properties(i).total_memory / 1e9 for i in range(torch.cuda.device_count()))\n",
        "        }\n",
        "\n",
        "    master_results = {\n",
        "        'optimization_summary': {\n",
        "            'total_models': len(results),\n",
        "            'successful_optimizations': successful_models,\n",
        "            'failed_optimizations': len(results) - successful_models,\n",
        "            'success_rate_percent': (successful_models / len(results)) * 100 if results else 0,\n",
        "            'gpu_accelerated': torch.cuda.is_available(),\n",
        "            'system_info': {\n",
        "                'cpu_cores': os.cpu_count(),\n",
        "                'ram_gb': psutil.virtual_memory().total / (1024**3),\n",
        "                **gpu_info\n",
        "            }\n",
        "        },\n",
        "        'results': results\n",
        "    }\n",
        "\n",
        "    with open(master_file, 'w') as f:\n",
        "        json.dump(master_results, f, indent=4, sort_keys=True)\n",
        "\n",
        "    cprint(f\"üíæ Master results saved to: {master_file}\", 'cyan', attrs=['bold'])\n",
        "\n",
        "    # Final summary\n",
        "    print(\"\\n\" + \"üìä\" * 50)\n",
        "    cprint(\"OPTIMIZATION SUMMARY\", 'yellow', attrs=['bold'])\n",
        "    print(\"üìä\" * 50)\n",
        "    print(f\"  üéØ Total Models: {len(results)}\")\n",
        "    print(f\"  ‚úÖ Successful: {successful_models}\")\n",
        "    print(f\"  ‚ùå Failed: {len(results) - successful_models}\")\n",
        "    print(f\"  üìà Success Rate: {(successful_models / len(results)) * 100:.1f}%\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"  üéÆ GPU Acceleration: Enabled ({torch.cuda.device_count()} GPUs)\")\n",
        "    else:\n",
        "        print(f\"  üíª GPU Acceleration: Disabled (CPU only)\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def display_startup_banner():\n",
        "    #Display an impressive startup banner\n",
        "    banner = \"\"\"\n",
        "‚îå‚îÄ THE FISH OPTIMIZER ‚îÄ‚îê\n",
        "‚îÇ   üêü Optimizing üêü   ‚îÇ\n",
        "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
        "    \"\"\"\n",
        "\n",
        "    # print(\"\\n\" + \"=\"*120)\n",
        "    cprint(banner, 'red', attrs=['bold'])\n",
        "    # print(\"=\"*120)\n",
        "    # cprint(\"üöÄ MAXIMUM GPU-ACCELERATED HYPERPARAMETER OPTIMIZATION üöÄ\", 'yellow', attrs=['bold'])\n",
        "    # cprint(\"üî• DESIGNED FOR MAXIMUM PERFORMANCE AND USER EXPERIENCE üî•\", 'cyan', attrs=['bold'])\n",
        "    # print(\"=\"*120)\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    \"\"\"Enhanced main function with spectacular UI and maximum GPU utilization\"\"\"\n",
        "\n",
        "    # Display startup banner\n",
        "    display_startup_banner()\n",
        "\n",
        "    # Environment setup with detailed reporting\n",
        "    print(\"\\nüîß SYSTEM INITIALIZATION\")\n",
        "    print(\"‚îÄ\" * 50)\n",
        "\n",
        "    optimal_threads, available_ram, gpu_memory_gb = setup_maximum_gpu_utilization()\n",
        "\n",
        "    # Data loading with progress\n",
        "    print(\"\\nüìä DATA LOADING AND PREPROCESSING\")\n",
        "    print(\"‚îÄ\" * 50)\n",
        "\n",
        "    try:\n",
        "        # You need to implement or import these classes\n",
        "        # from your_data_module import DataManager  # Replace with actual import\n",
        "\n",
        "        cprint(\"üîÑ Loading and balancing dataset...\", 'cyan', attrs=['bold'])\n",
        "        X, Y = DataManager.load_and_balance_data()\n",
        "\n",
        "        cprint(f\"‚úÖ Dataset loaded successfully!\", 'green', attrs=['bold'])\n",
        "        print(f\"   üìà Total samples: {len(X):,}\")\n",
        "        print(f\"   üè∑Ô∏è  Total labels: {len(Y):,}\")\n",
        "        print(f\"   üìä Classes: {len(np.unique(Y))}\")\n",
        "\n",
        "        if len(X) != len(Y) or len(X) == 0:\n",
        "            raise ValueError(\"Invalid dataset: inconsistent or empty data\")\n",
        "\n",
        "    except ImportError:\n",
        "        cprint(\"‚ùå DataManager not found. Please ensure it is imported.\", 'red', attrs=['bold'])\n",
        "        # # Create dummy data for testing\n",
        "        # cprint(\"üîÑ Creating dummy data for testing...\", 'yellow', attrs=['bold'])\n",
        "        # X = np.random.randn(1000, 224, 224, 3)\n",
        "        # Y = np.random.randint(0, 10, 1000)\n",
        "        # cprint(\"‚úÖ Dummy dataset created!\", 'green', attrs=['bold'])\n",
        "    except Exception as e:\n",
        "        cprint(f\"‚ùå Data loading failed: {e}\", 'red', attrs=['bold'])\n",
        "        return\n",
        "\n",
        "    # Prepare model configurations\n",
        "    print(\"\\nü§ñ MODEL CONFIGURATION\")\n",
        "    print(\"‚îÄ\" * 50)\n",
        "\n",
        "    # Default models if Config.MODELS is not available\n",
        "    try:\n",
        "        # from your_config_module import Config  # Replace with actual import\n",
        "        models = Config.MODELS\n",
        "        output_dir = Config.OUTPUT_DIR\n",
        "    except ImportError:\n",
        "        cprint(\"‚ö†Ô∏è  Config not found. Using default models.\", 'yellow', attrs=['bold'])\n",
        "        models = ['resnet50', 'efficientnet_b0', 'mobilenet_v3_large']\n",
        "        output_dir = './output'\n",
        "\n",
        "    model_configs = {}\n",
        "    for i, model_name in enumerate(models, 1):\n",
        "        model_configs[model_name] = {'X': X, 'Y': Y}\n",
        "        print(f\"  {i:2d}. {model_name}\")\n",
        "\n",
        "    cprint(f\"üéØ Configured {len(models)} models for optimization\", 'green', attrs=['bold'])\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(f\"{output_dir}/hyperparameters\", exist_ok=True)\n",
        "\n",
        "    # Run optimization\n",
        "    print(\"\\nüöÄ STARTING HYPERPARAMETER OPTIMIZATION\")\n",
        "    print(\"‚îÄ\" * 50)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    all_best_params = parallel_hyperparameter_optimization(\n",
        "        model_configs,\n",
        "        max_workers=1,\n",
        "        output_dir=output_dir  # Add this\n",
        "    )\n",
        "\n",
        "    end_time = time.time()\n",
        "    total_time = end_time - start_time\n",
        "\n",
        "    # Save results\n",
        "    save_optimization_results(all_best_params, output_dir)\n",
        "\n",
        "    # Final summary\n",
        "    print(\"\\n\" + \"üéâ\" * 60)\n",
        "    cprint(\"üèÜ HYPERPARAMETER OPTIMIZATION COMPLETED! üèÜ\", 'red', attrs=['bold'])\n",
        "    print(\"üéâ\" * 60)\n",
        "\n",
        "    successful = sum(1 for params in all_best_params.values() if params)\n",
        "    total = len(all_best_params)\n",
        "\n",
        "    print(f\"‚è±Ô∏è  Total Time: {total_time//3600:.0f}h {(total_time%3600)//60:.0f}m {total_time%60:.0f}s\")\n",
        "    print(f\"üìä Models Processed: {total}\")\n",
        "    print(f\"‚úÖ Successful Optimizations: {successful}\")\n",
        "    print(f\"‚ùå Failed Optimizations: {total - successful}\")\n",
        "    print(f\"üìà Success Rate: {100*successful/total:.1f}%\")\n",
        "    print(f\"üíæ Results Location: {output_dir}/hyperparameters/\")\n",
        "\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"üéÆ GPU Utilization: Maximum\")\n",
        "        print(f\"üî• Multi-GPU: {'Yes' if torch.cuda.device_count() > 1 else 'No'}\")\n",
        "\n",
        "    print(\"\\n\" + \"üéâ\" * 60)\n",
        "    cprint(\"üöÄ READY FOR TRAINING WITH OPTIMIZED HYPERPARAMETERS! üöÄ\", 'green', attrs=['bold'])\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmSTaip_n5bV",
        "outputId": "45982db6-893e-40f5-ce2c-e713cae82d98"
      },
      "id": "CmSTaip_n5bV",
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "‚îå‚îÄ THE FISH OPTIMIZER ‚îÄ‚îê\n",
            "‚îÇ   üêü Optimizing üêü   ‚îÇ\n",
            "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
            "    \n",
            "\n",
            "üîß SYSTEM INITIALIZATION\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "\n",
            "================================================================================\n",
            "üöÄ SETTING UP MAXIMUM GPU UTILIZATION\n",
            "================================================================================\n",
            "üéÆ GPU 0: NVIDIA L4\n",
            "   Memory: 23.8GB\n",
            "   Compute: 8.9\n",
            "   Cores: 58\n",
            "üíª CPU: 12 cores (using 12)\n",
            "üß† RAM: 53.0GB total, 48.9GB available\n",
            "\n",
            "üìä DATA LOADING AND PREPROCESSING\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "üîÑ Loading and balancing dataset...\n",
            "Loading and preprocessing data...\n",
            "Applying SMOTE for class balancing...\n",
            "Balanced data shape: (15000, 3, 224, 224)\n",
            "Balanced class distribution: [3000 3000 3000 3000 3000]\n",
            "‚úÖ Dataset loaded successfully!\n",
            "   üìà Total samples: 15,000\n",
            "   üè∑Ô∏è  Total labels: 15,000\n",
            "   üìä Classes: 5\n",
            "\n",
            "ü§ñ MODEL CONFIGURATION\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "   1. resnet50\n",
            "   2. efficientnet_b0\n",
            "   3. mobilenet_v3_large\n",
            "   4. vgg16\n",
            "   5. densenet121\n",
            "   6. inception_v3\n",
            "üéØ Configured 6 models for optimization\n",
            "\n",
            "üöÄ STARTING HYPERPARAMETER OPTIMIZATION\n",
            "‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "STARTING PARALLEL HYPERPARAMETER OPTIMIZATION\n",
            "\n",
            "üìç MODEL 1/6: RESNET50\n",
            "\n",
            "‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°\n",
            "OPTIMIZING RESNET50\n",
            "‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°\n",
            "\n",
            "================================================================================\n",
            "üöÄ SETTING UP MAXIMUM GPU UTILIZATION\n",
            "================================================================================\n",
            "üéÆ GPU 0: NVIDIA L4\n",
            "   Memory: 23.8GB\n",
            "   Compute: 8.9\n",
            "   Cores: 58\n",
            "üíª CPU: 12 cores (using 12)\n",
            "üß† RAM: 53.0GB total, 46.8GB available\n",
            "üéØ Maximum Batch Sizes - Train: 96, Val: 192\n",
            "üìä Data Distribution:\n",
            "   Train: 9,000 samples\n",
            "   Val:   3,000 samples\n",
            "   Test:  3,000 samples\n",
            "   Batch: Train=96, Val=192\n",
            "STARTING HYPERPARAMETER OPTIMIZATION FOR RESNET50\n",
            "üöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄ\n",
            "üéØ Target: 40 trials\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   1/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.0%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 1 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00003423\n",
            "    üîπ weight_decay        : 0.00522891\n",
            "    üîπ optimizer           : sgd\n",
            "    üîπ scheduler           : cosine\n",
            "    üîπ label_smoothing     : 0.05121532\n",
            "    üîπ gradient_clip       : 0.74698721\n",
            "    üîπ warmup_epochs       : 3\n",
            "    üîπ dropout             : 0.29198182\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 97.8M/97.8M [00:00<00:00, 226MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7595 VL:1.6545 | TA:20.17% VA:21.90% | TF1:20.17% VF1:18.69% | WP:2343\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7552 VL:1.6585 | TA:19.93% VA:22.20% | TF1:19.89% VF1:21.03% | WP:2334\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7501 VL:1.6433 | TA:20.88% VA:23.23% | TF1:20.88% VF1:22.33% | WP:2303\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7395 VL:1.6325 | TA:21.29% VA:24.07% | TF1:21.27% VF1:23.24% | WP:2278\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7293 VL:1.6253 | TA:21.09% VA:24.87% | TF1:21.07% VF1:23.87% | WP:2254\n",
            "‚ö†Ô∏è Early stopping cause epoch 5 but still not satisfactory accuracy obtain.\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 1 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 24.8667%\n",
            "  üèÜ NEW BEST ACCURACY: 24.8667%\n",
            "  üíæ Best params saved: ./output/hyperparameters/immediate/resnet50_best_params_trial_1.json\n",
            "üëë CURRENT BEST TRIAL STATUS - RESNET50\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #1\n",
            "  üéØ Best Accuracy: 24.8667%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     1.729287\n",
            "    üî∏ Val Loss:       1.625256\n",
            "    üî∏ Train Accuracy: 21.0909%\n",
            "    üî∏ Val Accuracy:   24.8667%\n",
            "    üî∏ Train F1:       21.0726%\n",
            "    üî∏ Val F1:         23.8655%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   2/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 2 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00204095\n",
            "    üîπ weight_decay        : 0.00000974\n",
            "    üîπ optimizer           : adam\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.13839788\n",
            "    üîπ gradient_clip       : 1.28718343\n",
            "    üîπ warmup_epochs       : 1\n",
            "    üîπ dropout             : 0.34138639\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1966 VL:1.3066 | TA:63.24% VA:69.17% | TF1:63.08% VF1:68.77% | WP:925\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9316 VL:0.7864 | TA:77.20% VA:88.83% | TF1:77.16% VF1:88.89% | WP:335\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8137 VL:0.7000 | TA:84.18% VA:89.33% | TF1:84.15% VF1:89.25% | WP:320\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7752 VL:0.5937 | TA:86.69% VA:96.83% | TF1:86.68% VF1:96.83% | WP:95\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7337 VL:0.5701 | TA:89.15% VA:98.33% | TF1:89.13% VF1:98.33% | WP:50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7050 VL:0.5623 | TA:90.98% VA:98.87% | TF1:90.98% VF1:98.86% | WP:34\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7128 VL:0.6246 | TA:89.85% VA:97.53% | TF1:89.85% VF1:97.54% | WP:74\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.6914 VL:0.5775 | TA:90.85% VA:98.33% | TF1:90.84% VF1:98.33% | WP:50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.6879 VL:0.6083 | TA:91.44% VA:97.40% | TF1:91.44% VF1:97.39% | WP:78\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.6413 VL:0.5428 | TA:93.66% VA:98.73% | TF1:93.66% VF1:98.73% | WP:38\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 2 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 98.8667%\n",
            "  üèÜ NEW BEST ACCURACY: 98.8667%\n",
            "  üíæ Best params saved: ./output/hyperparameters/immediate/resnet50_best_params_trial_2.json\n",
            "üëë CURRENT BEST TRIAL STATUS - RESNET50\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #2\n",
            "  üéØ Best Accuracy: 98.8667%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.705022\n",
            "    üî∏ Val Loss:       0.562334\n",
            "    üî∏ Train Accuracy: 90.9834%\n",
            "    üî∏ Val Accuracy:   98.8667%\n",
            "    üî∏ Train F1:       90.9765%\n",
            "    üî∏ Val F1:         98.8648%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   3/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 3 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00016152\n",
            "    üîπ weight_decay        : 0.00000294\n",
            "    üîπ optimizer           : sgd\n",
            "    üîπ scheduler           : step\n",
            "    üîπ label_smoothing     : 0.13656643\n",
            "    üîπ gradient_clip       : 0.64231983\n",
            "    üîπ warmup_epochs       : 2\n",
            "    üîπ dropout             : 0.32340466\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7548 VL:1.6142 | TA:20.15% VA:23.97% | TF1:20.12% VF1:22.64% | WP:2281\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7253 VL:1.5928 | TA:22.42% VA:27.33% | TF1:22.40% VF1:27.26% | WP:2180\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.6950 VL:1.5689 | TA:24.43% VA:30.47% | TF1:24.40% VF1:30.37% | WP:2086\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.6666 VL:1.5393 | TA:26.14% VA:33.33% | TF1:26.04% VF1:32.83% | WP:2000\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.6544 VL:1.5219 | TA:27.56% VA:35.60% | TF1:27.42% VF1:35.31% | WP:1932\n",
            "‚ö†Ô∏è Early stopping cause epoch 5 but still not satisfactory accuracy obtain.\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 3 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 35.6000%\n",
            "üëë CURRENT BEST TRIAL STATUS - RESNET50\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #2\n",
            "  üéØ Best Accuracy: 98.8667%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.705022\n",
            "    üî∏ Val Loss:       0.562334\n",
            "    üî∏ Train Accuracy: 90.9834%\n",
            "    üî∏ Val Accuracy:   98.8667%\n",
            "    üî∏ Train F1:       90.9765%\n",
            "    üî∏ Val F1:         98.8648%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   4/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 4 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00407780\n",
            "    üîπ weight_decay        : 0.00005753\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : step\n",
            "    üîπ label_smoothing     : 0.05554925\n",
            "    üîπ gradient_clip       : 1.05975363\n",
            "    üîπ warmup_epochs       : 1\n",
            "    üîπ dropout             : 0.24790968\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.3320 VL:1.6329 | TA:50.31% VA:51.63% | TF1:50.01% VF1:48.61% | WP:1451\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0423 VL:0.8662 | TA:63.24% VA:77.20% | TF1:63.09% VF1:77.82% | WP:684\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9093 VL:0.5912 | TA:71.08% VA:87.73% | TF1:70.97% VF1:87.28% | WP:368\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8123 VL:0.6270 | TA:77.69% VA:85.87% | TF1:77.62% VF1:85.28% | WP:424\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7408 VL:0.3971 | TA:79.07% VA:94.13% | TF1:79.02% VF1:94.11% | WP:176\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7234 VL:0.3537 | TA:80.07% VA:95.77% | TF1:80.05% VF1:95.77% | WP:127\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.6520 VL:0.4063 | TA:84.20% VA:93.80% | TF1:84.17% VF1:93.85% | WP:186\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.6117 VL:0.3395 | TA:85.17% VA:96.87% | TF1:85.15% VF1:96.87% | WP:94\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.5447 VL:0.3531 | TA:87.95% VA:96.43% | TF1:87.93% VF1:96.43% | WP:107\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.5039 VL:0.3120 | TA:89.10% VA:97.87% | TF1:89.09% VF1:97.86% | WP:64\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 4 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 97.8667%\n",
            "üëë CURRENT BEST TRIAL STATUS - RESNET50\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #2\n",
            "  üéØ Best Accuracy: 98.8667%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.705022\n",
            "    üî∏ Val Loss:       0.562334\n",
            "    üî∏ Train Accuracy: 90.9834%\n",
            "    üî∏ Val Accuracy:   98.8667%\n",
            "    üî∏ Train F1:       90.9765%\n",
            "    üî∏ Val F1:         98.8648%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   5/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 5 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00007196\n",
            "    üîπ weight_decay        : 0.00000546\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : cosine\n",
            "    üîπ label_smoothing     : 0.17128630\n",
            "    üîπ gradient_clip       : 1.90129940\n",
            "    üîπ warmup_epochs       : 1\n",
            "    üîπ dropout             : 0.38873243\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.3268 VL:0.9721 | TA:53.29% VA:78.37% | TF1:52.53% VF1:77.97% | WP:649\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0675 VL:0.7848 | TA:72.21% VA:92.17% | TF1:72.02% VF1:92.04% | WP:235\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9673 VL:0.7143 | TA:79.21% VA:95.87% | TF1:79.16% VF1:95.83% | WP:124\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9068 VL:0.6802 | TA:83.86% VA:97.73% | TF1:83.82% VF1:97.73% | WP:68\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8659 VL:0.6656 | TA:85.99% VA:98.07% | TF1:85.98% VF1:98.06% | WP:58\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8419 VL:0.6592 | TA:87.76% VA:98.07% | TF1:87.74% VF1:98.07% | WP:58\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8364 VL:0.6543 | TA:87.70% VA:98.27% | TF1:87.70% VF1:98.27% | WP:52\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8279 VL:0.6545 | TA:88.33% VA:98.13% | TF1:88.31% VF1:98.13% | WP:56\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8198 VL:0.6528 | TA:88.54% VA:98.33% | TF1:88.53% VF1:98.34% | WP:50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8250 VL:0.6540 | TA:87.98% VA:97.97% | TF1:87.97% VF1:97.96% | WP:61\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 5 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 98.3333%\n",
            "üëë CURRENT BEST TRIAL STATUS - RESNET50\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #2\n",
            "  üéØ Best Accuracy: 98.8667%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.705022\n",
            "    üî∏ Val Loss:       0.562334\n",
            "    üî∏ Train Accuracy: 90.9834%\n",
            "    üî∏ Val Accuracy:   98.8667%\n",
            "    üî∏ Train F1:       90.9765%\n",
            "    üî∏ Val F1:         98.8648%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   6/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 6 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00255506\n",
            "    üîπ weight_decay        : 0.00001128\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.00635978\n",
            "    üîπ gradient_clip       : 0.91462633\n",
            "    üîπ warmup_epochs       : 3\n",
            "    üîπ dropout             : 0.35141072\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1187 VL:1.5614 | TA:57.30% VA:58.70% | TF1:56.97% VF1:53.51% | WP:1239\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7528 VL:0.3881 | TA:72.26% VA:87.20% | TF1:72.13% VF1:87.13% | WP:384\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.6193 VL:0.3086 | TA:77.84% VA:92.33% | TF1:77.80% VF1:92.32% | WP:230\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.4839 VL:0.2016 | TA:83.01% VA:94.57% | TF1:82.99% VF1:94.54% | WP:163\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.4608 VL:0.1831 | TA:84.22% VA:95.40% | TF1:84.20% VF1:95.40% | WP:138\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.4146 VL:0.1747 | TA:86.44% VA:96.37% | TF1:86.41% VF1:96.33% | WP:109\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.3550 VL:0.1930 | TA:88.74% VA:95.60% | TF1:88.73% VF1:95.61% | WP:132\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.3484 VL:0.1192 | TA:88.64% VA:98.20% | TF1:88.63% VF1:98.20% | WP:54\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.3195 VL:0.1012 | TA:89.58% VA:98.43% | TF1:89.58% VF1:98.44% | WP:47\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.3046 VL:0.1130 | TA:90.31% VA:97.80% | TF1:90.31% VF1:97.80% | WP:66\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 6 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 98.4333%\n",
            "üëë CURRENT BEST TRIAL STATUS - RESNET50\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #2\n",
            "  üéØ Best Accuracy: 98.8667%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.705022\n",
            "    üî∏ Val Loss:       0.562334\n",
            "    üî∏ Train Accuracy: 90.9834%\n",
            "    üî∏ Val Accuracy:   98.8667%\n",
            "    üî∏ Train F1:       90.9765%\n",
            "    üî∏ Val F1:         98.8648%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   7/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 7 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00220946\n",
            "    üîπ weight_decay        : 0.00023519\n",
            "    üîπ optimizer           : adam\n",
            "    üîπ scheduler           : cosine\n",
            "    üîπ label_smoothing     : 0.09843854\n",
            "    üîπ gradient_clip       : 1.58788411\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.42930212\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1962 VL:0.9839 | TA:59.01% VA:71.80% | TF1:58.79% VF1:69.88% | WP:846\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8881 VL:0.6086 | TA:75.83% VA:91.27% | TF1:75.70% VF1:91.20% | WP:262\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7743 VL:0.5236 | TA:81.81% VA:94.10% | TF1:81.77% VF1:94.08% | WP:177\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7094 VL:0.5063 | TA:85.20% VA:96.10% | TF1:85.19% VF1:96.10% | WP:117\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.6714 VL:0.4633 | TA:86.83% VA:97.37% | TF1:86.81% VF1:97.38% | WP:79\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.6159 VL:0.4440 | TA:89.52% VA:98.33% | TF1:89.51% VF1:98.34% | WP:50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.5794 VL:0.4341 | TA:91.45% VA:98.87% | TF1:91.45% VF1:98.87% | WP:34\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.5501 VL:0.4234 | TA:92.87% VA:99.10% | TF1:92.86% VF1:99.10% | WP:27\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.5656 VL:0.4197 | TA:91.94% VA:98.97% | TF1:91.92% VF1:98.97% | WP:31\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.5515 VL:0.4153 | TA:92.71% VA:99.20% | TF1:92.70% VF1:99.20% | WP:24\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 7 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 99.2000%\n",
            "  üèÜ NEW BEST ACCURACY: 99.2000%\n",
            "  üíæ Best params saved: ./output/hyperparameters/immediate/resnet50_best_params_trial_7.json\n",
            "üëë CURRENT BEST TRIAL STATUS - RESNET50\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #7\n",
            "  üéØ Best Accuracy: 99.2000%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.551510\n",
            "    üî∏ Val Loss:       0.415300\n",
            "    üî∏ Train Accuracy: 92.7083%\n",
            "    üî∏ Val Accuracy:   99.2000%\n",
            "    üî∏ Train F1:       92.7017%\n",
            "    üî∏ Val F1:         99.1988%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   8/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 8 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00005265\n",
            "    üîπ weight_decay        : 0.00000563\n",
            "    üîπ optimizer           : adam\n",
            "    üîπ scheduler           : cosine\n",
            "    üîπ label_smoothing     : 0.10565790\n",
            "    üîπ gradient_clip       : 1.56466519\n",
            "    üîπ warmup_epochs       : 1\n",
            "    üîπ dropout             : 0.38146868\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.3023 VL:0.8921 | TA:50.69% VA:75.33% | TF1:49.66% VF1:74.79% | WP:740\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0003 VL:0.6115 | TA:69.37% VA:92.47% | TF1:69.07% VF1:92.48% | WP:226\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8808 VL:0.5666 | TA:76.62% VA:94.60% | TF1:76.57% VF1:94.60% | WP:162\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8099 VL:0.5309 | TA:81.42% VA:96.33% | TF1:81.38% VF1:96.33% | WP:110\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7716 VL:0.5107 | TA:82.99% VA:96.87% | TF1:82.97% VF1:96.86% | WP:94\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7437 VL:0.4991 | TA:84.72% VA:97.67% | TF1:84.70% VF1:97.66% | WP:70\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7201 VL:0.4948 | TA:85.85% VA:97.93% | TF1:85.83% VF1:97.93% | WP:62\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.6998 VL:0.4923 | TA:87.01% VA:97.97% | TF1:87.00% VF1:97.97% | WP:61\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7176 VL:0.4928 | TA:85.93% VA:98.00% | TF1:85.92% VF1:98.00% | WP:60\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7110 VL:0.4910 | TA:86.23% VA:98.00% | TF1:86.22% VF1:98.00% | WP:60\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 8 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 98.0000%\n",
            "üëë CURRENT BEST TRIAL STATUS - RESNET50\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #7\n",
            "  üéØ Best Accuracy: 99.2000%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.551510\n",
            "    üî∏ Val Loss:       0.415300\n",
            "    üî∏ Train Accuracy: 92.7083%\n",
            "    üî∏ Val Accuracy:   99.2000%\n",
            "    üî∏ Train F1:       92.7017%\n",
            "    üî∏ Val F1:         99.1988%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   9/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 9 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00004401\n",
            "    üîπ weight_decay        : 0.00104681\n",
            "    üîπ optimizer           : sgd\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.15184150\n",
            "    üîπ gradient_clip       : 1.97011647\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.36785082\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7931 VL:1.6450 | TA:18.68% VA:21.53% | TF1:18.67% VF1:18.88% | WP:2354\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7577 VL:1.6392 | TA:20.71% VA:23.43% | TF1:20.70% VF1:21.01% | WP:2297\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7306 VL:1.6052 | TA:21.85% VA:27.13% | TF1:21.82% VF1:24.50% | WP:2186\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7157 VL:1.5702 | TA:23.01% VA:31.97% | TF1:22.97% VF1:29.16% | WP:2041\n",
            "    ‚ö†Ô∏è Early stopping at epoch 4: Low accuracy probability detected\n",
            "    üîÑ Pruning trial - proceeding to next hyperparameter combination\n",
            "  ‚úÇÔ∏è TRIAL 9 PRUNED: Low accuracy probability detected\n",
            "  üîÑ Skipping to next hyperparameter combination for efficiency\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  10/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.4/23.8GB (1.7%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 10 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00270895\n",
            "    üîπ weight_decay        : 0.00000523\n",
            "    üîπ optimizer           : adam\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.13678239\n",
            "    üîπ gradient_clip       : 1.47306971\n",
            "    üîπ warmup_epochs       : 3\n",
            "    üîπ dropout             : 0.27837427\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.3496 VL:1.4633 | TA:52.33% VA:57.27% | TF1:51.86% VF1:56.54% | WP:1282\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0390 VL:0.8174 | TA:69.67% VA:85.43% | TF1:69.39% VF1:85.70% | WP:437\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9042 VL:0.6990 | TA:78.47% VA:93.67% | TF1:78.39% VF1:93.72% | WP:190\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8383 VL:1.4228 | TA:83.32% VA:94.80% | TF1:83.30% VF1:94.77% | WP:156\n",
            "    ‚ö†Ô∏è Early stopping at epoch 4: Low accuracy probability detected\n",
            "    üîÑ Pruning trial - proceeding to next hyperparameter combination\n",
            "  ‚úÇÔ∏è TRIAL 10 PRUNED: Low accuracy probability detected\n",
            "  üîÑ Skipping to next hyperparameter combination for efficiency\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  11/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.5/23.8GB (2.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 11 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00993064\n",
            "    üîπ weight_decay        : 0.00964701\n",
            "    üîπ optimizer           : adam\n",
            "    üîπ scheduler           : cosine\n",
            "    üîπ label_smoothing     : 0.12313000\n",
            "    üîπ gradient_clip       : 1.58040010\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.40152998\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.8242 VL:1.6172 | TA:21.92% VA:20.07% | TF1:21.68% VF1:6.94% | WP:2398\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.5876 VL:1.6377 | TA:25.90% VA:20.00% | TF1:24.78% VF1:6.67% | WP:2400\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.5291 VL:1.6457 | TA:31.41% VA:20.10% | TF1:27.83% VF1:8.54% | WP:2397\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.5049 VL:1.5735 | TA:34.91% VA:28.07% | TF1:30.89% VF1:16.01% | WP:2158\n",
            "    ‚ö†Ô∏è Early stopping at epoch 4: Low accuracy probability detected\n",
            "    üîÑ Pruning trial - proceeding to next hyperparameter combination\n",
            "  ‚úÇÔ∏è TRIAL 11 PRUNED: Low accuracy probability detected\n",
            "  üîÑ Skipping to next hyperparameter combination for efficiency\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  12/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.5/23.8GB (2.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 12 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00295701\n",
            "    üîπ weight_decay        : 0.00003453\n",
            "    üîπ optimizer           : adam\n",
            "    üîπ scheduler           : cosine\n",
            "    üîπ label_smoothing     : 0.07545577\n",
            "    üîπ gradient_clip       : 1.50034809\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.43502350\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2384 VL:2.4911 | TA:55.47% VA:48.03% | TF1:55.21% VF1:43.78% | WP:1559\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9111 VL:0.7245 | TA:72.28% VA:86.83% | TF1:72.14% VF1:86.75% | WP:395\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7679 VL:0.6234 | TA:79.85% VA:86.47% | TF1:79.80% VF1:86.27% | WP:406\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.6572 VL:0.4491 | TA:84.81% VA:95.30% | TF1:84.79% VF1:95.31% | WP:141\n",
            "    ‚ö†Ô∏è Early stopping at epoch 4: Low accuracy probability detected\n",
            "    üîÑ Pruning trial - proceeding to next hyperparameter combination\n",
            "  ‚úÇÔ∏è TRIAL 12 PRUNED: Low accuracy probability detected\n",
            "  üîÑ Skipping to next hyperparameter combination for efficiency\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  13/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.5/23.8GB (2.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 13 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00154566\n",
            "    üîπ weight_decay        : 0.00033114\n",
            "    üîπ optimizer           : adam\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.14546672\n",
            "    üîπ gradient_clip       : 1.02083600\n",
            "    üîπ warmup_epochs       : 1\n",
            "    üîπ dropout             : 0.41022859\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1776 VL:0.8862 | TA:63.78% VA:82.60% | TF1:63.54% VF1:81.71% | WP:522\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9245 VL:0.7288 | TA:78.81% VA:90.10% | TF1:78.76% VF1:89.98% | WP:297\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8543 VL:0.6938 | TA:83.04% VA:92.90% | TF1:83.02% VF1:92.96% | WP:213\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8097 VL:0.6317 | TA:85.37% VA:95.67% | TF1:85.36% VF1:95.65% | WP:130\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7937 VL:0.7146 | TA:86.56% VA:90.07% | TF1:86.54% VF1:89.92% | WP:298\n",
            "    ‚ö†Ô∏è Early stopping at epoch 5: Low accuracy probability detected\n",
            "    üîÑ Pruning trial - proceeding to next hyperparameter combination\n",
            "  ‚úÇÔ∏è TRIAL 13 PRUNED: Low accuracy probability detected\n",
            "  üîÑ Skipping to next hyperparameter combination for efficiency\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  14/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.5/23.8GB (2.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 14 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00235772\n",
            "    üîπ weight_decay        : 0.00000774\n",
            "    üîπ optimizer           : adam\n",
            "    üîπ scheduler           : cosine\n",
            "    üîπ label_smoothing     : 0.15639717\n",
            "    üîπ gradient_clip       : 1.00267001\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.26164763\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2664 VL:1.4943 | TA:59.58% VA:48.67% | TF1:59.04% VF1:47.01% | WP:1540\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9884 VL:0.7987 | TA:76.59% VA:89.30% | TF1:76.49% VF1:89.37% | WP:321\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8780 VL:0.6523 | TA:82.57% VA:96.33% | TF1:82.52% VF1:96.34% | WP:110\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8035 VL:0.7064 | TA:87.22% VA:96.03% | TF1:87.21% VF1:96.04% | WP:119\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7543 VL:0.6369 | TA:89.63% VA:95.90% | TF1:89.62% VF1:95.91% | WP:123\n",
            "    ‚ö†Ô∏è Early stopping at epoch 5: Low accuracy probability detected\n",
            "    üîÑ Pruning trial - proceeding to next hyperparameter combination\n",
            "  ‚úÇÔ∏è TRIAL 14 PRUNED: Low accuracy probability detected\n",
            "  üîÑ Skipping to next hyperparameter combination for efficiency\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  15/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.5/23.8GB (2.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 15 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00707272\n",
            "    üîπ weight_decay        : 0.00000710\n",
            "    üîπ optimizer           : adam\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.07942034\n",
            "    üîπ gradient_clip       : 0.71817234\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.38415415\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.6345 VL:2.6229 | TA:35.79% VA:34.57% | TF1:35.22% VF1:28.37% | WP:1963\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.5517 VL:1.1767 | TA:43.63% VA:56.77% | TF1:42.84% VF1:51.14% | WP:1297\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.4557 VL:1.1105 | TA:45.11% VA:58.50% | TF1:43.66% VF1:54.82% | WP:1245\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.4437 VL:4.4133 | TA:47.96% VA:57.53% | TF1:46.37% VF1:52.10% | WP:1274\n",
            "    ‚ö†Ô∏è Early stopping at epoch 4: Low accuracy probability detected\n",
            "    üîÑ Pruning trial - proceeding to next hyperparameter combination\n",
            "  ‚úÇÔ∏è TRIAL 15 PRUNED: Low accuracy probability detected\n",
            "  üîÑ Skipping to next hyperparameter combination for efficiency\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  16/40 STARTING - RESNET50\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.5/23.8GB (2.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 16 HYPERPARAMETERS - RESNET50\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00022317\n",
            "    üîπ weight_decay        : 0.00264748\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : cosine\n",
            "    üîπ label_smoothing     : 0.07964384\n",
            "    üîπ gradient_clip       : 1.84149564\n",
            "    üîπ warmup_epochs       : 1\n",
            "    üîπ dropout             : 0.41452941\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0601 VL:0.6839 | TA:64.25% VA:86.33% | TF1:63.89% VF1:86.14% | WP:410\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7354 VL:0.4255 | TA:81.88% VA:97.37% | TF1:81.85% VF1:97.37% | WP:79\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.6313 VL:0.4052 | TA:86.94% VA:97.83% | TF1:86.94% VF1:97.84% | WP:65\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.5603 VL:0.3686 | TA:89.98% VA:98.87% | TF1:89.97% VF1:98.87% | WP:34\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.5211 VL:0.3630 | TA:91.96% VA:99.13% | TF1:91.95% VF1:99.13% | WP:26\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.4744 VL:0.3532 | TA:94.03% VA:99.27% | TF1:94.03% VF1:99.27% | WP:22\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.4582 VL:0.3459 | TA:94.79% VA:99.50% | TF1:94.79% VF1:99.50% | WP:15\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.4523 VL:0.3450 | TA:94.90% VA:99.53% | TF1:94.90% VF1:99.53% | WP:14\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.4456 VL:0.3458 | TA:95.15% VA:99.57% | TF1:95.15% VF1:99.57% | WP:13\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.4499 VL:0.3434 | TA:94.89% VA:99.57% | TF1:94.89% VF1:99.57% | WP:13\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 16 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 99.5667%\n",
            "  üèÜ NEW BEST ACCURACY: 99.5667%\n",
            "  üíæ Best params saved: ./output/hyperparameters/immediate/resnet50_best_params_trial_16.json\n",
            "üëë CURRENT BEST TRIAL STATUS - RESNET50\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #16\n",
            "  üéØ Best Accuracy: 99.5667%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.445645\n",
            "    üî∏ Val Loss:       0.345767\n",
            "    üî∏ Train Accuracy: 95.1501%\n",
            "    üî∏ Val Accuracy:   99.5667%\n",
            "    üî∏ Train F1:       95.1456%\n",
            "    üî∏ Val F1:         99.5665%\n",
            "\n",
            "üéØ TARGET ACCURACY ACHIEVED!\n",
            "üèÜ Best Accuracy: 99.5667% >= 99.5%\n",
            "‚ö° Stopping optimization early after 16 trials\n",
            "üöÄ Moving to next model for maximum efficiency!\n",
            "\n",
            "üèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅ\n",
            "üéØ OPTIMIZATION COMPLETED - TARGET ACHIEVED!\n",
            "‚ö° Completed in 16 trials (saved 24 trials)\n",
            "üèÜ OPTIMIZATION BEST ACCURACY: 99.5667%\n",
            "üèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅüèÅ\n",
            "‚úÖ RESNET50 OPTIMIZATION COMPLETED!\n",
            "\n",
            "üìç MODEL 2/6: EFFICIENTNET_B0\n",
            "\n",
            "‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°\n",
            "OPTIMIZING EFFICIENTNET_B0\n",
            "‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°‚ö°\n",
            "\n",
            "================================================================================\n",
            "üöÄ SETTING UP MAXIMUM GPU UTILIZATION\n",
            "================================================================================\n",
            "üéÆ GPU 0: NVIDIA L4\n",
            "   Memory: 23.8GB\n",
            "   Compute: 8.9\n",
            "   Cores: 58\n",
            "üíª CPU: 12 cores (using 12)\n",
            "üß† RAM: 53.0GB total, 42.4GB available\n",
            "üéØ Maximum Batch Sizes - Train: 144, Val: 288\n",
            "üìä Data Distribution:\n",
            "   Train: 9,000 samples\n",
            "   Val:   3,000 samples\n",
            "   Test:  3,000 samples\n",
            "   Batch: Train=144, Val=288\n",
            "STARTING HYPERPARAMETER OPTIMIZATION FOR EFFICIENTNET_B0\n",
            "üöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄüöÄ\n",
            "üéØ Target: 40 trials\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   1/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 1 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00006948\n",
            "    üîπ weight_decay        : 0.00000294\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.16375324\n",
            "    üîπ gradient_clip       : 0.60238239\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.42540456\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20.5M/20.5M [00:00<00:00, 209MB/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.4176 VL:1.5019 | TA:45.56% VA:35.23% | TF1:45.05% VF1:31.10% | WP:1943\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2293 VL:0.8629 | TA:59.70% VA:85.47% | TF1:59.28% VF1:85.02% | WP:436\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1821 VL:0.8319 | TA:63.27% VA:88.07% | TF1:62.94% VF1:87.70% | WP:358\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1500 VL:0.7955 | TA:64.91% VA:90.70% | TF1:64.69% VF1:90.50% | WP:279\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1342 VL:0.7855 | TA:66.83% VA:91.50% | TF1:66.59% VF1:91.31% | WP:255\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1346 VL:0.7788 | TA:66.67% VA:91.70% | TF1:66.45% VF1:91.55% | WP:249\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1238 VL:0.7743 | TA:67.31% VA:92.17% | TF1:67.10% VF1:92.02% | WP:235\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1112 VL:0.7625 | TA:68.15% VA:92.93% | TF1:68.01% VF1:92.89% | WP:212\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1057 VL:0.7637 | TA:68.50% VA:92.73% | TF1:68.35% VF1:92.63% | WP:218\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1167 VL:0.7664 | TA:67.57% VA:92.37% | TF1:67.42% VF1:92.25% | WP:229\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 1 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 92.9333%\n",
            "  üèÜ NEW BEST ACCURACY: 92.9333%\n",
            "  üíæ Best params saved: ./output/hyperparameters/immediate/efficientnet_b0_best_params_trial_1.json\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #1\n",
            "  üéØ Best Accuracy: 92.9333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     1.111241\n",
            "    üî∏ Val Loss:       0.762549\n",
            "    üî∏ Train Accuracy: 68.1452%\n",
            "    üî∏ Val Accuracy:   92.9333%\n",
            "    üî∏ Train F1:       68.0089%\n",
            "    üî∏ Val F1:         92.8909%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   2/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 2 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00048215\n",
            "    üîπ weight_decay        : 0.00558695\n",
            "    üîπ optimizer           : sgd\n",
            "    üîπ scheduler           : cosine\n",
            "    üîπ label_smoothing     : 0.07026435\n",
            "    üîπ gradient_clip       : 0.75069538\n",
            "    üîπ warmup_epochs       : 2\n",
            "    üîπ dropout             : 0.47224331\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7279 VL:1.6374 | TA:22.28% VA:30.83% | TF1:22.29% VF1:26.47% | WP:2075\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.6176 VL:1.4150 | TA:28.19% VA:45.27% | TF1:28.18% VF1:45.68% | WP:1642\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.5579 VL:1.3035 | TA:32.11% VA:57.67% | TF1:32.02% VF1:57.86% | WP:1270\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.5131 VL:1.2417 | TA:35.53% VA:62.93% | TF1:35.35% VF1:62.88% | WP:1112\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.4727 VL:1.1933 | TA:38.21% VA:67.00% | TF1:38.06% VF1:66.80% | WP:990\n",
            "‚ö†Ô∏è Early stopping cause epoch 5 but still not satisfactory accuracy obtain.\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 2 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 67.0000%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #1\n",
            "  üéØ Best Accuracy: 92.9333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     1.111241\n",
            "    üî∏ Val Loss:       0.762549\n",
            "    üî∏ Train Accuracy: 68.1452%\n",
            "    üî∏ Val Accuracy:   92.9333%\n",
            "    üî∏ Train F1:       68.0089%\n",
            "    üî∏ Val F1:         92.8909%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   3/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 3 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00026774\n",
            "    üîπ weight_decay        : 0.00001611\n",
            "    üîπ optimizer           : sgd\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.02970417\n",
            "    üîπ gradient_clip       : 1.15282026\n",
            "    üîπ warmup_epochs       : 3\n",
            "    üîπ dropout             : 0.31924477\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7064 VL:1.6094 | TA:22.27% VA:23.73% | TF1:22.20% VF1:24.34% | WP:2288\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.5939 VL:1.3425 | TA:28.89% VA:49.97% | TF1:28.83% VF1:49.10% | WP:1501\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.5017 VL:1.2164 | TA:34.98% VA:59.80% | TF1:34.84% VF1:58.60% | WP:1206\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.4171 VL:1.1082 | TA:40.43% VA:66.00% | TF1:40.10% VF1:64.59% | WP:1020\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.3690 VL:1.0281 | TA:43.58% VA:69.97% | TF1:42.99% VF1:68.78% | WP:901\n",
            "‚ö†Ô∏è Early stopping cause epoch 5 but still not satisfactory accuracy obtain.\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 3 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 69.9667%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #1\n",
            "  üéØ Best Accuracy: 92.9333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     1.111241\n",
            "    üî∏ Val Loss:       0.762549\n",
            "    üî∏ Train Accuracy: 68.1452%\n",
            "    üî∏ Val Accuracy:   92.9333%\n",
            "    üî∏ Train F1:       68.0089%\n",
            "    üî∏ Val F1:         92.8909%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   4/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 4 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00002642\n",
            "    üîπ weight_decay        : 0.00095827\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : cosine\n",
            "    üîπ label_smoothing     : 0.05325717\n",
            "    üîπ gradient_clip       : 0.97399297\n",
            "    üîπ warmup_epochs       : 2\n",
            "    üîπ dropout             : 0.46204842\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.5585 VL:1.4556 | TA:31.74% VA:39.27% | TF1:31.63% VF1:36.81% | WP:1822\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.3227 VL:0.8671 | TA:47.17% VA:77.80% | TF1:46.60% VF1:77.16% | WP:666\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2098 VL:0.7726 | TA:53.99% VA:80.80% | TF1:53.39% VF1:80.29% | WP:576\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1678 VL:0.7018 | TA:55.58% VA:83.13% | TF1:55.16% VF1:82.71% | WP:506\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1308 VL:0.6777 | TA:58.01% VA:83.93% | TF1:57.49% VF1:83.45% | WP:482\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1048 VL:0.6627 | TA:59.42% VA:84.23% | TF1:58.92% VF1:83.81% | WP:473\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0979 VL:0.6519 | TA:60.13% VA:84.90% | TF1:59.69% VF1:84.51% | WP:453\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1155 VL:0.6449 | TA:58.74% VA:85.23% | TF1:58.21% VF1:84.86% | WP:443\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0947 VL:0.6464 | TA:60.28% VA:85.10% | TF1:59.87% VF1:84.76% | WP:447\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0988 VL:0.6484 | TA:58.75% VA:85.03% | TF1:58.34% VF1:84.65% | WP:449\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 4 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 85.2333%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #1\n",
            "  üéØ Best Accuracy: 92.9333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     1.111241\n",
            "    üî∏ Val Loss:       0.762549\n",
            "    üî∏ Train Accuracy: 68.1452%\n",
            "    üî∏ Val Accuracy:   92.9333%\n",
            "    üî∏ Train F1:       68.0089%\n",
            "    üî∏ Val F1:         92.8909%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   5/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 5 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00186202\n",
            "    üîπ weight_decay        : 0.00008613\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.08375178\n",
            "    üîπ gradient_clip       : 1.03353219\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.16366576\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0748 VL:1.2223 | TA:64.54% VA:55.20% | TF1:64.41% VF1:53.04% | WP:1344\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9028 VL:0.5350 | TA:73.04% VA:93.67% | TF1:72.95% VF1:93.64% | WP:190\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8864 VL:0.5250 | TA:73.95% VA:93.83% | TF1:73.85% VF1:93.79% | WP:185\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8696 VL:0.4956 | TA:74.85% VA:95.40% | TF1:74.77% VF1:95.37% | WP:138\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8336 VL:0.4849 | TA:75.91% VA:95.97% | TF1:75.85% VF1:95.93% | WP:121\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8329 VL:0.4917 | TA:76.64% VA:95.97% | TF1:76.59% VF1:95.96% | WP:121\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8527 VL:0.4699 | TA:75.54% VA:96.53% | TF1:75.45% VF1:96.51% | WP:104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8276 VL:0.4818 | TA:76.89% VA:96.47% | TF1:76.86% VF1:96.46% | WP:106\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8091 VL:0.4697 | TA:77.82% VA:96.53% | TF1:77.78% VF1:96.53% | WP:104\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8070 VL:0.4563 | TA:78.29% VA:97.63% | TF1:78.24% VF1:97.63% | WP:71\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 5 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 97.6333%\n",
            "  üèÜ NEW BEST ACCURACY: 97.6333%\n",
            "  üíæ Best params saved: ./output/hyperparameters/immediate/efficientnet_b0_best_params_trial_5.json\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   6/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 6 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00390995\n",
            "    üîπ weight_decay        : 0.00809562\n",
            "    üîπ optimizer           : sgd\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.15735502\n",
            "    üîπ gradient_clip       : 0.60461941\n",
            "    üîπ warmup_epochs       : 1\n",
            "    üîπ dropout             : 0.18467813\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.4924 VL:1.4829 | TA:39.14% VA:38.33% | TF1:38.91% VF1:34.38% | WP:1850\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2190 VL:0.8971 | TA:60.02% VA:83.10% | TF1:59.45% VF1:82.69% | WP:507\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1534 VL:0.8369 | TA:64.20% VA:86.60% | TF1:63.86% VF1:86.25% | WP:402\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1240 VL:0.8091 | TA:66.89% VA:88.87% | TF1:66.48% VF1:88.65% | WP:334\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1060 VL:0.7880 | TA:67.98% VA:90.27% | TF1:67.67% VF1:90.09% | WP:292\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1050 VL:0.7781 | TA:68.16% VA:91.20% | TF1:67.94% VF1:91.10% | WP:264\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0747 VL:0.7700 | TA:70.46% VA:91.50% | TF1:70.25% VF1:91.37% | WP:255\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0684 VL:0.7604 | TA:70.95% VA:91.97% | TF1:70.75% VF1:91.87% | WP:241\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0474 VL:0.7579 | TA:71.77% VA:91.93% | TF1:71.59% VF1:91.81% | WP:242\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0505 VL:0.7486 | TA:71.63% VA:92.40% | TF1:71.43% VF1:92.29% | WP:228\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 6 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 92.4000%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   7/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 7 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00434841\n",
            "    üîπ weight_decay        : 0.00152985\n",
            "    üîπ optimizer           : adam\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.17415136\n",
            "    üîπ gradient_clip       : 1.98320602\n",
            "    üîπ warmup_epochs       : 3\n",
            "    üîπ dropout             : 0.29373377\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2646 VL:1.3043 | TA:60.55% VA:54.73% | TF1:60.38% VF1:52.52% | WP:1358\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1343 VL:0.8117 | TA:68.07% VA:90.90% | TF1:67.95% VF1:90.78% | WP:273\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0980 VL:0.7939 | TA:70.14% VA:91.17% | TF1:70.01% VF1:91.05% | WP:265\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0873 VL:0.7806 | TA:70.90% VA:92.20% | TF1:70.79% VF1:92.22% | WP:234\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0809 VL:0.7811 | TA:71.15% VA:92.70% | TF1:71.03% VF1:92.63% | WP:219\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0710 VL:0.7748 | TA:71.57% VA:93.53% | TF1:71.46% VF1:93.54% | WP:194\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0604 VL:0.7825 | TA:72.29% VA:92.17% | TF1:72.18% VF1:92.04% | WP:235\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0725 VL:0.7696 | TA:71.65% VA:93.23% | TF1:71.54% VF1:93.20% | WP:203\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0744 VL:0.7822 | TA:71.19% VA:92.63% | TF1:71.06% VF1:92.62% | WP:221\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0495 VL:0.7385 | TA:73.30% VA:94.80% | TF1:73.13% VF1:94.78% | WP:156\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 7 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 94.8000%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   8/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 8 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00129302\n",
            "    üîπ weight_decay        : 0.00007080\n",
            "    üîπ optimizer           : sgd\n",
            "    üîπ scheduler           : cosine\n",
            "    üîπ label_smoothing     : 0.17024502\n",
            "    üîπ gradient_clip       : 1.64502223\n",
            "    üîπ warmup_epochs       : 1\n",
            "    üîπ dropout             : 0.43840866\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.5835 VL:1.4652 | TA:32.46% VA:42.90% | TF1:32.25% VF1:41.32% | WP:1713\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.3805 VL:0.9961 | TA:48.23% VA:80.40% | TF1:47.53% VF1:79.92% | WP:588\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2910 VL:0.9353 | TA:55.60% VA:82.77% | TF1:55.01% VF1:82.28% | WP:517\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2579 VL:0.9038 | TA:57.22% VA:84.47% | TF1:56.78% VF1:84.16% | WP:466\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2488 VL:0.8905 | TA:58.25% VA:84.87% | TF1:57.84% VF1:84.58% | WP:454\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2266 VL:0.8857 | TA:59.48% VA:85.13% | TF1:59.15% VF1:84.77% | WP:446\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2203 VL:0.8756 | TA:60.55% VA:85.83% | TF1:60.23% VF1:85.61% | WP:425\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2206 VL:0.8737 | TA:61.07% VA:86.03% | TF1:60.72% VF1:85.82% | WP:419\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2267 VL:0.8749 | TA:60.51% VA:85.93% | TF1:60.16% VF1:85.66% | WP:422\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2237 VL:0.8761 | TA:60.76% VA:85.53% | TF1:60.37% VF1:85.18% | WP:434\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 8 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 86.0333%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL   9/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 9 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00001247\n",
            "    üîπ weight_decay        : 0.00001041\n",
            "    üîπ optimizer           : sgd\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.11684650\n",
            "    üîπ gradient_clip       : 0.98404259\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.43916983\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7651 VL:1.6128 | TA:20.56% VA:23.63% | TF1:20.49% VF1:23.60% | WP:2291\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7661 VL:1.6651 | TA:20.23% VA:19.63% | TF1:20.13% VF1:18.60% | WP:2411\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7548 VL:1.6656 | TA:21.25% VA:19.93% | TF1:21.19% VF1:18.80% | WP:2402\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7522 VL:1.6591 | TA:20.72% VA:21.10% | TF1:20.64% VF1:19.83% | WP:2367\n",
            "    ‚ö†Ô∏è Early stopping at epoch 4: Low accuracy probability detected\n",
            "    üîÑ Pruning trial - proceeding to next hyperparameter combination\n",
            "  ‚úÇÔ∏è TRIAL 9 PRUNED: Low accuracy probability detected\n",
            "  üîÑ Skipping to next hyperparameter combination for efficiency\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  10/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.1/23.8GB (0.5%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 10 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00020085\n",
            "    üîπ weight_decay        : 0.00111974\n",
            "    üîπ optimizer           : sgd\n",
            "    üîπ scheduler           : step\n",
            "    üîπ label_smoothing     : 0.06013544\n",
            "    üîπ gradient_clip       : 0.75283023\n",
            "    üîπ warmup_epochs       : 1\n",
            "    üîπ dropout             : 0.31261634\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.7497 VL:1.6272 | TA:20.78% VA:23.33% | TF1:20.79% VF1:21.02% | WP:2300\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.6875 VL:1.5374 | TA:23.59% VA:32.30% | TF1:23.62% VF1:31.92% | WP:2031\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.6331 VL:1.4912 | TA:26.52% VA:36.20% | TF1:26.52% VF1:35.81% | WP:1914\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.6015 VL:1.4277 | TA:28.53% VA:42.93% | TF1:28.52% VF1:42.14% | WP:1712\n",
            "    ‚ö†Ô∏è Early stopping at epoch 4: Low accuracy probability detected\n",
            "    üîÑ Pruning trial - proceeding to next hyperparameter combination\n",
            "  ‚úÇÔ∏è TRIAL 10 PRUNED: Low accuracy probability detected\n",
            "  üîÑ Skipping to next hyperparameter combination for efficiency\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  11/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.1/23.8GB (0.5%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 11 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00509412\n",
            "    üîπ weight_decay        : 0.00001467\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.06108587\n",
            "    üîπ gradient_clip       : 0.61571769\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.14325044\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0609 VL:1.5600 | TA:63.84% VA:49.40% | TF1:63.74% VF1:47.01% | WP:1518\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9171 VL:0.4947 | TA:70.75% VA:92.13% | TF1:70.65% VF1:92.04% | WP:236\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8834 VL:0.4449 | TA:72.18% VA:94.10% | TF1:72.10% VF1:94.10% | WP:177\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8499 VL:0.4825 | TA:73.99% VA:92.67% | TF1:73.96% VF1:92.60% | WP:220\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8298 VL:0.4335 | TA:75.06% VA:94.60% | TF1:74.99% VF1:94.62% | WP:162\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7945 VL:0.4247 | TA:76.83% VA:94.87% | TF1:76.79% VF1:94.86% | WP:154\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7996 VL:0.4170 | TA:76.14% VA:95.20% | TF1:76.09% VF1:95.22% | WP:144\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7841 VL:0.4063 | TA:76.83% VA:96.10% | TF1:76.78% VF1:96.09% | WP:117\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7833 VL:0.4098 | TA:76.92% VA:96.33% | TF1:76.87% VF1:96.34% | WP:110\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7568 VL:0.4298 | TA:77.87% VA:95.03% | TF1:77.83% VF1:94.94% | WP:149\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 11 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 96.3333%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  12/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 12 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00517494\n",
            "    üîπ weight_decay        : 0.00004856\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.04003717\n",
            "    üîπ gradient_clip       : 1.21355778\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.10823502\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0226 VL:1.5745 | TA:64.81% VA:47.33% | TF1:64.69% VF1:43.22% | WP:1580\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8141 VL:0.3973 | TA:73.29% VA:92.97% | TF1:73.24% VF1:92.94% | WP:211\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8075 VL:0.3736 | TA:73.61% VA:93.97% | TF1:73.55% VF1:93.95% | WP:181\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7690 VL:0.3585 | TA:75.24% VA:94.87% | TF1:75.16% VF1:94.88% | WP:154\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7744 VL:0.3417 | TA:74.92% VA:95.67% | TF1:74.89% VF1:95.67% | WP:130\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7338 VL:0.3530 | TA:76.48% VA:95.43% | TF1:76.41% VF1:95.41% | WP:137\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7243 VL:0.3165 | TA:76.97% VA:96.57% | TF1:76.93% VF1:96.57% | WP:103\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7469 VL:0.3374 | TA:76.40% VA:95.87% | TF1:76.33% VF1:95.86% | WP:124\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7255 VL:0.3184 | TA:76.97% VA:96.80% | TF1:76.91% VF1:96.80% | WP:96\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.6950 VL:0.3290 | TA:78.23% VA:96.00% | TF1:78.19% VF1:96.00% | WP:120\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 12 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 96.8000%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  13/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 13 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00100916\n",
            "    üîπ weight_decay        : 0.00002210\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.06551879\n",
            "    üîπ gradient_clip       : 1.58413015\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.10511777\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0169 VL:1.4024 | TA:65.30% VA:49.47% | TF1:65.16% VF1:43.64% | WP:1516\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8591 VL:0.4722 | TA:73.34% VA:93.80% | TF1:73.24% VF1:93.73% | WP:186\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8075 VL:0.4462 | TA:75.96% VA:95.00% | TF1:75.88% VF1:94.97% | WP:150\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8017 VL:0.4258 | TA:76.67% VA:95.70% | TF1:76.58% VF1:95.67% | WP:129\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7851 VL:0.4263 | TA:77.03% VA:95.77% | TF1:76.96% VF1:95.75% | WP:127\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7735 VL:0.4247 | TA:77.34% VA:95.77% | TF1:77.27% VF1:95.77% | WP:127\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7650 VL:0.4065 | TA:77.53% VA:97.07% | TF1:77.47% VF1:97.06% | WP:88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7484 VL:0.3980 | TA:79.36% VA:97.37% | TF1:79.29% VF1:97.36% | WP:79\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7509 VL:0.4095 | TA:79.26% VA:97.07% | TF1:79.22% VF1:97.06% | WP:88\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7418 VL:0.4037 | TA:79.20% VA:97.10% | TF1:79.15% VF1:97.10% | WP:87\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 13 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 97.3667%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  14/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 14 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00013817\n",
            "    üîπ weight_decay        : 0.00000281\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.05772344\n",
            "    üîπ gradient_clip       : 1.54104726\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.12772187\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1205 VL:1.4055 | TA:57.76% VA:41.07% | TF1:57.43% VF1:38.76% | WP:1768\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8924 VL:0.4825 | TA:70.80% VA:91.87% | TF1:70.63% VF1:91.81% | WP:244\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8727 VL:0.4622 | TA:72.19% VA:92.73% | TF1:72.07% VF1:92.63% | WP:218\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8554 VL:0.4455 | TA:72.63% VA:93.67% | TF1:72.50% VF1:93.64% | WP:190\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8173 VL:0.4363 | TA:74.61% VA:93.87% | TF1:74.50% VF1:93.85% | WP:184\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8075 VL:0.4272 | TA:75.19% VA:94.37% | TF1:75.08% VF1:94.33% | WP:169\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7962 VL:0.4118 | TA:75.21% VA:95.20% | TF1:75.10% VF1:95.20% | WP:144\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7775 VL:0.4139 | TA:76.40% VA:95.33% | TF1:76.28% VF1:95.32% | WP:140\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7803 VL:0.3992 | TA:76.34% VA:95.90% | TF1:76.23% VF1:95.90% | WP:123\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7412 VL:0.3899 | TA:78.42% VA:96.77% | TF1:78.33% VF1:96.76% | WP:97\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 14 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 96.7667%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  15/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 15 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00018186\n",
            "    üîπ weight_decay        : 0.00038998\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.06416447\n",
            "    üîπ gradient_clip       : 1.11627358\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.23682698\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1244 VL:1.3723 | TA:59.06% VA:42.40% | TF1:58.70% VF1:41.14% | WP:1728\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9349 VL:0.5202 | TA:68.79% VA:91.00% | TF1:68.58% VF1:90.89% | WP:270\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8971 VL:0.4856 | TA:71.21% VA:92.77% | TF1:71.08% VF1:92.67% | WP:217\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8793 VL:0.4739 | TA:72.16% VA:93.20% | TF1:72.04% VF1:93.11% | WP:204\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8523 VL:0.4547 | TA:73.56% VA:94.33% | TF1:73.38% VF1:94.29% | WP:170\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8650 VL:0.4348 | TA:72.64% VA:95.70% | TF1:72.52% VF1:95.68% | WP:129\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8437 VL:0.4397 | TA:73.82% VA:95.33% | TF1:73.73% VF1:95.31% | WP:140\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8366 VL:0.4361 | TA:73.98% VA:95.10% | TF1:73.87% VF1:95.10% | WP:147\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7956 VL:0.4264 | TA:76.56% VA:95.87% | TF1:76.46% VF1:95.87% | WP:124\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8252 VL:0.4157 | TA:75.00% VA:95.83% | TF1:74.91% VF1:95.81% | WP:125\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 15 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 95.8667%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  16/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 16 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00515991\n",
            "    üîπ weight_decay        : 0.00011640\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.16672944\n",
            "    üîπ gradient_clip       : 1.08780468\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.23831028\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.2547 VL:1.6359 | TA:61.55% VA:41.47% | TF1:61.43% VF1:36.67% | WP:1756\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0809 VL:0.7607 | TA:71.58% VA:93.73% | TF1:71.49% VF1:93.72% | WP:188\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0905 VL:0.7629 | TA:71.09% VA:93.23% | TF1:71.02% VF1:93.09% | WP:203\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0607 VL:0.7813 | TA:72.78% VA:93.07% | TF1:72.73% VF1:93.04% | WP:208\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0461 VL:0.7529 | TA:73.54% VA:94.83% | TF1:73.48% VF1:94.79% | WP:155\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0402 VL:0.7478 | TA:73.62% VA:94.10% | TF1:73.57% VF1:93.97% | WP:177\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0264 VL:0.7079 | TA:74.60% VA:96.47% | TF1:74.55% VF1:96.46% | WP:106\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0029 VL:0.7043 | TA:75.97% VA:96.57% | TF1:75.90% VF1:96.57% | WP:103\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9931 VL:0.7110 | TA:76.85% VA:96.10% | TF1:76.78% VF1:96.10% | WP:117\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9768 VL:0.6996 | TA:78.14% VA:96.60% | TF1:78.06% VF1:96.60% | WP:102\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 16 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 96.6000%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  17/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 17 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00015711\n",
            "    üîπ weight_decay        : 0.00194776\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : cosine\n",
            "    üîπ label_smoothing     : 0.04414764\n",
            "    üîπ gradient_clip       : 1.72792857\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.10754869\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0739 VL:1.4623 | TA:60.50% VA:40.83% | TF1:60.13% VF1:39.12% | WP:1775\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8764 VL:0.4321 | TA:70.67% VA:92.13% | TF1:70.46% VF1:92.05% | WP:236\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8172 VL:0.4015 | TA:72.79% VA:93.03% | TF1:72.63% VF1:93.02% | WP:209\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7806 VL:0.3944 | TA:74.75% VA:93.57% | TF1:74.62% VF1:93.48% | WP:193\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7580 VL:0.3754 | TA:76.14% VA:94.23% | TF1:76.04% VF1:94.19% | WP:173\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7616 VL:0.3714 | TA:75.81% VA:94.33% | TF1:75.70% VF1:94.28% | WP:170\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7680 VL:0.3690 | TA:75.59% VA:94.50% | TF1:75.47% VF1:94.46% | WP:165\n",
            "    ‚ö†Ô∏è Early stopping at epoch 7: Low accuracy probability detected\n",
            "    üîÑ Pruning trial - proceeding to next hyperparameter combination\n",
            "  ‚úÇÔ∏è TRIAL 17 PRUNED: Low accuracy probability detected\n",
            "  üîÑ Skipping to next hyperparameter combination for efficiency\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  18/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.1/23.8GB (0.5%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 18 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00153205\n",
            "    üîπ weight_decay        : 0.00001640\n",
            "    üîπ optimizer           : adam\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.04859210\n",
            "    üîπ gradient_clip       : 1.79011822\n",
            "    üîπ warmup_epochs       : 0\n",
            "    üîπ dropout             : 0.23699063\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0225 VL:1.3916 | TA:63.55% VA:47.10% | TF1:63.36% VF1:45.85% | WP:1587\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8717 VL:0.4337 | TA:70.31% VA:92.80% | TF1:70.19% VF1:92.75% | WP:216\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8344 VL:0.4144 | TA:72.56% VA:93.40% | TF1:72.47% VF1:93.22% | WP:198\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7914 VL:0.3722 | TA:75.03% VA:95.47% | TF1:74.93% VF1:95.45% | WP:136\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7733 VL:0.3756 | TA:75.94% VA:95.37% | TF1:75.81% VF1:95.34% | WP:139\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7786 VL:0.3820 | TA:75.38% VA:94.90% | TF1:75.34% VF1:94.92% | WP:153\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7693 VL:0.3680 | TA:76.27% VA:95.80% | TF1:76.18% VF1:95.77% | WP:126\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7598 VL:0.3560 | TA:76.72% VA:96.20% | TF1:76.65% VF1:96.21% | WP:114\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7271 VL:0.3489 | TA:78.33% VA:96.60% | TF1:78.26% VF1:96.58% | WP:102\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7460 VL:0.3432 | TA:77.05% VA:96.83% | TF1:76.98% VF1:96.83% | WP:95\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 18 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 96.8333%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  19/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 19 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00635390\n",
            "    üîπ weight_decay        : 0.00057767\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : step\n",
            "    üîπ label_smoothing     : 0.05966546\n",
            "    üîπ gradient_clip       : 1.28340463\n",
            "    üîπ warmup_epochs       : 1\n",
            "    üîπ dropout             : 0.29075092\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1122 VL:1.3986 | TA:62.00% VA:52.70% | TF1:61.82% VF1:48.16% | WP:1419\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9901 VL:0.5027 | TA:67.10% VA:91.57% | TF1:67.04% VF1:91.40% | WP:253\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9013 VL:0.4453 | TA:71.01% VA:94.50% | TF1:70.95% VF1:94.49% | WP:165\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8647 VL:0.4230 | TA:72.80% VA:95.07% | TF1:72.74% VF1:95.04% | WP:148\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8489 VL:0.4126 | TA:73.51% VA:95.33% | TF1:73.47% VF1:95.29% | WP:140\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8265 VL:0.4094 | TA:74.24% VA:95.83% | TF1:74.15% VF1:95.81% | WP:125\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.8142 VL:0.3902 | TA:74.84% VA:96.63% | TF1:74.77% VF1:96.63% | WP:101\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7806 VL:0.3977 | TA:76.62% VA:96.57% | TF1:76.55% VF1:96.57% | WP:103\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7730 VL:0.3875 | TA:76.44% VA:96.83% | TF1:76.37% VF1:96.83% | WP:95\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.7637 VL:0.3770 | TA:77.27% VA:97.07% | TF1:77.22% VF1:97.07% | WP:88\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 19 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 97.0667%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  20/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 20 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00045474\n",
            "    üîπ weight_decay        : 0.00006359\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : cosine\n",
            "    üîπ label_smoothing     : 0.15132698\n",
            "    üîπ gradient_clip       : 1.59450945\n",
            "    üîπ warmup_epochs       : 1\n",
            "    üîπ dropout             : 0.15937908\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.1658 VL:1.4227 | TA:64.30% VA:49.17% | TF1:64.13% VF1:44.34% | WP:1525\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0554 VL:0.7476 | TA:70.74% VA:92.13% | TF1:70.60% VF1:91.97% | WP:236\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:1.0173 VL:0.7007 | TA:73.26% VA:94.87% | TF1:73.18% VF1:94.83% | WP:154\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    üìä TL:0.9863 VL:0.7028 | TA:75.00% VA:94.80% | TF1:74.90% VF1:94.76% | WP:156\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9747 VL:0.6783 | TA:76.34% VA:96.37% | TF1:76.28% VF1:96.36% | WP:109\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9619 VL:0.6716 | TA:76.96% VA:96.67% | TF1:76.90% VF1:96.66% | WP:100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9469 VL:0.6735 | TA:78.09% VA:96.43% | TF1:78.02% VF1:96.42% | WP:107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9544 VL:0.6696 | TA:77.41% VA:96.57% | TF1:77.33% VF1:96.56% | WP:103\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9583 VL:0.6684 | TA:77.14% VA:96.87% | TF1:77.04% VF1:96.86% | WP:94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9541 VL:0.6678 | TA:77.27% VA:96.77% | TF1:77.20% VF1:96.75% | WP:97\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 20 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 96.8667%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  21/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 21 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00031580\n",
            "    üîπ weight_decay        : 0.00000106\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : plateau\n",
            "    üîπ label_smoothing     : 0.11661282\n",
            "    üîπ gradient_clip       : 1.04387799\n",
            "    üîπ warmup_epochs       : 2\n",
            "    üîπ dropout             : 0.11193987\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:1.1100 VL:1.4371 | TA:63.63% VA:45.87% | TF1:63.42% VF1:40.82% | WP:1624\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9746 VL:0.6300 | TA:72.49% VA:93.43% | TF1:72.37% VF1:93.39% | WP:197\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9322 VL:0.6288 | TA:74.82% VA:93.40% | TF1:74.71% VF1:93.30% | WP:198\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9250 VL:0.6191 | TA:74.88% VA:93.73% | TF1:74.80% VF1:93.71% | WP:188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9101 VL:0.5969 | TA:76.15% VA:95.37% | TF1:76.08% VF1:95.35% | WP:139\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.8933 VL:0.5917 | TA:76.96% VA:95.93% | TF1:76.93% VF1:95.94% | WP:122\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.8685 VL:0.5803 | TA:79.04% VA:96.03% | TF1:78.99% VF1:96.02% | WP:119\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.8657 VL:0.5723 | TA:79.32% VA:96.30% | TF1:79.27% VF1:96.29% | WP:111\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.8801 VL:0.5748 | TA:78.08% VA:96.87% | TF1:78.04% VF1:96.85% | WP:94\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.8590 VL:0.5632 | TA:79.00% VA:96.93% | TF1:78.95% VF1:96.93% | WP:92\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 21 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 96.9333%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  22/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 22 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00450598\n",
            "    üîπ weight_decay        : 0.00031479\n",
            "    üîπ optimizer           : sgd\n",
            "    üîπ scheduler           : step\n",
            "    üîπ label_smoothing     : 0.03754654\n",
            "    üîπ gradient_clip       : 1.22094090\n",
            "    üîπ warmup_epochs       : 1\n",
            "    üîπ dropout             : 0.34974829\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:1.3490 VL:1.3903 | TA:44.60% VA:38.50% | TF1:44.21% VF1:36.52% | WP:1845\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:1.0445 VL:0.5344 | TA:61.82% VA:87.33% | TF1:61.45% VF1:86.97% | WP:380\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9742 VL:0.4863 | TA:64.74% VA:88.83% | TF1:64.39% VF1:88.63% | WP:335\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9536 VL:0.4702 | TA:65.18% VA:89.53% | TF1:64.84% VF1:89.33% | WP:314\n",
            "    ‚ö†Ô∏è Early stopping at epoch 4: Low accuracy probability detected\n",
            "    üîÑ Pruning trial - proceeding to next hyperparameter combination\n",
            "  ‚úÇÔ∏è TRIAL 22 PRUNED: Low accuracy probability detected\n",
            "  üîÑ Skipping to next hyperparameter combination for efficiency\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  23/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.1/23.8GB (0.5%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 23 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00523471\n",
            "    üîπ weight_decay        : 0.00376015\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : step\n",
            "    üîπ label_smoothing     : 0.11457826\n",
            "    üîπ gradient_clip       : 1.24856699\n",
            "    üîπ warmup_epochs       : 1\n",
            "    üîπ dropout             : 0.34801429\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:1.1847 VL:1.3610 | TA:62.33% VA:49.93% | TF1:62.18% VF1:48.74% | WP:1502\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:1.0363 VL:0.6711 | TA:69.70% VA:91.70% | TF1:69.60% VF1:91.70% | WP:249\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:1.0109 VL:0.6535 | TA:70.04% VA:92.43% | TF1:69.96% VF1:92.30% | WP:227\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9787 VL:0.6152 | TA:72.21% VA:94.03% | TF1:72.12% VF1:93.98% | WP:179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9484 VL:0.5947 | TA:73.96% VA:95.47% | TF1:73.90% VF1:95.44% | WP:136\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9438 VL:0.5725 | TA:74.09% VA:96.43% | TF1:74.04% VF1:96.42% | WP:107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9153 VL:0.5649 | TA:75.62% VA:96.27% | TF1:75.50% VF1:96.26% | WP:112\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9115 VL:0.5793 | TA:75.80% VA:95.83% | TF1:75.68% VF1:95.84% | WP:125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.9119 VL:0.5623 | TA:75.63% VA:96.90% | TF1:75.56% VF1:96.90% | WP:93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.8954 VL:0.5564 | TA:76.58% VA:96.83% | TF1:76.48% VF1:96.83% | WP:95\n",
            "  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
            "  ‚úÖ TRIAL 23 COMPLETED\n",
            "  üéØ Highest Validation Accuracy for this Trial: 96.9000%\n",
            "üëë CURRENT BEST TRIAL STATUS - EFFICIENTNET_B0\n",
            "üèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜüèÜ\n",
            "  ü•á Best Trial : #5\n",
            "  üéØ Best Accuracy: 97.6333%\n",
            "  üìä METRICS:\n",
            "    üî∏ Train Loss:     0.806968\n",
            "    üî∏ Val Loss:       0.456255\n",
            "    üî∏ Train Accuracy: 78.2930%\n",
            "    üî∏ Val Accuracy:   97.6333%\n",
            "    üî∏ Train F1:       78.2355%\n",
            "    üî∏ Val F1:         97.6347%\n",
            "\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "üî• TRIAL  24/40 STARTING - EFFICIENTNET_B0\n",
            "‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà\n",
            "  üéÆ GPU 0: 0.0/23.8GB (0.1%)\n",
            "\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "üìã TRIAL 24 HYPERPARAMETERS - EFFICIENTNET_B0\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n",
            "  üéØ HYPERPARAMETERS:\n",
            "    üîπ lr                  : 0.00347217\n",
            "    üîπ weight_decay        : 0.00012906\n",
            "    üîπ optimizer           : adamw\n",
            "    üîπ scheduler           : step\n",
            "    üîπ label_smoothing     : 0.05323297\n",
            "    üîπ gradient_clip       : 1.56319389\n",
            "    üîπ warmup_epochs       : 2\n",
            "    üîπ dropout             : 0.18189707\n",
            "üîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîßüîß\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:1.0135 VL:1.6286 | TA:65.32% VA:43.87% | TF1:65.18% VF1:39.11% | WP:1684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.8829 VL:0.4468 | TA:71.03% VA:93.00% | TF1:70.97% VF1:92.90% | WP:210\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.8223 VL:0.4122 | TA:74.14% VA:94.87% | TF1:74.06% VF1:94.86% | WP:154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.8114 VL:0.4060 | TA:74.62% VA:95.23% | TF1:74.55% VF1:95.22% | WP:143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.7583 VL:0.3880 | TA:76.61% VA:95.77% | TF1:76.56% VF1:95.74% | WP:127\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.7484 VL:0.3666 | TA:77.65% VA:96.90% | TF1:77.62% VF1:96.90% | WP:93\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.7228 VL:0.3693 | TA:78.84% VA:96.60% | TF1:78.78% VF1:96.59% | WP:102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.7394 VL:0.3515 | TA:77.45% VA:97.30% | TF1:77.40% VF1:97.30% | WP:81\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    üìä TL:0.7154 VL:0.3532 | TA:79.49% VA:97.33% | TF1:79.44% VF1:97.33% | WP:80\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  üèÉ Epoch 10 Train:  53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà        | 33/62 [00:04<00:02, 10.22it/s, Loss=0.7483, Acc=77.86%]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 12: Training Pipeline"
      ],
      "metadata": {
        "id": "UaFBF8Jucyz3"
      },
      "id": "UaFBF8Jucyz3"
    },
    {
      "cell_type": "code",
      "source": [
        "class EnhancedModelTrainer:\n",
        "    def __init__(self, model, model_name, hyperparameters):\n",
        "        self.model = model.to(Config.DEVICE)\n",
        "        self.model_name = model_name\n",
        "        self.hyperparameters = hyperparameters\n",
        "        self.best_val_acc = 0.0\n",
        "        self.best_val_f1 = 0.0\n",
        "        self.patience_counter = 0\n",
        "\n",
        "        # Resource management\n",
        "        self.resource_manager = ResourceManager()\n",
        "        self.memory_check_interval = 15\n",
        "\n",
        "\n",
        "\n",
        "        self._setup_training_components()\n",
        "\n",
        "\n",
        "\n",
        "        # Initialize history\n",
        "        self.history = {\n",
        "            'train_loss': [], 'train_acc': [], 'val_loss': [],\n",
        "            'val_acc': [], 'val_f1': [], 'learning_rates': []\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def _setup_training_components(self):\n",
        "        \"\"\"Setup optimizer, criterion, and scheduler\"\"\"\n",
        "        allowed_keys = ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier',\n",
        "                       'augmentation_strength', 'batch_size', 'optimizer_type',\n",
        "                       'scheduler_type', 'label_smoothing']\n",
        "        self.hyperparameters = {k: v for k, v in self.hyperparameters.items() if k in allowed_keys}\n",
        "\n",
        "        # Optimizer setup\n",
        "        lr = self.hyperparameters.get('lr', Config.LEARNING_RATE)\n",
        "        weight_decay = self.hyperparameters.get('weight_decay', Config.WEIGHT_DECAY)\n",
        "        optimizer_type = self.hyperparameters.get('optimizer_type', 'adamw')\n",
        "\n",
        "        if optimizer_type == 'adamw':\n",
        "            self.optimizer = optim.AdamW(\n",
        "                self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                fused=torch.cuda.is_available()\n",
        "            )\n",
        "        elif optimizer_type == 'adam':\n",
        "            self.optimizer = optim.Adam(\n",
        "                self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                fused=torch.cuda.is_available()\n",
        "            )\n",
        "        else:\n",
        "            self.optimizer = optim.SGD(\n",
        "                self.model.parameters(), lr=lr, weight_decay=weight_decay,\n",
        "                momentum=0.9, nesterov=True\n",
        "            )\n",
        "\n",
        "\n",
        "\n",
        "        # Criterion\n",
        "        label_smoothing = self.hyperparameters.get('label_smoothing', 0.1)\n",
        "        self.criterion = nn.CrossEntropyLoss(label_smoothing=label_smoothing)\n",
        "\n",
        "        # Scheduler\n",
        "        scheduler_type = self.hyperparameters.get('scheduler_type', 'cosine')\n",
        "        if scheduler_type == 'cosine':\n",
        "            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(\n",
        "                self.optimizer, T_max=Config.EPOCHS, eta_min=1e-6\n",
        "            )\n",
        "        elif scheduler_type == 'plateau':\n",
        "            self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                self.optimizer, mode='min', factor=0.5, patience=5\n",
        "            )\n",
        "        else:\n",
        "            self.scheduler = optim.lr_scheduler.ExponentialLR(self.optimizer, gamma=0.95)\n",
        "\n",
        "\n",
        "        # Mixed precision scaler\n",
        "        self.scaler = torch.cuda.amp.GradScaler(enabled=Config.USE_MIXED_PRECISION)\n",
        "\n",
        "\n",
        "\n",
        "    def train_epoch(self, train_loader, progress_tracker):\n",
        "        \"\"\"Enhanced training epoch with smart memory management\"\"\"\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        batch_count = len(train_loader)\n",
        "\n",
        "        tqdm.write(f\"Total Data: {len(train_loader.dataset):,}  Training : \"\n",
        "                   f\"{batch_count:,} batches, Batch_size: {train_loader.batch_size}\")\n",
        "\n",
        "        try:\n",
        "            for batch_idx, (images, labels) in enumerate(train_loader):\n",
        "                try:\n",
        "                    # Smart memory management\n",
        "                    if batch_idx % self.memory_check_interval == 0:\n",
        "                        if self.resource_manager.should_cleanup_aggressive():\n",
        "                            self.resource_manager.aggressive_cleanup()\n",
        "                            tqdm.write(f\"  Memory cleanup at batch {batch_idx}\")\n",
        "\n",
        "                    # Move data to device with optimized memory format\n",
        "                    images = images.to(Config.DEVICE, non_blocking=True, memory_format=torch.channels_last)\n",
        "                    # images = images.contiguous(memory_format=torch.channels_last)\n",
        "                    labels = labels.to(Config.DEVICE, non_blocking=True)\n",
        "\n",
        "                    # Forward pass\n",
        "                    self.optimizer.zero_grad(set_to_none=True)\n",
        "                    with torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "                        outputs = self.model(images)\n",
        "                        loss = self.criterion(outputs, labels)\n",
        "\n",
        "                    # Backward pass\n",
        "                    self.scaler.scale(loss).backward()\n",
        "                    self.scaler.unscale_(self.optimizer)\n",
        "                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
        "                    self.scaler.step(self.optimizer)\n",
        "                    self.scaler.update()\n",
        "\n",
        "                    # Calculate metrics\n",
        "                    _, predicted = torch.max(outputs, 1)\n",
        "                    batch_acc = (predicted == labels).float().mean().item()\n",
        "                    batch_loss = loss.item()\n",
        "\n",
        "                    # Update totals\n",
        "                    total_loss += batch_loss * images.size(0)\n",
        "                    total += images.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "\n",
        "                    # Update progress tracker\n",
        "                    progress_tracker.update_batch(batch_idx, batch_loss, batch_acc, is_training=True, total_batches=batch_count)\n",
        "\n",
        "                    # Progress logging every 50 batches\n",
        "                    # if batch_idx % 40 == 0 and batch_idx > 0:\n",
        "                    #     avg_loss = total_loss / total\n",
        "                    #     avg_acc = correct / total\n",
        "                    #     stats = self.resource_manager.get_memory_stats()\n",
        "                    #     tqdm.write(f\"  Batch {batch_idx:4d}/{batch_count} - \"\n",
        "                    #                f\"Loss: {avg_loss:.4f}, Acc: {avg_acc:.4f}, \"\n",
        "                    #                f\"GPU: {stats['gpu_percent']:.1f}%, CPU: {stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "                    # Memory cleanup for large batches\n",
        "                    del outputs, loss, predicted, images, labels\n",
        "\n",
        "                except Exception as e:\n",
        "                    tqdm.write(f\"Error in batch {batch_idx}: {str(e)}\")\n",
        "                    self.resource_manager.aggressive_cleanup()\n",
        "                    continue\n",
        "\n",
        "            # Final cleanup\n",
        "            self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "            return total_loss / max(1, total), correct / max(1, total)\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Training epoch failed: {str(e)}\")\n",
        "            self.resource_manager.aggressive_cleanup()\n",
        "            return float('inf'), 0.0\n",
        "\n",
        "\n",
        "\n",
        "    def validate_epoch(self, val_loader, progress_tracker):\n",
        "        \"\"\"Enhanced validation epoch with memory optimization\"\"\"\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        total_samples = 0\n",
        "        all_predictions = []\n",
        "        all_labels = []\n",
        "        all_probs = []\n",
        "        batch_count = len(val_loader)\n",
        "\n",
        "        tqdm.write(f\"Validation epoch: {len(val_loader.dataset):,} samples, \"\n",
        "                   f\"{batch_count:,} batches, batch_size: {val_loader.batch_size}\")\n",
        "\n",
        "        try:\n",
        "            with torch.no_grad():\n",
        "                for batch_idx, (images, labels) in enumerate(val_loader):\n",
        "                    try:\n",
        "                        images = images.to(Config.DEVICE, non_blocking=True, memory_format=torch.channels_last)\n",
        "                        # images = images.contiguous(memory_format=torch.channels_last)\n",
        "                        labels = labels.to(Config.DEVICE, non_blocking=True)\n",
        "\n",
        "                        with torch.cuda.amp.autocast(enabled=Config.USE_MIXED_PRECISION):\n",
        "                            outputs = self.model(images)\n",
        "                            loss = self.criterion(outputs, labels)\n",
        "\n",
        "                        _, predicted = torch.max(outputs, 1)\n",
        "                        batch_acc = (predicted == labels).float().mean().item()\n",
        "                        batch_loss = loss.item()\n",
        "\n",
        "                        # Store results\n",
        "                        total_loss += batch_loss * images.size(0)\n",
        "                        total_samples += images.size(0)\n",
        "                        all_predictions.extend(predicted.cpu().numpy())\n",
        "                        all_labels.extend(labels.cpu().numpy())\n",
        "                        all_probs.append(torch.softmax(outputs, dim=1).cpu().numpy())\n",
        "\n",
        "                        # Update progress\n",
        "                        progress_tracker.update_batch(batch_idx, batch_loss, batch_acc,\n",
        "                                                    is_training=False, total_batches=batch_count)\n",
        "\n",
        "                        # Memory cleanup\n",
        "                        del outputs, loss, predicted, images, labels\n",
        "\n",
        "                        # # Periodic memory management\n",
        "                        # if batch_idx % 20 == 0:\n",
        "                        #     self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "                    except Exception as e:\n",
        "                        tqdm.write(f\"Error in validation batch {batch_idx}: {str(e)}\")\n",
        "                        continue\n",
        "\n",
        "            # Calculate final metrics\n",
        "            all_probs = np.concatenate(all_probs, axis=0) if all_probs else np.array([])\n",
        "            val_acc = accuracy_score(all_labels, all_predictions)\n",
        "            val_f1 = f1_score(all_labels, all_predictions, average='macro', zero_division=0)\n",
        "\n",
        "            return total_loss / max(1, total_samples), val_acc, val_f1, all_predictions, all_labels, all_probs\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Validation epoch failed: {str(e)}\")\n",
        "            self.resource_manager.aggressive_cleanup()\n",
        "            return float('inf'), 0.0, 0.0, [], [], np.array([])\n",
        "\n",
        "\n",
        "\n",
        "    def train_main_model(self, train_loader, val_loader, test_loader=None):\n",
        "        \"\"\"Main model training with comprehensive logging\"\"\"\n",
        "        if not train_loader or len(train_loader.dataset) == 0:\n",
        "            tqdm.write(f\"Skipping {self.model_name}: No training data\")\n",
        "            return None, None\n",
        "\n",
        "        if not val_loader or len(val_loader.dataset) == 0:\n",
        "            tqdm.write(f\"Skipping {self.model_name}: No validation data\")\n",
        "            return None, None\n",
        "\n",
        "        tqdm.write(f\"\\nTraining {self.model_name}\")\n",
        "        tqdm.write(f\"Training samples: {len(train_loader.dataset):,}\")\n",
        "        tqdm.write(f\"Validation samples: {len(val_loader.dataset):,}\")\n",
        "        tqdm.write(f\"Total epochs: {Config.EPOCHS}\")\n",
        "        tqdm.write(f\"Batch size: {train_loader.batch_size}\")\n",
        "\n",
        "        # Print hyperparameters\n",
        "        tqdm.write(\"Hyperparameters:\")\n",
        "        for key, value in self.hyperparameters.items():\n",
        "            if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                tqdm.write(f\"  {key}: {value:.4f}\")\n",
        "            else:\n",
        "                tqdm.write(f\"  {key}: {value}\")\n",
        "\n",
        "        # Setup model for training\n",
        "        self.model = self.model.to(Config.DEVICE, memory_format=torch.channels_last)\n",
        "\n",
        "        # Add this line after model creation:\n",
        "        # self.model = torch.compile(self.model, mode=\"max-autotune\")\n",
        "\n",
        "        # torch.backends.cudnn.benchmark = True\n",
        "        # torch.backends.cudnn.deterministic = False\n",
        "\n",
        "\n",
        "        # Progress tracker\n",
        "        progress_tracker = TrainingProgressTracker(self.model_name, Config.EPOCHS, len(train_loader))\n",
        "\n",
        "        # Training loop\n",
        "        training_start_time = time.time()\n",
        "\n",
        "        # # Before loop\n",
        "        # single_models = {}\n",
        "        # single_results = {}\n",
        "\n",
        "        for epoch in range(Config.EPOCHS):\n",
        "            epoch_start_time = time.time()\n",
        "            tqdm.write(f\"\\nEpoch {epoch + 1}/{Config.EPOCHS}\")\n",
        "\n",
        "            progress_tracker.start_epoch(epoch)\n",
        "\n",
        "            # Training phase\n",
        "            train_loss, train_acc = self.train_epoch(train_loader, progress_tracker)\n",
        "\n",
        "            # Validation phase\n",
        "            val_loss, val_acc, val_f1, predictions, labels, probs = self.validate_epoch(val_loader, progress_tracker)\n",
        "\n",
        "            # Learning rate scheduling\n",
        "            if isinstance(self.scheduler, optim.lr_scheduler.ReduceLROnPlateau):\n",
        "                self.scheduler.step(val_loss)\n",
        "            else:\n",
        "                self.scheduler.step()\n",
        "\n",
        "            # Progress tracking\n",
        "            is_best = val_f1 > self.best_val_f1 * 1.001\n",
        "            current_lr = self.optimizer.param_groups[0]['lr']\n",
        "\n",
        "            progress_tracker.finish_epoch(train_loss, train_acc, val_loss, val_acc, val_f1, is_best=is_best, lr=current_lr)\n",
        "\n",
        "            # Store history\n",
        "            self.history['train_loss'].append(train_loss)\n",
        "            self.history['train_acc'].append(train_acc)\n",
        "            self.history['val_loss'].append(val_loss)\n",
        "            self.history['val_acc'].append(val_acc)\n",
        "            self.history['val_f1'].append(val_f1)\n",
        "            self.history['learning_rates'].append(current_lr)\n",
        "\n",
        "            # Early stopping and best model saving\n",
        "            # if is_best:\n",
        "            #     self.best_val_f1 = val_f1\n",
        "            #     self.best_val_acc = val_acc\n",
        "            #     self.patience_counter = 0\n",
        "            #     # torch.save(f\"{Config.OUTPUT_DIR}/best_model/{self.model_name}_best.pt\")\n",
        "            #     # Save complete model with architecture and hyperparameters\n",
        "            #     torch.save({\n",
        "            #         'state_dict': self.model.state_dict(),\n",
        "            #         'hyperparameters': self.hyperparameters,\n",
        "            #         'model_name': self.model_name\n",
        "            #     }, f\"{Config.OUTPUT_DIR}/best_model/{self.model_name}_best.pt\")\n",
        "\n",
        "            #     tqdm.write(f\"New best model saved: F1={val_f1:.4f}, Acc={val_acc:.4f}\")\n",
        "            # else:\n",
        "            #     self.patience_counter += 1\n",
        "            # Early stopping and best model saving\n",
        "            if is_best:\n",
        "                self.best_val_f1 = val_f1\n",
        "                self.best_val_acc = val_acc\n",
        "                self.patience_counter = 0\n",
        "\n",
        "                # Create comprehensive checkpoint\n",
        "                checkpoint = {\n",
        "                    # Model architecture and weights\n",
        "                    'state_dict': self.model.state_dict(),\n",
        "                    'model_name': self.model_name,\n",
        "                    'hyperparameters': self.hyperparameters,\n",
        "\n",
        "                    # Training metadata\n",
        "                    'epoch': epoch + 1,\n",
        "                    'best_val_f1': val_f1,\n",
        "                    'best_val_acc': val_acc,\n",
        "                    'optimizer_state': self.optimizer.state_dict(),\n",
        "                    'scheduler_state': self.scheduler.state_dict() if self.scheduler else None,\n",
        "\n",
        "                    # Architecture info for reconstruction\n",
        "                    'num_classes': Config.NUM_CLASSES,\n",
        "                    'dropout_rate': self.hyperparameters.get('dropout', 0.5),\n",
        "                    'hidden_dim_multiplier': self.hyperparameters.get('hidden_dim_multiplier', 0.5),\n",
        "\n",
        "                    # Save format version for future compatibility\n",
        "                    'save_format_version': '1.0'\n",
        "                }\n",
        "\n",
        "                # Save with error handling\n",
        "                try:\n",
        "                    torch.save(checkpoint, f\"{Config.OUTPUT_DIR}/best_model/{self.model_name}_best.pt\")\n",
        "                    tqdm.write(f\"‚úÖ Best model saved: F1={val_f1:.4f}, Acc={val_acc:.4f}\")\n",
        "                except Exception as e:\n",
        "                    tqdm.write(f\"‚ùå Error saving model {self.model_name}: {e}\")\n",
        "            else:\n",
        "                self.patience_counter += 1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # Epoch summary\n",
        "            epoch_time = time.time() - epoch_start_time\n",
        "            tqdm.write(f\"\\nEpoch {epoch + 1} Summary:\")\n",
        "            tqdm.write(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
        "            tqdm.write(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}, Val F1: {val_f1:.4f}\")\n",
        "            tqdm.write(f\"  Learning Rate: {current_lr:.6f}\")\n",
        "            tqdm.write(f\"  Epoch Time: {epoch_time:.1f}s\")\n",
        "            tqdm.write(f\"  Best F1 so far: {self.best_val_f1:.4f}\")\n",
        "\n",
        "            # Early stopping check\n",
        "            if self.patience_counter >= Config.PATIENCE:\n",
        "                total_time = time.time() - training_start_time\n",
        "                tqdm.write(f\"Early stopping at epoch {epoch + 1}\")\n",
        "                tqdm.write(f\"Total training time: {total_time:.1f}s\")\n",
        "                break\n",
        "\n",
        "        # # Load best model for evaluation\n",
        "        # best_model_path = f\"{Config.OUTPUT_DIR}/best_model/{self.model_name}_best.pt\"\n",
        "        # if os.path.exists(best_model_path):\n",
        "        #     # self.model.load_state_dict(torch.load(best_model_path, map_location=Config.DEVICE))\n",
        "\n",
        "        #     tqdm.write(f\"Loaded best model from {best_model_path}\")\n",
        "        # else:\n",
        "        #     tqdm.write(\"Warning: Best model not found, using current weights\")\n",
        "        # Load best model for evaluation with robust error handling\n",
        "        best_model_path = f\"{Config.OUTPUT_DIR}/best_model/{self.model_name}_best.pt\"\n",
        "        if os.path.exists(best_model_path):\n",
        "            try:\n",
        "                checkpoint = torch.load(best_model_path, map_location=Config.DEVICE, weights_only=False)\n",
        "\n",
        "                if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
        "                    # New comprehensive format\n",
        "                    self.model.load_state_dict(checkpoint['state_dict'])\n",
        "                    tqdm.write(f\"‚úÖ Loaded best model (v{checkpoint.get('save_format_version', '1.0')})\")\n",
        "                else:\n",
        "                    # Legacy format or direct state_dict\n",
        "                    self.model.load_state_dict(checkpoint)\n",
        "                    tqdm.write(f\"‚úÖ Loaded best model (legacy format)\")\n",
        "\n",
        "            except Exception as e:\n",
        "                tqdm.write(f\"‚ö†Ô∏è Could not load best model: {e}\")\n",
        "                tqdm.write(f\"Continuing with current weights...\")\n",
        "        else:\n",
        "            tqdm.write(f\"‚ö†Ô∏è Best model file not found, using current weights\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Final evaluation\n",
        "        evaluator = ModelEvaluator()\n",
        "        eval_loader = test_loader if test_loader else val_loader\n",
        "\n",
        "        with torch.no_grad():\n",
        "            result = evaluator.evaluate_model(self.model, eval_loader, self.model_name)\n",
        "\n",
        "        # Save results\n",
        "        # result_to_save = {\n",
        "        #     'history': {k: torch.tensor(v, dtype=torch.float32) for k, v in self.history.items()},\n",
        "        #     'result': {\n",
        "        #         'accuracy': torch.tensor(result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "        #         'f1': torch.tensor(result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "        #         'conf_matrix': torch.tensor(result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "        #         'true_labels': torch.tensor(result.get('true_labels', []), dtype=torch.int64),\n",
        "        #         'predictions': torch.tensor(result.get('predictions', []), dtype=torch.int64),\n",
        "        #         'probabilities': torch.tensor(result.get('probabilities', np.zeros((0, Config.NUM_CLASSES))), dtype=torch.float32),\n",
        "        #         'misclassified': [{'image': item['image'].cpu(), 'true_label': item['true_label'], 'pred_label': item['pred_label']}\n",
        "        #                         for item in result.get('misclassified', [])] if result.get('misclassified') else []\n",
        "        #     }\n",
        "        # }\n",
        "\n",
        "        result_to_save = {\n",
        "            'history': {k: torch.as_tensor(v, dtype=torch.float32).detach().cpu() for k, v in self.history.items()},\n",
        "            'result': {\n",
        "                'accuracy': torch.as_tensor(result.get('accuracy', 0.0), dtype=torch.float32).detach().cpu(),\n",
        "                'f1': torch.as_tensor(result.get('f1_macro', 0.0), dtype=torch.float32).detach().cpu(),\n",
        "                'conf_matrix': torch.as_tensor(result.get('conf_matrix', np.array([[]])), dtype=torch.int64).detach().cpu(),\n",
        "                'true_labels': torch.as_tensor(result.get('true_labels', []), dtype=torch.int64).detach().cpu(),\n",
        "                'predictions': torch.as_tensor(result.get('predictions', []), dtype=torch.int64).detach().cpu(),\n",
        "                # 'probabilities': torch.as_tensor(result.get('probabilities', np.zeros((0, Config.NUM_CLASSES))), dtype=torch.float32).detach().cpu(),\n",
        "                'probabilities': torch.as_tensor(\n",
        "                    result.get('probabilities') if result.get('probabilities') is not None else np.zeros((0, Config.NUM_CLASSES)),\n",
        "                    dtype=torch.float32\n",
        "                ).detach().cpu(),\n",
        "                # 'probabilities': torch.as_tensor(result.get('probabilities') if result.get('probabilities') is not None else np.zeros((0, Config.NUM_CLASSES)), dtype=torch.float32).detach().cpu(),\n",
        "                'misclassified': [\n",
        "                    {'image': item['image'].detach().cpu(),\n",
        "                    'true_label': item['true_label'],\n",
        "                    'pred_label': item['pred_label']}\n",
        "                    for item in result.get('misclassified', [])\n",
        "                ] if result.get('misclassified') else []\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "\n",
        "        main_result_path = f\"{Config.OUTPUT_DIR}/model_results/{self.model_name}_main_results.pt\"\n",
        "        torch.save(result_to_save, main_result_path)\n",
        "        tqdm.write(f\"Results saved to {main_result_path}\")\n",
        "\n",
        "        # Training summary\n",
        "        total_training_time = time.time() - training_start_time\n",
        "        tqdm.write(f\"\\nTraining Summary for {self.model_name}:\")\n",
        "        tqdm.write(f\"  Final Accuracy: {result.get('accuracy', 0.0):.4f}\")\n",
        "        tqdm.write(f\"  Final F1 Score: {result.get('f1_macro', 0.0):.4f}\")\n",
        "        tqdm.write(f\"  Best Validation F1: {self.best_val_f1:.4f}\")\n",
        "        tqdm.write(f\"  Total Training Time: {total_training_time:.1f}s\")\n",
        "        tqdm.write(f\"  Epochs Completed: {epoch + 1}/{Config.EPOCHS}\")\n",
        "\n",
        "        # Cleanup\n",
        "        del result_to_save, result, evaluator, eval_loader\n",
        "        self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "        # return self.history, None\n",
        "        # return None, None  # Don't return data since it's saved and also change calling function from main\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def train_kfold(self, train_loader, val_loader, test_loader, n_folds=3):\n",
        "        \"\"\"K-fold cross-validation with detailed logging\"\"\"\n",
        "        if n_folds <= 0:\n",
        "            tqdm.write(f\"Skipping k-fold for {self.model_name}: n_folds <= 0\")\n",
        "            return []\n",
        "\n",
        "\n",
        "        from torch.utils.data import ConcatDataset\n",
        "        combined_dataset = ConcatDataset([\n",
        "            train_loader.dataset,\n",
        "            val_loader.dataset\n",
        "            # test_loader.dataset if test_loader is not None else []\n",
        "        ])\n",
        "        dataset = combined_dataset\n",
        "        test_loader_fold=test_loader\n",
        "\n",
        "        # dataset = train_loader.dataset\n",
        "        total_samples = len(dataset)\n",
        "        min_samples_per_fold = 500\n",
        "\n",
        "        # Adjust folds based on data availability\n",
        "        if total_samples < n_folds * min_samples_per_fold:\n",
        "            n_folds = max(1, total_samples // min_samples_per_fold)\n",
        "            tqdm.write(f\"Adjusted to {n_folds} folds due to insufficient data\")\n",
        "\n",
        "        if n_folds < 2:\n",
        "            tqdm.write(f\"Skipping k-fold: need at least {min_samples_per_fold*2} samples, have {total_samples}\")\n",
        "            return []\n",
        "\n",
        "        # Calculate fold statistics\n",
        "        samples_per_fold = total_samples // n_folds\n",
        "        train_samples_per_fold = total_samples - samples_per_fold\n",
        "\n",
        "        tqdm.write(f\"\\nK-fold Cross-Validation Setup for {self.model_name}:\")\n",
        "        tqdm.write(f\"  Total samples: {total_samples:,}\")\n",
        "        tqdm.write(f\"  Number of folds: {n_folds}\")\n",
        "        tqdm.write(f\"  Samples per fold (validation): {samples_per_fold:,}\")\n",
        "        tqdm.write(f\"  Samples per fold (training): {train_samples_per_fold:,}\")\n",
        "\n",
        "        # Create fold indices\n",
        "        fold_indices = []\n",
        "        for i in range(n_folds):\n",
        "            val_start = i * samples_per_fold\n",
        "            val_end = min(val_start + samples_per_fold, total_samples)\n",
        "            val_idx = list(range(val_start, val_end))\n",
        "            train_idx = list(range(0, val_start)) + list(range(val_end, total_samples))\n",
        "            fold_indices.append((train_idx, val_idx))\n",
        "\n",
        "            tqdm.write(f\"  Fold {i+1}: Train={len(train_idx):,}, Val={len(val_idx):,}\")\n",
        "\n",
        "        # Optimize settings for k-fold\n",
        "        # fold_batch_size = self.resource_manager.optimize_batch_size(64, 1.0)\n",
        "        # Use the ResourceManager method directly\n",
        "        base_batch_size = self.hyperparameters.get('batch_size', Config.BATCH_SIZE)\n",
        "        # Use the same complexity calculation as in main()\n",
        "        model_complexity_map = {\n",
        "            'efficientnet': 1.5,\n",
        "            'resnet': 1.0,\n",
        "            'vgg': 0.8,\n",
        "            'mobilenet': 0.6,\n",
        "            'densenet': 1.3,\n",
        "            'convnext': 1.4\n",
        "        }\n",
        "        model_complexity = model_complexity_map.get(self.model_name.split('_')[0].lower(), 1.0)\n",
        "        fold_batch_size = self.resource_manager.optimize_batch_size(base_batch_size, model_complexity)\n",
        "        # fold_batch_size = self.resource_manager.optimize_batch_size(base_batch_size, model_name=self.model_name)\n",
        "\n",
        "        prefetch_factor = min(4, max(2, self.resource_manager.cpu_memory_gb // 10))\n",
        "        num_workers = min(8, mp.cpu_count() // 2)\n",
        "\n",
        "        tqdm.write(f\"K-fold optimized settings:\")\n",
        "        tqdm.write(f\"  Batch size: {fold_batch_size}\")\n",
        "        tqdm.write(f\"  Workers: {num_workers}\")\n",
        "        tqdm.write(f\"  Prefetch factor: {prefetch_factor}\")\n",
        "\n",
        "        fold_results = []\n",
        "        total_kfold_start = time.time()\n",
        "\n",
        "        for fold, (train_idx, val_idx) in enumerate(fold_indices, 1):\n",
        "            fold_start_time = time.time()\n",
        "            tqdm.write(f\"\\nTraining Fold {fold}/{n_folds}\")\n",
        "\n",
        "            try:\n",
        "                # Create fold-specific data loaders\n",
        "                train_subsampler = SubsetRandomSampler(train_idx)\n",
        "                val_subsampler = SubsetRandomSampler(val_idx)\n",
        "\n",
        "                train_loader_fold = DataLoader(\n",
        "                    dataset,\n",
        "                    batch_size=fold_batch_size,\n",
        "                    sampler=train_subsampler,\n",
        "                    num_workers=num_workers,\n",
        "                    pin_memory=torch.cuda.is_available(),\n",
        "                    prefetch_factor=prefetch_factor,\n",
        "                    persistent_workers=num_workers > 0,\n",
        "                    worker_init_fn=worker_init_fn if 'worker_init_fn' in globals() else None\n",
        "                )\n",
        "\n",
        "                val_loader_fold = DataLoader(\n",
        "                    dataset,\n",
        "                    batch_size=fold_batch_size,\n",
        "                    sampler=val_subsampler,\n",
        "                    num_workers=num_workers,\n",
        "                    pin_memory=torch.cuda.is_available(),\n",
        "                    prefetch_factor=prefetch_factor,\n",
        "                    persistent_workers=num_workers > 0,\n",
        "                    worker_init_fn=worker_init_fn if 'worker_init_fn' in globals() else None\n",
        "                )\n",
        "\n",
        "                # Create fold model\n",
        "                fold_model = ModelFactory.create_model(\n",
        "                    self.model_name,\n",
        "                    num_classes=Config.NUM_CLASSES,\n",
        "                    dropout_rate=self.hyperparameters.get('dropout', 0.5),\n",
        "                    hidden_dim_multiplier=self.hyperparameters.get('hidden_dim_multiplier', 0.5)\n",
        "                ).to(Config.DEVICE, memory_format=torch.channels_last)\n",
        "\n",
        "                # Create fold trainer\n",
        "                fold_trainer = EnhancedModelTrainer(fold_model, f\"{self.model_name}_fold_{fold}\", self.hyperparameters)\n",
        "\n",
        "                # Train fold\n",
        "                # fold_history, fold_result =\n",
        "                fold_trainer.train_main_model(train_loader_fold, val_loader_fold, test_loader=None)\n",
        "                fold_time = time.time() - fold_start_time\n",
        "\n",
        "                # Save trained model\n",
        "                fold_model_path = f\"{Config.OUTPUT_DIR}/kfold_results/{self.model_name}_fold_{fold}_model.pt\"\n",
        "                torch.save(fold_model.state_dict(), fold_model_path)\n",
        "\n",
        "\n",
        "                # Load the model back (optional but ensures evaluation uses saved model)\n",
        "                fold_model.load_state_dict(torch.load(fold_model_path))\n",
        "                fold_model.to(Config.DEVICE)\n",
        "\n",
        "                # Evaluate the fold\n",
        "                evaluator = ModelEvaluator()\n",
        "                eval_loader = test_loader_fold  # or test_loader if you have it\n",
        "                with torch.no_grad():\n",
        "                    fold_result = evaluator.evaluate_model(fold_model, eval_loader, f\"{self.model_name}_fold_{fold}\")\n",
        "\n",
        "                # # Handle fold results\n",
        "                # if fold_history is None or fold_result is None:\n",
        "                #     tqdm.write(f\"Fold {fold} training failed\")\n",
        "                #     fold_result = {\n",
        "                #         'accuracy': 0.0, 'f1_macro': 0.0, 'conf_matrix': np.array([[]]),\n",
        "                #         'true_labels': [], 'predictions': [], 'probabilities': np.zeros((0, Config.NUM_CLASSES)),\n",
        "                #         'misclassified': []\n",
        "                #     }\n",
        "                #     fold_history = {'val_loss': [], 'val_acc': []}\n",
        "\n",
        "\n",
        "                # # Store results\n",
        "                # fold_results.append({\n",
        "                #     'history': {\n",
        "                #         'val_loss': fold_history.get('val_loss', []),\n",
        "                #         'val_acc': fold_history.get('val_acc', [])\n",
        "                #     },\n",
        "                #     'result': {\n",
        "                #         'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "                #         'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "                #         'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "                #         'misclassified': fold_result.get('misclassified', [])\n",
        "                #     }\n",
        "                # })\n",
        "\n",
        "                # Save fold results\n",
        "                # fold_result_to_save = {\n",
        "                #     'history': {\n",
        "                #         'val_loss': torch.tensor(fold_history.get('val_loss', []), dtype=torch.float32),\n",
        "                #         'val_acc': torch.tensor(fold_history.get('val_acc', []), dtype=torch.float32)\n",
        "                #     },\n",
        "                #     'result': {\n",
        "                #         'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "                #         'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "                #         'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "                #         'misclassified': fold_result.get('misclassified', [])\n",
        "                #     }\n",
        "                # }\n",
        "                # Save fold results\n",
        "                fold_result_to_save = {\n",
        "                    'history': {  # assuming train_main_model updates self.history inside fold_trainer\n",
        "                        'val_loss': torch.tensor(fold_trainer.history.get('val_loss', []), dtype=torch.float32),\n",
        "                        'val_acc': torch.tensor(fold_trainer.history.get('val_acc', []), dtype=torch.float32)\n",
        "                    },\n",
        "                    'result': {\n",
        "                        'accuracy': torch.tensor(fold_result.get('accuracy', 0.0), dtype=torch.float32),\n",
        "                        'f1': torch.tensor(fold_result.get('f1_macro', 0.0), dtype=torch.float32),\n",
        "                        'conf_matrix': torch.tensor(fold_result.get('conf_matrix', np.array([[]])), dtype=torch.int64),\n",
        "                        'misclassified': fold_result.get('misclassified', [])\n",
        "                    }\n",
        "                }\n",
        "\n",
        "\n",
        "\n",
        "                fold_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{self.model_name}_fold_{fold}_results.pt\"\n",
        "                torch.save(fold_result_to_save, fold_result_path)\n",
        "\n",
        "                tqdm.write(f\"Fold {fold} completed in {fold_time:.1f}s - \"\n",
        "                          f\"Accuracy: {fold_result.get('accuracy', 0.0):.4f}, \"\n",
        "                          f\"F1: {fold_result.get('f1_macro', 0.0):.4f}\")\n",
        "\n",
        "                # Cleanup fold\n",
        "                del fold_trainer, fold_model #, fold_history, fold_result\n",
        "                del train_loader_fold, val_loader_fold, train_subsampler, val_subsampler\n",
        "                self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "            except Exception as e:\n",
        "                tqdm.write(f\"Error in fold {fold}: {str(e)}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "                continue\n",
        "\n",
        "        total_kfold_time = time.time() - total_kfold_start\n",
        "        # successful_folds = len(fold_results)\n",
        "\n",
        "        tqdm.write(f\"\\nK-fold Summary for {self.model_name}:\")\n",
        "        # tqdm.write(f\"  Successful folds: {successful_folds}/{n_folds}\")\n",
        "        tqdm.write(f\"  Total k-fold time: {total_kfold_time:.1f}s\")\n",
        "        # tqdm.write(f\"  Average time per fold: {total_kfold_time/max(1,successful_folds):.1f}s\")\n",
        "\n",
        "        # return []\n",
        "        # return fold_results\n",
        "\n",
        "\n",
        "\n",
        "    def cleanup_trainer(self):\n",
        "        \"\"\"Complete cleanup of trainer resources\"\"\"\n",
        "        try:\n",
        "            if hasattr(self, 'model'):\n",
        "                del self.model\n",
        "            if hasattr(self, 'optimizer'):\n",
        "                del self.optimizer\n",
        "            if hasattr(self, 'scheduler'):\n",
        "                del self.scheduler\n",
        "            if hasattr(self, 'criterion'):\n",
        "                del self.criterion\n",
        "            if hasattr(self, 'scaler'):\n",
        "                del self.scaler\n",
        "\n",
        "            self.history.clear()\n",
        "            self.resource_manager.aggressive_cleanup()\n",
        "\n",
        "        except Exception as e:\n",
        "            tqdm.write(f\"Cleanup error: {e}\")"
      ],
      "metadata": {
        "id": "V57jiUT2c3BV"
      },
      "id": "V57jiUT2c3BV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 13: Model Training"
      ],
      "metadata": {
        "id": "rQ_reeX1cZz4"
      },
      "id": "rQ_reeX1cZz4"
    },
    {
      "cell_type": "code",
      "source": [
        "# orig_numpy = torch.Tensor.numpy\n",
        "# def patched_numpy(self, *args, **kwargs):\n",
        "#     if self.is_cuda:\n",
        "#         raise RuntimeError(f\"Tried to call .numpy() on CUDA tensor at line ???. Move it to CPU first!\")\n",
        "#     return orig_numpy(self, *args, **kwargs)\n",
        "\n",
        "# torch.Tensor.numpy = patched_numpy\n",
        "\n",
        "class ResourceManager:\n",
        "    \"\"\"Smart resource management for optimal GPU/CPU utilization\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.gpu_memory_gb = 20\n",
        "        self.cpu_memory_gb = 50\n",
        "        self.max_gpu_usage = 0.85  # 85% of 20GB = 17GB\n",
        "        self.max_cpu_usage = 0.90  # 80% of 50GB = 40GB\n",
        "\n",
        "    def get_memory_stats(self):\n",
        "        \"\"\"Get current memory usage statistics\"\"\"\n",
        "        stats = {'cpu_percent': psutil.virtual_memory().percent}\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            stats['gpu_allocated_gb'] = torch.cuda.memory_allocated() / (1024**3)\n",
        "            stats['gpu_reserved_gb'] = torch.cuda.memory_reserved() / (1024**3)\n",
        "            stats['gpu_percent'] = (stats['gpu_reserved_gb'] / self.gpu_memory_gb) * 100\n",
        "        else:\n",
        "            stats.update({'gpu_allocated_gb': 0, 'gpu_reserved_gb': 0, 'gpu_percent': 0})\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def should_cleanup_aggressive(self):\n",
        "        \"\"\"Check if aggressive cleanup is needed\"\"\"\n",
        "        stats = self.get_memory_stats()\n",
        "        return (stats['gpu_percent'] > 90 or stats['cpu_percent'] > 90)\n",
        "\n",
        "    def aggressive_cleanup(self):\n",
        "        \"\"\"Perform comprehensive memory cleanup\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "        gc.collect()\n",
        "        time.sleep(0.1)  # Brief pause for system cleanup\n",
        "\n",
        "    def optimize_batch_size(self, base_size, model_complexity=1.0):\n",
        "        \"\"\"Calculate optimal batch size based on current memory state\"\"\"\n",
        "        stats = self.get_memory_stats()\n",
        "\n",
        "        # Reduce batch size if memory usage is high\n",
        "        memory_factor = max(0.4, 1.0 - (stats['gpu_percent'] / 100))\n",
        "        optimal_size = int(base_size * memory_factor / model_complexity)\n",
        "\n",
        "        return max(32, min(256, optimal_size))  # Keep within reasonable bounds\n",
        "\n",
        "\n",
        "def safe_gpu_convert(data):\n",
        "    \"\"\"Safely convert GPU tensors to CPU numpy arrays or lists\"\"\"\n",
        "    if torch.is_tensor(data):\n",
        "        if data.is_cuda:\n",
        "            data = data.detach().cpu()\n",
        "        if data.dim() == 0:\n",
        "            return data.item()\n",
        "        elif data.dtype == torch.bool or data.dtype == torch.uint8:\n",
        "            return data.numpy()\n",
        "        else:\n",
        "            return data.numpy() if data.dim() > 0 else data.item()\n",
        "    elif isinstance(data, list):\n",
        "        return [safe_gpu_convert(item) for item in data]\n",
        "    elif isinstance(data, dict):\n",
        "        return {k: safe_gpu_convert(v) for k, v in data.items()}\n",
        "    elif isinstance(data, np.ndarray):\n",
        "        return data  # Already numpy\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"\\nStarting Fish Species Model Training...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Environment setup for maximum performance\n",
        "    setup_environment()\n",
        "\n",
        "\n",
        "    # Set optimal thread count for CPU utilization\n",
        "    print(f\"CPU : {os.cpu_count()}\")\n",
        "    print(f\"USER: {os.getenv('USER')}\")\n",
        "    print(f\"HOME: {os.getenv('HOME')}\")\n",
        "    torch.set_num_threads(min(16, os.cpu_count()))\n",
        "    os.environ['OMP_NUM_THREADS'] = str(min(16, os.cpu_count()))\n",
        "\n",
        "    # OpenMP ‚Üí Open Multi-Processing.\n",
        "    # OpenMP is a widely used API for parallel programming on CPUs.\n",
        "    # Many scientific libraries (like NumPy, PyTorch, TensorFlow,\n",
        "    # -OpenCV, Scikit-learn) rely on OpenMP to run operations in parallel across CPU cores.\n",
        "    # In main() after line 720:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    # Auto-benchmarks and selects fastest cuDNN algorithms for your specific hardware and input sizes\n",
        "    # Takes ~5-10 seconds at start but can provide 10-20% speedup throughout training\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    # Allows cuDNN to use fastest available algorithms even if they produce slightly different results each run\n",
        "    # Trades reproducibility for speed - essential for maximum performance in production training\n",
        "    # torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    # Uses TensorFloat-32 (19-bit precision) instead of full Float-32 for matrix multiplications\n",
        "    # Provides ~1.6x speedup on Ampere GPUs with negligible accuracy loss for deep learning\n",
        "    # torch.backends.cudnn.allow_tf32 = True\n",
        "    # Enables TF32 precision for cuDNN operations (convolutions, pooling, batch norm)\n",
        "    # Accelerates CNN layers by 1.3-1.6x on RTX 30/40 series and A100+ GPUs\n",
        "    torch.backends.cuda.enable_flash_sdp(True)\n",
        "    # Activates Flash Attention algorithm for memory-efficient attention computations\n",
        "    # Reduces GPU memory usage by 2-4x and increases attention speed, crucial for transformer layers\n",
        "\n",
        "    # GPU optimizations\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "        gpu_props = torch.cuda.get_device_properties(0)\n",
        "        print(f\"GPU: {gpu_props.name}, Memory: {gpu_props.total_memory / 1024**3:.1f}GB\")\n",
        "\n",
        "    # CPU info\n",
        "    print(f\"CPU Cores: {os.cpu_count()}, Using threads: {torch.get_num_threads()}\")\n",
        "\n",
        "    # Ensure all output directories exist\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/models\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/kfold_results\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/model_results\", exist_ok=True)\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/best_model\", exist_ok=True)\n",
        "\n",
        "    # Initialize resource manager\n",
        "    resource_manager = ResourceManager()\n",
        "\n",
        "    # Load and balance data (only once)\n",
        "    print(\"\\nLoading and balancing data...\")\n",
        "    X, Y = DataManager.load_and_balance_data()\n",
        "    print(f\"Total samples after balancing: {len(X):,}, Labels: {len(Y):,}\")\n",
        "\n",
        "    # Validate data consistency\n",
        "    if len(X) != len(Y):\n",
        "        raise ValueError(f\"Inconsistent data: X has {len(X)} samples, Y has {len(Y)} labels\")\n",
        "    if len(X) == 0:\n",
        "        raise ValueError(\"No data available after loading and balancing\")\n",
        "\n",
        "    # Load all best parameters from hyperparameter optimization\n",
        "    master_params_file = f\"{Config.OUTPUT_DIR}/hyperparameters/all_best_params.json\"\n",
        "    if os.path.exists(master_params_file):\n",
        "        with open(master_params_file, 'r') as f:\n",
        "            all_best_params = json.load(f)\n",
        "        print(f\"Loaded best parameters for {len(all_best_params)} models\")\n",
        "    else:\n",
        "        print(\"No hyperparameters found, using default parameters\")\n",
        "        all_best_params = {}\n",
        "\n",
        "    # Process each model individually\n",
        "    for model_name in Config.MODELS:\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"TRAINING MODEL: {model_name}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Pre-model memory state\n",
        "        pre_stats = resource_manager.get_memory_stats()\n",
        "        print(f\"Pre-training memory - GPU: {pre_stats['gpu_allocated_gb']:.2f}GB ({pre_stats['gpu_percent']:.1f}%), \"\n",
        "              f\"CPU: {pre_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "        try:\n",
        "            # Load best parameters for this model\n",
        "            if model_name in all_best_params:\n",
        "                best_params = all_best_params[model_name]\n",
        "                print(f\"Using optimized parameters for {model_name}\")\n",
        "            else:\n",
        "                # Load individual parameter file as fallback\n",
        "                params_file = f\"{Config.OUTPUT_DIR}/hyperparameters/{model_name}_best_params.json\"\n",
        "                if os.path.exists(params_file):\n",
        "                    with open(params_file, 'r') as f:\n",
        "                        best_params = json.load(f)\n",
        "                    print(f\"Loaded individual parameters for {model_name}\")\n",
        "                else:\n",
        "                    # Default parameters as last resort\n",
        "                    best_params = {\n",
        "                        'lr': 0.001,\n",
        "                        'weight_decay': 0.0001,\n",
        "                        'dropout': 0.5,\n",
        "                        'batch_size': 32,\n",
        "                        'hidden_dim_multiplier': 0.5,\n",
        "                        'augmentation_strength': 'medium'\n",
        "                    }\n",
        "                    print(f\"Using default parameters for {model_name}\")\n",
        "\n",
        "            # Display parameters being used\n",
        "            print(f\"\\n{model_name.upper()} TRAINING PARAMETERS:\")\n",
        "            for key, value in best_params.items():\n",
        "                if key in ['lr', 'weight_decay', 'dropout', 'hidden_dim_multiplier', 'label_smoothing']:\n",
        "                    print(f\"  {key}: {value:.4f}\")\n",
        "                else:\n",
        "                    print(f\"  {key}: {value}\")\n",
        "\n",
        "            # Step 1: Create data loaders with optimized parameters\n",
        "            print(f\"\\n1. CREATING DATA LOADERS WITH OPTIMIZED PARAMETERS FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Calculate optimal batch size based on model complexity\n",
        "            model_complexity_map = {\n",
        "                'efficientnet_': 1.5,  # matches efficientnet_b0, efficientnet_b7 etc.\n",
        "                'resnet': 1.0,         # matches resnet18, resnet50 etc.\n",
        "                'vgg': 0.8,            # matches vgg16, vgg19 etc.\n",
        "                'mobilenet_': 0.6,     # matches mobilenet_v2, mobilenet_v3 etc.\n",
        "                'densenet': 1.3,       # matches densenet121, densenet201 etc.\n",
        "                'convnext_': 1.4       # matches convnext_tiny, convnext_base etc.\n",
        "            }\n",
        "\n",
        "            model_complexity = model_complexity_map.get(model_name.split('_')[0].lower(), 1.0) #model_name gets from for loop.\n",
        "            #\"EfficientNet_B0\".split('_')[0].lower() ‚Üí \"efficientnet\"\n",
        "            base_batch_size = best_params.get('batch_size', Config.BATCH_SIZE)\n",
        "            optimized_batch_size = resource_manager.optimize_batch_size(base_batch_size, model_complexity)\n",
        "\n",
        "            # Create with optimized batch size and GPU-optimized settings\n",
        "            train_loader, val_loader, test_loader, val_data, test_data = DataManager.create_data_loaders(\n",
        "                X, Y,\n",
        "                test_size=0.2,\n",
        "                batch_size=optimized_batch_size,\n",
        "                augmentation_strength=best_params.get('augmentation_strength', 'medium')\n",
        "            )\n",
        "\n",
        "            # Optimize data loaders for GPU\n",
        "            optimal_workers = min(16, max(8, os.cpu_count() // 2))\n",
        "            for loader in [train_loader, val_loader, test_loader]:\n",
        "                if loader:\n",
        "                    loader.pin_memory = torch.cuda.is_available()\n",
        "                    loader.num_workers = optimal_workers\n",
        "                    loader.prefetch_factor = 4 if optimal_workers > 0 else 2\n",
        "\n",
        "            # Validate data loaders\n",
        "            print(f\"Train: {len(train_loader.dataset)}, Val: {len(val_loader.dataset)}, Test: {len(test_loader.dataset)}\")\n",
        "            print(f\"Optimized batch size: {optimized_batch_size} (complexity factor: {model_complexity})\")\n",
        "\n",
        "            if not train_loader or len(train_loader.dataset) == 0:\n",
        "                print(f\"Skipping {model_name}: No training data available\")\n",
        "                continue #To Go Next Model\n",
        "            if not val_loader or len(val_loader.dataset) == 0:\n",
        "                print(f\"Skipping {model_name}: No validation data available\")\n",
        "                continue\n",
        "\n",
        "            # Additional validation for val_data and test_data tuples\n",
        "            if val_data is not None and len(val_data) == 2:\n",
        "                print(f\"Val data tuple: X={len(val_data[0])}, Y={len(val_data[1])}\")\n",
        "                if len(val_data[0]) != len(val_data[1]):\n",
        "                    print(f\"WARNING: Validation data inconsistency: {len(val_data[0])} samples vs {len(val_data[1])} labels\")\n",
        "\n",
        "            if test_data is not None and len(test_data) == 2:\n",
        "                print(f\"Test data tuple: X={len(test_data[0])}, Y={len(test_data[1])}\")\n",
        "                if len(test_data[0]) != len(test_data[1]):\n",
        "                    print(f\"WARNING: Test data inconsistency: {len(test_data[0])} samples vs {len(test_data[1])} labels\")\n",
        "\n",
        "            # Step 2: Train main model\n",
        "            print(f\"\\n2. MAIN MODEL TRAINING FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            model = ModelFactory.create_model(\n",
        "                model_name,\n",
        "                num_classes=Config.NUM_CLASSES,\n",
        "                dropout_rate=best_params.get('dropout', 0.5),\n",
        "                hidden_dim_multiplier=best_params.get('hidden_dim_multiplier', 0.5)\n",
        "            ).to(Config.DEVICE, memory_format=torch.channels_last)  # GPU optimization\n",
        "\n",
        "            # Model info\n",
        "            total_model_params = sum(p.numel() for p in model.parameters())\n",
        "            trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "            print(f\"Model created: {total_model_params:,} total params, {trainable_params:,} trainable\")\n",
        "\n",
        "            # Additional GPU optimizations\n",
        "            torch.backends.cudnn.benchmark = True\n",
        "            torch.backends.cudnn.deterministic = False\n",
        "            # Tells cuDNN (NVIDIA's deep learning library) to find the fastest algorithm for your hardware and input size.\n",
        "            # Benchmarking finds the fastest algorithm.\n",
        "            # Non-determinism allows cuDNN to use even faster (but slightly variable) methods.\n",
        "            # Together ‚Üí maximum training speed, but with non-reproducible results (F1 score may vary slightly between runs).\n",
        "            # For speed ‚Üí benchmark=True, deterministic=False (your case).\n",
        "            # For reproducibility ‚Üí benchmark=False, deterministic=True.\n",
        "\n",
        "            trainer = EnhancedModelTrainer(model, model_name, best_params)\n",
        "            # history, result = trainer.train_main_model(train_loader, val_loader, test_loader)\n",
        "            trainer.train_main_model(train_loader, val_loader, test_loader)\n",
        "\n",
        "            # if history is None or result is None: #No Need cause Data is saved to Disk Directly\n",
        "            #     print(f\"Training failed for {model_name}, skipping...\")\n",
        "            #     continue\n",
        "\n",
        "            print(f\"Main model training completed for {model_name}\")\n",
        "\n",
        "            # Step 3: K-fold cross-validation\n",
        "            print(f\"\\n3. K-FOLD CROSS-VALIDATION FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Ensure we have sufficient data for k-fold\n",
        "            total_samples = len(train_loader.dataset)\n",
        "            min_samples_per_fold = 500\n",
        "            max_folds = total_samples // min_samples_per_fold\n",
        "            n_folds = min(3, max_folds) if max_folds > 1 else 0\n",
        "\n",
        "            if n_folds > 1:\n",
        "                print(f\"Performing {n_folds}-fold cross-validation...\")\n",
        "                # fold_results =\n",
        "                trainer.train_kfold(train_loader, val_loader, test_loader,n_folds=n_folds)\n",
        "                print(f\"K-fold validation completed for {model_name}\")\n",
        "            else:\n",
        "                print(f\"Skipping k-fold validation for {model_name}: insufficient data (need >{min_samples_per_fold*2} samples)\")\n",
        "                fold_results = []\n",
        "\n",
        "            # Step 4: Save model in both .pt and .keras formats\n",
        "            print(f\"\\n4. SAVING MODEL FILES FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Save model for ensemble\n",
        "            model_state_dict = model.state_dict()\n",
        "            torch.save(model_state_dict, f\"{Config.OUTPUT_DIR}/models/{model_name}_for_ensemble.pt\")\n",
        "            print(f\"Model saved for ensemble: {model_name}\")\n",
        "\n",
        "            # Save model as .pt file (PyTorch format)\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'model_name': model_name,\n",
        "                'num_classes': Config.NUM_CLASSES,\n",
        "                'hyperparameters': best_params,\n",
        "                'architecture_info': {\n",
        "                    'dropout_rate': best_params.get('dropout', 0.5),\n",
        "                    'hidden_dim_multiplier': best_params.get('hidden_dim_multiplier', 0.5)\n",
        "                }\n",
        "            }, f\"{Config.OUTPUT_DIR}/best_model/{model_name}_best.pt\")\n",
        "            print(f\"Model saved as .pt file: {model_name}_best.pt\")\n",
        "\n",
        "            # Save model as .keras file (if TensorFlow/Keras conversion is available)\n",
        "            try:\n",
        "                # This would require conversion logic if needed\n",
        "                # For now, we'll save a placeholder or skip\n",
        "                print(f\"Keras format saving for {model_name} - conversion logic needed\")\n",
        "            except Exception as e:\n",
        "                print(f\"Could not save {model_name} in Keras format: {e}\")\n",
        "\n",
        "            # Step 5: Memory cleanup for this model\n",
        "            print(f\"\\n5. MEMORY CLEANUP FOR {model_name}\")\n",
        "            print(\"-\"*50)\n",
        "\n",
        "            # Clear all variables specific to this model\n",
        "            trainer.cleanup_trainer()\n",
        "            # del trainer, history, result, model_state_dict\n",
        "            del train_loader, val_loader, test_loader\n",
        "            if 'model' in locals():\n",
        "                del model\n",
        "            if 'model_state_dict' in locals():\n",
        "                del model_state_dict\n",
        "\n",
        "            # Force garbage collection and GPU cleanup\n",
        "            resource_manager.aggressive_cleanup()\n",
        "\n",
        "            # Post-model memory state\n",
        "            post_stats = resource_manager.get_memory_stats()\n",
        "            memory_freed = pre_stats['gpu_allocated_gb'] - post_stats['gpu_allocated_gb']\n",
        "\n",
        "            print(f\"Memory cleanup completed for {model_name}:\")\n",
        "            print(f\"  GPU memory freed: {memory_freed:.2f}GB\")\n",
        "            print(f\"  Current GPU usage: {post_stats['gpu_percent']:.1f}%\")\n",
        "            print(f\"  Current CPU usage: {post_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "            print(f\"‚úì {model_name} TRAINING COMPLETED!\")\n",
        "            print(f\"{'='*70}\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {model_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "            # Emergency cleanup\n",
        "            try:\n",
        "                if 'trainer' in locals():\n",
        "                    trainer.cleanup_trainer()\n",
        "                    del trainer\n",
        "                if 'model' in locals():\n",
        "                    del model\n",
        "                resource_manager.aggressive_cleanup()\n",
        "            except:\n",
        "                pass\n",
        "            continue\n",
        "\n",
        "    # Final cleanup\n",
        "    print(\"\\nFinal cleanup and summary...\")\n",
        "    try:\n",
        "        # Clean up all remaining variables\n",
        "        if 'X' in locals():\n",
        "            del X\n",
        "        if 'Y' in locals():\n",
        "            del Y\n",
        "        if 'all_best_params' in locals():\n",
        "            del all_best_params\n",
        "\n",
        "        resource_manager.aggressive_cleanup()\n",
        "\n",
        "        # Final memory stats\n",
        "        final_stats = resource_manager.get_memory_stats()\n",
        "        print(f\"Final GPU memory: {final_stats['gpu_allocated_gb']:.2f}GB allocated ({final_stats['gpu_percent']:.1f}%)\")\n",
        "        print(f\"Final CPU usage: {final_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in final cleanup: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"MODEL TRAINING COMPLETED!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nGenerated Files:\")\n",
        "    print(f\"- Model checkpoints: {Config.OUTPUT_DIR}/models/\")\n",
        "    print(f\"- Training results: {Config.OUTPUT_DIR}/model_results/\")\n",
        "    print(f\"- K-fold results: {Config.OUTPUT_DIR}/kfold_results/\")\n",
        "    print(f\"- Best models: {Config.OUTPUT_DIR}/best_model/\")\n",
        "\n",
        "\n",
        "# Environment setup and multiprocessing configuration\n",
        "import torch.multiprocessing as mp\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "n1jro0uqbxGu"
      },
      "id": "n1jro0uqbxGu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 14: Visualization Function Call"
      ],
      "metadata": {
        "id": "DcoZXMdccf7h"
      },
      "id": "DcoZXMdccf7h"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "15.Fish Species Classification Pipeline - Visualization Module\n",
        "========================================================\n",
        "\n",
        "This module handles all visualization generation using saved models and results.\n",
        "It loads saved .pt model files and generates comprehensive visualizations.\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import time\n",
        "import psutil\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# orig_numpy = torch.Tensor.numpy\n",
        "# def patched_numpy(self, *args, **kwargs):\n",
        "#     if self.is_cuda:\n",
        "#         raise RuntimeError(f\"Tried to call .numpy() on CUDA tensor at line ???. Move it to CPU first!\")\n",
        "#     return orig_numpy(self, *args, **kwargs)\n",
        "\n",
        "# torch.Tensor.numpy = patched_numpy\n",
        "\n",
        "class ResourceManager:\n",
        "    \"\"\"Smart resource management for optimal GPU/CPU utilization\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.gpu_memory_gb = 20\n",
        "        self.cpu_memory_gb = 50\n",
        "        self.max_gpu_usage = 0.85  # 85% of 20GB = 17GB\n",
        "        self.max_cpu_usage = 0.90  # 80% of 50GB = 40GB\n",
        "\n",
        "    def get_memory_stats(self):\n",
        "        \"\"\"Get current memory usage statistics\"\"\"\n",
        "        stats = {'cpu_percent': psutil.virtual_memory().percent}\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            stats['gpu_allocated_gb'] = torch.cuda.memory_allocated() / (1024**3)\n",
        "            stats['gpu_reserved_gb'] = torch.cuda.memory_reserved() / (1024**3)\n",
        "            stats['gpu_percent'] = (stats['gpu_reserved_gb'] / self.gpu_memory_gb) * 100\n",
        "        else:\n",
        "            stats.update({'gpu_allocated_gb': 0, 'gpu_reserved_gb': 0, 'gpu_percent': 0})\n",
        "\n",
        "        return stats\n",
        "\n",
        "    def should_cleanup_aggressive(self):\n",
        "        \"\"\"Check if aggressive cleanup is needed\"\"\"\n",
        "        stats = self.get_memory_stats()\n",
        "        return (stats['gpu_percent'] > 90 or stats['cpu_percent'] > 90)\n",
        "\n",
        "    def aggressive_cleanup(self):\n",
        "        \"\"\"Perform comprehensive memory cleanup\"\"\"\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "        gc.collect()\n",
        "        time.sleep(0.1)  # Brief pause for system cleanup\n",
        "\n",
        "    def optimize_batch_size(self, base_size, model_complexity=1.0):\n",
        "        \"\"\"Calculate optimal batch size based on current memory state\"\"\"\n",
        "        stats = self.get_memory_stats()\n",
        "\n",
        "        # Reduce batch size if memory usage is high\n",
        "        memory_factor = max(0.4, 1.0 - (stats['gpu_percent'] / 100))\n",
        "        optimal_size = int(base_size * memory_factor / model_complexity)\n",
        "\n",
        "        return max(32, min(256, optimal_size))  # Keep within reasonable bounds\n",
        "\n",
        "\n",
        "def safe_gpu_convert(data):\n",
        "    \"\"\"Safely convert GPU tensors to CPU numpy arrays or lists\"\"\"\n",
        "    if torch.is_tensor(data):\n",
        "        if data.is_cuda:\n",
        "            data = data.detach().cpu()\n",
        "        if data.dim() == 0:\n",
        "            return data.item()\n",
        "        elif data.dtype == torch.bool or data.dtype == torch.uint8:\n",
        "            return data.numpy()\n",
        "        else:\n",
        "            return data.numpy() if data.dim() > 0 else data.item()\n",
        "    elif isinstance(data, list):\n",
        "        return [safe_gpu_convert(item) for item in data]\n",
        "    elif isinstance(data, dict):\n",
        "        return {k: safe_gpu_convert(v) for k, v in data.items()}\n",
        "    elif isinstance(data, np.ndarray):\n",
        "        return data  # Already numpy\n",
        "    else:\n",
        "        return data\n",
        "\n",
        "\n",
        "def load_model_safely(model_name, model_path):\n",
        "    \"\"\"Safely load model with multiple fallback strategies\"\"\"\n",
        "    try:\n",
        "        checkpoint = torch.load(model_path, map_location=Config.DEVICE, weights_only=False)\n",
        "\n",
        "        if isinstance(checkpoint, dict) and 'state_dict' in checkpoint:\n",
        "            # New comprehensive format - use saved architecture info\n",
        "            model = ModelFactory.create_model(\n",
        "                model_name,\n",
        "                num_classes=checkpoint.get('num_classes', Config.NUM_CLASSES),\n",
        "                dropout_rate=checkpoint.get('dropout_rate', 0.5),\n",
        "                hidden_dim_multiplier=checkpoint.get('hidden_dim_multiplier', 0.5)\n",
        "            )\n",
        "            model.to(Config.DEVICE)\n",
        "            model.load_state_dict(checkpoint['state_dict'])\n",
        "            return model, f\"new format v{checkpoint.get('save_format_version', '1.0')}\"\n",
        "\n",
        "        elif isinstance(checkpoint, dict):\n",
        "            # Legacy format - try with hyperparameters\n",
        "            hyperparams = checkpoint.get('hyperparameters', {})\n",
        "            model = ModelFactory.create_model(\n",
        "                model_name,\n",
        "                num_classes=Config.NUM_CLASSES,\n",
        "                dropout_rate=hyperparams.get('dropout', 0.5),\n",
        "                hidden_dim_multiplier=hyperparams.get('hidden_dim_multiplier', 0.5)\n",
        "            )\n",
        "            model.to(Config.DEVICE)\n",
        "            model.load_state_dict(checkpoint)\n",
        "            return model, \"legacy nested format\"\n",
        "\n",
        "        else:\n",
        "            # Try direct loading with parameter combinations\n",
        "            param_combinations = [\n",
        "                (0.5, 0.5), (0.3, 0.5), (0.7, 0.5),\n",
        "                (0.5, 0.3), (0.5, 0.7), (0.5, 1.0), (0.5, 1.5)\n",
        "            ]\n",
        "\n",
        "            for dropout, hidden_mult in param_combinations:\n",
        "                try:\n",
        "                    model = ModelFactory.create_model(\n",
        "                        model_name,\n",
        "                        num_classes=Config.NUM_CLASSES,\n",
        "                        dropout_rate=dropout,\n",
        "                        hidden_dim_multiplier=hidden_mult\n",
        "                    )\n",
        "                    model.to(Config.DEVICE)\n",
        "                    model.load_state_dict(checkpoint)\n",
        "                    return model, f\"direct format (dropout={dropout}, hidden={hidden_mult})\"\n",
        "                except RuntimeError:\n",
        "                    continue\n",
        "\n",
        "            return None, \"failed all combinations\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"loading error: {str(e)}\"\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"\\nStarting Fish Species Visualization Generation...\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Environment setup for maximum performance\n",
        "    setup_environment()\n",
        "\n",
        "\n",
        "    # Set optimal thread count for CPU utilization\n",
        "    print(f\"CPU : {os.cpu_count()}\")\n",
        "    print(f\"USER: {os.getenv('USER')}\")\n",
        "    print(f\"HOME: {os.getenv('HOME')}\")\n",
        "    torch.set_num_threads(min(16, os.cpu_count()))\n",
        "    os.environ['OMP_NUM_THREADS'] = str(min(16, os.cpu_count()))\n",
        "\n",
        "    # OpenMP ‚Üí Open Multi-Processing.\n",
        "    # OpenMP is a widely used API for parallel programming on CPUs.\n",
        "    # Many scientific libraries (like NumPy, PyTorch, TensorFlow,\n",
        "    # -OpenCV, Scikit-learn) rely on OpenMP to run operations in parallel across CPU cores.\n",
        "    # In main() after line 720:\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    # Auto-benchmarks and selects fastest cuDNN algorithms for your specific hardware and input sizes\n",
        "    # Takes ~5-10 seconds at start but can provide 10-20% speedup throughout training\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    # Allows cuDNN to use fastest available algorithms even if they produce slightly different results each run\n",
        "    # Trades reproducibility for speed - essential for maximum performance in production training\n",
        "    # torch.backends.cuda.matmul.allow_tf32 = True\n",
        "    # Uses TensorFloat-32 (19-bit precision) instead of full Float-32 for matrix multiplications\n",
        "    # Provides ~1.6x speedup on Ampere GPUs with negligible accuracy loss for deep learning\n",
        "    # torch.backends.cudnn.allow_tf32 = True\n",
        "    # Enables TF32 precision for cuDNN operations (convolutions, pooling, batch norm)\n",
        "    # Accelerates CNN layers by 1.3-1.6x on RTX 30/40 series and A100+ GPUs\n",
        "    torch.backends.cuda.enable_flash_sdp(True)\n",
        "    # Activates Flash Attention algorithm for memory-efficient attention computations\n",
        "    # Reduces GPU memory usage by 2-4x and increases attention speed, crucial for transformer layers\n",
        "\n",
        "    # GPU optimizations\n",
        "    if torch.cuda.is_available():\n",
        "        torch.backends.cudnn.benchmark = True\n",
        "        torch.backends.cudnn.deterministic = False\n",
        "        torch.backends.cuda.matmul.allow_tf32 = True\n",
        "\n",
        "        gpu_props = torch.cuda.get_device_properties(0)\n",
        "        print(f\"GPU: {gpu_props.name}, Memory: {gpu_props.total_memory / 1024**3:.1f}GB\")\n",
        "\n",
        "    # CPU info\n",
        "    print(f\"CPU Cores: {os.cpu_count()}, Using threads: {torch.get_num_threads()}\")\n",
        "\n",
        "    # Ensure visualization output directory exists\n",
        "    os.makedirs(f\"{Config.OUTPUT_DIR}/visualizations\", exist_ok=True)\n",
        "\n",
        "    # Initialize resource manager\n",
        "    resource_manager = ResourceManager()\n",
        "\n",
        "    # Load and balance data for visualization (if needed for test data)\n",
        "    print(\"\\nLoading data for visualization...\")\n",
        "    X, Y = DataManager.load_and_balance_data()\n",
        "    print(f\"Total samples: {len(X):,}, Labels: {len(Y):,}\")\n",
        "\n",
        "    # Initialize components\n",
        "    visualizer = EnhancedVisualizations()\n",
        "    single_models = {}\n",
        "    single_results = {}\n",
        "\n",
        "    # Load trained models and results\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(\"LOADING TRAINED MODELS AND RESULTS\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Load models with enhanced error handling\n",
        "    for model_name in Config.MODELS:\n",
        "        model_path = os.path.join(Config.OUTPUT_DIR, \"best_model\", f\"{model_name}_best.pt\")\n",
        "\n",
        "        if not os.path.exists(model_path):\n",
        "            print(f\"‚ö†Ô∏è  Model file not found: {model_name}\")\n",
        "            continue\n",
        "\n",
        "        model, load_info = load_model_safely(model_name, model_path)\n",
        "\n",
        "        if model is not None:\n",
        "            model.eval()\n",
        "            single_models[model_name] = model\n",
        "            print(f\"‚úÖ Loaded {model_name} ({load_info})\")\n",
        "\n",
        "            # Load evaluation results for visualization compatibility\n",
        "            result_path = f\"{Config.OUTPUT_DIR}/model_results/{model_name}_main_results.pt\"\n",
        "            if os.path.exists(result_path):\n",
        "                try:\n",
        "                    saved_results = torch.load(result_path, map_location='cpu', weights_only=False)\n",
        "                    result_data = saved_results.get('result', {})\n",
        "\n",
        "                    single_results[model_name] = {\n",
        "                        'model_name': model_name,\n",
        "                        'accuracy': float(result_data.get('accuracy', 0.0)),\n",
        "                        'f1_macro': float(result_data.get('f1', 0.0)),\n",
        "                        'f1_weighted': float(result_data.get('f1', 0.0)),  # Add f1_weighted key\n",
        "                        'predictions': result_data.get('predictions', []),\n",
        "                        'true_labels': result_data.get('true_labels', []),\n",
        "                        'probabilities': result_data.get('probabilities', np.zeros((0, Config.NUM_CLASSES))),\n",
        "                        'conf_matrix': result_data.get('conf_matrix', np.zeros((Config.NUM_CLASSES, Config.NUM_CLASSES))),\n",
        "                        'misclassified': result_data.get('misclassified', [])\n",
        "                    }\n",
        "\n",
        "                    # Convert tensors to numpy for visualization compatibility\n",
        "                    for key in ['predictions', 'true_labels', 'probabilities', 'conf_matrix']:\n",
        "                        if torch.is_tensor(single_results[model_name][key]):\n",
        "                            single_results[model_name][key] = single_results[model_name][key].numpy()\n",
        "\n",
        "                    print(f\"üìä Results loaded: Acc={single_results[model_name]['accuracy']:.4f}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"‚ö†Ô∏è  Could not load results for {model_name}: {e}\")\n",
        "                    single_results[model_name] = {'model_name': model_name, 'accuracy': 0.0, 'f1_macro': 0.0, 'f1_weighted': 0.0}\n",
        "            else:\n",
        "                print(f\"‚ö†Ô∏è  No results file for {model_name}\")\n",
        "                single_results[model_name] = {'model_name': model_name, 'accuracy': 0.0, 'f1_macro': 0.0, 'f1_weighted': 0.0}\n",
        "        else:\n",
        "            print(f\"‚ùå Failed to load {model_name}: {load_info}\")\n",
        "\n",
        "    print(f\"\\nüéØ Loaded: {len(single_models)} models, {len(single_results)} result sets\")\n",
        "\n",
        "    # Create test data loader for visualizations that need it\n",
        "    if len(single_models) > 0:\n",
        "        print(\"\\nCreating test data loader for visualizations...\")\n",
        "        _, _, test_loader, val_data, test_data = DataManager.create_data_loaders(X, Y, test_size=0.2)\n",
        "        print(f\"Test loader created with {len(test_loader.dataset)} samples\")\n",
        "\n",
        "    # Generate visualizations for each model\n",
        "    for model_name in single_models.keys():\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"GENERATING VISUALIZATIONS FOR: {model_name}\")\n",
        "        print(f\"{'='*70}\")\n",
        "\n",
        "        # Pre-visualization memory state\n",
        "        pre_stats = resource_manager.get_memory_stats()\n",
        "        print(f\"Pre-visualization memory - GPU: {pre_stats['gpu_allocated_gb']:.2f}GB ({pre_stats['gpu_percent']:.1f}%), \"\n",
        "              f\"CPU: {pre_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "        try:\n",
        "            # Load saved results for plotting (ensuring consistency)\n",
        "            main_result_path = f\"{Config.OUTPUT_DIR}/model_results/{model_name}_main_results.pt\"\n",
        "\n",
        "            if os.path.exists(main_result_path):\n",
        "                saved_data = torch.load(main_result_path, map_location=Config.DEVICE, weights_only=False)\n",
        "                history_for_viz = saved_data['history']\n",
        "                result_for_viz = saved_data['result']\n",
        "                print(f\"Using saved results for {model_name} visualization\")\n",
        "            else:\n",
        "                result_for_viz = {}\n",
        "                history_for_viz = {}\n",
        "                def add_strikethrough(text):\n",
        "                    return ''.join(c + '\\u0336' for c in text)\n",
        "                print(f\"{add_strikethrough('Using current')} No results for {model_name} visualization\")\n",
        "\n",
        "            print(f\"Result keys: {list(result_for_viz.keys()) if result_for_viz else 'None'}\")\n",
        "\n",
        "            # Convert all data to CPU/numpy for visualization (GPU-safe conversion)\n",
        "            history_viz = safe_gpu_convert(history_for_viz)\n",
        "            result_viz = safe_gpu_convert(result_for_viz)\n",
        "\n",
        "            # Validate result data\n",
        "            true_labels = result_viz.get('true_labels', np.array([]))\n",
        "            predictions = result_viz.get('predictions', np.array([]))\n",
        "            probabilities = result_viz.get('probabilities', np.array([]))\n",
        "\n",
        "            # ADD THE CONVERSION LINES HERE:\n",
        "            if torch.is_tensor(true_labels):\n",
        "                true_labels = true_labels.detach().cpu().numpy()\n",
        "            if torch.is_tensor(predictions):\n",
        "                predictions = predictions.detach().cpu().numpy()\n",
        "            if torch.is_tensor(probabilities):\n",
        "                probabilities = probabilities.detach().cpu().numpy()\n",
        "            # ADD THESE ADDITIONAL CONVERSIONS:\n",
        "            # Convert history data to safe formats\n",
        "            for key in ['train_loss', 'train_acc', 'val_loss', 'val_acc', 'val_f1']:\n",
        "                if key in history_viz and torch.is_tensor(history_viz[key]):\n",
        "                    history_viz[key] = history_viz[key].detach().cpu().numpy().tolist()\n",
        "\n",
        "            print(f\"Data validation for {model_name}:\")\n",
        "            print(f\"  true_labels: {type(true_labels)}, shape: {getattr(true_labels, 'shape', len(true_labels) if hasattr(true_labels, '__len__') else 'scalar')}\")\n",
        "            print(f\"  predictions: {type(predictions)}, shape: {getattr(predictions, 'shape', len(predictions) if hasattr(predictions, '__len__') else 'scalar')}\")\n",
        "            print(f\"  probabilities: {type(probabilities)}, shape: {getattr(probabilities, 'shape', 'unknown')}\")\n",
        "\n",
        "            # Check if we have valid data for plotting\n",
        "            if (true_labels.size > 0 and predictions.size > 0 and true_labels.shape[0] == predictions.shape[0]):\n",
        "                plots_generated = 0\n",
        "\n",
        "                # Training history plot\n",
        "                train_loss = history_viz.get('train_loss')\n",
        "                if train_loss is not None and hasattr(train_loss, '__len__') and len(train_loss) > 0:\n",
        "                    try:\n",
        "                        # Add this conversion:\n",
        "                        if history_viz.get('train_loss') is not None:\n",
        "                            if isinstance(history_viz['train_loss'], np.ndarray):\n",
        "                                history_viz['train_loss'] = history_viz['train_loss'].tolist()\n",
        "                        if history_viz.get('train_acc') is not None:\n",
        "                            if isinstance(history_viz['train_acc'], np.ndarray):\n",
        "                                history_viz['train_acc'] = history_viz['train_acc'].tolist()\n",
        "                        if history_viz.get('val_loss') is not None:\n",
        "                            if isinstance(history_viz['val_loss'], np.ndarray):\n",
        "                                history_viz['val_loss'] = history_viz['val_loss'].tolist()\n",
        "                        if history_viz.get('val_acc') is not None:\n",
        "                            if isinstance(history_viz['val_acc'], np.ndarray):\n",
        "                                history_viz['val_acc'] = history_viz['val_acc'].tolist()\n",
        "\n",
        "                        visualizer.plot_single_model_history(history_viz, model_name)\n",
        "                        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_history.png\", dpi=150, bbox_inches='tight')\n",
        "                        plt.close('all')\n",
        "                        print(f\"Training history plot generated for {model_name}\")\n",
        "                        plots_generated += 1\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error plotting training history for {model_name}: {e}\")\n",
        "\n",
        "                try:\n",
        "                    # ROC Curves\n",
        "                    visualizer.plot_roc_curves(result_viz, model_name)\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_roc.png\", dpi=150, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "                    print(f\"ROC curves plot generated for {model_name}\")\n",
        "                    plots_generated += 1\n",
        "\n",
        "                    # Confusion Matrix\n",
        "                    visualizer.plot_confusion_matrix(result_viz, model_name)\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_confusion.png\", dpi=150, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "                    print(f\"Confusion matrix plot generated for {model_name}\")\n",
        "                    plots_generated += 1\n",
        "\n",
        "                    # Misclassified Images\n",
        "                    misclassified = result_viz.get('misclassified', [])\n",
        "                    if misclassified is not None and len(misclassified) > 0:\n",
        "                        # Convert any GPU tensors in misclassified images to CPU\n",
        "                        for item in result_viz['misclassified']:\n",
        "                            if isinstance(item, dict) and 'image' in item:\n",
        "                                if torch.is_tensor(item['image']):\n",
        "                                    item['image'] = item['image'].detach().cpu()\n",
        "                                elif isinstance(item['image'], np.ndarray):\n",
        "                                    # Optionally transpose if channel-first\n",
        "                                    if item['image'].shape[0] in [1,3]:\n",
        "                                        item['image'] = np.transpose(item['image'], (1, 2, 0))\n",
        "\n",
        "                        visualizer.plot_misclassified_images(result_viz['misclassified'], model_name)\n",
        "                        plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_misclassified.png\", dpi=150, bbox_inches='tight')\n",
        "                        plt.close('all')\n",
        "                        print(f\"Misclassified images plot generated for {model_name}\")\n",
        "                        plots_generated += 1\n",
        "                    else:\n",
        "                        print(f\"No misclassified images to plot for {model_name}\")\n",
        "\n",
        "                    # XAI Visualization\n",
        "                    if model_name in single_models and test_loader is not None and len(test_loader.dataset) > 0:\n",
        "                        try:\n",
        "                            model = single_models[model_name]\n",
        "                            visualizer.plot_single_model_xai(model, model_name, test_loader)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_xai.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "                            print(f\"XAI visualization generated for {model_name}\")\n",
        "                            plots_generated += 1\n",
        "                        except Exception as xai_error:\n",
        "                            print(f\"XAI visualization error for {model_name}: {xai_error}\")\n",
        "                    else:\n",
        "                        print(f\"Skipping XAI visualization for {model_name}: model or test_loader not available\")\n",
        "\n",
        "                except Exception as plot_error:\n",
        "                    print(f\"Visualization error for {model_name}: {plot_error}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "\n",
        "                print(f\"Generated {plots_generated} main visualization plots for {model_name}\")\n",
        "\n",
        "            else:\n",
        "                print(f\"Skipping main visualizations for {model_name}: data validation failed\")\n",
        "                print(f\"  true_labels length: {true_labels.shape[0] if hasattr(true_labels, 'shape') else 'scalar'}\")\n",
        "                print(f\"  predictions length: {predictions.shape[0] if hasattr(predictions, 'shape') else 'scalar'}\")\n",
        "\n",
        "            # K-fold results plotting (load from saved files)\n",
        "            print(f\"Loading and plotting k-fold results for {model_name}...\")\n",
        "            fold_results_loaded = []\n",
        "\n",
        "            # Check for k-fold results\n",
        "            for fold in range(1, 4):  # Assuming max 3 folds\n",
        "                fold_result_path = f\"{Config.OUTPUT_DIR}/kfold_results/{model_name}_fold_{fold}_results.pt\"\n",
        "                if os.path.exists(fold_result_path):\n",
        "                    try:\n",
        "                        fold_data = torch.load(fold_result_path, map_location=Config.DEVICE, weights_only=False)\n",
        "\n",
        "                        # Convert GPU tensors to CPU/numpy\n",
        "                        fold_converted = {\n",
        "                            'history': safe_gpu_convert(fold_data['history']),\n",
        "                            'result': safe_gpu_convert(fold_data['result'])\n",
        "                        }\n",
        "                        fold_results_loaded.append(fold_converted)\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error loading fold {fold} results: {e}\")\n",
        "\n",
        "            if fold_results_loaded is not None and len(fold_results_loaded) > 0:\n",
        "                try:\n",
        "                    visualizer.plot_kfold_results(fold_results_loaded, model_name, test_loader)\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{model_name}_kfold.png\", dpi=150, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "                    print(f\"K-fold results plot generated for {model_name}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Error plotting k-fold results for {model_name}: {e}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "            else:\n",
        "                print(f\"No k-fold results to plot for {model_name}\")\n",
        "\n",
        "            print(f\"All visualizations completed for {model_name}\")\n",
        "\n",
        "            # Memory cleanup for this model's visualizations\n",
        "            if 'history_viz' in locals():\n",
        "                del history_viz\n",
        "            if 'result_viz' in locals():\n",
        "                del result_viz\n",
        "            if 'fold_results_loaded' in locals():\n",
        "                del fold_results_loaded\n",
        "            if 'history_for_viz' in locals():\n",
        "                del history_for_viz\n",
        "            if 'result_for_viz' in locals():\n",
        "                del result_for_viz\n",
        "\n",
        "            # Force garbage collection and GPU cleanup\n",
        "            plt.close('all')\n",
        "            resource_manager.aggressive_cleanup()\n",
        "\n",
        "            # Post-visualization memory state\n",
        "            post_stats = resource_manager.get_memory_stats()\n",
        "            memory_freed = pre_stats['gpu_allocated_gb'] - post_stats['gpu_allocated_gb']\n",
        "\n",
        "            print(f\"Memory cleanup completed for {model_name}:\")\n",
        "            print(f\"  GPU memory freed: {memory_freed:.2f}GB\")\n",
        "            print(f\"  Current GPU usage: {post_stats['gpu_percent']:.1f}%\")\n",
        "            print(f\"  Current CPU usage: {post_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "            print(f\"‚úì {model_name} VISUALIZATIONS COMPLETED!\")\n",
        "            print(f\"{'='*70}\\n\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in visualization process for {model_name}: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    # Step: Ensemble processing and visualizations (only if we have trained models)\n",
        "    if single_models and 'val_data' in locals():\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"GENERATING ENSEMBLE VISUALIZATIONS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        try:\n",
        "            if (val_data is not None and len(val_data) == 2 and len(val_data[0]) > 0 and len(val_data[1]) > 0 and len(val_data[0]) == len(val_data[1])):\n",
        "\n",
        "                ensemble_manager = EnsembleManager(single_models, val_data)\n",
        "                ensemble_results, best_ensemble = ensemble_manager.test_ensemble_combinations()\n",
        "\n",
        "                # Generate visualizations for ensemble methods\n",
        "                print(\"\\nGenerating visualizations for ensemble methods...\")\n",
        "                for ensemble_name, ensemble_result in ensemble_results.items():\n",
        "                    try:\n",
        "                        # Convert GPU tensors to CPU for visualization\n",
        "                        ensemble_result_viz = safe_gpu_convert(ensemble_result)\n",
        "\n",
        "                        true_labels_ens = ensemble_result_viz.get('true_labels', [])\n",
        "                        predictions_ens = ensemble_result_viz.get('predictions', [])\n",
        "\n",
        "                        if (len(true_labels_ens) > 0 and\n",
        "                            len(predictions_ens) > 0 and\n",
        "                            len(true_labels_ens) == len(predictions_ens)):\n",
        "\n",
        "                            visualizer.plot_roc_curves(ensemble_result_viz, ensemble_name)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{ensemble_name}_roc.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "\n",
        "                            visualizer.plot_confusion_matrix(ensemble_result_viz, ensemble_name)\n",
        "                            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/{ensemble_name}_confusion.png\", dpi=150, bbox_inches='tight')\n",
        "                            plt.close('all')\n",
        "\n",
        "                            # F1 per class visualization\n",
        "                            from sklearn.metrics import f1_score\n",
        "                            f1_per_class = f1_score(ensemble_result_viz['true_labels'],\n",
        "                                                   ensemble_result_viz['predictions'], average=None)\n",
        "                            fig, ax = plt.subplots(figsize=(10, 6))\n",
        "                            ax.bar(range(Config.NUM_CLASSES), f1_per_class, color='lightgreen', alpha=0.8)\n",
        "                            ax.set_xticks(range(Config.NUM_CLASSES))\n",
        "                            ax.set_xticklabels(Config.CLASS_LABELS, rotation=45, ha='right')\n",
        "                            ax.set_title(f'F1 Scores per Class - {ensemble_name}',\n",
        "                                       fontsize=14, fontweight='bold', pad=15)\n",
        "                            ax.set_xlabel('Class', fontsize=12, fontweight='bold')\n",
        "                            ax.set_ylabel('F1 Score', fontsize=12, fontweight='bold')\n",
        "                            ax.grid(True, alpha=0.3)\n",
        "                            for i, v in enumerate(f1_per_class):\n",
        "                                ax.text(i, v + 0.01, f'{v:.2f}', ha='center', va='bottom', fontsize=10)\n",
        "                            save_path = f\"{Config.OUTPUT_DIR}/visualizations/{ensemble_name}_f1_per_class.png\"\n",
        "                            plt.savefig(save_path, dpi=300, bbox_inches='tight',\n",
        "                                      facecolor='white', edgecolor='none')\n",
        "                            plt.close()\n",
        "                            print(f\"F1 scores per class saved: {save_path}\")\n",
        "                        else:\n",
        "                            print(f\"Skipping visualizations for {ensemble_name}: invalid data\")\n",
        "                    except Exception as e:\n",
        "                        print(f\"Error generating ensemble visualizations for {ensemble_name}: {e}\")\n",
        "\n",
        "                    # Clear memory\n",
        "                    if 'ensemble_result_viz' in locals():\n",
        "                        del ensemble_result_viz\n",
        "                    resource_manager.aggressive_cleanup()\n",
        "\n",
        "                # Comment out the problematic ensemble test evaluation\n",
        "                print(\"Skipping ensemble test evaluation (method not implemented)\")\n",
        "                # if (best_ensemble and test_data is not None and len(test_data) == 2 and\n",
        "                #     len(test_data[0]) == len(test_data[1]) and len(test_data[0]) > 0):\n",
        "                #     print(\"Evaluating best ensemble on test set...\")\n",
        "                #     # Ensemble test evaluation code commented out\n",
        "\n",
        "            else:\n",
        "                print(\"Skipping ensemble analysis: no valid validation data\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in ensemble processing: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    # Step: Generate comprehensive visualizations (only if we have results)\n",
        "    if single_results:\n",
        "        print(\"\\n\" + \"=\"*70)\n",
        "        print(\"GENERATING COMPREHENSIVE ANALYSIS VISUALIZATIONS\")\n",
        "        print(\"=\"*70)\n",
        "\n",
        "        try:\n",
        "            # Convert all results to CPU/numpy for final plotting\n",
        "            single_results_viz = safe_gpu_convert(single_results)\n",
        "            ensemble_results_viz = safe_gpu_convert(ensemble_results) if 'ensemble_results' in locals() else {}\n",
        "\n",
        "            # Plot overall model comparison\n",
        "            if single_results_viz and len(single_results_viz) > 0:\n",
        "                visualizer.plot_model_comparison(single_results_viz,ensemble_results_viz)\n",
        "                plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/model_comparison.png\", dpi=300, bbox_inches='tight')\n",
        "                plt.close('all')\n",
        "\n",
        "            # Generate comprehensive report\n",
        "            visualizer.generate_comprehensive_report(\n",
        "                single_results_viz,\n",
        "                ensemble_results_viz,\n",
        "                best_ensemble if 'best_ensemble' in locals() else None\n",
        "            )\n",
        "            plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/comprehensive_report.png\", dpi=300, bbox_inches='tight')\n",
        "            plt.close('all')\n",
        "\n",
        "            # Additional visualizations\n",
        "            if 'test_loader' in locals() and test_loader is not None and len(test_loader.dataset) > 0:\n",
        "                try:\n",
        "                    visualizer.plot_comparative_xai(\n",
        "                        single_models,\n",
        "                        ensemble_results_viz,\n",
        "                        test_loader,\n",
        "                        max_images=2\n",
        "                    )\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/comparative_xai.png\", dpi=300, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "\n",
        "                    visualizer.plot_lrp_grid(single_models, test_loader)\n",
        "                    plt.savefig(f\"{Config.OUTPUT_DIR}/visualizations/lrp_grid.png\", dpi=300, bbox_inches='tight')\n",
        "                    plt.close('all')\n",
        "                except Exception as e:\n",
        "                    print(f\"Error in additional visualizations: {e}\")\n",
        "\n",
        "            print(\"Comprehensive analysis completed successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error in comprehensive analysis: {e}\")\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "\n",
        "    # Final cleanup\n",
        "    print(\"\\nFinal cleanup and summary...\")\n",
        "    try:\n",
        "        # Clean up all remaining variables\n",
        "        if 'single_models' in locals():\n",
        "            del single_models\n",
        "        if 'test_loader' in locals():\n",
        "            del test_loader\n",
        "        if 'single_results' in locals():\n",
        "            del single_results\n",
        "        if 'single_results_viz' in locals():\n",
        "            del single_results_viz\n",
        "        if 'ensemble_results' in locals():\n",
        "            del ensemble_results\n",
        "        if 'ensemble_results_viz' in locals():\n",
        "            del ensemble_results_viz\n",
        "        if 'best_ensemble' in locals():\n",
        "            del best_ensemble\n",
        "        if 'visualizer' in locals():\n",
        "            del visualizer\n",
        "        if 'X' in locals():\n",
        "            del X\n",
        "        if 'Y' in locals():\n",
        "            del Y\n",
        "\n",
        "        resource_manager.aggressive_cleanup()\n",
        "\n",
        "        # Final memory stats\n",
        "        final_stats = resource_manager.get_memory_stats()\n",
        "        print(f\"Final GPU memory: {final_stats['gpu_allocated_gb']:.2f}GB allocated ({final_stats['gpu_percent']:.1f}%)\")\n",
        "        print(f\"Final CPU usage: {final_stats['cpu_percent']:.1f}%\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in final cleanup: {e}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"VISUALIZATION GENERATION COMPLETED!\")\n",
        "    print(\"=\"*70)\n",
        "    print(\"\\nGenerated Files:\")\n",
        "    print(f\"- All visualizations: {Config.OUTPUT_DIR}/visualizations/\")\n",
        "\n",
        "\n",
        "# Environment setup and multiprocessing configuration\n",
        "import torch.multiprocessing as mp\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "duEhaAVCb1f7"
      },
      "id": "duEhaAVCb1f7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚úÖ Step 15: Analysis on Real_World Data"
      ],
      "metadata": {
        "id": "_X2tyIMkfV_q"
      },
      "id": "_X2tyIMkfV_q"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, models\n",
        "from PIL import Image\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "# ---------------------------\n",
        "# CONFIG\n",
        "# ---------------------------\n",
        "MODEL_PATH = \"best_model.pth\"   # ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ trained model file\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "# ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ dataset ‡¶è‡¶∞ class ‡¶≤‡¶ø‡¶∏‡ßç‡¶ü (‡¶®‡¶ø‡¶ú‡ßá‡¶∞ dataset ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ ‡¶¨‡¶¶‡¶≤‡¶æ‡¶¨‡ßá)\n",
        "CLASS_NAMES = [\"ilish\", \"chandana\", \"sardin\", \"sardinella\", \"punctatus\"]\n",
        "\n",
        "# ---------------------------\n",
        "# Load Model\n",
        "# ---------------------------\n",
        "def load_model():\n",
        "    model = models.resnet50(weights=None)   # ‡¶§‡ßÅ‡¶Æ‡¶ø ‡¶Ø‡ßá‡¶ü‡¶æ ‡¶¨‡ßç‡¶Ø‡¶¨‡¶π‡¶æ‡¶∞ ‡¶ï‡¶∞‡ßá‡¶õ‡ßã ‡¶∏‡ßá‡¶ü‡¶æ ‡¶¨‡¶∏‡¶æ‡¶ì\n",
        "    num_features = model.fc.in_features\n",
        "    model.fc = nn.Linear(num_features, len(CLASS_NAMES))\n",
        "\n",
        "    checkpoint = torch.load(MODEL_PATH, map_location=DEVICE)\n",
        "    model.load_state_dict(checkpoint[\"model_state_dict\"])  # ‡¶§‡ßã‡¶Æ‡¶æ‡¶∞ save format ‡¶Ö‡¶®‡ßÅ‡¶Ø‡¶æ‡ßü‡ßÄ adjust ‡¶ï‡¶∞‡ßã\n",
        "    model.to(DEVICE)\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# ---------------------------\n",
        "# Preprocess\n",
        "# ---------------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),    # training ‡¶∏‡¶Æ‡ßü ‡¶Ø‡¶æ ‡¶¶‡¶ø‡ßü‡ßá‡¶õ‡ßã, ‡¶∏‡ßá‡¶ü‡¶æ ‡¶Æ‡ßá‡¶≤‡¶æ‡¶§‡ßá ‡¶π‡¶¨‡ßá\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                         [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "def load_image(img_path=None, img_url=None):\n",
        "    if img_path:\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "    elif img_url:\n",
        "        response = requests.get(img_url)\n",
        "        image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "    else:\n",
        "        raise ValueError(\"Provide either img_path or img_url\")\n",
        "    return image\n",
        "\n",
        "# ---------------------------\n",
        "# Prediction\n",
        "# ---------------------------\n",
        "def predict_image(model, image):\n",
        "    img_tensor = transform(image).unsqueeze(0).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(img_tensor)\n",
        "        probs = torch.softmax(outputs, dim=1)\n",
        "        conf, pred = torch.max(probs, 1)\n",
        "    return CLASS_NAMES[pred.item()], conf.item()\n",
        "\n",
        "# ---------------------------\n",
        "# Main\n",
        "# ---------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    model = load_model()\n",
        "\n",
        "    # Option 1: ‡¶≤‡ßã‡¶ï‡¶æ‡¶≤ ‡¶´‡¶æ‡¶á‡¶≤ ‡¶•‡ßá‡¶ï‡ßá\n",
        "    img_path = \"test_fish.jpg\"\n",
        "    image = load_image(img_path=img_path)\n",
        "    label, confidence = predict_image(model, image)\n",
        "    print(f\"Prediction: {label} ({confidence:.2f})\")\n",
        "\n",
        "    # Option 2: URL ‡¶•‡ßá‡¶ï‡ßá\n",
        "    img_url = \"https://example.com/sample_fish.jpg\"\n",
        "    image = load_image(img_url=img_url)\n",
        "    label, confidence = predict_image(model, image)\n",
        "    print(f\"Prediction: {label} ({confidence:.2f})\")\n"
      ],
      "metadata": {
        "id": "kcr-u7s4phe3"
      },
      "id": "kcr-u7s4phe3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cdd48bb6",
      "metadata": {
        "id": "cdd48bb6"
      },
      "source": [
        "#End"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}